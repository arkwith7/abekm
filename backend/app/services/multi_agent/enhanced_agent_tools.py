"""
í™•ì¥ëœ AI Agent Tools - ëª¨ë“  ì—ì´ì „íŠ¸ ìœ í˜•ì„ íˆ´ë¡œ ì •ì˜
ê° ì—ì´ì „íŠ¸ë¥¼ ë…ë¦½ì ì¸ íˆ´ë¡œ ê°œë°œí•˜ì—¬ ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ì—ì„œ í™œìš©
"""

from typing import Dict, Any, List, Optional, Type, Tuple
from pydantic import BaseModel, Field
from loguru import logger
import json
import asyncio
from datetime import datetime
import os
import hashlib
from functools import lru_cache
from app.core.config import settings
import httpx

# ê¸°ì¡´ ì„œë¹„ìŠ¤ë“¤ import
from app.services.core.ai_service import ai_service
from app.services.chat.ai_agent_service import ai_agent_service
from app.schemas.chat import SelectedDocument

# ê¸°ì¡´ BaseTool ì„í¬íŠ¸
try:  # ìš°ì„  langchain_core
    from langchain_core.tools import BaseTool  # type: ignore
except ImportError:
    try:
        from langchain.tools import BaseTool  # type: ignore
    except ImportError:  # pragma: no cover
        class BaseTool:  # minimal fallback
            name: str = ""
            description: str = ""
            args_schema: Optional[Type[BaseModel]] = None
            def _run(self, *args, **kwargs): return {"error": "BaseTool fallback"}
            def run(self, *args, **kwargs): return self._run(*args, **kwargs)

# -----------------------------------------------------------------------------
# ê°„ë‹¨ Web Search Tool (Phase 1) - mock ë˜ëŠ” ì™¸ë¶€ API ì—°ë™ í‹€ (BaseTool import ì´í›„ ì •ì˜)
# -----------------------------------------------------------------------------

class WebSearchInput(BaseModel):
    query: str = Field(description="ê²€ìƒ‰ ì§ˆì˜")
    top_n: int = Field(default=6, description="ê°€ì ¸ì˜¬ ìµœëŒ€ ê²°ê³¼ ìˆ˜")
    lang: str = Field(default="ko", description="ê²°ê³¼ ì–¸ì–´")


class WebSearchTool(BaseTool):
    name: str = "web_search"
    description: str = "ì™¸ë¶€ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì—¬ ì œëª©/URL/ìŠ¤ë‹ˆí« Evidenceë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ë‚´ë¶€ RAG ì €ì‹ ë¢° ì‹œ ì¦ê°•ì— ì‚¬ìš©."  # noqa: E501
    args_schema: Type[BaseModel] = WebSearchInput

    async def _arun(self, query: str, top_n: int = 6, lang: str = "ko", **kwargs) -> Dict[str, Any]:
        try:
            if not settings.web_search_enabled:
                return {"success": False, "error": "web search disabled", "results": []}
            provider = settings.web_search_provider
            results: List[Dict[str, Any]] = []
            if provider == "mock":
                base_items = [
                    {
                        "id": f"mock-{i}",
                        "title": f"ëª¨ì˜ ê²€ìƒ‰ ê²°ê³¼ {i}: {query[:20]}",
                        "url": f"https://example.com/{hashlib.md5((query+str(i)).encode()).hexdigest()[:8]}",
                        "snippet": f"'{query}' ì™€(ê³¼) ê´€ë ¨ëœ ì™¸ë¶€ ê³µê°œ ì •ë³´ ì˜ˆì‹œ ìŠ¤ë‹ˆí« {i}."
                    }
                    for i in range(1, top_n + 1)
                ]
                results.extend(base_items)
            else:
                results.append({
                    "id": "not-implemented",
                    "title": f"{provider} provider integration pending",
                    "url": "https://placeholder.invalid",
                    "snippet": "êµ¬í˜„ ì˜ˆì •: API í‚¤ ì„¤ì • í›„ ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜"
                })
            return {
                "success": True,
                "provider": provider,
                "query": query,
                "results": results[:top_n],
                "metadata": {
                    "timestamp": datetime.now().isoformat(),
                    "result_count": len(results[:top_n])
                }
            }
        except Exception as e:
            logger.error(f"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e), "results": []}

    def _run(self, query: str, top_n: int = 6, lang: str = "ko", **kwargs) -> Dict[str, Any]:
        try:
            return asyncio.run(self._arun(query=query, top_n=top_n, lang=lang, **kwargs))
        except RuntimeError:
            logger.warning("ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰ ì¤‘ ë™ê¸° web_search í˜¸ì¶œ - mock fallback")
            return {"success": True, "provider": "mock", "query": query, "results": []}


# -----------------------------------------------------------------------------
# FetchWebsiteTool - ê²€ìƒ‰ ê²°ê³¼ URL ë³¸ë¬¸ ì¶”ì¶œ (ê°„ë‹¨ ë²„ì „)
# -----------------------------------------------------------------------------

class FetchWebsiteInput(BaseModel):
    urls: List[str] = Field(description="ê°€ì ¸ì˜¬ URL ëª©ë¡")
    max_chars: int = Field(default=8000, description="í˜ì´ì§€ë‹¹ ìµœëŒ€ ì¶”ì¶œ ê¸¸ì´")
    clean_html: bool = Field(default=True, description="HTML íƒœê·¸ ì œê±° ì—¬ë¶€")


class FetchWebsiteTool(BaseTool):
    name: str = "fetch_website"
    description: str = "ì›¹ í˜ì´ì§€ ë³¸ë¬¸ì„ ë¹„ë™ê¸°ë¡œ ê°€ì ¸ì™€ RAG ì¦ê°•ìš© í…ìŠ¤íŠ¸ ìŠ¤ë‹ˆí«ì„ ìƒì„±í•©ë‹ˆë‹¤. (ê°„ë‹¨ ì¶”ì¶œ)"
    args_schema: Type[BaseModel] = FetchWebsiteInput

    async def _arun(self, urls: List[str], max_chars: int = 8000, clean_html: bool = True, **kwargs) -> Dict[str, Any]:
        if not settings.web_fetch_enabled:
            return {"success": False, "error": "web fetch disabled", "pages": []}
        # ë„ë©”ì¸ í•„í„°
        allowed = settings.web_fetch_allow_domains or None
        blocked = set(settings.web_fetch_block_domains or [])
        filtered_urls = []
        for u in urls:
            try:
                host = u.split("//",1)[-1].split("/",1)[0]
                if any(b in host for b in blocked):
                    continue
                if allowed and not any(a in host for a in allowed):
                    continue
                filtered_urls.append(u)
            except Exception:
                continue
        limited = filtered_urls[: settings.web_fetch_max_concurrent]
        headers = {"User-Agent": settings.web_fetch_user_agent}
        timeout = settings.web_fetch_timeout_seconds
        results: List[Dict[str, Any]] = []
        async with httpx.AsyncClient(timeout=timeout, follow_redirects=True) as client:
            tasks = [self._fetch_one(client, url, headers, max_chars, clean_html) for url in limited]
            pages = await asyncio.gather(*tasks, return_exceptions=True)
        for p in pages:
            if isinstance(p, dict) and p.get("content"):
                results.append(p)
        return {
            "success": True,
            "pages": results,
            "metadata": {
                "fetched": len(results),
                "requested": len(urls),
                "used": len(limited)
            }
        }

    async def _fetch_one(self, client: httpx.AsyncClient, url: str, headers: Dict[str,str], max_chars: int, clean_html: bool) -> Dict[str, Any]:
        try:
            resp = await client.get(url, headers=headers)
            text = resp.text or ""
            # ì•„ì£¼ ë‹¨ìˆœí•œ HTML ì œê±° (ì¶”í›„ trafilatura ëŒ€ì²´ ê°€ëŠ¥)
            if clean_html:
                import re
                text = re.sub(r"<script[\s\S]*?</script>", " ", text, flags=re.I)
                text = re.sub(r"<style[\s\S]*?</style>", " ", text, flags=re.I)
                text = re.sub(r"<[^>]+>", " ", text)
            normalized = " ".join(text.split())[:max_chars]
            return {
                "url": url,
                "content": normalized,
                "char_count": len(normalized),
                "source_type": "web_page",
                "retrieval_stage": "web_fetch"
            }
        except Exception as e:
            logger.warning(f"í˜ì´ì§€ fetch ì‹¤íŒ¨: {url} - {e}")
            return {}

    def _run(self, urls: List[str], max_chars: int = 8000, clean_html: bool = True, **kwargs) -> Dict[str, Any]:
        try:
            return asyncio.run(self._arun(urls=urls, max_chars=max_chars, clean_html=clean_html, **kwargs))
        except RuntimeError:
            logger.warning("ì´ë²¤íŠ¸ ë£¨í”„ ë‚´ ë™ê¸° fetch_website í˜¸ì¶œ - ë¹ˆ ê²°ê³¼")
            return {"success": False, "error": "loop running"}

# =============================================================================
# Tool Input ìŠ¤í‚¤ë§ˆ ì •ì˜
# =============================================================================

class GeneralChatInput(BaseModel):
    query: str = Field(description="ì‚¬ìš©ìì˜ ì§ˆë¬¸ ë˜ëŠ” ëŒ€í™” ë‚´ìš©")
    context: Optional[str] = Field(default="", description="ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸")

class DocumentSummaryInput(BaseModel):
    documents: List[Dict[str, Any]] = Field(description="ìš”ì•½í•  ë¬¸ì„œ ëª©ë¡")
    summary_type: str = Field(default="comprehensive", description="ìš”ì•½ ìœ í˜•: brief, comprehensive, detailed")
    focus_areas: List[str] = Field(default=[], description="ì§‘ì¤‘í•  ì˜ì—­ë“¤")

class KeywordExtractionInput(BaseModel):
    documents: List[Dict[str, Any]] = Field(description="í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ë¬¸ì„œ ëª©ë¡")
    max_keywords: int = Field(default=20, description="ì¶”ì¶œí•  ìµœëŒ€ í‚¤ì›Œë“œ ìˆ˜")
    include_phrases: bool = Field(default=True, description="í‚¤ í”„ë ˆì´ì¦ˆ í¬í•¨ ì—¬ë¶€")

class PresentationGenerationInput(BaseModel):
    content: str = Field(description="í”„ë ˆì  í…Œì´ì…˜ ìƒì„± ê¸°ë°˜ ë‚´ìš©")
    slide_count: int = Field(default=8, description="ìƒì„±í•  ìŠ¬ë¼ì´ë“œ ìˆ˜")
    template_style: str = Field(default="business", description="í…œí”Œë¦¿ ìŠ¤íƒ€ì¼")
    include_charts: bool = Field(default=True, description="ì°¨íŠ¸ í¬í•¨ ì—¬ë¶€")

class TemplateDocumentInput(BaseModel):
    template_type: str = Field(description="í…œí”Œë¦¿ ìœ í˜•: report, proposal, memo, etc.")
    content_data: Dict[str, Any] = Field(description="í…œí”Œë¦¿ì— ì±„ìš¸ ë°ì´í„°")
    output_format: str = Field(default="docx", description="ì¶œë ¥ í˜•ì‹")

class KnowledgeGraphInput(BaseModel):
    documents: List[Dict[str, Any]] = Field(description="ì§€ì‹ê·¸ë˜í”„ ìƒì„±í•  ë¬¸ì„œë“¤")
    max_nodes: int = Field(default=50, description="ìµœëŒ€ ë…¸ë“œ ìˆ˜")
    relationship_types: List[str] = Field(default=[], description="ê´€ê³„ ìœ í˜• í•„í„°")

class DocumentAnalysisInput(BaseModel):
    documents: List[Dict[str, Any]] = Field(description="ë¶„ì„í•  ë¬¸ì„œ ëª©ë¡")
    analysis_depth: str = Field(default="standard", description="ë¶„ì„ ê¹Šì´: shallow, standard, deep")
    focus_metrics: List[str] = Field(default=[], description="ì§‘ì¤‘í•  ì§€í‘œë“¤")

class InsightGenerationInput(BaseModel):
    data_sources: List[Dict[str, Any]] = Field(description="ì¸ì‚¬ì´íŠ¸ ë„ì¶œí•  ë°ì´í„° ì†ŒìŠ¤")
    insight_types: List[str] = Field(default=["trend", "pattern", "anomaly"], description="ì¸ì‚¬ì´íŠ¸ ìœ í˜•")
    confidence_threshold: float = Field(default=0.7, description="ì‹ ë¢°ë„ ì„ê³„ê°’")

class ReportGenerationInput(BaseModel):
    report_type: str = Field(description="ë³´ê³ ì„œ ìœ í˜•: executive, technical, analysis, etc.")
    data_sources: List[Dict[str, Any]] = Field(description="ë³´ê³ ì„œ ì‘ì„± ë°ì´í„°")
    sections: List[str] = Field(default=[], description="í¬í•¨í•  ì„¹ì…˜ë“¤")

class ScriptGenerationInput(BaseModel):
    presentation_content: str = Field(description="ë°œí‘œ ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ ë‚´ìš©")
    presentation_duration: int = Field(default=10, description="ë°œí‘œ ì˜ˆìƒ ì‹œê°„(ë¶„)")
    audience_level: str = Field(default="general", description="ì²­ì¤‘ ìˆ˜ì¤€: executive, technical, general")

class KeyPointsExtractionInput(BaseModel):
    content: str = Field(description="í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•  ë‚´ìš©")
    max_points: int = Field(default=10, description="ì¶”ì¶œí•  ìµœëŒ€ í¬ì¸íŠ¸ ìˆ˜")
    categorize: bool = Field(default=True, description="ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ ì—¬ë¶€")

# =============================================================================
# ê°œë³„ ì—ì´ì „íŠ¸ íˆ´ êµ¬í˜„
# =============================================================================

class GeneralChatTool(BaseTool):
    name: str = "general_chat_tool"
    description: str = """ì¼ë°˜ì ì¸ ëŒ€í™”ì™€ ì§ˆì˜ì‘ë‹µì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. RAG ê¸°ëŠ¥ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    ì…ë ¥: ì‚¬ìš©ì ì§ˆë¬¸, ì»¨í…ìŠ¤íŠ¸
    ì¶œë ¥: ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì‘ë‹µ"""
    args_schema: Type[BaseModel] = GeneralChatInput
    
    def _run(self, tool_input: str = "", **kwargs) -> Dict[str, Any]:
        """ë™ê¸° ì‹¤í–‰ ì§„ì…ì  (LangChain í˜¸í™˜). ê°€ëŠ¥í•˜ë©´ ë¹„ë™ê¸° ê²½ë¡œ ì‚¬ìš© ê¶Œì¥."""
        query, context = self._parse_inputs(tool_input, **kwargs)
        try:
            # ë…ë¦½ ë™ê¸° í™˜ê²½: ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ë¡œ ì‹¤í–‰
            return asyncio.run(self._execute_general_chat_async(query, context))
        except RuntimeError:
            # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ ì•ˆì—ì„œ í˜¸ì¶œëœ ê²½ìš° (ì˜ëª»ëœ ì‚¬ìš© ê²½ë¡œ)
            logger.warning("âš ï¸ ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰ ì¤‘ì— _runì´ í˜¸ì¶œë˜ì—ˆìŠµë‹ˆë‹¤. _arun ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            return self._fallback_simulation(query, context, reason="event loop already running; use _arun")
        except Exception as e:
            logger.error(f"âŒ ì¼ë°˜ ëŒ€í™” íˆ´ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e), "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}

    async def _arun(self, tool_input: str = "", **kwargs) -> Dict[str, Any]:
        """ë¹„ë™ê¸° ì‹¤í–‰ (ê¶Œì¥)"""
        query, context = self._parse_inputs(tool_input, **kwargs)
        return await self._execute_general_chat_async(query, context)

    def _parse_inputs(self, tool_input: str = "", **kwargs) -> tuple[str, str]:
        if isinstance(tool_input, str) and tool_input.strip():
            try:
                data = json.loads(tool_input)
                query = data.get("query", tool_input)
                context = data.get("context", "")
            except json.JSONDecodeError:
                query = tool_input
                context = ""
        else:
            query = kwargs.get("query", "")
            context = kwargs.get("context", "")
        logger.info(f"ğŸ’¬ ì¿¼ë¦¬: {query[:50]}...")
        return query, context

    async def _execute_general_chat_async(self, query: str, context: str = "") -> Dict[str, Any]:
        try:
            logger.info(f"ğŸ” ì‹¤ì œ RAG ê²€ìƒ‰ ìˆ˜í–‰ (async): {query}")
            enhanced_query, references, context_info, rag_stats = await ai_agent_service.prepare_context_with_documents(
                query=query,
                selected_documents=[],
                agent_type="general"
            )

            # 1) ë ˆí¼ëŸ°ìŠ¤ ì •ì œ/ì¤‘ë³µ ì œê±° ë° ë³´ê°•
            cleaned_refs = self._dedupe_and_normalize_references(references)
            top_refs = cleaned_refs[:6]

            # 2) ìœ ì‚¬ë„ ë° í’ˆì§ˆ íŒë‹¨
            avg_sim = rag_stats.get("avg_similarity", 0) if isinstance(rag_stats, dict) else 0
            low_signal = (len(top_refs) == 0) or (avg_sim < 0.05)

            # 2-a) ì €ì‹ ë¢° ì‹œ ì›¹ ê²€ìƒ‰ ì¦ê°• (Phase 1: lightweight snippets) - ë³„ë„ WebSearchTool í™œìš©
            web_augmented_refs: List[Dict[str, Any]] = []
            web_used = False
            if low_signal and settings.web_search_enabled:
                try:
                    web_tool = enhanced_tool_registry.get_tool("web_search")  # type: ignore  # defined later
                    if web_tool:
                        web_results = await web_tool._arun(query=query, top_n=4)  # type: ignore
                        if web_results.get("success"):
                            web_refs = web_results.get("results", [])
                            # ì›¹ Evidence êµ¬ì¡° í†µì¼
                            for wr in web_refs:
                                web_augmented_refs.append({
                                    "chunk_id": wr.get("id") or wr.get("url"),
                                    "content": wr.get("snippet", "")[:800],
                                    "source": wr.get("title") or wr.get("url"),
                                    "similarity_score": 0.0,  # ì™¸ë¶€ ê²€ìƒ‰ì€ ì¬ë­í‚¹ ì „ 0
                                    "metadata": {
                                        "url": wr.get("url"),
                                        "source_type": "web",
                                        "retrieval_stage": "web_fallback"
                                    }
                                })
                            if web_augmented_refs:
                                # ë‚´ë¶€ refsì™€ ë³‘í•© (ë‹¨ìˆœ append, ì´í›„ formatì—ì„œ êµ¬ë¶„)
                                top_refs = (top_refs + web_augmented_refs)[:8]
                                web_used = True
                                low_signal = False  # Evidence í™•ë³´ë¡œ ì¬í‰ê°€
                except Exception as we:
                    logger.warning(f"ğŸŒ ì›¹ ê²€ìƒ‰ ì¦ê°• ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {we}")

            # 3) (ì„ íƒ) ì¶”ê°€ í˜ì´ì§€ fetch ì¡°ê±´: ì›¹ ì¦ê°• ì‚¬ìš© & ì§§ì€ snippet ë¹„ìœ¨ ë†’ìŒ
            fetch_used = False
            if web_used and settings.web_fetch_enabled:
                short_count = sum(1 for r in web_augmented_refs if len(r.get("content","")) < 120)
                if short_count >= 2:  # íœ´ë¦¬ìŠ¤í‹± ê¸°ì¤€
                    fetch_tool = enhanced_tool_registry.get_tool("fetch_website")
                    if fetch_tool:
                        candidate_urls = [r.get("metadata", {}).get("url") for r in web_augmented_refs if r.get("metadata", {}).get("url")]
                        try:
                            fetch_arun = getattr(fetch_tool, "_arun", None)
                            fetch_res = None
                            if callable(fetch_arun):
                                possible = fetch_arun(urls=candidate_urls[:3], max_chars=settings.web_fetch_max_chars)
                                # awaitable ê²€ì‚¬
                                if hasattr(possible, "__await__"):
                                    fetch_res = await possible  # type: ignore
                                else:
                                    fetch_res = possible
                            if fetch_res is None:
                                fetch_res = fetch_tool._run(urls=candidate_urls[:3], max_chars=settings.web_fetch_max_chars)
                            if isinstance(fetch_res, dict) and fetch_res.get("success"):
                                for pg in fetch_res.get("pages", []):
                                    if isinstance(pg, dict):
                                        top_refs.append({
                                            "chunk_id": pg.get("url"),
                                            "content": pg.get("content", "")[:800],
                                            "source": pg.get("url"),
                                            "similarity_score": 0.0,
                                            "metadata": {
                                                "url": pg.get("url"),
                                                "source_type": "web_page",
                                                "retrieval_stage": pg.get("retrieval_stage")
                                            }
                                        })
                                fetch_used = True
                        except Exception as fe:
                            logger.warning(f"ì›¹ í˜ì´ì§€ fetch ì˜¤ë¥˜: {fe}")

            # 4) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ + citation ì§€ì‹œ ì¶”ê°€
            system_prompt = self._build_system_prompt_with_citation()

            # 5) ì»¨í…ìŠ¤íŠ¸ ë¸”ë¡ êµ¬ì„± (í˜ì´ì§€ fetch í›„ ìƒìœ„ 8ê°œ ì¬ìŠ¬ë¼ì´ìŠ¤)
            top_refs = top_refs[:8]
            context_block = self._format_context_block(top_refs)

            # 6) ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„± (low-signal ì•ˆë‚´ í¬í•¨)
            user_prefix_flags = []
            if low_signal:
                user_prefix_flags.append("âš  ë‚´ë¶€ ë¬¸ì„œ ê·¼ê±° ë¶€ì¡±")
            if web_used:
                user_prefix_flags.append("ğŸŒ ì™¸ë¶€ ì›¹ ê²€ìƒ‰ ì¦ê°• ì ìš©")
            if fetch_used:
                user_prefix_flags.append("ğŸ“° ì›¹ í˜ì´ì§€ ë³¸ë¬¸ ì¶”ì¶œ")
            user_prefix = ("[" + ", ".join(user_prefix_flags) + "]\n") if user_prefix_flags else ""
            user_message = (
                f"{user_prefix}ì§ˆë¬¸: {query}\n\n"
                + (f"ì„ íƒëœ ì»¨í…ìŠ¤íŠ¸:\n{context_block}\n\n" if context_block else "")
                + "ì§€ì¹¨: ìœ„ 'ì»¨í…ìŠ¤íŠ¸' ë‚´ì—ì„œ ì§ì ‘ í™•ì¸ ê°€ëŠ¥í•œ ë‚´ìš©ì— ê·¼ê±°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n"
                + "ê·¼ê±°ê°€ ë¶€ì¡±í•œ ë¶€ë¶„ì€ '(ë¬¸ì„œ ê·¼ê±° ë¶€ì¡±)' ë¼ê³  ëª…ì‹œí•˜ê³  ì¼ë°˜ ì§€ì‹ì€ ë³„ë„ êµ¬ë¶„."
            )

            # 7) chat_completion í˜¸ì¶œ (system + user)
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ]
            completion = await ai_service.chat_completion(messages)  # returns dict
            ai_response_text = completion.get("response", "")

            # 8) ê·¼ê±° ì„¹ì…˜ êµ¬ì„± (ê²€ìƒ‰ ì‹¤íŒ¨/ì €í’ˆì§ˆ ì‹œ êµ¬ë¶„)
            evidence_mode = "document_citations"
            final_response = ai_response_text.strip()
            if low_signal:  # ì›¹ ì¦ê°•ì—ë„ ë¶ˆêµ¬í•˜ê³  ì—¬ì „íˆ ê·¼ê±° ì—†ìŒ
                evidence_mode = "llm_inferred"
                llm_note = (
                    "ë¬¸ì„œ ê²€ìƒ‰ì—ì„œ ì‹ ë¢°í•  ë§Œí•œ ê´€ë ¨ ì²­í¬ë¥¼ ì°¾ì§€ ëª»í•˜ì—¬ ëª¨ë¸ì˜ ì¼ë°˜ ì§€ì‹ê³¼ "
                    "ê°œì¸ì •ë³´ë³´í˜¸ ì¼ë°˜ ì›ì¹™ì„ ì°¸ê³ í•´ ì´ˆì•ˆ í˜•íƒœë¡œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ì¡°ì§ ê·œì •/ì •ì±… ë¬¸ì„œë¥¼ "
                    "êµì°¨ê²€ì¦ í›„ í™•ì •í•˜ì„¸ìš”."
                )
                # LLM ì¶”ë¡  ê·¼ê±°(ì¹´í…Œê³ ë¦¬ ì‹) í‘œí˜„
                inferred_points = [
                    "ê°œì¸ì •ë³´ ìµœì†Œ ìˆ˜ì§‘ ë° ëª©ì  ëª…í™•í™”",
                    "ì ‘ê·¼ê¶Œí•œ ì—­í• ê¸°ë°˜ í†µì œ(RBAC) ì ìš©",
                    "ì•”í˜¸í™”: ì €ì¥ ë°ì´í„°(At-Rest) + ì „ì†¡ êµ¬ê°„ TLS",
                    "ë¡œê·¸/ëª¨ë‹ˆí„°ë§ ë° ì´ìƒí–‰ìœ„ íƒì§€",
                    "ì •ê¸° êµìœ¡ ë° íŒŒê¸°/ë³´ì¡´ ì£¼ê¸° ê´€ë¦¬"
                ]
                evidence_section = (
                    "âš  ë¬¸ì„œ ê·¼ê±° ì—†ìŒ (RAG ë¯¸íƒìƒ‰ ë˜ëŠ” ë‚®ì€ ìœ ì‚¬ë„)\n" + llm_note + "\n\n" +
                    "### ğŸ” ì¼ë°˜ ì§€ì‹ ê¸°ë°˜ í•µì‹¬ ê³ ë ¤ ì˜ì—­\n" + "\n".join(f"- {p}" for p in inferred_points)
                )
                final_response += "\n\n---\n### ğŸ“Œ ì°¸ê³  ì•ˆë‚´ (ë¬¸ì„œ ê·¼ê±° ë¶€ì¡±)\n" + evidence_section
            else:
                # ì¸ë¼ì¸ citation ìš°ì„  ì‚½ì…
                final_response = self._inject_inline_citations(final_response, top_refs)
                evidence_section = self._build_evidence_section(top_refs)
                if evidence_section:
                    final_response += "\n\n---\n### ğŸ“š ì°¸ê³  ê·¼ê±°\n" + evidence_section

            # 9) ë©”íƒ€ë°ì´í„° êµ¬ì„± (í”„ë¡¬í”„íŠ¸ í”„ë¦¬ë·°)
            prompt_preview = (system_prompt + "\n" + user_message)[:400]

            logger.info(f"âœ… RAG ê²€ìƒ‰ ì™„ë£Œ: {len(cleaned_refs)}ê°œ ì°¸ì¡° (ì‚¬ìš© {len(top_refs)}) low_signal={low_signal}")
            return {
                "success": True,
                "response": final_response,
                "references": top_refs,
                "context_used": bool(context_block),
                "agent_type": "general",
                "rag_stats": {**rag_stats, "low_signal": low_signal},
                "metadata": {
                    "timestamp": datetime.now().isoformat(),
                    "processing_method": "real_rag",
                    "references_found": len(cleaned_refs),
                    "enhanced_query_used": bool(enhanced_query != query),
                    "prompt_preview": prompt_preview,
                    "evidence_mode": evidence_mode,
                    "web_augmented": web_used,
                    "web_results": len(web_augmented_refs),
                    "web_fetch_used": fetch_used
                }
            }
        except Exception as e:
            logger.error(f"âŒ ì‹¤ì œ RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return self._fallback_simulation(query, context, reason=str(e))

    def _fallback_simulation(self, query: str, context: str, reason: str) -> Dict[str, Any]:
        keywords = self._extract_keywords(query)
        simulated_chunks = self._simulate_rag_search(query, keywords)
        response = self._generate_response_with_context(query, simulated_chunks)
        return {
            "success": True,
            "response": response,
            "references": simulated_chunks,
            "context_used": bool(context),
            "agent_type": "general",
            "fallback_reason": reason,
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "processing_method": "fallback_simulation",
                "keywords_found": keywords,
                "chunks_simulated": len(simulated_chunks)
            }
        }
    # --- Fallback helper methods (original simulation logic relocated) ---
    def _extract_keywords(self, query: str) -> List[str]:
        keywords = []
        keyword_patterns = {
            "ê°œì¸ì •ë³´ë³´í˜¸": ["ê°œì¸ì •ë³´ë³´í˜¸", "ê°œì¸ì •ë³´", "privacy", "personal", "data"],
            "ë¬¸ì„œ": ["ë¬¸ì„œ", "document", "íŒŒì¼", "file"],
            "ë³´ì•ˆ": ["ë³´ì•ˆ", "security", "ì•”í˜¸í™”", "encryption"],
            "ì •ì±…": ["ì •ì±…", "policy", "ê°€ì´ë“œ", "guide"],
            "ë²•ê·œ": ["ë²•", "ê·œì •", "regulation", "compliance"],
        }
        ql = query.lower()
        for category, patterns in keyword_patterns.items():
            if any(p in ql for p in patterns):
                keywords.append(category)
        return keywords

    def _simulate_rag_search(self, query: str, keywords: List[str]) -> List[Dict[str, Any]]:
        simulated_results: List[Dict[str, Any]] = []
        if "ê°œì¸ì •ë³´ë³´í˜¸" in keywords:
            simulated_results.append({
                "chunk_id": "doc001_chunk01",
                "content": "ê°œì¸ì •ë³´ë³´í˜¸ë²•ì— ë”°ë¥¸ ê°œì¸ì •ë³´ ì²˜ë¦¬ ë°©ì¹¨ ìˆ˜ë¦½ ê°€ì´ë“œë¼ì¸",
                "source": "ê°œì¸ì •ë³´ë³´í˜¸_ì •ì±…_ê°€ì´ë“œ.pdf",
                "similarity_score": 0.92,
                "metadata": {"page": 1, "section": "ì •ì±… ê°œìš”"},
            })
        if "ë¬¸ì„œ" in keywords:
            simulated_results.append({
                "chunk_id": "doc004_chunk01",
                "content": "ë¬¸ì„œ ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ë¶„ë¥˜ ì²´ê³„ ë° ì ‘ê·¼ ê¶Œí•œ ì„¤ì •",
                "source": "ë¬¸ì„œê´€ë¦¬_ì‹œìŠ¤í…œ_ìš´ì˜ê°€ì´ë“œ.pdf",
                "similarity_score": 0.79,
                "metadata": {"page": 8, "section": "ë¬¸ì„œ ë¶„ë¥˜"},
            })
        return simulated_results[:5]

    # --- New helper methods for real RAG response ---
    def _dedupe_and_normalize_references(self, refs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        seen = set()
        normed = []
        for r in refs:
            cid = r.get("chunk_id") or r.get("id") or ""
            content = (r.get("content") or "").strip()
            key = cid + content[:50]
            if key in seen:
                continue
            seen.add(key)
            source = r.get("source") or r.get("file_name") or r.get("fileName") or ""
            meta = r.get("metadata") or {}
            # í˜ì´ì§€/page_number/page ë“± í†µí•©
            page = meta.get("page") or meta.get("page_number") or meta.get("pageIndex")
            meta_out = {**meta}
            if page is not None:
                meta_out["page"] = page
            # ë‚´ë¶€/ì›¹ êµ¬ë¶„ ê¸°ë³¸ê°’ ì§€ì •
            if "source_type" not in meta_out:
                meta_out["source_type"] = "internal"
            normed.append({
                "chunk_id": cid,
                "content": content[:800],
                "source": source,
                "similarity_score": r.get("similarity_score", 0.0),
                "metadata": meta_out
            })
        # similarity ë†’ì€ ìˆœ ì •ë ¬ (ì—­ìˆœ)
        normed.sort(key=lambda x: x.get("similarity_score", 0), reverse=True)
        return normed

    def _format_context_block(self, refs: List[Dict[str, Any]]) -> str:
        if not refs:
            return ""
        lines = []
        for i, r in enumerate(refs, 1):
            page = r.get("metadata", {}).get("page")
            src = r.get("source") or ""
            snippet = r.get("content", "")[:300].replace("\n", " ")
            lines.append(f"[{i}] (ìœ ì‚¬ë„ {r.get('similarity_score',0):.3f}) {src} p{page if page is not None else '?'} :: {snippet}")
        return "\n".join(lines)

    def _build_evidence_section(self, refs: List[Dict[str, Any]]) -> str:
        if not refs:
            return ""
        out = []
        for i, r in enumerate(refs, 1):
            meta = r.get("metadata", {})
            page = meta.get("page", "?")
            src = r.get("source") or ""  # could be empty if not stored
            kws = meta.get("keywords") or []
            kw_str = ", ".join(kws[:5]) if kws else "-"
            marker = self._marker_for_reference(i, meta.get("source_type"))
            out.append(f"{i}. {marker} íŒŒì¼: {src or '(ë¯¸ê¸°ë¡)'} | p.{page} | í‚¤ì›Œë“œ: {kw_str}")
        return "\n".join(out)

    def _marker_for_reference(self, index: int, source_type: Optional[str]) -> str:
        st = (source_type or "internal").lower()
        if st == "web_page":
            return f"[WP{index}]"
        if st.startswith("web"):
            return f"[W{index}]"
        return f"[I{index}]"

    def _inject_inline_citations(self, answer: str, refs: List[Dict[str, Any]]) -> str:
        """ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìˆœì°¨ citation ì‚½ì… (ê°„ë‹¨ íœ´ë¦¬ìŠ¤í‹±)."""
        if not refs or not answer.strip():
            return answer
        import re
        sentences = re.split(r"(.*?[\.\?\!])(\s+|$)", answer, flags=re.S)
        # sentences list includes captured groups; rebuild carefully
        rebuilt = []
        ref_index = 0
        total_refs = len(refs)
        for chunk in sentences:
            if not chunk:
                continue
            if ref_index < total_refs and re.search(r"[\.\?\!]$", chunk.strip()):
                meta = refs[ref_index].get("metadata", {})
                marker = self._marker_for_reference(ref_index + 1, meta.get("source_type"))
                # ì´ë¯¸ ë™ì¼ ë§ˆì»¤ ì¡´ì¬í•˜ë©´ ì¤‘ë³µ ì‚½ì… ì•ˆ í•¨
                if marker not in chunk:
                    chunk = chunk.rstrip() + " " + marker
                ref_index += 1
            rebuilt.append(chunk)
        # ë‚¨ì€ referenceê°€ ìˆìœ¼ë©´ ë‹µë³€ ëì— ë¬¶ì–´ì„œ ì¶”ê°€
        if ref_index < total_refs:
            tail_markers = []
            for j in range(ref_index, total_refs):
                meta = refs[j].get("metadata", {})
                tail_markers.append(self._marker_for_reference(j + 1, meta.get("source_type")))
            rebuilt.append("\n\n" + " ".join(tail_markers))
        return "".join(rebuilt)

    def _build_system_prompt_with_citation(self) -> str:
        try:
            from pathlib import Path
            prompt_path = Path(__file__).parent.parent.parent.parent / "prompts" / "general.prompt"
            base = ""
            if prompt_path.exists():
                base = prompt_path.read_text(encoding="utf-8").strip()
            citation_rules = (
                "\n\nì¶”ê°€ ê·œì¹™:\n"
                "- ë°˜ë“œì‹œ ë‹µë³€ ë§ˆì§€ë§‰ì— 'ğŸ“š ì°¸ê³  ê·¼ê±°' ì„¹ì…˜ í¬í•¨ (ì¡´ì¬í•˜ëŠ” ë ˆí¼ëŸ°ìŠ¤ë§Œ).\n"
                "- ê·¼ê±° ì—†ëŠ” ì£¼ì¥ì—” '(ë¬¸ì„œ ê·¼ê±° ë¶€ì¡±)' í‘œì‹œ.\n"
                "- ë¬¸ì„œ í‘œí˜„ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ê¸°ë³´ë‹¤ ìš”ì•½/ì¬êµ¬ì„±.\n"
                "- ê°œì¸ì •ë³´/ë³´ì•ˆ ê´€ë ¨ ì§ˆë¬¸ ì‹œ ë²•/ì •ì±… ëª…ì¹­ ì •í™•íˆ ì–¸ê¸‰í•˜ê³  ê·¼ê±° ë¬¸ì„œ ë²ˆí˜¸/í˜ì´ì§€ í‘œê¸°.")
            return base + citation_rules
        except Exception:
            return "ë‹¹ì‹ ì€ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ê·¼ê±°ë¥¼ ì œì‹œí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
    
    def _generate_response_with_context(self, query: str, chunks: List[Dict[str, Any]]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„±"""
        if not chunks:
            return f"'{query}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì‹œê±°ë‚˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”."
        
        # ì²­í¬ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ êµ¬ì„±
        response_parts = [f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.\n"]
        
        response_parts.append("## ğŸ“‹ ê´€ë ¨ ë¬¸ì„œ ëª©ë¡:")
        for i, chunk in enumerate(chunks, 1):
            source = chunk.get("source", "ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ì„œ")
            content = chunk.get("content", "ë‚´ìš© ì—†ìŒ")
            score = chunk.get("similarity_score", 0.0)
            
            response_parts.append(f"{i}. **{source}**")
            response_parts.append(f"   - ë‚´ìš©: {content[:100]}...")
            response_parts.append(f"   - ê´€ë ¨ë„: {score:.2f}")
            response_parts.append("")
        
        response_parts.append("## ğŸ“„ ìš”ì•½:")
        if "ê°œì¸ì •ë³´ë³´í˜¸" in query:
            response_parts.append("ê°œì¸ì •ë³´ë³´í˜¸ ê´€ë ¨ ë¬¸ì„œë“¤ì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ìš” ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:")
            response_parts.append("- ê°œì¸ì •ë³´ë³´í˜¸ë²• ì¤€ìˆ˜ ê°€ì´ë“œë¼ì¸")
            response_parts.append("- GDPR ì»´í”Œë¼ì´ì–¸ìŠ¤ ì ˆì°¨")
            response_parts.append("- ê°œì¸ì •ë³´ ìˆ˜ì§‘Â·ì´ìš© ë™ì˜ì„œ ì–‘ì‹")
        else:
            response_parts.append("ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í†µí•´ ê´€ë ¨ ì •ë³´ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        response_parts.append("\në” ìì„¸í•œ ë‚´ìš©ì„ ì›í•˜ì‹œë©´ íŠ¹ì • ë¬¸ì„œë¥¼ ì„ íƒí•˜ì—¬ ìƒì„¸ ë¶„ì„ì„ ìš”ì²­í•´ ì£¼ì„¸ìš”.")
        
        return "\n".join(response_parts)


class DocumentSummaryTool(BaseTool):
    name: str = "document_summary_tool"
    description: str = """ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•©ë‹ˆë‹¤.
    ì…ë ¥: ë¬¸ì„œ ëª©ë¡, ìš”ì•½ ìœ í˜•, ì§‘ì¤‘ ì˜ì—­
    ì¶œë ¥: êµ¬ì¡°í™”ëœ ë¬¸ì„œ ìš”ì•½"""
    args_schema: Type[BaseModel] = DocumentSummaryInput
    
    def _run(
        self, 
        documents: List[Dict[str, Any]], 
        summary_type: str = "comprehensive",
        focus_areas: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        logger.info(f"ğŸ“ ë¬¸ì„œ ìš”ì•½ íˆ´ ì‹¤í–‰: {len(documents)}ê°œ ë¬¸ì„œ")
        
        try:
            focus_areas = focus_areas or []
            
            # ìš”ì•½ ìƒì„± ë¡œì§
            summary_result = {
                "executive_summary": "ë¬¸ì„œë“¤ì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•œ ì„ì› ìš”ì•½ë³¸",
                "key_findings": [
                    "ì£¼ìš” ë°œê²¬ì‚¬í•­ 1",
                    "ì£¼ìš” ë°œê²¬ì‚¬í•­ 2", 
                    "ì£¼ìš” ë°œê²¬ì‚¬í•­ 3"
                ],
                "recommendations": [
                    "ê¶Œì¥ì‚¬í•­ 1",
                    "ê¶Œì¥ì‚¬í•­ 2"
                ],
                "document_count": len(documents),
                "summary_type": summary_type,
                "focus_areas": focus_areas,
                "metadata": {
                    "generation_timestamp": datetime.now().isoformat(),
                    "estimated_reading_time": f"{len(documents) * 2}ë¶„"
                }
            }
            
            logger.info(f"âœ… ë¬¸ì„œ ìš”ì•½ ì™„ë£Œ: {summary_type} íƒ€ì…")
            return {"success": True, **summary_result}
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ìš”ì•½ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}


class KeywordExtractionTool(BaseTool):
    name: str = "keyword_extraction_tool"
    description: str = """ë¬¸ì„œì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œì™€ ì£¼ì œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì…ë ¥: ë¬¸ì„œ ëª©ë¡, ìµœëŒ€ í‚¤ì›Œë“œ ìˆ˜, í‚¤ í”„ë ˆì´ì¦ˆ í¬í•¨ ì—¬ë¶€
    ì¶œë ¥: ì¶”ì¶œëœ í‚¤ì›Œë“œì™€ ë¶„ì„ ê²°ê³¼"""
    args_schema: Type[BaseModel] = KeywordExtractionInput
    
    def _run(
        self, 
        documents: List[Dict[str, Any]], 
        max_keywords: int = 20,
        include_phrases: bool = True
    ) -> Dict[str, Any]:
        logger.info(f"ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ íˆ´ ì‹¤í–‰: {len(documents)}ê°œ ë¬¸ì„œ")
        
        try:
            # í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§
            extracted_keywords = [
                {"keyword": "AI", "frequency": 15, "relevance": 0.95},
                {"keyword": "ìë™í™”", "frequency": 12, "relevance": 0.88},
                {"keyword": "íš¨ìœ¨ì„±", "frequency": 10, "relevance": 0.82},
                {"keyword": "ë°ì´í„° ë¶„ì„", "frequency": 8, "relevance": 0.79},
                {"keyword": "ë””ì§€í„¸ ì „í™˜", "frequency": 6, "relevance": 0.75}
            ]
            
            key_phrases = [
                {"phrase": "ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ ìë™í™”", "frequency": 5, "relevance": 0.90},
                {"phrase": "ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •", "frequency": 4, "relevance": 0.85}
            ] if include_phrases else []
            
            result = {
                "keywords": extracted_keywords[:max_keywords],
                "key_phrases": key_phrases,
                "topic_categories": ["ê¸°ìˆ ", "ë¹„ì¦ˆë‹ˆìŠ¤", "í˜ì‹ "],
                "document_count": len(documents),
                "extraction_stats": {
                    "total_keywords_found": len(extracted_keywords),
                    "total_phrases_found": len(key_phrases),
                    "avg_relevance": 0.84
                },
                "metadata": {
                    "extraction_timestamp": datetime.now().isoformat(),
                    "include_phrases": include_phrases
                }
            }
            
            logger.info(f"âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ: {len(extracted_keywords)}ê°œ í‚¤ì›Œë“œ")
            return {"success": True, **result}
            
        except Exception as e:
            logger.error(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}


class PresentationGenerationTool(BaseTool):
    name: str = "presentation_generation_tool"
    description: str = """ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í”„ë ˆì  í…Œì´ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì…ë ¥: ê¸°ë°˜ ë‚´ìš©, ìŠ¬ë¼ì´ë“œ ìˆ˜, í…œí”Œë¦¿ ìŠ¤íƒ€ì¼
    ì¶œë ¥: ìƒì„±ëœ í”„ë ˆì  í…Œì´ì…˜ íŒŒì¼ê³¼ ë©”íƒ€ë°ì´í„°"""
    args_schema: Type[BaseModel] = PresentationGenerationInput
    
    async def _arun(
        self,
        content: str,
        slide_count: int = 8,
        template_style: str = "business",
        include_charts: bool = True
    ) -> Dict[str, Any]:
        """ë¹„ë™ê¸° í”„ë ˆì  í…Œì´ì…˜ ìƒì„± (ê¶Œì¥ ê²½ë¡œ)."""
        logger.info(f"ğŸ“Š (async) í”„ë ˆì  í…Œì´ì…˜ ìƒì„± íˆ´ ì‹¤í–‰: {slide_count}ê°œ ìŠ¬ë¼ì´ë“œ")
        try:
            # í…œí”Œë¦¿ ë¯¸ì ìš©(Quick) íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
            from app.services.presentation.quick_ppt_generator_service import quick_ppt_service
            topic = content.split('\n')[0][:70] if content else "í”„ë ˆì  í…Œì´ì…˜"
            deck = quick_ppt_service.generate_fixed_outline(
                topic=topic,
                context_text=content[:8000],
                max_slides=slide_count
            )
            file_path = quick_ppt_service.build_quick_pptx(deck)
            return {
                "success": True,
                "file_path": file_path,
                "file_name": file_path.split('/')[-1],
                "slide_count": getattr(deck, 'max_slides', slide_count),
                "template_style": template_style,  # quick ê²½ë¡œì—ì„œëŠ” ìŠ¤íƒ€ì¼ì´ ì‹œê°ì  í…Œë§ˆì— ì§ì ‘ ë°˜ì˜ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
                "outline": {
                    "title": deck.topic,
                    "slides": [{"title": s.title, "layout": s.layout} for s in deck.slides]
                },
                "metadata": {
                    "generation_timestamp": datetime.now().isoformat(),
                    "content_length": len(content),
                    "include_charts": include_charts,  # quick ê²½ë¡œì—ì„œëŠ” ë¬´ì‹œë  ìˆ˜ ìˆìŒ
                    "async": True
                }
            }
        except Exception as e:
            logger.error(f"âŒ (async) í”„ë ˆì  í…Œì´ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}

    # ë™ê¸° í´ë°± (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€)
    def _run(
        self,
        content: str,
        slide_count: int = 8,
        template_style: str = "business",
        include_charts: bool = True
    ) -> Dict[str, Any]:
        try:
            loop = None
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:
                pass
            if loop and loop.is_running():
                return asyncio.run_coroutine_threadsafe(
                    self._arun(content=content, slide_count=slide_count, template_style=template_style, include_charts=include_charts),
                    loop
                ).result(timeout=180)
            else:
                return asyncio.run(
                    self._arun(content=content, slide_count=slide_count, template_style=template_style, include_charts=include_charts)
                )
        except Exception as e:
            logger.error(f"âŒ (sync wrapper) í”„ë ˆì  í…Œì´ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}


class DocumentAnalysisTool(BaseTool):
    name: str = "document_analysis_tool"  
    description: str = """ë¬¸ì„œì˜ êµ¬ì¡°ì™€ íŒ¨í„´ì„ ê¹Šì´ ìˆê²Œ ë¶„ì„í•©ë‹ˆë‹¤.
    ì…ë ¥: ë¬¸ì„œ ëª©ë¡, ë¶„ì„ ê¹Šì´, ì§‘ì¤‘ ì§€í‘œ
    ì¶œë ¥: ìƒì„¸í•œ ë¬¸ì„œ ë¶„ì„ ê²°ê³¼"""
    args_schema: Type[BaseModel] = DocumentAnalysisInput
    
    def _run(
        self, 
        documents: List[Dict[str, Any]], 
        analysis_depth: str = "standard",
        focus_metrics: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        logger.info(f"ğŸ”¬ ë¬¸ì„œ ë¶„ì„ íˆ´ ì‹¤í–‰: {len(documents)}ê°œ ë¬¸ì„œ, ê¹Šì´={analysis_depth}")
        
        try:
            focus_metrics = focus_metrics or ["readability", "structure", "content_quality"]
            
            analysis_result = {
                "document_overview": {
                    "total_documents": len(documents),
                    "total_pages": sum(doc.get("page_count", 1) for doc in documents),
                    "file_types": list(set(doc.get("file_type", "unknown") for doc in documents))
                },
                "content_analysis": {
                    "readability_score": 0.75,
                    "complexity_level": "medium",
                    "main_topics": ["ê¸°ìˆ  ë™í–¥", "ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ", "ì‹œì¥ ë¶„ì„"],
                    "sentiment_analysis": {"positive": 0.6, "neutral": 0.3, "negative": 0.1}
                },
                "structure_analysis": {
                    "has_headers": True,
                    "has_tables": any(doc.get("has_tables", False) for doc in documents),
                    "has_images": any(doc.get("has_images", False) for doc in documents),
                    "citation_count": 12
                },
                "quality_metrics": {
                    "completeness": 0.85,
                    "consistency": 0.78,
                    "accuracy_indicators": ["citations", "data_sources", "methodology"]
                },
                "metadata": {
                    "analysis_depth": analysis_depth,
                    "focus_metrics": focus_metrics,
                    "analysis_timestamp": datetime.now().isoformat()
                }
            }
            
            logger.info(f"âœ… ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ: {analysis_depth} ê¹Šì´")
            return {"success": True, **analysis_result}
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}


class InsightGenerationTool(BaseTool):
    name: str = "insight_generation_tool"
    description: str = """ë°ì´í„°ì—ì„œ ì˜ë¯¸ìˆëŠ” í†µì°°ê³¼ íŒ¨í„´ì„ ë°œê²¬í•©ë‹ˆë‹¤.
    ì…ë ¥: ë°ì´í„° ì†ŒìŠ¤, ì¸ì‚¬ì´íŠ¸ ìœ í˜•, ì‹ ë¢°ë„ ì„ê³„ê°’
    ì¶œë ¥: ë°œê²¬ëœ ì¸ì‚¬ì´íŠ¸ì™€ ë¶„ì„ ê²°ê³¼"""
    args_schema: Type[BaseModel] = InsightGenerationInput
    
    def _run(
        self, 
        data_sources: List[Dict[str, Any]], 
        insight_types: Optional[List[str]] = None,
        confidence_threshold: float = 0.7
    ) -> Dict[str, Any]:
        logger.info(f"ğŸ’¡ ì¸ì‚¬ì´íŠ¸ ìƒì„± íˆ´ ì‹¤í–‰: {len(data_sources)}ê°œ ì†ŒìŠ¤")
        
        try:
            insight_types = insight_types or ["trend", "pattern", "anomaly"]
            
            insights = [
                {
                    "title": "ë¹„ìš© ì ˆê° ê¸°íšŒ ë°œê²¬",
                    "type": "pattern",
                    "description": "ìë™í™” ë„ì…ìœ¼ë¡œ 30% ë¹„ìš© ì ˆê° ê°€ëŠ¥",
                    "confidence": 0.89,
                    "impact": "high",
                    "supporting_data": ["Process A: 25% ì ˆê°", "Process B: 35% ì ˆê°"]
                },
                {
                    "title": "ì„±ê³¼ ì§€í‘œ ìƒìŠ¹ íŠ¸ë Œë“œ",
                    "type": "trend",
                    "description": "ì§€ë‚œ 6ê°œì›”ê°„ KPI ì§€ì†ì  ìƒìŠ¹",
                    "confidence": 0.82,
                    "impact": "medium",
                    "supporting_data": ["Q1: +15%", "Q2: +22%"]
                }
            ]
            
            # ì‹ ë¢°ë„ í•„í„°ë§
            filtered_insights = [i for i in insights if i["confidence"] >= confidence_threshold]
            
            result = {
                "insights": filtered_insights,
                "insight_count": len(filtered_insights),
                "categories": {
                    "high_impact": len([i for i in filtered_insights if i["impact"] == "high"]),
                    "medium_impact": len([i for i in filtered_insights if i["impact"] == "medium"]),
                    "low_impact": len([i for i in filtered_insights if i["impact"] == "low"])
                },
                "confidence_stats": {
                    "average_confidence": sum(i["confidence"] for i in filtered_insights) / len(filtered_insights) if filtered_insights else 0,
                    "min_confidence": confidence_threshold
                },
                "metadata": {
                    "insight_types": insight_types,
                    "data_sources_count": len(data_sources),
                    "generation_timestamp": datetime.now().isoformat()
                }
            }
            
            logger.info(f"âœ… ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ: {len(filtered_insights)}ê°œ ì¸ì‚¬ì´íŠ¸")
            return {"success": True, **result}
            
        except Exception as e:
            logger.error(f"âŒ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}


# =============================================================================
# í™•ì¥ëœ íˆ´ ë ˆì§€ìŠ¤íŠ¸ë¦¬
# =============================================================================

class EnhancedToolRegistry:
    """í™•ì¥ëœ ë©€í‹° ì—ì´ì „íŠ¸ ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬"""
    
    def __init__(self):
        self.tools = {
            # ì‹ ê·œ ì›¹ ê²€ìƒ‰ íˆ´
            "web_search": WebSearchTool(),
            # ê¸°ì¡´ íˆ´ë“¤
            "document_analysis": DocumentAnalysisTool(),
            "summary_generation": DocumentSummaryTool(),
            "insight_extraction": InsightGenerationTool(),
            "presentation_build": PresentationGenerationTool(),
            
            # ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ íˆ´ë“¤
            "general_chat": GeneralChatTool(),
            "keyword_extraction": KeywordExtractionTool(),
            "document_summary": DocumentSummaryTool(),
            "presentation_generation": PresentationGenerationTool(),
            "document_analysis_detailed": DocumentAnalysisTool(),
            "insight_generation": InsightGenerationTool(),
            
            # TODO: ì¶”ê°€ êµ¬í˜„ í•„ìš”í•œ íˆ´ë“¤
            # "template_document": TemplateDocumentTool(),
            # "knowledge_graph": KnowledgeGraphTool(), 
            # "report_generation": ReportGenerationTool(),
            # "script_generation": ScriptGenerationTool(),
            # "key_points_extraction": KeyPointsExtractionTool(),
        }
        
        # ì—ì´ì „íŠ¸ íƒ€ì…ê³¼ íˆ´ ë§¤í•‘
        self.agent_tool_mapping = {
            'general': 'general_chat',
            'web-search': 'web_search',
            'summarizer': 'document_summary', 
            'keyword-extractor': 'keyword_extraction',
            'presentation': 'presentation_generation',
            'analyzer': 'document_analysis_detailed',
            'insight': 'insight_generation',
            # 'template': 'template_document',
            # 'knowledge-graph': 'knowledge_graph',
            # 'report-generator': 'report_generation', 
            # 'script-generator': 'script_generation',
            # 'key-points': 'key_points_extraction'
        }
        
    def get_tool(self, tool_name: str) -> Optional[BaseTool]:
        """ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        return self.tools.get(tool_name)
        
    def get_tool_by_agent_type(self, agent_type: str) -> Optional[BaseTool]:
        """ì—ì´ì „íŠ¸ íƒ€ì…ìœ¼ë¡œ íˆ´ ë°˜í™˜"""
        tool_name = self.agent_tool_mapping.get(agent_type)
        return self.get_tool(tool_name) if tool_name else None
        
    def get_all_tools(self) -> List[BaseTool]:
        """ëª¨ë“  ë„êµ¬ ëª©ë¡ ë°˜í™˜"""
        return list(self.tools.values())
        
    def get_tool_descriptions(self) -> Dict[str, str]:
        """ë„êµ¬ ì„¤ëª… ëª©ë¡ ë°˜í™˜"""
        return {name: tool.description for name, tool in self.tools.items()}
        
    def get_agent_capabilities(self) -> Dict[str, Dict[str, Any]]:
        """ê° ì—ì´ì „íŠ¸ì˜ ì—­ëŸ‰ ì •ë³´ ë°˜í™˜"""
        capabilities = {}
        for agent_type, tool_name in self.agent_tool_mapping.items():
            tool = self.get_tool(tool_name)
            if tool:
                capabilities[agent_type] = {
                    "tool_name": tool_name,
                    "description": tool.description,
                    "available": True
                }
            else:
                capabilities[agent_type] = {
                    "tool_name": tool_name,
                    "description": "êµ¬í˜„ ì˜ˆì •",
                    "available": False
                }
        return capabilities


# ì „ì—­ í™•ì¥ëœ ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¸ìŠ¤í„´ìŠ¤
enhanced_tool_registry = EnhancedToolRegistry()
