"""ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì„œë¹„ìŠ¤
===========================

ê³ ê¸‰ ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤
- pgvector ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
- CLIP ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ (ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ í¬ë¡œìŠ¤ ëª¨ë‹¬)
- ì»¨í…Œì´ë„ˆë³„ í•„í„°ë§
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í…ìŠ¤íŠ¸ + CLIP)
"""

from typing import List, Dict, Any, Optional
import logging
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, text

from app.models.document.multimodal_models import DocEmbedding, DocChunk
from app.models import TbFileBssInfo
from app.services.core.korean_nlp_service import korean_nlp_service
from app.core.config import settings

# CLIP ì„ë² ë”© ì„œë¹„ìŠ¤
try:
    from app.services.document.vision.image_embedding_service import ImageEmbeddingService
    image_embedding_service = ImageEmbeddingService()
except ImportError:
    image_embedding_service = None

logger = logging.getLogger(__name__)

class MultimodalSearchService:
    """ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì„œë¹„ìŠ¤"""
    
    async def search_similar_chunks(
        self,
        query_text: str,
        session: AsyncSession,
        top_k: int = 10,
        container_ids: Optional[List[str]] = None,
        file_ids: Optional[List[int]] = None,
        similarity_threshold: float = 0.3
    ) -> List[Dict[str, Any]]:
        """ìœ ì‚¬ë„ ê¸°ë°˜ ì²­í¬ ê²€ìƒ‰
        
        Args:
            query_text: ê²€ìƒ‰ ì¿¼ë¦¬
            session: DB ì„¸ì…˜
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            container_ids: í•„í„°ë§í•  ì»¨í…Œì´ë„ˆ ID ëª©ë¡
            file_ids: í•„í„°ë§í•  íŒŒì¼ ID ëª©ë¡
            similarity_threshold: ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = await korean_nlp_service.generate_korean_embedding(query_text)
            if not query_embedding:
                logger.warning("ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                return []
            
            # 2. ì°¨ì› ì¡°ì • (ì œë¡œ íŒ¨ë”©)
            max_dim = settings.vector_dimension
            if len(query_embedding) < max_dim:
                query_embedding = query_embedding + [0.0] * (max_dim - len(query_embedding))
            elif len(query_embedding) > max_dim:
                query_embedding = query_embedding[:max_dim]
            
            # 3. pgvector ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
            vector_literal = "[" + ",".join(map(str, query_embedding)) + "]"
            
            # ê¸°ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬
            base_query = f"""
            SELECT 
                de.embedding_id,
                dc.chunk_id,
                dc.file_bss_info_sno,
                dc.chunk_index,
                dc.content_text,
                dc.token_count,
                dc.modality,
                fbf.file_lgc_nm as file_name,
                fbf.knowledge_container_id,
                de.vector <=> '{vector_literal}'::vector as distance
            FROM doc_embedding de
            JOIN doc_chunk dc ON de.chunk_id = dc.chunk_id
            JOIN tb_file_bss_info fbf ON dc.file_bss_info_sno = fbf.file_bss_info_sno
            WHERE fbf.del_yn = 'N'
            """
            
            # í•„í„° ì¡°ê±´ ì¶”ê°€
            conditions = []
            if container_ids:
                container_filter = "'" + "','".join(container_ids) + "'"
                conditions.append(f"fbf.knowledge_container_id IN ({container_filter})")
            
            if file_ids:
                file_filter = ",".join(map(str, file_ids))
                conditions.append(f"dc.file_bss_info_sno IN ({file_filter})")
            
            if conditions:
                base_query += " AND " + " AND ".join(conditions)
            
            # ì •ë ¬ ë° ì œí•œ
            base_query += f"""
            ORDER BY distance ASC
            LIMIT {top_k}
            """
            
            # 4. ì¿¼ë¦¬ ì‹¤í–‰
            result = await session.execute(text(base_query))
            rows = result.fetchall()
            
            # 5. ê²°ê³¼ í¬ë§·íŒ…
            search_results = []
            for row in rows:
                similarity_score = 1.0 - float(row.distance)  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                
                if similarity_score < similarity_threshold:
                    continue
                
                search_results.append({
                    "chunk_id": row.chunk_id,
                    "embedding_id": row.embedding_id,
                    "file_id": row.file_bss_info_sno,
                    "chunk_index": row.chunk_index,
                    "content": row.content_text,
                    "token_count": row.token_count,
                    "modality": row.modality,
                    "file_name": row.file_name,
                    "container_id": row.knowledge_container_id,
                    "similarity_score": similarity_score,
                    "distance": float(row.distance)
                })
            
            logger.info(f"ìœ ì‚¬ë„ ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼ (ì„ê³„ê°’: {similarity_threshold})")
            return search_results
            
        except Exception as e:
            logger.error(f"ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def get_chunk_context(
        self,
        chunk_id: int,
        session: AsyncSession,
        context_window: int = 2
    ) -> Dict[str, Any]:
        """ì²­í¬ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ
        
        Args:
            chunk_id: ëŒ€ìƒ ì²­í¬ ID
            session: DB ì„¸ì…˜
            context_window: ì•ë’¤ë¡œ ê°€ì ¸ì˜¬ ì²­í¬ ìˆ˜
            
        Returns:
            ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        """
        try:
            # ëŒ€ìƒ ì²­í¬ ì •ë³´ ì¡°íšŒ
            stmt = select(DocChunk).where(DocChunk.chunk_id == chunk_id)
            result = await session.execute(stmt)
            target_chunk = result.scalar_one_or_none()
            
            if not target_chunk:
                return {"error": "ì²­í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            # ê°™ì€ íŒŒì¼ì˜ ì¸ì ‘ ì²­í¬ë“¤ ì¡°íšŒ
            context_stmt = select(DocChunk).where(
                DocChunk.file_bss_info_sno == target_chunk.file_bss_info_sno
            ).where(
                DocChunk.chunk_index >= target_chunk.chunk_index - context_window
            ).where(
                DocChunk.chunk_index <= target_chunk.chunk_index + context_window
            ).order_by(DocChunk.chunk_index)
            
            context_result = await session.execute(context_stmt)
            context_chunks = context_result.scalars().all()
            
            return {
                "target_chunk": {
                    "chunk_id": target_chunk.chunk_id,
                    "chunk_index": target_chunk.chunk_index,
                    "content": target_chunk.content_text,
                    "token_count": target_chunk.token_count
                },
                "context_chunks": [
                    {
                        "chunk_id": chunk.chunk_id,
                        "chunk_index": chunk.chunk_index,
                        "content": chunk.content_text,
                        "is_target": chunk.chunk_id == chunk_id
                    }
                    for chunk in context_chunks
                ],
                "total_context_length": sum(len(chunk.content_text or "") for chunk in context_chunks)
            }
            
        except Exception as e:
            logger.error(f"ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    async def search_multimodal_clip(
        self,
        query: str,
        session: AsyncSession,
        query_type: str = "text",
        top_k: int = 10,
        container_ids: Optional[List[str]] = None,
        file_ids: Optional[List[int]] = None,
        similarity_threshold: float = 0.3,
        modality_filter: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """CLIP ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ ê²½ë¡œ)
            session: DB ì„¸ì…˜
            query_type: ì¿¼ë¦¬ ìœ í˜• ('text' ë˜ëŠ” 'image')
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            container_ids: í•„í„°ë§í•  ì»¨í…Œì´ë„ˆ ID ëª©ë¡
            file_ids: í•„í„°ë§í•  íŒŒì¼ ID ëª©ë¡
            similarity_threshold: ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
            modality_filter: ê²€ìƒ‰ ëŒ€ìƒ ëª¨ë‹¬ë¦¬í‹° ('text', 'image', None=ëª¨ë‘)
            
        Returns:
            CLIP ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            if not image_embedding_service:
                logger.error("CLIP ì„ë² ë”© ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return []
            
            # 1. CLIP ì„ë² ë”© ìƒì„±
            clip_embedding = None
            if query_type == "text":
                # í…ìŠ¤íŠ¸ ì¿¼ë¦¬ â†’ CLIP í…ìŠ¤íŠ¸ ì„ë² ë”©
                logger.info(f"[CLIP] í…ìŠ¤íŠ¸ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±: {query[:50]}...")
                clip_embedding = await image_embedding_service.generate_text_embedding(query)
            elif query_type == "image":
                # ì´ë¯¸ì§€ ì¿¼ë¦¬ â†’ CLIP ì´ë¯¸ì§€ ì„ë² ë”©
                logger.info(f"[CLIP] ì´ë¯¸ì§€ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±: {query}")
                clip_embedding = await image_embedding_service.generate_image_embedding(query)
            
            if not clip_embedding:
                logger.warning("CLIP ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                return []
            
            # 2. ì°¨ì› ì¡°ì • (CLIPì€ 512ì°¨ì›)
            clip_dim = 512
            if len(clip_embedding) < clip_dim:
                clip_embedding = clip_embedding + [0.0] * (clip_dim - len(clip_embedding))
            elif len(clip_embedding) > clip_dim:
                clip_embedding = clip_embedding[:clip_dim]
            
            # 3. pgvector CLIP ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
            vector_literal = "[" + ",".join(map(str, clip_embedding)) + "]"
            
            # ğŸ”· í”„ë¡œë°”ì´ë”ë³„ ë²¡í„° ì»¬ëŸ¼ ì„ íƒ
            from app.core.config import settings
            provider = settings.get_current_embedding_provider()
            
            if provider == 'bedrock':
                # AWS Bedrock: TwelveLabs Marengo (512d)
                vector_column = "de.aws_marengo_vector_512"
                vector_not_null = f"{vector_column} IS NOT NULL"
                logger.info(f"[CLIP] AWS Bedrock ë²¡í„° ì‚¬ìš© (aws_marengo_vector_512)")
            else:
                # Azure OpenAI: CLIP (512d)
                vector_column = "COALESCE(de.azure_clip_vector, de.clip_vector)"
                vector_not_null = "(de.azure_clip_vector IS NOT NULL OR de.clip_vector IS NOT NULL)"
                logger.info(f"[CLIP] Azure CLIP ë²¡í„° ì‚¬ìš© (azure_clip_vector)")
            
            # ê¸°ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬ (í”„ë¡œë°”ì´ë”ë³„ ë²¡í„° ì»¬ëŸ¼ ì‚¬ìš©)
            base_query = f"""
            SELECT 
                de.embedding_id,
                dc.chunk_id,
                dc.file_bss_info_sno,
                dc.chunk_index,
                dc.content_text,
                dc.token_count,
                dc.modality,
                fbf.file_lgc_nm as file_name,
                fbf.knowledge_container_id,
                {vector_column} <=> '{vector_literal}'::vector as distance
            FROM doc_embedding de
            JOIN doc_chunk dc ON de.chunk_id = dc.chunk_id
            JOIN tb_file_bss_info fbf ON dc.file_bss_info_sno = fbf.file_bss_info_sno
            WHERE fbf.del_yn = 'N'
            AND {vector_not_null}
            """
            
            # í•„í„° ì¡°ê±´ ì¶”ê°€
            conditions = []
            
            # ì»¨í…Œì´ë„ˆ í•„í„°
            if container_ids:
                container_filter = "'" + "','".join(container_ids) + "'"
                conditions.append(f"fbf.knowledge_container_id IN ({container_filter})")
            
            # íŒŒì¼ í•„í„°
            if file_ids:
                file_filter = ",".join(map(str, file_ids))
                conditions.append(f"dc.file_bss_info_sno IN ({file_filter})")
            
            # ëª¨ë‹¬ë¦¬í‹° í•„í„°
            if modality_filter:
                conditions.append(f"dc.modality = '{modality_filter}'")
            
            if conditions:
                base_query += " AND " + " AND ".join(conditions)
            
            # ì •ë ¬ ë° ì œí•œ
            base_query += f"""
            ORDER BY distance ASC
            LIMIT {top_k}
            """
            
            # 4. ì¿¼ë¦¬ ì‹¤í–‰
            logger.info(f"[CLIP] ê²€ìƒ‰ ì‹¤í–‰ - ì¿¼ë¦¬ íƒ€ì…: {query_type}, ëª¨ë‹¬ë¦¬í‹°: {modality_filter or 'ì „ì²´'}")
            result = await session.execute(text(base_query))
            rows = result.fetchall()
            
            # 5. ê²°ê³¼ í¬ë§·íŒ…
            search_results = []
            for row in rows:
                similarity_score = 1.0 - float(row.distance)  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                
                if similarity_score < similarity_threshold:
                    continue
                
                search_results.append({
                    "chunk_id": row.chunk_id,
                    "embedding_id": row.embedding_id,
                    "file_id": row.file_bss_info_sno,
                    "chunk_index": row.chunk_index,
                    "content": row.content_text,
                    "token_count": row.token_count,
                    "modality": row.modality,
                    "file_name": row.file_name,
                    "container_id": row.knowledge_container_id,
                    "similarity_score": similarity_score,
                    "distance": float(row.distance)
                })
            
            logger.info(f"[CLIP] ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼ (ì„ê³„ê°’: {similarity_threshold})")
            return search_results
            
        except Exception as e:
            logger.error(f"[CLIP] ê²€ìƒ‰ ì‹¤íŒ¨: {e}", exc_info=True)
            return []
    
    async def search_hybrid(
        self,
        query_text: str,
        session: AsyncSession,
        top_k: int = 20,
        container_ids: Optional[List[str]] = None,
        file_ids: Optional[List[int]] = None,
        text_weight: float = 0.6,
        clip_weight: float = 0.4,
        similarity_threshold: float = 0.3
    ) -> List[Dict[str, Any]]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í…ìŠ¤íŠ¸ ë²¡í„° + CLIP)
        
        Args:
            query_text: ê²€ìƒ‰ ì¿¼ë¦¬
            session: DB ì„¸ì…˜
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            container_ids: í•„í„°ë§í•  ì»¨í…Œì´ë„ˆ ID ëª©ë¡
            file_ids: í•„í„°ë§í•  íŒŒì¼ ID ëª©ë¡
            text_weight: í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (0.0 ~ 1.0)
            clip_weight: CLIP ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (0.0 ~ 1.0)
            similarity_threshold: ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
            
        Returns:
            í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # 1. í…ìŠ¤íŠ¸ ë²¡í„° ê²€ìƒ‰
            logger.info(f"[HYBRID] í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹œì‘ (weight={text_weight})")
            text_results = await self.search_similar_chunks(
                query_text=query_text,
                session=session,
                top_k=top_k * 2,  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ í†µí•©
                container_ids=container_ids,
                file_ids=file_ids,
                similarity_threshold=similarity_threshold * 0.8  # ì„ê³„ê°’ ì™„í™”
            )
            
            # 2. CLIP ê²€ìƒ‰
            logger.info(f"[HYBRID] CLIP ê²€ìƒ‰ ì‹œì‘ (weight={clip_weight})")
            clip_results = await self.search_multimodal_clip(
                query=query_text,
                session=session,
                query_type="text",
                top_k=top_k * 2,
                container_ids=container_ids,
                file_ids=file_ids,
                similarity_threshold=similarity_threshold * 0.8
            )
            
            # 3. ê²°ê³¼ í†µí•© (chunk_id ê¸°ì¤€)
            merged_results = {}
            
            # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
            for result in text_results:
                chunk_id = result['chunk_id']
                merged_results[chunk_id] = {
                    **result,
                    'text_score': result['similarity_score'],
                    'clip_score': 0.0,
                    'hybrid_score': result['similarity_score'] * text_weight
                }
            
            # CLIP ê²€ìƒ‰ ê²°ê³¼ ë³‘í•©
            for result in clip_results:
                chunk_id = result['chunk_id']
                clip_score = result['similarity_score']
                
                if chunk_id in merged_results:
                    # ì´ë¯¸ ìˆëŠ” ê²½ìš° CLIP ì ìˆ˜ ì¶”ê°€
                    merged_results[chunk_id]['clip_score'] = clip_score
                    merged_results[chunk_id]['hybrid_score'] += clip_score * clip_weight
                else:
                    # ìƒˆë¡œìš´ ê²½ìš° ì¶”ê°€
                    merged_results[chunk_id] = {
                        **result,
                        'text_score': 0.0,
                        'clip_score': clip_score,
                        'hybrid_score': clip_score * clip_weight
                    }
            
            # 4. í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ë¡œ ì •ë ¬
            sorted_results = sorted(
                merged_results.values(),
                key=lambda x: x['hybrid_score'],
                reverse=True
            )[:top_k]
            
            # 5. ìµœì¢… í•„í„°ë§ (ì„ê³„ê°’)
            filtered_results = [
                result for result in sorted_results
                if result['hybrid_score'] >= similarity_threshold
            ]
            
            logger.info(f"[HYBRID] ê²€ìƒ‰ ì™„ë£Œ: í…ìŠ¤íŠ¸={len(text_results)}, CLIP={len(clip_results)}, í†µí•©={len(filtered_results)}ê°œ")
            return filtered_results
            
        except Exception as e:
            logger.error(f"[HYBRID] ê²€ìƒ‰ ì‹¤íŒ¨: {e}", exc_info=True)
            return []

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
multimodal_search_service = MultimodalSearchService()