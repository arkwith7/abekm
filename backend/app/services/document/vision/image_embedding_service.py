"""CLIP ê¸°ë°˜ ì´ë¯¸ì§€ ì„ë² ë”© ì„œë¹„ìŠ¤

ë¡œì»¬ CLIP ë˜ëŠ” Azure CLIP ëª¨ë¸ì„ ì‚¬ìš©í•œ ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ìƒì„±:
1) ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± (512d)
2) í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (512d) - í¬ë¡œìŠ¤ ëª¨ë‹¬ ê²€ìƒ‰
3) Perceptual Hash (pHash) ìƒì„±
4) ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

íŠ¹ì§•:
- ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ê°€ ê°™ì€ ë²¡í„° ê³µê°„ì— ë§¤í•‘
- ì‹œê°ì  ìœ ì‚¬ë„ ê²€ìƒ‰ ê°€ëŠ¥
- í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰ ê°€ëŠ¥ (í¬ë¡œìŠ¤ ëª¨ë‹¬)

Fallback ì „ëµ:
1. Azure CLIP API (ìš°ì„ )
2. ë¡œì»¬ Hugging Face CLIP ëª¨ë¸ (ìë™ fallback)
3. Placeholder ì„ë² ë”© (ìµœí›„)
"""

from __future__ import annotations
import io
import base64
from typing import List, Dict, Any, Optional
from PIL import Image
import imagehash
import httpx
import logging

from app.core.config import settings

logger = logging.getLogger(__name__)

try:
    import numpy as np  # noqa
except Exception:  # pragma: no cover
    np = None  # type: ignore

# ë¡œì»¬ CLIP ëª¨ë¸ (Hugging Face)
try:
    from transformers import CLIPProcessor, CLIPModel
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    CLIPProcessor = None
    CLIPModel = None
    torch = None


class ImageEmbeddingService:
    """ë©€í‹°ëª¨ë‹¬ ì´ë¯¸ì§€ ì„ë² ë”© ì„œë¹„ìŠ¤ (Provider ê¸°ë°˜ ë™ì  ì„ íƒ)
    
    âš ï¸ ì¤‘ìš”: ì´ ì„œë¹„ìŠ¤ëŠ” ë©€í‹°ëª¨ë‹¬(ì´ë¯¸ì§€+í…ìŠ¤íŠ¸) ì„ë² ë”© ì „ìš©ì…ë‹ˆë‹¤.
    ì¼ë°˜ í…ìŠ¤íŠ¸ ì„ë² ë”©ì€ EmbeddingServiceë¥¼ ì‚¬ìš©í•˜ì„¸ìš”!
    
    ìš©ë„:
    - ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± (512d)
    - í¬ë¡œìŠ¤ëª¨ë‹¬ ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ì„ë² ë”© (ì´ë¯¸ì§€ì™€ ê°™ì€ ë²¡í„° ê³µê°„)
    - ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¹„êµ
    
    ì§€ì› Provider:
    - bedrock: AWS Bedrock TwelveLabs Marengo (512d) - ë©€í‹°ëª¨ë‹¬ ì „ìš©
    - azure_openai: Azure CLIP (512d) - ë©€í‹°ëª¨ë‹¬ ì „ìš©
    - local: Hugging Face CLIP (fallback)
    
    ì¼ë°˜ í…ìŠ¤íŠ¸ ì„ë² ë”© (ë¬¸ì„œ ì²­í‚¹, RAG ì¿¼ë¦¬):
    - EmbeddingService ì‚¬ìš© â†’ amazon.titan-embed-text-v2:0 (1024d)
    """
    
    def __init__(self, target_dim: int = 512):
        self.target_dim = target_dim
        
        # Provider ì„¤ì • ì½ê¸°
        self.provider = getattr(settings, 'default_embedding_provider', 'bedrock').lower()
        
        # AWS Bedrock ì„¤ì •
        self.use_bedrock = False
        self.bedrock_model_id = None
        self.bedrock_client = None
        if self.provider == 'bedrock':
            self.bedrock_model_id = getattr(settings, 'bedrock_multimodal_embedding_model_id', None)
            self.use_bedrock = bool(self.bedrock_model_id)
            if self.use_bedrock:
                try:
                    import boto3
                    self.bedrock_client = boto3.client(
                        'bedrock-runtime',
                        region_name=settings.aws_region,
                        aws_access_key_id=settings.aws_access_key_id,
                        aws_secret_access_key=settings.aws_secret_access_key
                    )
                    logger.info(f"âœ… AWS Bedrock ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ì´ˆê¸°í™”: {self.bedrock_model_id}")
                except Exception as e:
                    logger.warning(f"âš ï¸ Bedrock ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    self.use_bedrock = False
        
        # Azure CLIP ì„¤ì •
        self.endpoint = settings.azure_openai_multimodal_embedding_endpoint
        self.api_key = settings.azure_openai_multimodal_embedding_api_key
        self.deployment = settings.azure_openai_multimodal_embedding_deployment
        self.use_azure_clip = False
        if self.provider == 'azure_openai':
            self.use_azure_clip = bool(self.endpoint and self.api_key)
            if self.use_azure_clip:
                logger.info(f"âœ… Azure CLIP ì„œë¹„ìŠ¤ ì´ˆê¸°í™”: {self.deployment}")
        
        # ë¡œì»¬ CLIP ëª¨ë¸ ì´ˆê¸°í™” (lazy loading, fallback)
        self.local_clip_model = None
        self.local_clip_processor = None
        self.local_clip_device = "cpu"
        self.local_clip_initialized = False
        self.use_local_clip = TRANSFORMERS_AVAILABLE
        
        # Azure CLIP ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ë¡œì»¬ CLIP ì‚¬ìš©
        self.azure_clip_failed = False
        
        # í˜„ì¬ í™œì„± provider ë¡œê¹…
        if self.use_bedrock:
            logger.info(f"ğŸ¯ ë©€í‹°ëª¨ë‹¬ Provider: AWS Bedrock ({self.bedrock_model_id})")
        elif self.use_azure_clip:
            logger.info(f"ğŸ¯ ë©€í‹°ëª¨ë‹¬ Provider: Azure OpenAI ({self.deployment})")
        elif self.use_local_clip:
            logger.info("ğŸ¯ ë©€í‹°ëª¨ë‹¬ Provider: ë¡œì»¬ CLIP (Hugging Face)")
        else:
            # ëª¨ë“  Providerê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ê²½ê³ 
            logger.warning("âš ï¸ ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© Provider ì—†ìŒ")
            logger.warning("âš ï¸ transformers ë¯¸ì„¤ì¹˜ - pip install transformers torch")
            logger.warning("âš ï¸ ë˜ëŠ” .envì—ì„œ AWS Bedrock/Azure OpenAI ì„¤ì • í•„ìš”")
    
    def _initialize_local_clip(self):
        """ë¡œì»¬ CLIP ëª¨ë¸ ì´ˆê¸°í™” (Lazy Loading)"""
        if self.local_clip_initialized or not self.use_local_clip:
            return
        
        try:
            logger.info("ğŸ”„ ë¡œì»¬ CLIP ëª¨ë¸ ë¡œë”© ì¤‘ (openai/clip-vit-base-patch32)...")
            
            model_name = "openai/clip-vit-base-patch32"
            self.local_clip_processor = CLIPProcessor.from_pretrained(model_name)
            self.local_clip_model = CLIPModel.from_pretrained(model_name)
            
            # GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ ì‚¬ìš©
            if torch and torch.cuda.is_available():
                self.local_clip_device = "cuda"
                self.local_clip_model = self.local_clip_model.to(self.local_clip_device)
                logger.info("âœ… ë¡œì»¬ CLIP ëª¨ë¸ ë¡œë”© ì™„ë£Œ (GPU)")
            else:
                logger.info("âœ… ë¡œì»¬ CLIP ëª¨ë¸ ë¡œë”© ì™„ë£Œ (CPU)")
            
            self.local_clip_initialized = True
            
        except Exception as e:
            logger.error(f"âŒ ë¡œì»¬ CLIP ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.use_local_clip = False
    
    def _generate_local_image_embedding(self, image_bytes: bytes) -> Optional[List[float]]:
        """ë¡œì»¬ CLIPìœ¼ë¡œ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±"""
        try:
            self._initialize_local_clip()
            
            if not self.local_clip_initialized:
                return None
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(io.BytesIO(image_bytes))
            
            with torch.no_grad():
                inputs = self.local_clip_processor(images=image, return_tensors="pt")
                
                if self.local_clip_device == "cuda":
                    inputs = {k: v.to(self.local_clip_device) for k, v in inputs.items()}
                
                image_features = self.local_clip_model.get_image_features(**inputs)
                
                # L2 ì •ê·œí™”
                image_features = image_features / image_features.norm(dim=-1, keepdim=True)
                
                # CPUë¡œ ì´ë™ ë° ë¦¬ìŠ¤íŠ¸ ë³€í™˜
                embedding = image_features.cpu().numpy()[0].tolist()
                
                logger.info(f"âœ… ë¡œì»¬ CLIP ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±: {len(embedding)}d")
                return embedding
                
        except Exception as e:
            logger.error(f"âŒ ë¡œì»¬ CLIP ì´ë¯¸ì§€ ì„ë² ë”© ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_bedrock_image_embedding(self, image_bytes: bytes, caption: Optional[str] = None) -> Optional[List[float]]:
        """AWS Bedrockìœ¼ë¡œ ë©€í‹°ëª¨ë‹¬ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± (TwelveLabs Marengo)
        
        Args:
            image_bytes: ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„°
            caption: ì´ë¯¸ì§€ ìº¡ì…˜ í…ìŠ¤íŠ¸ (ì„ íƒ) - ì œê³µ ì‹œ text_image ëª¨ë“œë¡œ ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ìƒì„±
        
        Returns:
            512ì°¨ì› ì„ë² ë”© ë²¡í„°
        """
        try:
            if not self.use_bedrock or not self.bedrock_client:
                return None
            
            import json
            
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            img_base64 = base64.b64encode(image_bytes).decode('utf-8')
            
            # Bedrock API í˜¸ì¶œ (TwelveLabs Marengo í˜•ì‹)
            if caption and caption.strip():
                # ğŸ¯ ë©€í‹°ëª¨ë‹¬: ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ë™ì‹œ ì„ë² ë”© (text_image)
                request_body = json.dumps({
                    "inputType": "text_image",
                    "text_image": {
                        "inputText": caption.strip(),
                        "mediaSource": {
                            "base64String": img_base64
                        }
                    }
                })
                logger.info(f"[BEDROCK] ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ìš”ì²­ (text_image) - caption: {caption[:50]}...")
            else:
                # ì´ë¯¸ì§€ë§Œ ì„ë² ë”© (image)
                request_body = json.dumps({
                    "inputType": "image",
                    "image": {
                        "mediaSource": {
                            "base64String": img_base64
                        }
                    }
                })
                logger.info(f"[BEDROCK] ì´ë¯¸ì§€ ì„ë² ë”© ìš”ì²­ (image only)")
            
            response = self.bedrock_client.invoke_model(
                modelId=self.bedrock_model_id,
                body=request_body,
                contentType="application/json",
                accept="application/json"
            )
            
            # ì‘ë‹µ íŒŒì‹± (Marengo 3.0 ì‘ë‹µ í˜•ì‹: {"data": {"embedding": [...]}})
            response_body = json.loads(response['body'].read())
            
            # data.embedding ê²½ë¡œë¡œ ì ‘ê·¼
            embedding = None
            if 'data' in response_body:
                data = response_body['data']
                if isinstance(data, dict):
                    embedding = data.get('embedding')
                elif isinstance(data, list) and len(data) > 0:
                    embedding = data[0].get('embedding')
            elif 'embedding' in response_body:
                # í˜¸í™˜ì„±: ì§ì ‘ embedding í•„ë“œ
                embedding = response_body['embedding']
            
            if embedding and isinstance(embedding, list):
                mode_str = "text_image (ë©€í‹°ëª¨ë‹¬)" if caption else "image"
                logger.info(f"âœ… Bedrock {mode_str} ì„ë² ë”©: {len(embedding)}d ({self.bedrock_model_id})")
                return embedding
            else:
                logger.warning(f"âš ï¸ Bedrock ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {response_body}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ Bedrock ë©€í‹°ëª¨ë‹¬ ì´ë¯¸ì§€ ì„ë² ë”© ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_bedrock_text_embedding(self, text: str) -> Optional[List[float]]:
        """AWS Bedrockìœ¼ë¡œ ë©€í‹°ëª¨ë‹¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (TwelveLabs Marengo)
        
        âš ï¸ ì£¼ì˜: ì´ ë©”ì„œë“œëŠ” í¬ë¡œìŠ¤ëª¨ë‹¬ ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ì„ë² ë”© ì „ìš©ì…ë‹ˆë‹¤.
        ì¼ë°˜ í…ìŠ¤íŠ¸ ì„ë² ë”©(ë¬¸ì„œ ì²­í‚¹, RAG ì¿¼ë¦¬)ì€ EmbeddingServiceë¥¼ ì‚¬ìš©í•˜ì„¸ìš”!
        """
        try:
            if not self.use_bedrock or not self.bedrock_client:
                return None
            
            import json
            
            # Bedrock API í˜¸ì¶œ (TwelveLabs Marengo í˜•ì‹)
            request_body = json.dumps({
                "inputType": "text",
                "text": {
                    "inputText": text
                }
            })
            
            response = self.bedrock_client.invoke_model(
                modelId=self.bedrock_model_id,
                body=request_body,
                contentType="application/json",
                accept="application/json"
            )
            
            # ì‘ë‹µ íŒŒì‹± (Marengo 3.0 ì‘ë‹µ í˜•ì‹: {"data": {"embedding": [...]}})
            response_body = json.loads(response['body'].read())
            
            # data.embedding ê²½ë¡œë¡œ ì ‘ê·¼
            embedding = None
            if 'data' in response_body:
                data = response_body['data']
                if isinstance(data, dict):
                    embedding = data.get('embedding')
                elif isinstance(data, list) and len(data) > 0:
                    embedding = data[0].get('embedding')
            elif 'embedding' in response_body:
                # í˜¸í™˜ì„±: ì§ì ‘ embedding í•„ë“œ
                embedding = response_body['embedding']
            
            if embedding and isinstance(embedding, list):
                logger.info(f"âœ… Bedrock ë©€í‹°ëª¨ë‹¬ í…ìŠ¤íŠ¸ ì„ë² ë”©: {len(embedding)}d ({self.bedrock_model_id}) - í¬ë¡œìŠ¤ëª¨ë‹¬ ê²€ìƒ‰ìš©")
                return embedding
            else:
                logger.warning(f"âš ï¸ Bedrock ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {response_body}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ Bedrock ë©€í‹°ëª¨ë‹¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ì‹¤íŒ¨: {e}")
            return None
    
    def _generate_local_text_embedding(self, text: str) -> Optional[List[float]]:
        """ë¡œì»¬ CLIPìœ¼ë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        try:
            self._initialize_local_clip()
            
            if not self.local_clip_initialized:
                return None
            
            with torch.no_grad():
                inputs = self.local_clip_processor(text=[text], return_tensors="pt", padding=True)
                
                if self.local_clip_device == "cuda":
                    inputs = {k: v.to(self.local_clip_device) for k, v in inputs.items()}
                
                text_features = self.local_clip_model.get_text_features(**inputs)
                
                # L2 ì •ê·œí™”
                text_features = text_features / text_features.norm(dim=-1, keepdim=True)
                
                # CPUë¡œ ì´ë™ ë° ë¦¬ìŠ¤íŠ¸ ë³€í™˜
                embedding = text_features.cpu().numpy()[0].tolist()
                
                logger.info(f"âœ… ë¡œì»¬ CLIP í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±: {len(embedding)}d")
                return embedding
                
        except Exception as e:
            logger.error(f"âŒ ë¡œì»¬ CLIP í…ìŠ¤íŠ¸ ì„ë² ë”© ì‹¤íŒ¨: {e}")
            return None

    def compute_phash(self, img: Image.Image) -> str:
        """Perceptual Hash ìƒì„±"""
        return str(imagehash.phash(img))

    async def generate_image_embedding(
        self, 
        image_path: Optional[str] = None,
        image_bytes: Optional[bytes] = None,
        caption: Optional[str] = None
    ) -> Optional[List[float]]:
        """ë©€í‹°ëª¨ë‹¬ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± (Provider ê¸°ë°˜ ë™ì  ì„ íƒ)
        
        ìš°ì„ ìˆœìœ„:
        1. AWS Bedrock TwelveLabs Marengo (provider=bedrock) â†’ 512d
        2. Azure CLIP (provider=azure_openai) â†’ 512d
        3. ë¡œì»¬ CLIP (fallback) â†’ 512d
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            image_bytes: ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„°
            caption: ì´ë¯¸ì§€ ìº¡ì…˜ í…ìŠ¤íŠ¸ (ì„ íƒ) - "Figure 1. Diagram...", "Table 2. Results..."
            
        Returns:
            512ì°¨ì› ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ë²¡í„° ë˜ëŠ” None
        """
        # ì´ë¯¸ì§€ ë°ì´í„° ì¤€ë¹„
        if image_path:
            with open(image_path, "rb") as f:
                img_data = f.read()
        elif image_bytes:
            img_data = image_bytes
        else:
            raise ValueError("image_path ë˜ëŠ” image_bytes ì¤‘ í•˜ë‚˜ í•„ìš”")
        
        # 1ë‹¨ê³„: AWS Bedrock ì‹œë„ (provider=bedrock) - ìº¡ì…˜ í¬í•¨ ê°€ëŠ¥
        if self.use_bedrock:
            embedding = self._generate_bedrock_image_embedding(img_data, caption=caption)
            if embedding:
                return embedding
            logger.warning("âš ï¸ Bedrock ì‹¤íŒ¨, ë‹¤ìŒ ë°©ë²• ì‹œë„...")
        
        # 2ë‹¨ê³„: Azure CLIP ì‹œë„ (provider=azure_openai, ì‹¤íŒ¨ ì „ë ¥ ì—†ì„ ë•Œë§Œ)
        if self.use_azure_clip and not self.azure_clip_failed:
            try:
                # Base64 ì¸ì½”ë”©
                img_base64 = base64.b64encode(img_data).decode("utf-8")
                
                # Azure CLIP API í˜¸ì¶œ (image + text í•„ë“œ ëª¨ë‘ í•„ìš”)
                async with httpx.AsyncClient() as client:
                    response = await client.post(
                        self.endpoint,
                        headers={
                            "Content-Type": "application/json",
                            "Accept": "application/json",
                            "Authorization": f"Bearer {self.api_key}"
                        },
                        json={
                            "input_data": {
                                "columns": ["image", "text"],  # ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” ìŠ¤í‚¤ë§ˆ
                                "data": [[img_base64, ""]]     # textëŠ” ë¹ˆ ë¬¸ìì—´ (ì´ë¯¸ì§€ë§Œ ì„ë² ë”©)
                            }
                        },
                        timeout=30.0
                    )
                    response.raise_for_status()
                    result = response.json()
                
                # ì‘ë‹µ íŒŒì‹±: [{"image_features": [...], "text_features": [...]}] í˜•ì‹
                embedding = None
                if isinstance(result, list) and len(result) > 0:
                    first_item = result[0]
                    if isinstance(first_item, dict):
                        # image_features ì¶”ì¶œ (ì´ë¯¸ì§€ ì„ë² ë”©)
                        embedding = first_item.get("image_features")
                    elif isinstance(first_item, list):
                        # ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì¸ ê²½ìš°
                        embedding = first_item
                elif isinstance(result, dict):
                    # dict ì‘ë‹µì¸ ê²½ìš°
                    embedding = (result.get("image_features") or
                               result.get("output", [[]])[0] or 
                               result.get("embedding") or
                               result.get("data", [[]])[0])
                
                if embedding and isinstance(embedding, list) and len(embedding) > 0:
                    logger.info(f"âœ… Azure CLIP ì´ë¯¸ì§€ ì„ë² ë”©: {len(embedding)}d")
                    return embedding
                else:
                    logger.warning(f"âš ï¸ Azure CLIP ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {type(result)}, Fallback ì‹œë„...")
                    self.azure_clip_failed = True
                    
            except httpx.HTTPStatusError as e:
                logger.warning(f"âš ï¸ Azure CLIP API ì˜¤ë¥˜ (HTTP {e.response.status_code}), Fallback ì‹œë„...")
                self.azure_clip_failed = True  # ì´í›„ ìš”ì²­ì€ ë°”ë¡œ ë¡œì»¬ CLIP ì‚¬ìš©
            except Exception as e:
                logger.warning(f"âš ï¸ Azure CLIP ì‹¤íŒ¨: {str(e)[:100]}, Fallback ì‹œë„...")
                self.azure_clip_failed = True
        
        # 3ë‹¨ê³„: ë¡œì»¬ CLIP Fallback
        if self.use_local_clip:
            embedding = self._generate_local_image_embedding(img_data)
            if embedding:
                return embedding
        
        # 3ë‹¨ê³„: Placeholder (ìµœí›„ì˜ ìˆ˜ë‹¨)
        logger.warning("âš ï¸ CLIP ì‚¬ìš© ë¶ˆê°€ - placeholder ì„ë² ë”© ë°˜í™˜")
        return await self._generate_placeholder_embedding(image_path, image_bytes)

    async def generate_text_embedding(self, text: str) -> Optional[List[float]]:
        """ë©€í‹°ëª¨ë‹¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (í¬ë¡œìŠ¤ëª¨ë‹¬ ê²€ìƒ‰ ì „ìš©)
        
        âš ï¸ ì¤‘ìš”: ì´ ë©”ì„œë“œëŠ” í¬ë¡œìŠ¤ëª¨ë‹¬ ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ì„ë² ë”© ì „ìš©ì…ë‹ˆë‹¤!
        - ìš©ë„: í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰ (ì´ë¯¸ì§€ì™€ ê°™ì€ 512d ë²¡í„° ê³µê°„)
        - ì¼ë°˜ í…ìŠ¤íŠ¸ ì„ë² ë”©(ë¬¸ì„œ ì²­í‚¹, RAG ì¿¼ë¦¬)ì€ EmbeddingService ì‚¬ìš©!
        
        ìš°ì„ ìˆœìœ„:
        1. AWS Bedrock TwelveLabs Marengo (provider=bedrock) â†’ 512d
        2. Azure CLIP (provider=azure_openai) â†’ 512d
        3. ë¡œì»¬ CLIP (fallback) â†’ 512d
        
        ì¼ë°˜ í…ìŠ¤íŠ¸ ì„ë² ë”© (RAG ì‹œìŠ¤í…œ):
        - EmbeddingService.get_embedding() ì‚¬ìš©
        - amazon.titan-embed-text-v2:0 â†’ 1024d
        
        Args:
            text: í¬ë¡œìŠ¤ëª¨ë‹¬ ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ì¿¼ë¦¬
            
        Returns:
            512ì°¨ì› ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© ë²¡í„° ë˜ëŠ” None
        """
        # 1ë‹¨ê³„: AWS Bedrock ì‹œë„ (provider=bedrock)
        if self.use_bedrock:
            embedding = self._generate_bedrock_text_embedding(text)
            if embedding:
                return embedding
            logger.warning("âš ï¸ Bedrock í…ìŠ¤íŠ¸ ì„ë² ë”© ì‹¤íŒ¨, Fallback ì‹œë„...")
        
        # 2ë‹¨ê³„: Azure CLIP ì‹œë„ (provider=azure_openai, ì‹¤íŒ¨ ì „ë ¥ ì—†ì„ ë•Œë§Œ)
        if self.use_azure_clip and not self.azure_clip_failed:
            try:
                # Azure CLIP API í˜¸ì¶œ (image + text í•„ë“œ ëª¨ë‘ í•„ìš”)
                # í…ìŠ¤íŠ¸ë§Œ ì„ë² ë”©í•  ë•ŒëŠ” imageë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ì „ì†¡
                async with httpx.AsyncClient() as client:
                    response = await client.post(
                        self.endpoint,
                        headers={
                            "Content-Type": "application/json",
                            "Accept": "application/json",
                            "Authorization": f"Bearer {self.api_key}"
                        },
                        json={
                            "input_data": {
                                "columns": ["image", "text"],  # ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” ìŠ¤í‚¤ë§ˆ
                                "data": [["", text]]           # imageëŠ” ë¹ˆ ë¬¸ìì—´ (í…ìŠ¤íŠ¸ë§Œ ì„ë² ë”©)
                            }
                        },
                        timeout=30.0
                    )
                    response.raise_for_status()
                    result = response.json()
                
                # ì‘ë‹µ íŒŒì‹±: [{"image_features": [...], "text_features": [...]}] í˜•ì‹
                embedding = None
                if isinstance(result, list) and len(result) > 0:
                    first_item = result[0]
                    if isinstance(first_item, dict):
                        # text_features ì¶”ì¶œ (í…ìŠ¤íŠ¸ ì„ë² ë”©)
                        embedding = first_item.get("text_features")
                    elif isinstance(first_item, list):
                        embedding = first_item
                elif isinstance(result, dict):
                    embedding = (result.get("text_features") or
                               result.get("output", [[]])[0] or 
                               result.get("embedding") or
                               result.get("data", [[]])[0])
                
                if embedding and isinstance(embedding, list) and len(embedding) > 0:
                    logger.info(f"âœ… Azure CLIP í…ìŠ¤íŠ¸ ì„ë² ë”©: {len(embedding)}d")
                    return embedding
                else:
                    embedding = None
                
                if embedding:
                    logger.info(f"âœ… Azure CLIP í…ìŠ¤íŠ¸ ì„ë² ë”©: {len(embedding)}d")
                    return embedding
                    
            except httpx.HTTPStatusError as e:
                logger.warning(f"âš ï¸ Azure CLIP API ì˜¤ë¥˜ (HTTP {e.response.status_code}), Fallback ì‹œë„...")
                self.azure_clip_failed = True
            except Exception as e:
                logger.warning(f"âš ï¸ Azure CLIP ì‹¤íŒ¨: {str(e)[:100]}, Fallback ì‹œë„...")
                self.azure_clip_failed = True
        
        # 3ë‹¨ê³„: ë¡œì»¬ CLIP Fallback
        if self.use_local_clip:
            embedding = self._generate_local_text_embedding(text)
            if embedding:
                return embedding
        
        # 4ë‹¨ê³„: None ë°˜í™˜ (í…ìŠ¤íŠ¸ëŠ” placeholder ì—†ìŒ)
        logger.warning("âš ï¸ CLIP í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ë¶ˆê°€")
        return None

    async def _generate_placeholder_embedding(
        self,
        image_path: Optional[str] = None,
        image_bytes: Optional[bytes] = None
    ) -> List[float]:
        """Placeholder ì„ë² ë”© ìƒì„± (Azure CLIP ë¯¸ì„¤ì • ì‹œ)"""
        if image_path:
            with open(image_path, "rb") as f:
                img_bytes = f.read()
        elif image_bytes:
            img_bytes = image_bytes
        else:
            return [0.0] * self.target_dim
        
        with Image.open(io.BytesIO(img_bytes)) as img:
            h = self.compute_phash(img)
            ints = [int(h[i:i+2], 16) for i in range(0, len(h), 2)]
            vec = (ints * (self.target_dim // len(ints) + 1))[: self.target_dim]
            max_v = max(vec) or 1
            return [v / max_v for v in vec]

    async def extract_features(
        self, 
        img_bytes: bytes,
        generate_embedding: bool = True
    ) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
        
        Args:
            img_bytes: ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„°
            generate_embedding: ì„ë² ë”© ìƒì„± ì—¬ë¶€
            
        Returns:
            {
                "phash": str,
                "embedding": List[float],
                "width": int,
                "height": int,
                "aspect_ratio": float,
                "vector_dimension": int
            }
        """
        with Image.open(io.BytesIO(img_bytes)) as im:
            im = im.convert('RGB')
            phash = self.compute_phash(im)
            
            # ì„ë² ë”© ìƒì„±
            embedding = None
            if generate_embedding:
                embedding = await self.generate_image_embedding(image_bytes=img_bytes)
            
            return {
                "phash": phash,
                "embedding": embedding,
                "width": im.width,
                "height": im.height,
                "aspect_ratio": round(im.width / im.height, 4) if im.height else None,
                "vector_dimension": len(embedding) if embedding else None
            }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
image_embedding_service = ImageEmbeddingService()
