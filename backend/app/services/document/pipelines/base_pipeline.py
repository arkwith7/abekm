"""
ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ í´ë˜ìŠ¤
"""
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


class DocumentPipeline(ABC):
    """
    ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì¶”ìƒ í´ë˜ìŠ¤
    
    ëª¨ë“  ë¬¸ì„œ ìœ í˜•ë³„ íŒŒì´í”„ë¼ì¸ì€ ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ êµ¬í˜„í•´ì•¼ í•¨.
    Template Method íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ê³µí†µ ì²˜ë¦¬ íë¦„ì„ ì •ì˜í•˜ê³ ,
    ìœ í˜•ë³„ íŠ¹í™” ë¡œì§ì€ ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„.
    
    ì²˜ë¦¬ ë‹¨ê³„:
    1. extract: ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    2. chunk: ì¶”ì¶œëœ ì½˜í…ì¸ ë¥¼ ê²€ìƒ‰ ê°€ëŠ¥í•œ ì²­í¬ë¡œ ë¶„í• 
    3. embed: ì²­í¬ë¥¼ ë²¡í„°ë¡œ ì„ë² ë”©
    4. index: ë²¡í„° DBì— ì¸ë±ì‹±
    """
    
    def __init__(
        self,
        document_id: int,
        file_path: str,
        file_name: str,
        container_id: str,
        processing_options: Dict[str, Any],
        user_emp_no: str
    ):
        """
        íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            document_id: ë¬¸ì„œ ID (file_bss_info_sno)
            file_path: ë¬¸ì„œ íŒŒì¼ ê²½ë¡œ (ë¡œì»¬ or S3/Blob)
            file_name: ë¬¸ì„œ íŒŒì¼ëª…
            container_id: ì»¨í…Œì´ë„ˆ ID
            processing_options: ë¬¸ì„œ ìœ í˜•ë³„ ì²˜ë¦¬ ì˜µì…˜
            user_emp_no: ì‚¬ìš©ì ì‚¬ë²ˆ
        """
        self.document_id = document_id
        self.file_path = file_path
        self.file_name = file_name
        self.container_id = container_id
        self.processing_options = processing_options or {}
        self.user_emp_no = user_emp_no
        
        # íŒŒì¼ í™•ì¥ì
        self.file_extension = Path(file_name).suffix.lower()
        
        logger.info(f"ğŸ­ [{self.__class__.__name__}] íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”: {file_name}")
        logger.info(f"   ğŸ“„ ë¬¸ì„œ ID: {document_id}")
        logger.info(f"   ğŸ“ ì»¨í…Œì´ë„ˆ: {container_id}")
        logger.info(f"   âš™ï¸ ì²˜ë¦¬ ì˜µì…˜: {processing_options}")
    
    async def process(self) -> Dict[str, Any]:
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Template Method)
        
        Returns:
            Dict containing:
                - success: bool
                - statistics: Dict with processing stats
                - error: Optional error message
        """
        logger.info(f"ğŸš€ [{self.__class__.__name__}] íŒŒì´í”„ë¼ì¸ ì‹œì‘: {self.file_name}")
        
        try:
            # 1ë‹¨ê³„: ë¬¸ì„œì—ì„œ ê°ì²´ ì¶”ì¶œ
            logger.info(f"ğŸ“¤ [{self.__class__.__name__}] 1ë‹¨ê³„: ê°ì²´ ì¶”ì¶œ")
            extraction_result = await self.extract()
            
            if not extraction_result.get("success"):
                return {
                    "success": False,
                    "error": f"ì¶”ì¶œ ì‹¤íŒ¨: {extraction_result.get('error')}",
                    "statistics": {}
                }
            
            # 2ë‹¨ê³„: ì²­í‚¹
            logger.info(f"âœ‚ï¸ [{self.__class__.__name__}] 2ë‹¨ê³„: ì²­í‚¹")
            chunking_result = await self.chunk(extraction_result)
            
            if not chunking_result.get("success"):
                return {
                    "success": False,
                    "error": f"ì²­í‚¹ ì‹¤íŒ¨: {chunking_result.get('error')}",
                    "statistics": {}
                }
            
            # 3ë‹¨ê³„: ì„ë² ë”©
            logger.info(f"ğŸ”¢ [{self.__class__.__name__}] 3ë‹¨ê³„: ì„ë² ë”©")
            embedding_result = await self.embed(chunking_result)
            
            if not embedding_result.get("success"):
                return {
                    "success": False,
                    "error": f"ì„ë² ë”© ì‹¤íŒ¨: {embedding_result.get('error')}",
                    "statistics": {}
                }
            
            # 4ë‹¨ê³„: ì¸ë±ì‹±
            logger.info(f"ğŸ’¾ [{self.__class__.__name__}] 4ë‹¨ê³„: ì¸ë±ì‹±")
            indexing_result = await self.index(embedding_result)
            
            if not indexing_result.get("success"):
                return {
                    "success": False,
                    "error": f"ì¸ë±ì‹± ì‹¤íŒ¨: {indexing_result.get('error')}",
                    "statistics": {}
                }
            
            # í†µê³„ ì§‘ê³„
            statistics = self._aggregate_statistics(
                extraction_result,
                chunking_result,
                embedding_result,
                indexing_result
            )
            
            logger.info(f"âœ… [{self.__class__.__name__}] íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            logger.info(f"   ğŸ“Š í†µê³„: {statistics}")
            
            return {
                "success": True,
                "statistics": statistics
            }
            
        except Exception as e:
            logger.error(f"âŒ [{self.__class__.__name__}] íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "statistics": {}
            }
    
    @abstractmethod
    async def extract(self) -> Dict[str, Any]:
        """
        ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        
        Returns:
            Dict containing:
                - success: bool
                - extracted_objects: List[Dict] - ì¶”ì¶œëœ ê°ì²´ë“¤
                - metadata: Dict - ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
                - error: Optional error message
        """
        pass
    
    @abstractmethod
    async def chunk(self, extraction_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì¶”ì¶œëœ ê°ì²´ë“¤ì„ ê²€ìƒ‰ ê°€ëŠ¥í•œ ì²­í¬ë¡œ ë¶„í• 
        
        Args:
            extraction_result: extract() ë©”ì„œë“œì˜ ë°˜í™˜ê°’
        
        Returns:
            Dict containing:
                - success: bool
                - chunks: List[Dict] - ì²­í¬ ë¦¬ìŠ¤íŠ¸
                - error: Optional error message
        """
        pass
    
    @abstractmethod
    async def embed(self, chunking_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì²­í¬ë“¤ì„ ë²¡í„°ë¡œ ì„ë² ë”©
        
        Args:
            chunking_result: chunk() ë©”ì„œë“œì˜ ë°˜í™˜ê°’
        
        Returns:
            Dict containing:
                - success: bool
                - embeddings: List[Dict] - ì„ë² ë”©ëœ ì²­í¬ë“¤
                - error: Optional error message
        """
        pass
    
    @abstractmethod
    async def index(self, embedding_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì„ë² ë”©ëœ ì²­í¬ë“¤ì„ ë²¡í„° DBì— ì¸ë±ì‹±
        
        Args:
            embedding_result: embed() ë©”ì„œë“œì˜ ë°˜í™˜ê°’
        
        Returns:
            Dict containing:
                - success: bool
                - indexed_count: int - ì¸ë±ì‹±ëœ ì²­í¬ ìˆ˜
                - error: Optional error message
        """
        pass
    
    def _aggregate_statistics(
        self,
        extraction_result: Dict[str, Any],
        chunking_result: Dict[str, Any],
        embedding_result: Dict[str, Any],
        indexing_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ê° ë‹¨ê³„ì˜ í†µê³„ ì§‘ê³„
        
        Returns:
            Dict with aggregated statistics
        """
        return {
            "total_objects_extracted": len(extraction_result.get("extracted_objects", [])),
            "total_chunks": len(chunking_result.get("chunks", [])),
            "total_embeddings": len(embedding_result.get("embeddings", [])),
            "total_indexed": indexing_result.get("indexed_count", 0),
            "pipeline_type": self.__class__.__name__
        }
    
    def _get_option(self, key: str, default: Any = None) -> Any:
        """
        ì²˜ë¦¬ ì˜µì…˜ ê°’ ê°€ì ¸ì˜¤ê¸° (í—¬í¼ ë©”ì„œë“œ)
        
        Args:
            key: ì˜µì…˜ í‚¤
            default: ê¸°ë³¸ê°’
        
        Returns:
            ì˜µì…˜ ê°’ ë˜ëŠ” ê¸°ë³¸ê°’
        """
        return self.processing_options.get(key, default)
