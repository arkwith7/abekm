"""
ğŸ“„ WKMS ë¬¸ì„œ ì„œë¹„ìŠ¤
===================

ğŸ¯ ëª©ì : ë¬¸ì„œ CRUD ë° íŒŒì¼ ì‹œìŠ¤í…œ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í•µì‹¬ ì„œë¹„ìŠ¤

ğŸ”— ê´€ê³„ë„:
```
v1/documents.py (API Layer)
    â†“ í˜¸ì¶œ
document_service.py (Business Logic)
    â†“ ë°ì´í„° ì ‘ê·¼
TbFileBssInfo, TbFileDtlInfo (Data Layer)
    â†“ ì €ì¥
PostgreSQL Database
```

ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥:
- create_document_fro            # ğŸ”„ 2ë‹¨ê³„: ìƒˆë¡œìš´ í†µí•© RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            try:
                logger.info(f"ğŸ”„ [DOC-SERVICE-DEBUG] 2ë‹¨ê³„ RAG íŒŒì´í”„ë¼ì¸ ì‹œì‘")pload(): ì—…ë¡œë“œëœ íŒŒì¼ì˜ ë¬¸ì„œ ìƒì„±
- delete_document_by_id(): ë¬¸ì„œ ì†Œí”„íŠ¸ ì‚­ì œ
- get_document(): ë¬¸ì„œ ì¡°íšŒ
- list_documents(): ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ

ğŸ”„ í™•ì¥ ê³„íš:
- ë¬¸ì„œ ë²„ì „ ê´€ë¦¬
- ìë™ ë°±ì—… ë° ë³µì›
- ë¬¸ì„œ í†µê³„ ë¶„ì„
"""

import os
from pathlib import Path
import aiofiles
import logging
from typing import List, Optional
from fastapi import UploadFile
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update, delete

logger = logging.getLogger(__name__)
from app.models import TbFileBssInfo, TbFileDtlInfo
from app.schemas.chat import DocumentCreate, DocumentResponse
from app.services.core.embedding_service import EmbeddingService
from app.services.core.korean_nlp_service import KoreanNLPService
from app.services.document.storage.vector_embedding_service import VectorEmbeddingService
from app.services.auth.notification_service import NotificationService
from app.core.config import settings

try:
    from app.utils.storage_paths import classify_key_scheme as _classify_key_scheme
except Exception:
    _classify_key_scheme = lambda k: 'unknown'

class DocumentService:
    def __init__(self, db: Optional[AsyncSession] = None):
        self.db = db
        try:
            self.embedding_service = EmbeddingService()
            self.korean_nlp_service = KoreanNLPService()
            self.vector_embedding_service = VectorEmbeddingService()
            self.notification_service = NotificationService()
        except Exception as e:
            logger.warning(f"DocumentService ì´ˆê¸°í™” ì¤‘ ì¼ë¶€ ì„œë¹„ìŠ¤ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
            # í•„ìˆ˜ê°€ ì•„ë‹Œ ì„œë¹„ìŠ¤ë“¤ì´ë¯€ë¡œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            self.embedding_service = None
            self.korean_nlp_service = None
            self.vector_embedding_service = None
            self.notification_service = None
    
    async def create_document(self, document_data: DocumentCreate) -> DocumentResponse:
        """
        ìƒˆ ë¬¸ì„œ ìƒì„± - tb_file_bss_info í…Œì´ë¸” ì‚¬ìš©
        """
        try:
            # íŒŒì¼ ê¸°ë³¸ ì •ë³´ ìƒì„±
            file_bss_info = TbFileBssInfo(
                file_lgc_nm=document_data.title,
                file_psl_nm=document_data.file_path.split('/')[-1] if document_data.file_path else document_data.title,
                file_extsn=document_data.file_path.split('.')[-1] if '.' in document_data.file_path else 'txt',
                path=document_data.file_path,
                korean_metadata=document_data.metadata or {},
                drcy_sno=1,  # ê¸°ë³¸ ë””ë ‰í† ë¦¬
                created_by="system",
                last_modified_by="system"
            )
            
            self.db.add(file_bss_info)
            await self.db.flush()  # ID ìƒì„±ì„ ìœ„í•´ flush
            
            # íŒŒì¼ ìƒì„¸ ì •ë³´ ìƒì„±
            file_dtl_info = TbFileDtlInfo(
                file_bss_info_sno=file_bss_info.file_bss_info_sno,
                content_text=document_data.content,
                document_title=document_data.title,
                metadata_json=document_data.metadata or {}
            )
            
            self.db.add(file_dtl_info)
            await self.db.commit()
            await self.db.refresh(file_bss_info)
            
            return DocumentResponse(
                id=str(file_bss_info.file_bss_info_sno),
                title=file_bss_info.file_lgc_nm,
                content=document_data.content,
                file_path=file_bss_info.path,
                metadata=file_bss_info.korean_metadata,
                created_at=file_bss_info.created_date,
                updated_at=file_bss_info.last_modified_date
            )
            
        except Exception as e:
            await self.db.rollback()
            raise e
    
    async def upload_and_process_file(self, file: UploadFile) -> DocumentResponse:
        """
        íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬
        """
        try:
            # ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(settings.UPLOAD_DIR, exist_ok=True)
            
            # íŒŒì¼ ì €ì¥
            file_path = os.path.join(settings.UPLOAD_DIR, file.filename)
            async with aiofiles.open(file_path, 'wb') as f:
                content = await file.read()
                await f.write(content)
            
            # íŒŒì¼ ë‚´ìš© ì½ê¸° (í…ìŠ¤íŠ¸ íŒŒì¼ì¸ ê²½ìš°)
            file_content = ""
            if file.filename.endswith(('.txt', '.md', '.py', '.js', '.html', '.css')):
                async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                    file_content = await f.read()
            else:
                # ë°”ì´ë„ˆë¦¬ íŒŒì¼ì˜ ê²½ìš° íŒŒì¼ëª…ê³¼ ê¸°ë³¸ ì •ë³´ë§Œ ì €ì¥
                file_content = f"íŒŒì¼ëª…: {file.filename}\níŒŒì¼ í¬ê¸°: {len(content)} bytes"
            
            # ë¬¸ì„œ ìƒì„±
            document_data = DocumentCreate(
                title=file.filename,
                content=file_content,
                file_path=file_path,
                metadata={
                    "original_filename": file.filename,
                    "file_size": len(content),
                    "content_type": file.content_type
                }
            )
            
            return await self.create_document(document_data)
            
        except Exception as e:
            # ì—…ë¡œë“œ ì‹¤íŒ¨ ì‹œ íŒŒì¼ ì‚­ì œ
            if 'file_path' in locals() and os.path.exists(file_path):
                os.remove(file_path)
            raise e
    
    async def get_document(self, document_id: str) -> Optional[DocumentResponse]:
        """
        ë¬¸ì„œ ì¡°íšŒ - tb_file_bss_info í…Œì´ë¸” ì‚¬ìš©
        """
        try:
            stmt = select(TbFileBssInfo).where(TbFileBssInfo.file_bss_info_sno == int(document_id))
            result = await self.db.execute(stmt)
            file_info = result.scalar_one_or_none()
            
            if not file_info:
                return None
            
            return DocumentResponse(
                id=str(file_info.file_bss_info_sno),
                title=file_info.file_lgc_nm,
                content="",  # ìƒì„¸ ë‚´ìš©ì€ ë³„ë„ ì¡°íšŒ í•„ìš”
                file_path=file_info.path,
                metadata=file_info.korean_metadata or {},
                created_at=file_info.created_date,
                updated_at=file_info.last_modified_date
            )
            
        except Exception as e:
            logger.error(f"Error getting document: {e}")
            return None
    
    async def list_documents(self, skip: int = 0, limit: int = 100) -> List[DocumentResponse]:
        """
        ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ - tb_file_bss_info í…Œì´ë¸” ì‚¬ìš©
        """
        try:
            stmt = (select(TbFileBssInfo)
                   .where(TbFileBssInfo.del_yn == 'N')
                   .offset(skip)
                   .limit(limit)
                   .order_by(TbFileBssInfo.created_date.desc()))
            result = await self.db.execute(stmt)
            file_infos = result.scalars().all()
            
            return [
                DocumentResponse(
                    id=str(file_info.file_bss_info_sno),
                    title=file_info.file_lgc_nm,
                    content="",  # ëª©ë¡ì—ì„œëŠ” ë‚´ìš© ì œì™¸
                    file_path=file_info.path,
                    metadata=file_info.korean_metadata or {},
                    created_at=file_info.created_date,
                    updated_at=file_info.last_modified_date
                ) for file_info in file_infos
            ]
            
        except Exception as e:
            logger.error(f"Error listing documents: {e}")
            return []

    async def create_document_basic_info(
        self,
        file_path: str,
        file_name: str,
        file_size: int,
        file_extension: str,
        user_emp_no: str,
        container_id: str,
        session: AsyncSession,
        processing_status: str = 'pending',
        document_type: str = 'general',  # âœ… ì¶”ê°€
        processing_options: Optional[dict] = None  # âœ… ì¶”ê°€
    ) -> dict:
        """
        ë¬¸ì„œ ê¸°ë³¸ ì •ë³´ë§Œ DBì— ì €ì¥ (RAG íŒŒì´í”„ë¼ì¸ ì œì™¸)
        ë¹„ë™ê¸° ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ë¥¼ ìœ„í•œ ê²½ëŸ‰ ë²„ì „
        
        Args:
            file_path: DBì— ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            file_name: íŒŒì¼ëª…
            file_size: íŒŒì¼ í¬ê¸°
            file_extension: íŒŒì¼ í™•ì¥ì
            user_emp_no: ì‚¬ìš©ì ì‚¬ë²ˆ
            container_id: ì»¨í…Œì´ë„ˆ ID
            session: DB ì„¸ì…˜
            processing_status: ì²˜ë¦¬ ìƒíƒœ (ê¸°ë³¸: 'pending')
            document_type: ë¬¸ì„œ ìœ í˜• (ê¸°ë³¸: 'general')
            processing_options: ë¬¸ì„œ ìœ í˜•ë³„ ì²˜ë¦¬ ì˜µì…˜
        
        Returns:
            dict: {success, document_id, file_hash}
        """
        logger.info(f"ğŸ“Š [DOC-SERVICE] ë¬¸ì„œ ê¸°ë³¸ ì •ë³´ ì €ì¥: {file_name} (ìœ í˜•: {document_type})")
        
        if processing_options is None:
            processing_options = {}
        
        try:
            import hashlib
            
            # ê°„ë‹¨í•œ í•´ì‹œ ìƒì„± (íŒŒì¼ëª… ê¸°ë°˜)
            file_hash = hashlib.md5(file_name.encode('utf-8')).hexdigest()
            
            # íŒŒì¼ ìƒì„¸ ì •ë³´ ìƒì„±
            file_dtl_info = TbFileDtlInfo(
                sj=file_name,
                cn="",
                file_sz=file_size,
                authr=user_emp_no,
                created_by=user_emp_no,
                last_modified_by=user_emp_no
            )
            
            session.add(file_dtl_info)
            await session.flush()
            
            # íŒŒì¼ ê¸°ë³¸ ì •ë³´ ìƒì„±
            file_bss_info = TbFileBssInfo(
                drcy_sno=1,
                file_dtl_info_sno=file_dtl_info.file_dtl_info_sno,
                file_lgc_nm=file_name,
                file_psl_nm=file_name,
                file_extsn=file_extension.lstrip('.'),
                path=file_path,
                knowledge_container_id=container_id,
                owner_emp_no=user_emp_no,
                created_by=user_emp_no,
                last_modified_by=user_emp_no,
                korean_metadata={"file_hash": file_hash, "file_size": file_size},
                processing_status=processing_status,
                processing_started_at=None,
                processing_completed_at=None,
                processing_error=None,
                document_type=document_type,  # âœ… ì¶”ê°€
                processing_options=processing_options  # âœ… ì¶”ê°€
            )
            
            session.add(file_bss_info)
            await session.flush()
            await session.commit()
            
            document_id = file_bss_info.file_bss_info_sno
            
            logger.info(f"âœ… [DOC-SERVICE] ë¬¸ì„œ ê¸°ë³¸ ì •ë³´ ì €ì¥ ì™„ë£Œ: doc_id={document_id}")
            
            return {
                "success": True,
                "document_id": document_id,
                "file_hash": file_hash
            }
            
        except Exception as e:
            logger.error(f"âŒ [DOC-SERVICE] ë¬¸ì„œ ê¸°ë³¸ ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}")
            await session.rollback()
            return {
                "success": False,
                "error": str(e)
            }

    async def create_document_from_upload(
        self,
        file_path: str,  # DBì— ì €ì¥í•  ê²½ë¡œ (S3 í‚¤ ë˜ëŠ” ë¡œì»¬ ê²½ë¡œ)
        file_name: str,
        file_size: int,
        file_extension: str,
        user_emp_no: str,
        container_id: str,
        session: AsyncSession,
        local_source_path: Optional[str] = None,  # í•´ì‹œ ê³„ì‚° ë“±ì— ì‚¬ìš©í•  ë¡œì»¬ ì„ì‹œ íŒŒì¼ ê²½ë¡œ
        use_multimodal: bool = True,  # ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ì—¬ë¶€
        document_type: str = 'general',  # âœ… ì¶”ê°€
        processing_options: Optional[dict] = None  # âœ… ì¶”ê°€
    ) -> dict:
        """ì—…ë¡œë“œëœ íŒŒì¼ë¡œë¶€í„° ë¬¸ì„œ ìƒì„± + RAG íŒŒì´í”„ë¼ì¸ (ë©€í‹°ëª¨ë‹¬ ì§€ì›)"""
        
        if processing_options is None:
            processing_options = {}
        
        logger.info(f"ğŸš€ [DOC-SERVICE-DEBUG] ë¬¸ì„œ ìƒì„± ì‹œì‘: {file_name} (ìœ í˜•: {document_type})")
        logger.info(f"ğŸ” [DOC-SERVICE-DEBUG] ê²½ë¡œ ìŠ¤í‚´ ê°ì§€: {file_path} -> {_classify_key_scheme(file_path)}")
        logger.info(f"ğŸ¨ [DOC-SERVICE-DEBUG] ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸: {'í™œì„±í™”' if use_multimodal else 'ë¹„í™œì„±í™”'}")
        
        try:
            import hashlib
            import tempfile
            from app.core.config import settings as app_settings
            
            # íŒŒì¼ í•´ì‹œ ìƒì„± (ë¡œì»¬ ê²½ë¡œ ìš°ì„ , ì—†ìœ¼ë©´ S3ì—ì„œ ì„ì‹œ ë‹¤ìš´ë¡œë“œ)
            file_hash = None
            hash_path = None
            try:
                # 1) ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬ëœ ë¡œì»¬ ì†ŒìŠ¤ ê²½ë¡œ ì‚¬ìš©
                if local_source_path and os.path.exists(local_source_path):
                    hash_path = local_source_path
                # 2) DB ê²½ë¡œê°€ ë¡œì»¬ ê²½ë¡œë¡œ ì¡´ì¬í•˜ëŠ” ê²½ìš°
                elif file_path and os.path.exists(file_path):
                    hash_path = file_path
                # 3) S3 ëª¨ë“œì´ê³  file_pathê°€ S3 í‚¤ë¡œ ë³´ì´ëŠ” ê²½ìš°: ì„ì‹œ ë‹¤ìš´ë¡œë“œ
                else:
                    storage_backend = getattr(app_settings, 'storage_backend', 'local')
                    looks_like_s3_key = bool(file_path) and not os.path.isabs(file_path) and '/' in file_path
                    if storage_backend == 's3' and looks_like_s3_key:
                        try:
                            from app.services.core.aws_service import S3Service
                            s3 = S3Service()
                            tmp_fd, tmp_path = tempfile.mkstemp(prefix='hash_', suffix=Path(file_path).suffix or '')
                            os.close(tmp_fd)
                            await s3.download_file(object_key=file_path, local_path=tmp_path)
                            hash_path = tmp_path
                        except Exception as _:
                            hash_path = None
                
                if hash_path and os.path.exists(hash_path):
                    with open(hash_path, 'rb') as f:
                        file_hash = hashlib.md5(f.read()).hexdigest()
                else:
                    # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: íŒŒì¼ëª… ê¸°ë°˜ í•´ì‹œ
                    file_hash = hashlib.md5(file_name.encode('utf-8')).hexdigest()
            finally:
                # ì„ì‹œ ë‹¤ìš´ë¡œë“œ íŒŒì¼ ì •ë¦¬
                if 'tmp_path' in locals():
                    try:
                        if os.path.exists(tmp_path):
                            os.remove(tmp_path)
                    except Exception:
                        pass
            
            # íŒŒì¼ ìƒì„¸ ì •ë³´ ìƒì„±
            file_dtl_info = TbFileDtlInfo(
                sj=file_name,
                cn="",
                file_sz=file_size,
                authr=user_emp_no,
                created_by=user_emp_no,
                last_modified_by=user_emp_no
            )
            
            session.add(file_dtl_info)
            await session.flush()
            
            # íŒŒì¼ ê¸°ë³¸ ì •ë³´ ìƒì„± (DB pathëŠ” ì…ë ¥ë°›ì€ file_path ê·¸ëŒ€ë¡œ ì‚¬ìš©)
            file_bss_info = TbFileBssInfo(
                drcy_sno=1,
                file_dtl_info_sno=file_dtl_info.file_dtl_info_sno,
                file_lgc_nm=file_name,
                file_psl_nm=file_name,
                file_extsn=file_extension.lstrip('.'),
                path=file_path,
                knowledge_container_id=container_id,
                owner_emp_no=user_emp_no,
                created_by=user_emp_no,
                last_modified_by=user_emp_no,
                korean_metadata={"file_hash": file_hash, "file_size": file_size},
                document_type=document_type,  # âœ… ì¶”ê°€
                processing_options=processing_options  # âœ… ì¶”ê°€
            )
            
            session.add(file_bss_info)
            await session.flush()
            await session.commit()
            
            logger.info(f"âœ… [DOC-SERVICE-DEBUG] ë¬¸ì„œ ìƒì„± ì„±ê³µ: ë¬¸ì„œ ID {file_bss_info.file_bss_info_sno}")
            
            # ==========================================
            # RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë©€í‹°ëª¨ë‹¬ vs ê¸°ì¡´) - ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
            # ==========================================
            multimodal_stats = None  # ì´ˆê¸°í™”
            try:
                if use_multimodal:
                    # ğŸ¨ ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
                    logger.info(f"ğŸ¨ [DOC-SERVICE-DEBUG] ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
                    from app.services.document.multimodal_document_service import multimodal_document_service

                    effective_provider = settings.get_current_llm_provider()

                    multimodal_result = await multimodal_document_service.process_document_multimodal(
                        file_path=local_source_path or file_path,
                        file_bss_info_sno=int(getattr(file_bss_info, 'file_bss_info_sno')),
                        container_id=container_id,
                        user_emp_no=user_emp_no,
                        session=session,
                        provider=effective_provider,
                        model_profile="default"
                    )
                    
                    if multimodal_result.get("success", False):
                        logger.info(f"âœ… [DOC-SERVICE-DEBUG] ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ ì„±ê³µ")
                        logger.info(f"   ğŸ“Š ì¶”ì¶œ: {multimodal_result.get('objects_count')}ê°œ ê°ì²´")
                        logger.info(f"   ğŸ“¦ ì²­í‚¹: {multimodal_result.get('chunks_count')}ê°œ ì²­í¬")
                        logger.info(f"   ğŸ”¢ ì„ë² ë”©: {multimodal_result.get('embeddings_count')}ê°œ ë²¡í„°")
                    else:
                        error_msg = multimodal_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                        logger.error(f"âŒ [DOC-SERVICE-DEBUG] ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {error_msg}")
                        # ğŸš¨ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ë¥¼ ì¹˜ëª…ì  ì˜¤ë¥˜ë¡œ ì²˜ë¦¬
                        await session.rollback()
                        return {
                            "success": False,
                            "error": f"ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹¤íŒ¨: {error_msg}"
                        }
                    
                    # ê²°ê³¼ë¥¼ ë°˜í™˜ ê°ì²´ì— í¬í•¨ì‹œí‚¤ê¸° ìœ„í•´ ì „ì²´ ìŠ¤ì½”í”„ì— ì €ì¥
                    stats_dict = multimodal_result.get("stats", {}) or {}
                    multimodal_stats = {
                        "enabled": True,
                        "success": multimodal_result.get("success", False),
                        "error": multimodal_result.get("error"),
                        "objects_count": multimodal_result.get("objects_count"),
                        "chunks_count": multimodal_result.get("chunks_count"),
                        "embeddings_count": multimodal_result.get("embeddings_count"),
                        "vector_dimension": stats_dict.get("vector_dimension"),
                        "elapsed_seconds": stats_dict.get("elapsed_seconds"),
                        "tables": stats_dict.get("tables", 0),
                        "images": stats_dict.get("images", 0),
                        "figures": stats_dict.get("figures", 0),
                    }
                        
                else:
                    # ğŸ“‹ ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
                    logger.info(f"ğŸ“‹ [DOC-SERVICE-DEBUG] ê¸°ì¡´ RAG íŒŒì´í”„ë¼ì¸ ì‹œì‘")
                    from app.services.document.pipeline.integrated_document_pipeline_service import integrated_pipeline_service
                    
                    rag_result = await integrated_pipeline_service.process_document_for_rag(
                        file_path=local_source_path or file_path,
                        file_name=file_name,
                        container_id=container_id,
                        user_emp_no=user_emp_no,
                        file_bss_info_sno=int(getattr(file_bss_info, 'file_bss_info_sno'))
                    )
                    
                    if rag_result.get("success", False):
                        logger.info(f"âœ… [DOC-SERVICE-DEBUG] ê¸°ì¡´ RAG íŒŒì´í”„ë¼ì¸ ì„±ê³µ")
                    else:
                        error_msg = rag_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                        logger.error(f"âŒ [DOC-SERVICE-DEBUG] ê¸°ì¡´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {error_msg}")
                        # ğŸš¨ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ë¥¼ ì¹˜ëª…ì  ì˜¤ë¥˜ë¡œ ì²˜ë¦¬
                        await session.rollback()
                        return {
                            "success": False,
                            "error": f"RAG ì²˜ë¦¬ ì‹¤íŒ¨: {error_msg}"
                        }
                    
            except Exception as e:
                logger.error(f"ğŸ’¥ [DOC-SERVICE-DEBUG] RAG íŒŒì´í”„ë¼ì¸ ì˜ˆì™¸: {str(e)}")
                # ğŸš¨ ì˜ˆì™¸ë¥¼ ì¹˜ëª…ì  ì˜¤ë¥˜ë¡œ ì²˜ë¦¬
                await session.rollback()
                return {
                    "success": False,
                    "error": f"RAG ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}"
                }
            
            return {
                "success": True,
                "document_id": file_bss_info.file_bss_info_sno,
                "detail_id": file_dtl_info.file_dtl_info_sno,
                "file_hash": file_hash,
                "message": "ë¬¸ì„œ ì—…ë¡œë“œ ì²˜ë¦¬ ì™„ë£Œ",
                "multimodal": multimodal_stats if use_multimodal else None
            }
            
        except Exception as e:
            await session.rollback()
            logger.error(f"ğŸ’¥ [DOC-SERVICE-DEBUG] ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {
                "success": False,
                "error": f"ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}"
            }
    
    async def delete_document_by_id(
        self,
        document_id: int,
        user_emp_no: str,
        session: AsyncSession
    ) -> dict:
        """
        ë¬¸ì„œ ì‚­ì œ (ì†Œí”„íŠ¸ ì‚­ì œ)
        """
        try:
            stmt = select(TbFileBssInfo).where(TbFileBssInfo.file_bss_info_sno == document_id)
            result = await session.execute(stmt)
            file_info = result.scalar_one_or_none()
            
            if not file_info:
                return {
                    "success": False,
                    "error": "ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # ì‚­ì œ ëŒ€ìƒ ê²½ë¡œ ìŠ¤í‚´ ë¡œê¹… (raw ìŠ¤í‚´ ì ìš© ì—¬ë¶€ í™•ì¸ìš©)
            try:
                file_path_val_preview = getattr(file_info, 'path', '') or ''
                logger.info(f"ğŸ” [DOC-SERVICE-DEBUG] ì‚­ì œ ëŒ€ìƒ ê²½ë¡œ ìŠ¤í‚´: {file_path_val_preview} -> {_classify_key_scheme(file_path_val_preview)}")
            except Exception:
                pass

            # ğŸ” ê¶Œí•œ í™•ì¸ (í†µì¼ëœ permission_service ì‚¬ìš©)
            owner_emp_no = getattr(file_info, 'owner_emp_no', None)
            creator_emp_no = getattr(file_info, 'created_by', None)
            container_id = getattr(file_info, 'knowledge_container_id', None)
            
            if container_id:
                from app.services.auth.permission_service import permission_service
                can_delete, permission_message = await permission_service.check_delete_permission(
                    user_emp_no=user_emp_no,
                    container_id=container_id,
                    owner_emp_no=owner_emp_no,
                    created_by=creator_emp_no
                )
                if not can_delete:
                    logger.warning(
                        f"ë¬¸ì„œ ì‚­ì œ ê¶Œí•œ ì—†ìŒ - ì‚¬ìš©ì: {user_emp_no}, ë¬¸ì„œ: {document_id}, ë©”ì‹œì§€: {permission_message}"
                    )
                    return {
                        "success": False,
                        "error": f"ë¬¸ì„œ ì‚­ì œ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {permission_message}"
                    }
            else:
                # ì»¨í…Œì´ë„ˆ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì†Œìœ ì/ìƒì„±ìë§Œ ì‚­ì œ ê°€ëŠ¥
                if (owner_emp_no or creator_emp_no) and user_emp_no not in {owner_emp_no, creator_emp_no}:
                    return {
                        "success": False,
                        "error": "ë¬¸ì„œ ì‚­ì œ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤."
                    }
            # 1. ë©”ì¸ íŒŒì¼ ì •ë³´ ì†Œí”„íŠ¸ ì‚­ì œ (ì„  ì»¤ë°‹, í›„ í´ë¦°ì—… ì „ëµ)
            setattr(file_info, 'del_yn', 'Y')
            setattr(file_info, 'last_modified_by', user_emp_no)
            
            # 2. íŒŒì¼ ìƒì„¸ ì •ë³´ ì†Œí”„íŠ¸ ì‚­ì œ
            if getattr(file_info, 'file_dtl_info_sno', None):
                stmt_dtl = (update(TbFileDtlInfo)
                           .where(TbFileDtlInfo.file_dtl_info_sno == file_info.file_dtl_info_sno)
                           .values(del_yn='Y', last_modified_by=user_emp_no))
                await session.execute(stmt_dtl)
            
            await session.commit()
            
            # 3. ë¬¼ë¦¬ì  íŒŒì¼/ì˜¤ë¸Œì íŠ¸ ì‚­ì œ (ì˜µì…˜)
            file_path_val = getattr(file_info, 'path', '') or ''
            try:
                from app.core.config import settings as app_settings
                storage_backend = getattr(app_settings, 'storage_backend', 'local')
            except Exception:
                storage_backend = 'local'

            if storage_backend == 's3' and file_path_val and ('/' in file_path_val) and not os.path.isabs(file_path_val):
                # S3 í‚¤ë¡œ íŒë‹¨ -> ì˜¤ë¸Œì íŠ¸ ì‚­ì œ
                try:
                    from app.services.core.aws_service import S3Service
                    s3 = S3Service()
                    await s3.delete_file(file_path_val)
                    logger.info(f"S3 ì˜¤ë¸Œì íŠ¸ ì‚­ì œ ì™„ë£Œ: {file_path_val}")
                except Exception as e:
                    logger.warning(f"S3 ì˜¤ë¸Œì íŠ¸ ì‚­ì œ ì‹¤íŒ¨: {e}")
            elif storage_backend == 'azure_blob' and file_path_val and ('/' in file_path_val) and not os.path.isabs(file_path_val):
                try:
                    from app.services.core.azure_blob_service import get_azure_blob_service
                    azure = get_azure_blob_service()
                    # ê¸°ë³¸ ìš©ë„ëŠ” raw, prefixì— ë”°ë¼ ì¬ì„¤ì •
                    purpose = 'raw'
                    blob_path = file_path_val
                    if file_path_val.startswith(('raw/', 'intermediate/', 'derived/')):
                        maybe_purpose, _, remainder = file_path_val.partition('/')
                        if maybe_purpose and remainder:
                            purpose = maybe_purpose
                            blob_path = remainder
                    if azure.delete_blob(blob_path, purpose=purpose):
                        logger.info(f"Azure Blob ì‚­ì œ ì™„ë£Œ: {purpose}/{blob_path}")
                    else:
                        logger.warning(f"Azure Blob ì‚­ì œ ë¶ˆê°€ ë˜ëŠ” ë¯¸ì¡´ì¬: {purpose}/{blob_path}")
                except Exception as e:
                    logger.warning(f"Azure Blob ì‚­ì œ ì‹¤íŒ¨: {e}")
            else:
                # ë¡œì»¬ íŒŒì¼ ì‚­ì œ
                if file_path_val and os.path.exists(file_path_val):
                    try:
                        os.remove(file_path_val)
                        logger.info(f"ë¬¼ë¦¬ì  íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path_val}")
                    except Exception as e:
                        logger.warning(f"ë¬¼ë¦¬ì  íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

            # 4. PDF ìºì‹œ ì‚­ì œ
            try:
                cache_dir = Path("backend/uploads/pdf_cache")
                patterns = [f"{document_id}_*.pdf"]
                for pattern in patterns:
                    for p in cache_dir.glob(pattern):
                        try:
                            p.unlink()
                            logger.info(f"PDF ìºì‹œ ì‚­ì œ: {p}")
                        except Exception as e:
                            logger.warning(f"PDF ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {e}")
            except Exception:
                pass

            # 5. ì—°ê´€ ë°ì´í„° ì •ë¦¬ (ë²¡í„° ì²­í¬ / ê²€ìƒ‰ ì¸ë±ìŠ¤) - ë©”ì¸ ì»¤ë°‹ ì´í›„ ë¶„ë¦¬ íŠ¸ëœì­ì…˜/ì—°ê²°ë¡œ ìˆ˜í–‰
            try:
                cleanup_ok = await self._cleanup_vector_and_index_artifacts_standalone(
                    document_id=document_id,
                    user_emp_no=user_emp_no,
                )
                if not cleanup_ok:
                    logger.warning(
                        "ì—°ê´€ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨ - ë¬¸ì„œ ID: %s (í–¥í›„ ë°°ì¹˜ ì •ë¦¬ í•„ìš”)",
                        document_id
                    )
            except Exception as e:
                # í´ë¦°ì—… ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ê²½ê³ ë§Œ ë‚¨ê¹€
                logger.warning(
                    "ì—°ê´€ ë°ì´í„° ì •ë¦¬ ì¤‘ ì˜ˆì™¸ - ë¬¸ì„œ ID: %s, ì˜¤ë¥˜: %s (í–¥í›„ ë°°ì¹˜ ì •ë¦¬)",
                    document_id,
                    e
                )
            
            logger.info(f"ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ - ID: {document_id}, ì‚¬ìš©ì: {user_emp_no}")
            
            # ğŸ”¢ ì»¨í…Œì´ë„ˆì˜ document_count ì—…ë°ì´íŠ¸
            if container_id:
                try:
                    from app.services.auth.container_service import ContainerService
                    container_svc = ContainerService(session)
                    updated_count = await container_svc.update_container_document_count(container_id)
                    logger.info(f"ğŸ“Š ì»¨í…Œì´ë„ˆ ë¬¸ì„œ ê°œìˆ˜ ì—…ë°ì´íŠ¸: {container_id} -> {updated_count}ê°œ")
                except Exception as count_error:
                    logger.warning(f"âš ï¸ ì»¨í…Œì´ë„ˆ ë¬¸ì„œ ê°œìˆ˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ë¬´ì‹œ): {count_error}")
            
            return {
                "success": True,
                "message": "ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
            }
            
        except Exception as e:
            await session.rollback()
            logger.exception(f"ë¬¸ì„œ ì‚­ì œ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ - ë¬¸ì„œ ID: {document_id}, ì‚¬ìš©ì: {user_emp_no}")
            return {
                "success": False,
                "error": f"ë¬¸ì„œ ì‚­ì œ ì‹¤íŒ¨: {str(e)}"
            }

    async def _cleanup_vector_and_index_artifacts(
        self,
        document_id: int,
        user_emp_no: str,
        session: AsyncSession  # ë©”ì¸ ì„¸ì…˜ì„ ë°›ì•„ì„œ ì‚¬ìš©
    ) -> bool:
        """
        Delete or soft-delete vector/search artifacts using the provided session.
        ë©”ì¸ ì„¸ì…˜ì„ ê³µìœ í•˜ì—¬ connection ì¶©ëŒ ë°©ì§€
        """
        try:
            from app.models import VsDocContentsChunks
            from app.models.document.unified_search_models import TbDocumentSearchIndex
            
            # ë²¡í„° ì²­í¬ ì†Œí”„íŠ¸ ì‚­ì œ
            stmt_chunks = (update(VsDocContentsChunks)
                          .where(VsDocContentsChunks.file_bss_info_sno == document_id)
                          .values(del_yn='Y', last_modified_by=user_emp_no))
            await session.execute(stmt_chunks)

            # ê²€ìƒ‰ ì¸ë±ìŠ¤ ì‚­ì œ
            stmt_search = delete(TbDocumentSearchIndex).where(
                TbDocumentSearchIndex.file_bss_info_sno == document_id
            )
            await session.execute(stmt_search)
            
            logger.info(f"âœ… [CLEANUP-DEBUG] ë¬¸ì„œ ì—°ê´€ ë°ì´í„° ì •ë¦¬ ì„±ê³µ: doc_id={document_id}")
            return True
            
        except Exception as cleanup_error:
            logger.error(
                "âŒ [CLEANUP-DEBUG] ë¬¸ì„œ ì—°ê´€ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: doc_id=%s, ì˜¤ë¥˜=%s",
                document_id,
                cleanup_error
            )
            return False

    async def _cleanup_vector_and_index_artifacts_standalone(
        self,
        document_id: int,
        user_emp_no: str,
    ) -> bool:
        """
        ë³„ë„ì˜ ì§§ì€-lived ì„¸ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì—°ê´€ ë°ì´í„° ì •ë¦¬ë¥¼ ìˆ˜í–‰.
        - ë©”ì¸ ì‚­ì œ ì»¤ë°‹ ì´í›„ í˜¸ì¶œ
        - ìì²´ íŠ¸ëœì­ì…˜ê³¼ ì»¤ë°‹/ë¡¤ë°± ì²˜ë¦¬
        - ì¼ì‹œì ì¸ ì—°ê²° ë¬¸ì œì— ëŒ€ë¹„í•˜ì—¬ ì†Œê·œëª¨ ì¬ì‹œë„
        """
        from asyncio import sleep
        from app.core.database import get_async_session_local
        from app.models import VsDocContentsChunks
        from app.models.document.unified_search_models import TbDocumentSearchIndex
        
        max_attempts = 3
        delay = 2.0  # 0.5 â†’ 2.0 (ì´ˆê¸° ëŒ€ê¸° ì‹œê°„ ì¦ê°€)
        
        for attempt in range(1, max_attempts + 1):
            try:
                # ë§¤ë²ˆ ìƒˆë¡œìš´ connection factory ìƒì„±
                async_session_factory = get_async_session_local()
                async with async_session_factory() as cleanup_session:
                    try:
                        # EXPLICIT transaction control
                        async with cleanup_session.begin():
                            stmt_chunks = (update(VsDocContentsChunks)
                                           .where(VsDocContentsChunks.file_bss_info_sno == document_id)
                                           .values(del_yn='Y', last_modified_by=user_emp_no))
                            await cleanup_session.execute(stmt_chunks)

                            stmt_search = delete(TbDocumentSearchIndex).where(
                                TbDocumentSearchIndex.file_bss_info_sno == document_id
                            )
                            await cleanup_session.execute(stmt_search)
                        
                        # begin() context ì¢…ë£Œ ì‹œ ìë™ commit
                        logger.info(f"âœ… [CLEANUP-DEBUG] (standalone) ë¬¸ì„œ ì—°ê´€ ë°ì´í„° ì •ë¦¬ ì„±ê³µ: doc_id={document_id}")
                        return True
                        
                    except Exception as inner_e:
                        # begin() contextëŠ” ìë™ rollbackí•˜ì§€ë§Œ ëª…ì‹œì  ë¡œê¹…
                        logger.warning(
                            "[CLEANUP-DEBUG] (standalone) ì‹œë„ %s/%s ì‹¤íŒ¨ - doc_id=%s: %s",
                            attempt, max_attempts, document_id, inner_e
                        )
                        raise  # ì™¸ë¶€ exceptë¡œ ì „íŒŒ
                        
            except Exception as e:
                if attempt < max_attempts:
                    logger.info(f"ğŸ”„ [CLEANUP-DEBUG] {delay}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    await sleep(delay)
                    delay = min(delay * 2.5, 10.0)  # 2ì´ˆ â†’ 5ì´ˆ â†’ 10ì´ˆ
                else:
                    logger.error(
                        "âŒ [CLEANUP-DEBUG] (standalone) ìµœì¢… ì‹¤íŒ¨ - doc_id=%s, ì˜¤ë¥˜=%s",
                        document_id, e
                    )
                    return False
        
        return False


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
document_service = DocumentService(None)  # ì„¸ì…˜ì€ ì‚¬ìš©ì‹œ ì „ë‹¬
