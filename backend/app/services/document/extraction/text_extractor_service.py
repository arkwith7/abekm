"""
ğŸ“„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„œë¹„ìŠ¤
===================

ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ì„œë¹„ìŠ¤
- PDF, DOCX, TXT, HWP ë“± ì§€ì›
- í•œêµ­ì–´ ì¸ì½”ë”© ì²˜ë¦¬
- ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
"""

import os
import logging
from typing import Dict, Any, Optional
from pathlib import Path

from app.core.config import settings

logger = logging.getLogger(__name__)

class TextExtractorService:
    """ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.supported_extensions = {'.txt', '.md', '.py', '.js', '.html', '.css', '.json', '.xml'}
        
    async def extract_text_from_file(self, file_path: str, file_extension: str = None) -> Dict[str, Any]:
        """
        íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            file_extension: íŒŒì¼ í™•ì¥ì (Noneì¸ ê²½ìš° íŒŒì¼ ê²½ë¡œì—ì„œ ì¶”ì¶œ)
            
        Returns:
            Dict containing extracted text and metadata
        """
        if file_extension is None:
            file_extension = Path(file_path).suffix
            
        return await self.extract_text(file_path, file_extension)
    
    async def extract_text(self, file_path: str, file_extension: str) -> Dict[str, Any]:
        """
        íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (ë‚´ë¶€ ë©”ì„œë“œ)
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            file_extension: íŒŒì¼ í™•ì¥ì
            
        Returns:
            Dict containing extracted text and metadata
        """
        try:
            result = {
                "text": "",
                "metadata": {},
                "success": True,
                "error": None,
                "text_length": 0,
                "encoding": "utf-8"
            }
            
            # Azure Blob ê²½ë¡œì¸ì§€ í™•ì¸ (raw/ ë˜ëŠ” processed/ë¡œ ì‹œì‘)
            is_blob_path = file_path.startswith('raw/') or file_path.startswith('processed/')
            actual_file_path = file_path
            temp_file_path = None
            
            try:
                if is_blob_path:
                    # Azure Blobì—ì„œ ì„ì‹œ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ
                    from app.services.core.azure_blob_service import azure_blob_service
                    import tempfile
                    
                    logger.info(f"ğŸ“¥ Azure Blobì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {file_path}")
                    
                    # ì„ì‹œ íŒŒì¼ ìƒì„±
                    file_ext = os.path.splitext(file_path)[1]
                    temp_fd, temp_file_path = tempfile.mkstemp(suffix=file_ext)
                    os.close(temp_fd)
                    
                    # Blobì—ì„œ ë‹¤ìš´ë¡œë“œ (ë™ê¸° ë©”ì„œë“œ)
                    blob_data = azure_blob_service.download_blob_to_bytes(file_path, purpose='raw')
                    if not blob_data:
                        raise Exception(f"Azure Blob ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {file_path}")
                    
                    # ì„ì‹œ íŒŒì¼ì— ì €ì¥
                    with open(temp_file_path, 'wb') as f:
                        f.write(blob_data)
                    
                    actual_file_path = temp_file_path
                    logger.info(f"âœ… Azure Blob ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_path} â†’ {temp_file_path}")
                
                if not os.path.exists(actual_file_path):
                    result["success"] = False
                    result["error"] = "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    return result
                
                # íŒŒì¼ í™•ì¥ìë³„ ì²˜ë¦¬
                if file_extension.lower() in self.supported_extensions:
                    result = await self._extract_text_file(actual_file_path, result)
                elif file_extension.lower() == '.pdf':
                    result = await self._extract_pdf_file(actual_file_path, result)
                elif file_extension.lower() in ['.docx', '.doc']:
                    result = await self._extract_docx_file(actual_file_path, result)
                elif file_extension.lower() in ['.pptx', '.ppt']:
                    result = await self._extract_pptx_file(actual_file_path, result)
                elif file_extension.lower() in ['.xlsx', '.xls']:
                    result = await self._extract_excel_file(actual_file_path, result)
                elif file_extension.lower() in ['.hwp', '.hwpx']:
                    result = await self._extract_hwp_file(actual_file_path, result)
                else:
                    result["text"] = f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_extension}"
                    result["success"] = False
                    result["error"] = "Unsupported file format"
                
                # í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°
                result["text_length"] = len(result["text"])
                
                # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                file_stats = os.stat(actual_file_path)
                result["metadata"].update({
                    "file_size": file_stats.st_size,
                    "last_modified": file_stats.st_mtime,
                    "extraction_method": self._get_extraction_method(file_extension)
                })
                
                # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ ì¶”ê°€ (ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œìš©)
                result["actual_file_path"] = actual_file_path
                result["is_temp_file"] = temp_file_path is not None
                
                logger.info(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ - íŒŒì¼: {file_path}, ê¸¸ì´: {result['text_length']}ì")
                return result
            
            finally:
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬ (extraction_result ë°˜í™˜ í›„ multimodal pipelineì—ì„œ ì²˜ë¦¬)
                # ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ì´ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë„ë¡ ì—¬ê¸°ì„œëŠ” ì‚­ì œí•˜ì§€ ì•ŠìŒ
                # multimodal_document_serviceì—ì„œ ì²˜ë¦¬ ì™„ë£Œ í›„ ì •ë¦¬
                if temp_file_path and os.path.exists(temp_file_path):
                    logger.info(f"ğŸ”„ ì„ì‹œ íŒŒì¼ ìœ ì§€ (ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ìš©): {temp_file_path}")
                    # os.removeëŠ” í˜¸ì¶œìì—ê²Œ ìœ„ì„
            
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ - íŒŒì¼: {file_path}, ì˜¤ë¥˜: {e}")
            return {
                "text": "",
                "metadata": {},
                "success": False,
                "error": str(e),
                "text_length": 0,
                "encoding": "utf-8"
            }
    
    async def _extract_text_file(self, file_path: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ íŒŒì¼ ì¶”ì¶œ"""
        try:
            # ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
            encodings = ['utf-8', 'cp949', 'euc-kr', 'latin-1']
            
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        result["text"] = f.read()
                        result["encoding"] = encoding
                        break
                except UnicodeDecodeError:
                    continue
            else:
                # ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨ì‹œ ë°”ì´ë„ˆë¦¬ë¡œ ì½ì–´ì„œ ì—ëŸ¬ ë¬´ì‹œ
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    result["text"] = f.read()
                    result["encoding"] = "utf-8 (with errors ignored)"
            
        except Exception as e:
            result["success"] = False
            result["error"] = f"í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}"
        
        return result
    
    async def _extract_pdf_file(self, file_path: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """PDF íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ - Provider ê¸°ë°˜ ë¼ìš°íŒ… + Fallback ë¡œì§"""
        
        provider = settings.document_processing_provider.lower().strip()
        fallback_provider = settings.document_processing_fallback.lower().strip() if settings.document_processing_fallback else None
        
        logger.info(f"ğŸ“„ [PDF-EXTRACT] ë¬¸ì„œ ì²˜ë¦¬ Provider: {provider} (Fallback: {fallback_provider or 'None'})")
        logger.info(f"ğŸ“„ [PDF-EXTRACT] íŒŒì¼: {file_path}")
        
        # Primary Provider ì‹œë„
        primary_success = False
        
        # Azure Document Intelligence
        if provider == "azure_di":
            try:
                from .azure_document_intelligence_service import azure_document_intelligence_service
                
                logger.info(f"Azure Document Intelligenceë¡œ PDF ë¶„ì„ ì‹œë„: {file_path}")
                di_result = await azure_document_intelligence_service.analyze_pdf(file_path)
                
                if di_result.success:
                    logger.info(f"âœ… Azure DI ì„±ê³µ: {file_path}")
                    converted_result = azure_document_intelligence_service.create_internal_extraction_result(di_result)
                    result.update(converted_result)
                    return result
                else:
                    logger.warning(f"âš ï¸ Azure DI ì‹¤íŒ¨: {di_result.error}")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ Azure DI ì˜ˆì™¸: {e}")
        
        # Upstage Document Parse
        elif provider == "upstage":
            try:
                logger.info(f"ğŸ”· [UPSTAGE] Upstage Document Parse ì‚¬ìš© - íŒŒì¼: {file_path}")
                from .upstage_document_service import upstage_document_service
                
                logger.info(f"ğŸ”· [UPSTAGE] upstage_document_service ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
                logger.info(f"ğŸ”· [UPSTAGE] API í‚¤ ì„¤ì • ì—¬ë¶€: {bool(upstage_document_service.api_key)}")
                
                logger.info(f"ğŸ”· [UPSTAGE] Document Parse í˜¸ì¶œ ì‹œì‘: {file_path}")
                upstage_result = await upstage_document_service.parse_document(file_path)
                
                logger.info(f"ğŸ”· [UPSTAGE] Document Parse í˜¸ì¶œ ì™„ë£Œ - success: {upstage_result.success}")
                
                if upstage_result.success:
                    logger.info(f"âœ… [UPSTAGE] Upstage ì„±ê³µ: {file_path}")
                    logger.info(f"âœ… [UPSTAGE] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(upstage_result.text)}")
                    logger.info(f"âœ… [UPSTAGE] í˜ì´ì§€ ìˆ˜: {len(upstage_result.pages)}")
                    logger.info(f"âœ… [UPSTAGE] í…Œì´ë¸” ìˆ˜: {len(upstage_result.tables)}")
                    logger.info(f"âœ… [UPSTAGE] ì´ë¯¸ì§€ ìˆ˜: {len(upstage_result.figures)}")
                    
                    converted_result = upstage_document_service.create_internal_extraction_result(upstage_result)
                    result.update(converted_result)
                    primary_success = True
                else:
                    logger.warning(f"âš ï¸ [UPSTAGE] Upstage ì‹¤íŒ¨: {upstage_result.error}")
            
            except Exception as e:
                logger.error(f"âŒ [UPSTAGE] Upstage ì˜ˆì™¸ ë°œìƒ: {e}", exc_info=True)
        
        # AWS Textract (í–¥í›„ êµ¬í˜„)
        elif provider == "aws_textract":
            logger.warning(f"âš ï¸ AWS Textract providerëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            # TODO: AWS Textract êµ¬í˜„
        
        # ê¸°íƒ€ Provider (pdfplumber, tesseract ë“±)
        elif provider == "etc_other":
            logger.info(f"ğŸ“š ê¸°íƒ€ ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬(pdfplumber) ì‚¬ìš©")
            primary_success = True  # pdfplumberëŠ” ì•„ë˜ì—ì„œ í•­ìƒ ì‹¤í–‰
        
        # ì•Œ ìˆ˜ ì—†ëŠ” Provider
        else:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” Provider '{provider}'")
        
        # Fallback Provider ì‹œë„
        if not primary_success and fallback_provider and fallback_provider != provider:
            logger.info(f"ğŸ”„ Fallback Providerë¡œ ì¬ì‹œë„: {fallback_provider}")
            
            if fallback_provider == "upstage":
                try:
                    logger.info(f"ğŸ”· [FALLBACK-UPSTAGE] Upstage Document Parse ì‚¬ìš© - íŒŒì¼: {file_path}")
                    from .upstage_document_service import upstage_document_service
                    
                    logger.info(f"ğŸ”· [FALLBACK-UPSTAGE] upstage_document_service ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
                    logger.info(f"ğŸ”· [FALLBACK-UPSTAGE] API í‚¤ ì„¤ì • ì—¬ë¶€: {bool(upstage_document_service.api_key)}")
                    
                    logger.info(f"ğŸ”· [FALLBACK-UPSTAGE] Document Parse í˜¸ì¶œ ì‹œì‘: {file_path}")
                    upstage_result = await upstage_document_service.parse_document(file_path)
                    
                    logger.info(f"ğŸ”· [FALLBACK-UPSTAGE] Document Parse í˜¸ì¶œ ì™„ë£Œ - success: {upstage_result.success}")
                    
                    if upstage_result.success:
                        logger.info(f"âœ… [FALLBACK-UPSTAGE] Upstage ì„±ê³µ: {file_path}")
                        logger.info(f"âœ… [FALLBACK-UPSTAGE] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(upstage_result.text)}")
                        
                        converted_result = upstage_document_service.create_internal_extraction_result(upstage_result)
                        result.update(converted_result)
                        return result
                    else:
                        logger.warning(f"âš ï¸ [FALLBACK-UPSTAGE] Upstage ì‹¤íŒ¨: {upstage_result.error}")
                        
                except Exception as e:
                    logger.error(f"âŒ [FALLBACK-UPSTAGE] Upstage ì˜ˆì™¸ ë°œìƒ: {e}", exc_info=True)
            
            elif fallback_provider == "azure_di":
                try:
                    from .azure_document_intelligence_service import azure_document_intelligence_service
                    
                    logger.info(f"[Fallback] Azure DIë¡œ PDF ë¶„ì„ ì‹œë„: {file_path}")
                    di_result = await azure_document_intelligence_service.analyze_pdf(file_path)
                    
                    if di_result.success:
                        logger.info(f"âœ… [Fallback] Azure DI ì„±ê³µ: {file_path}")
                        converted_result = azure_document_intelligence_service.create_internal_extraction_result(di_result)
                        result.update(converted_result)
                        return result
                    else:
                        logger.warning(f"âš ï¸ [Fallback] Azure DI ì‹¤íŒ¨: {di_result.error}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ [Fallback] Azure DI ì˜ˆì™¸: {e}")
        
        # ìµœì¢… Fallback: pdfplumber (í•­ìƒ ì‚¬ìš© ê°€ëŠ¥)
        
        # pdfplumber í´ë°± ë˜ëŠ” ê¸°ë³¸ ë°©ì‹
        return await self._extract_pdf_with_pdfplumber(file_path, result)
    
    async def _extract_pdf_with_pdfplumber(self, file_path: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """PDF íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ (pdfplumber ì‚¬ìš©) - í˜ì´ì§€ë³„ êµ¬ì¡°í™”"""
        try:
            import pdfplumber
            
            text_content = ""
            page_count = 0
            pages_data = []  # í˜ì´ì§€ë³„ êµ¬ì¡°í™” ë°ì´í„°
            
            with pdfplumber.open(file_path) as pdf:
                page_count = len(pdf.pages)
                for page_num, page in enumerate(pdf.pages):
                    page_text = page.extract_text() or ""
                    page_tables = page.extract_tables() or []
                    page_images = page.images or []
                    
                    # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ìš©)
                    images_metadata = []
                    for img_idx, img in enumerate(page_images):
                        images_metadata.append({
                            'image_index': img_idx,
                            'x0': img.get('x0', 0),
                            'y0': img.get('y0', 0),
                            'x1': img.get('x1', 0),
                            'y1': img.get('y1', 0),
                            'width': img.get('width', 0),
                            'height': img.get('height', 0),
                            # í–¥í›„ í™•ì¥: 'image_path', 'image_base64', 'ocr_text'
                        })
                    
                    # í˜ì´ì§€ë³„ ë°ì´í„° ì €ì¥
                    pages_data.append({
                        'page_no': page_num + 1,
                        'text': page_text.strip(),
                        'tables_count': len(page_tables),
                        'images_count': len(page_images),
                        'images_metadata': images_metadata,  # âœ… ì´ë¯¸ì§€ ìƒì„¸ ì •ë³´
                        'char_count': len(page_text),
                        'has_content': bool(page_text.strip() or page_tables or page_images)
                    })
                    
                    if page_text:
                        text_content += f"\n[í˜ì´ì§€ {page_num + 1}]\n{page_text}\n"
            
            if text_content.strip():
                result["text"] = text_content.strip()
                result["metadata"].update({
                    "page_count": page_count,
                    "pages": pages_data,  # âœ… ì¶”ê°€
                    "total_tables": sum(p['tables_count'] for p in pages_data),
                    "total_images": sum(p['images_count'] for p in pages_data),
                    "extraction_method": "pdfplumber_fallback" if settings.use_azure_document_intelligence_pdf else "pdfplumber",
                    "char_count": len(text_content),
                    "extraction_note": f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ (í˜ì´ì§€ë³„ êµ¬ì¡°í™”) - {'Azure DI í´ë°±' if settings.use_azure_document_intelligence_pdf else 'pdfplumber'}"
                })
                logger.info(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ: {len(text_content)}ì, {page_count}í˜ì´ì§€")
            else:
                result["text"] = f"PDF íŒŒì¼: {Path(file_path).name}\n\n[í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” PDF íŒŒì¼ì…ë‹ˆë‹¤]"
                result["metadata"]["extraction_note"] = "ì¶”ì¶œ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŒ"
                result["metadata"]["pages"] = pages_data  # ë¹ˆ í˜ì´ì§€ ì •ë³´ë¼ë„ ì €ì¥
                
        except Exception as e:
            result["success"] = False
            result["error"] = f"PDF íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            logger.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return result
    
    async def _extract_docx_file(self, file_path: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """DOCX íŒŒì¼ í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ì¶”ì¶œ (python-docx ì‚¬ìš©) - êµ¬ì¡°í™”"""
        try:
            from docx import Document
            import zipfile
            import io
            from PIL import Image
            
            doc = Document(file_path)
            text_content = ""
            paragraph_count = 0
            paragraphs_data = []  # ë¬¸ë‹¨ ë°ì´í„°
            tables_data = []  # í‘œ ë°ì´í„°
            images_metadata = []  # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°
            
            # ë¬¸ë‹¨ë³„ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            for para_idx, paragraph in enumerate(doc.paragraphs):
                if paragraph.text.strip():
                    text_content += paragraph.text + "\n"
                    paragraph_count += 1
                    paragraphs_data.append({
                        'paragraph_no': para_idx + 1,
                        'text': paragraph.text.strip(),
                        'char_count': len(paragraph.text)
                    })
            
            # í‘œ ë‚´ìš©ë„ ì¶”ì¶œ
            table_count = 0
            for table_idx, table in enumerate(doc.tables):
                table_count += 1
                table_text = f"\n[í‘œ {table_count}]\n"
                table_rows = []
                table_cells = []  # 2D ì…€ êµ¬ì¡° (ì¤‘ë³µ ì €ì¥ ê°€ëŠ¥í•˜ë‚˜ ê²€ìƒ‰/êµ¬ì¡° í™•ì¥ ìš©ë„)
                for row in table.rows:
                    row_cell_texts = []
                    for cell in row.cells:
                        ctext = cell.text.strip() if cell.text else ""
                        row_cell_texts.append(ctext)
                    row_text = " | ".join(row_cell_texts)
                    if row_text.strip():
                        table_text += row_text + "\n"
                    table_rows.append(row_text)
                    table_cells.append(row_cell_texts)
                text_content += table_text
                
                tables_data.append({
                    'table_no': table_count,
                    'rows_count': len(table.rows),
                    'cols_count': len(table.columns) if hasattr(table, 'columns') else 0,
                    'content': table_rows,
                    'cells': table_cells,
                    'has_header': True if table_rows else False  # ë‹¨ìˆœ ì²« í–‰ì„ í—¤ë”ë¡œ ê°„ì£¼ (ì¶”í›„ ê³ ë„í™” ê°€ëŠ¥)
                })
            
            # ì´ë¯¸ì§€ ì¶”ì¶œ (DOCXëŠ” ì‹¤ì œë¡œëŠ” ZIP íŒŒì¼)
            image_count = 0
            try:
                with zipfile.ZipFile(file_path, 'r') as docx_zip:
                    # word/media/ í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì°¾ê¸°
                    media_files = [name for name in docx_zip.namelist() if name.startswith('word/media/')]
                    
                    for media_file in media_files:
                        try:
                            # ì´ë¯¸ì§€ íŒŒì¼ì¸ì§€ í™•ì¸ (í™•ì¥ì ê¸°ì¤€)
                            if any(media_file.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff']):
                                image_count += 1
                                
                                # ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì½ê¸°
                                image_data = docx_zip.read(media_file)
                                
                                # PILë¡œ ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ
                                try:
                                    with Image.open(io.BytesIO(image_data)) as img:
                                        width, height = img.size
                                        format_name = img.format or 'Unknown'
                                        
                                        images_metadata.append({
                                            'image_index': image_count,
                                            'filename': os.path.basename(media_file),
                                            'format': format_name,
                                            'width': width,
                                            'height': height,
                                            'size_bytes': len(image_data),
                                            'media_path': media_file,
                                            'binary_data': image_data  # ë°”ì´ë„ˆë¦¬ ë°ì´í„° í¬í•¨ (ì¼ì‹œì )
                                        })
                                        
                                except Exception as img_err:
                                    logger.warning(f"DOCX ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨ ({media_file}): {img_err}")
                                    # ê¸°ë³¸ ë©”íƒ€ë°ì´í„°ë¼ë„ ì €ì¥
                                    images_metadata.append({
                                        'image_index': image_count,
                                        'filename': os.path.basename(media_file),
                                        'format': 'Unknown',
                                        'size_bytes': len(image_data),
                                        'media_path': media_file,
                                        'binary_data': image_data  # ë°”ì´ë„ˆë¦¬ ë°ì´í„° í¬í•¨ (ì¼ì‹œì )
                                    })
                                    
                        except Exception as file_err:
                            logger.warning(f"DOCX ë¯¸ë””ì–´ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ({media_file}): {file_err}")
                            
            except Exception as zip_err:
                logger.warning(f"DOCX ZIP ì²˜ë¦¬ ì‹¤íŒ¨: {zip_err}")
            
            # ê²°ê³¼ êµ¬ì„±
            if text_content.strip():
                result["text"] = text_content.strip()
                
                # pages êµ¬ì¡°ë¡œ ë³€í™˜ (ë©€í‹°ëª¨ë‹¬ ì„œë¹„ìŠ¤ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´)
                pages_data = [{
                    'page_no': 1,
                    'text': text_content.strip(),
                    'images_metadata': images_metadata,
                    'tables_count': table_count,
                    'images_count': image_count,
                    'tables_metadata': tables_data  # í˜ì´ì§€ ìˆ˜ì¤€ í‘œ ìƒì„¸ êµ¬ì¡° ì œê³µ
                }]
                
                result["metadata"].update({
                    "paragraph_count": paragraph_count,
                    "paragraphs": paragraphs_data[:50],  # ìµœëŒ€ 50ê°œê¹Œì§€ë§Œ (í¬ê¸° ì œí•œ)
                    "table_count": table_count,
                    "tables": tables_data,
                    "pages": pages_data,  # ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ì„ ìœ„í•œ pages êµ¬ì¡° ì¶”ê°€
                    "extraction_method": "python-docx",
                    "char_count": len(text_content),
                    "extraction_note": f"DOCX í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ì¶”ì¶œ ì„±ê³µ (êµ¬ì¡°í™”) - ì´ë¯¸ì§€ {image_count}ê°œ"
                })
                logger.info(f"DOCX ì¶”ì¶œ ì„±ê³µ: {len(text_content)}ì, {paragraph_count}ê°œ ë¬¸ë‹¨, {table_count}ê°œ í‘œ, {image_count}ê°œ ì´ë¯¸ì§€")
            else:
                result["text"] = f"DOCX íŒŒì¼: {Path(file_path).name}\n\n[í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” DOCX íŒŒì¼ì…ë‹ˆë‹¤]"
                result["metadata"]["extraction_note"] = "ì¶”ì¶œ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŒ"
            
        except Exception as e:
            result["success"] = False
            result["error"] = f"DOCX íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            logger.error(f"DOCX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return result
    
    async def _extract_excel_file(self, file_path: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """Excel íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ (openpyxl ì‚¬ìš©) - ì‹œíŠ¸ë³„ êµ¬ì¡°í™”"""
        try:
            from openpyxl import load_workbook
            
            workbook = load_workbook(file_path, read_only=True)
            text_content = ""
            sheet_count = 0
            sheets_data = []  # ì‹œíŠ¸ ë°ì´í„°
            
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                sheet_count += 1
                text_content += f"\n[ì‹œíŠ¸: {sheet_name}]\n"
                
                row_count = 0
                sheet_rows = []
                for row in sheet.iter_rows(values_only=True):
                    if any(cell is not None and str(cell).strip() for cell in row):
                        row_text = " | ".join([str(cell) if cell is not None else "" for cell in row])
                        text_content += row_text + "\n"
                        sheet_rows.append(row_text)
                        row_count += 1
                        
                        # ë„ˆë¬´ ë§ì€ í–‰ì€ ì œí•œ
                        if row_count > 1000:
                            text_content += "[... ì¶”ê°€ í–‰ ìƒëµ ...]\n"
                            break
                
                sheets_data.append({
                    'sheet_no': sheet_count,
                    'sheet_name': sheet_name,
                    'rows_count': row_count,
                    'content': sheet_rows[:100]  # ìµœëŒ€ 100í–‰ê¹Œì§€ë§Œ
                })
            
            workbook.close()
            
            if text_content.strip():
                result["text"] = text_content.strip()
                result["metadata"].update({
                    "sheet_count": sheet_count,
                    "sheets": sheets_data,
                    "extraction_method": "openpyxl",
                    "char_count": len(text_content),
                    "extraction_note": "Excel í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ (ì‹œíŠ¸ë³„ êµ¬ì¡°í™”)"
                })
                logger.info(f"Excel í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ: {len(text_content)}ì, {sheet_count}ê°œ ì‹œíŠ¸")
            else:
                result["text"] = f"Excel íŒŒì¼: {Path(file_path).name}\n\n[í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” Excel íŒŒì¼ì…ë‹ˆë‹¤]"
                result["metadata"]["extraction_note"] = "ì¶”ì¶œ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŒ"
            
        except Exception as e:
            result["success"] = False
            result["error"] = f"Excel íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            logger.error(f"Excel í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return result
    
    async def _extract_hwp_file(self, file_path: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """HWP íŒŒì¼ ë° HWPX íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê°œì„ ëœ ë°©ì‹)"""
        try:
            # ìƒˆë¡œìš´ HWP ë³€í™˜ ì„œë¹„ìŠ¤ ì‚¬ìš©
            from .hwp_converter_service import hwp_converter_service
            
            # LibreOffice ë³€í™˜ ë°©ì‹ ì‹œë„
            hwp_result = await hwp_converter_service.extract_text_from_hwp(file_path)
            
            if hwp_result['success']:
                result['success'] = True
                result['text'] = hwp_result['text']
                result['metadata'].update(hwp_result['metadata'])
                result['metadata']['extraction_method'] = 'libreoffice_conversion'
            else:
                # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
                ext = Path(file_path).suffix.lower()
                if ext == '.hwpx':
                    # HWPX: ZIP + XML êµ¬ì¡°
                    import zipfile
                    try:
                        import lxml.etree as ET
                    except ImportError:
                        import xml.etree.ElementTree as ET
                    
                    with zipfile.ZipFile(file_path, 'r') as z:
                        # ê¸°ë³¸ ì„¹ì…˜ íŒŒì¼ ì½ê¸°
                        xml_names = [n for n in z.namelist() if n.endswith('.xml')]
                        text_content = ''
                        for name in xml_names:
                            try:
                                data = z.read(name)
                                tree = ET.fromstring(data)
                                # ëª¨ë“  í…ìŠ¤íŠ¸ ë…¸ë“œ ìˆ˜ì§‘
                                texts = tree.xpath('//text()')
                                text_content += '\n'.join(texts) + '\n'
                            except Exception:
                                continue
                    
                    result['text'] = text_content.strip() or f'HWPX íŒŒì¼ì…ë‹ˆë‹¤: {Path(file_path).name}\n[í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨]'
                    result['metadata'].update({
                        'extraction_method': 'hwp5-xml-fallback',
                        'char_count': len(result['text']),
                        'extraction_note': 'HWPX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ (í´ë°± ë°©ì‹)'
                    })
                else:
                    # HWP: OLE íŒŒì¼ PrvText ìŠ¤íŠ¸ë¦¼ ì¶”ì¶œ
                    import olefile
                    ole = olefile.OleFileIO(file_path)
                    if ole.exists('PrvText'):
                        raw = ole.openstream('PrvText').read()
                        try:
                            text = raw.decode('utf-16le')
                        except Exception:
                            text = raw.decode('cp949', errors='ignore')
                        result['text'] = text.strip() or f'HWP íŒŒì¼ì…ë‹ˆë‹¤: {Path(file_path).name}\n[PrvText ë¹ˆ ìŠ¤íŠ¸ë¦¼]'
                        result['metadata'].update({
                            'extraction_method': 'olefile-PrvText-fallback',
                            'char_count': len(result['text']),
                            'extraction_note': 'HWP í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ (í´ë°± ë°©ì‹)'
                        })
                    else:
                        result['text'] = f'HWP íŒŒì¼ì…ë‹ˆë‹¤: {Path(file_path).name}\n[PrvText ìŠ¤íŠ¸ë¦¼ ì—†ìŒ]'
                        result['metadata']['extraction_note'] = 'HWP PrvText ìŠ¤íŠ¸ë¦¼ ì—†ìŒ (í´ë°± ë°©ì‹)'
                        
        except Exception as e:
            result['success'] = False
            result['error'] = f'HWP/HWPX ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}'
        
        return result
    
    def _get_extraction_method(self, file_extension: str) -> str:
        """íŒŒì¼ í™•ì¥ìë³„ ì¶”ì¶œ ë°©ë²• ë°˜í™˜"""
        methods = {
            '.txt': 'direct_text_read',
            '.md': 'direct_text_read',
            '.py': 'direct_text_read',
            '.js': 'direct_text_read',
            '.html': 'direct_text_read',
            '.css': 'direct_text_read',
            '.json': 'direct_text_read',
            '.xml': 'direct_text_read',
            '.pdf': 'pdf_extraction_library',
            '.docx': 'python_docx_library',
            '.doc': 'python_docx_library',
            '.xlsx': 'openpyxl_library',
            '.xls': 'openpyxl_library',
            '.pptx': 'python_pptx_library',
            '.ppt': 'python_pptx_library',
            '.hwp': 'olefile_library'
        }
        return methods.get(file_extension.lower(), 'unknown')

    async def _extract_pptx_file(self, file_path: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """PPTX íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ (python-pptx ì‚¬ìš©)"""
        try:
            from pptx import Presentation
            import io
            from PIL import Image
            
            presentation = Presentation(file_path)
            text_content = ""
            slide_count = 0
            shape_count = 0
            total_text_length = 0
            slides_data = []  # ìŠ¬ë¼ì´ë“œë³„ êµ¬ì¡°í™” ë°ì´í„°
            
            # ìŠ¬ë¼ì´ë“œë³„ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            for slide_idx, slide in enumerate(presentation.slides):
                slide_count += 1
                slide_text = f"\n[ìŠ¬ë¼ì´ë“œ {slide_idx + 1}]\n"
                slide_has_content = False
                slide_tables_count = 0
                slide_charts_count = 0
                slide_text_content = ""
                slide_tables_metadata = []  # í‘œ ìƒì„¸ êµ¬ì¡° (cells í¬í•¨)
                
                # ìŠ¬ë¼ì´ë“œì˜ ëª¨ë“  shapeì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                for shape_idx, shape in enumerate(slide.shapes):
                    shape_content = ""
                    
                    try:
                        # Shape ìœ í˜• í™•ì¸ (ì•ˆì „í•œ ì²˜ë¦¬ë¥¼ ìœ„í•´)
                        shape_type = getattr(shape, 'shape_type', None)
                        
                        # í…ìŠ¤íŠ¸ ë°•ìŠ¤/ë„í˜•ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        if hasattr(shape, "text"):
                            text = shape.text.strip()
                            if text:
                                shape_content += text + "\n"
                                slide_has_content = True
                        
                        # í…ìŠ¤íŠ¸ í”„ë ˆì„ì´ ìˆëŠ” ê²½ìš° (ë” ìƒì„¸í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
                        if hasattr(shape, "text_frame") and shape.text_frame is not None:
                            try:
                                for paragraph in shape.text_frame.paragraphs:
                                    paragraph_text = ""
                                    for run in paragraph.runs:
                                        if run.text and run.text.strip():
                                            paragraph_text += run.text
                                    if paragraph_text.strip():
                                        shape_content += paragraph_text.strip() + "\n"
                                        slide_has_content = True
                            except Exception as e:
                                logger.debug(f"í…ìŠ¤íŠ¸ í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
                                pass
                        
                        # í‘œê°€ ìˆëŠ” ê²½ìš° í‘œ ë‚´ìš©ë„ ì¶”ì¶œ
                        if hasattr(shape, "table") and shape.table is not None:
                            try:
                                table = shape.table
                                slide_tables_count += 1  # âœ… í‘œ ì¹´ìš´íŠ¸
                                table_content = "\n[í‘œ]\n"
                                table_rows_raw = []
                                table_cells_2d = []
                                for row in table.rows:
                                    row_texts = []
                                    for cell in row.cells:
                                        cell_text = cell.text.strip() if cell.text else ""
                                        if cell_text:
                                            row_texts.append(cell_text)
                                        else:
                                            row_texts.append("")
                                    if row_texts:
                                        table_content += " | ".join(row_texts) + "\n"
                                    table_rows_raw.append(" | ".join(row_texts))
                                    table_cells_2d.append(row_texts)
                                if len(table_content) > 10:  # ì‹¤ì œ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ
                                    shape_content += table_content
                                    slide_has_content = True
                                # í‘œ ë©”íƒ€ë°ì´í„° ì €ì¥ (ë‚´ìš© ìœ ë¬´ ìƒê´€ì—†ì´ êµ¬ì¡° ë³´ì¡´)
                                slide_tables_metadata.append({
                                    'table_index': slide_tables_count - 1,
                                    'rows_count': len(table.rows),
                                    'cols_count': len(table.columns) if hasattr(table, 'columns') else 0,
                                    'content': table_rows_raw,
                                    'cells': table_cells_2d,
                                    'has_header': True if table_rows_raw else False
                                })
                            except Exception as e:
                                logger.debug(f"í‘œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
                                pass
                        
                        # ì°¨íŠ¸ì˜ ì œëª©ì´ë‚˜ ë°ì´í„° ë ˆì´ë¸” ì¶”ì¶œ ì‹œë„
                        try:
                            if hasattr(shape, "chart"):
                                # ì°¨íŠ¸ ê°ì²´ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ ë” ì•ˆì „í•˜ê²Œ í™•ì¸
                                chart = getattr(shape, "chart", None)
                                if chart is not None:
                                    slide_charts_count += 1  # âœ… ì°¨íŠ¸ ì¹´ìš´íŠ¸
                                    try:
                                        # ì°¨íŠ¸ ì œëª© ì¶”ì¶œ ì‹œë„
                                        if hasattr(chart, "chart_title") and chart.chart_title:
                                            if hasattr(chart.chart_title, "has_text_frame") and chart.chart_title.has_text_frame:
                                                chart_title = chart.chart_title.text_frame.text.strip()
                                                if chart_title:
                                                    shape_content += f"[ì°¨íŠ¸ ì œëª©] {chart_title}\n"
                                                    slide_has_content = True
                                    except Exception as chart_title_error:
                                        logger.debug(f"ì°¨íŠ¸ ì œëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {chart_title_error}")
                                        pass
                        except Exception as e:
                            # ì°¨íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
                            logger.debug(f"ì°¨íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
                            pass
                        
                        if shape_content:
                            shape_count += 1
                            slide_text += f"  {shape_content}"
                            total_text_length += len(shape_content)
                            
                    except Exception as shape_error:
                        # ê°œë³„ shape ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ë‹¤ìŒ shapeë¡œ ê³„ì† ì§„í–‰
                        logger.debug(f"Shape ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {shape_error}")
                        continue
                
                # ìŠ¬ë¼ì´ë“œ ë…¸íŠ¸ ì¶”ì¶œ ì‹œë„
                try:
                    if hasattr(slide, "notes_slide") and slide.notes_slide and slide.notes_slide.shapes:
                        notes_text = ""
                        for shape in slide.notes_slide.shapes:
                            if hasattr(shape, "text") and shape.text and shape.text.strip():
                                notes_text += shape.text.strip() + " "
                        if notes_text.strip():
                            slide_text += f"\n[ë…¸íŠ¸] {notes_text.strip()}\n"
                            slide_has_content = True
                            total_text_length += len(notes_text)
                except Exception as e:
                    logger.debug(f"ìŠ¬ë¼ì´ë“œ ë…¸íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
                    pass
                
                if slide_has_content:
                    text_content += slide_text
                    slide_text_content = slide_text
                else:
                    # í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ìŠ¬ë¼ì´ë“œë„ ê¸°ë¡
                    text_content += f"\n[ìŠ¬ë¼ì´ë“œ {slide_idx + 1}] (ì‹œê°ì  ì½˜í…ì¸  - í…ìŠ¤íŠ¸ ì—†ìŒ)\n"
                    slide_text_content = "(ì‹œê°ì  ì½˜í…ì¸  - í…ìŠ¤íŠ¸ ì—†ìŒ)"
                
                # ìŠ¬ë¼ì´ë“œë³„ êµ¬ì¡°í™” ë°ì´í„° ì €ì¥
                
                # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ìš©)
                images_metadata = []
                for shape in slide.shapes:
                    try:
                        # ì´ë¯¸ì§€ ë˜ëŠ” ê·¸ë¦¼ shape í™•ì¸
                        if hasattr(shape, 'image'):
                            try:
                                img_blob = shape.image.blob  # ì›ë³¸ ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬
                                img_ext = shape.image.ext or 'png'
                                size_bytes = len(img_blob)
                                pixel_width = None
                                pixel_height = None
                                try:
                                    with Image.open(io.BytesIO(img_blob)) as im:
                                        pixel_width, pixel_height = im.size
                                except Exception as pil_err:
                                    logger.debug(f"PPTX ì´ë¯¸ì§€ PIL ë¡œë“œ ì‹¤íŒ¨ (ë¬´ì‹œ): {pil_err}")
                                images_metadata.append({
                                    'image_index': len(images_metadata),
                                    'left': int(getattr(shape, 'left', 0)),
                                    'top': int(getattr(shape, 'top', 0)),
                                    'width': int(getattr(shape, 'width', 0)),
                                    'height': int(getattr(shape, 'height', 0)),
                                    'ext': img_ext,
                                    'size_bytes': size_bytes,
                                    'pixel_width': pixel_width,
                                    'pixel_height': pixel_height,
                                    'binary_data': img_blob  # ë©€í‹°ëª¨ë‹¬ í›„ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì œê±° / í™œìš©
                                })
                            except Exception as im_err:
                                logger.debug(f"PPTX ì´ë¯¸ì§€ ë©”íƒ€ ìˆ˜ì§‘ ì‹¤íŒ¨ (ë¬´ì‹œ): {im_err}")
                    except:
                        pass
                
                slides_data.append({
                    'slide_no': slide_idx + 1,
                    'text': slide_text_content.strip(),
                    'tables_count': slide_tables_count,
                    'charts_count': slide_charts_count,
                    'images_count': len(images_metadata),  # âœ… ì´ë¯¸ì§€ ê°œìˆ˜
                    'images_metadata': images_metadata,  # âœ… ì´ë¯¸ì§€ ìƒì„¸ ì •ë³´
                    'tables_metadata': slide_tables_metadata,  # í‘œ ìƒì„¸ êµ¬ì¡°
                    'char_count': len(slide_text_content),
                    'has_content': slide_has_content
                })
            
            # ê²°ê³¼ ì²˜ë¦¬
            if total_text_length > 10:  # ìµœì†Œ 10ì ì´ìƒì˜ ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•Œ
                result["text"] = text_content.strip()
                result["metadata"].update({
                    "slide_count": slide_count,
                    "slides": slides_data,  # âœ… ì¶”ê°€
                    "shape_count": shape_count,
                    "total_tables": sum(s['tables_count'] for s in slides_data),
                    "total_charts": sum(s['charts_count'] for s in slides_data),
                    "total_images": sum(s.get('images_count', 0) for s in slides_data),  # âœ… ì „ì²´ ì´ë¯¸ì§€ ê°œìˆ˜
                    "extraction_method": "python-pptx-enhanced",
                    "char_count": len(text_content),
                    "meaningful_text_length": total_text_length,
                    "extraction_note": "PPTX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ (ìŠ¬ë¼ì´ë“œë³„ êµ¬ì¡°í™”, ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° í¬í•¨)"
                })
                logger.info(f"PPTX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ: {len(text_content)}ì (ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸: {total_text_length}ì), {slide_count}ìŠ¬ë¼ì´ë“œ")
            else:
                # í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë©”ì‹œì§€ì™€ í•¨ê»˜ ìŠ¬ë¼ì´ë“œ ì •ë³´ ì œê³µ
                fallback_text = f"PowerPoint íŒŒì¼: {Path(file_path).name}\n\n"
                fallback_text += f"ì´ {slide_count}ê°œ ìŠ¬ë¼ì´ë“œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n"
                fallback_text += "ì£¼ë¡œ ì´ë¯¸ì§€, ë„í˜•, ì°¨íŠ¸ ë“±ì˜ ì‹œê°ì  ì½˜í…ì¸ ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ì œí•œì ì…ë‹ˆë‹¤.\n\n"
                if text_content.strip():
                    fallback_text += "ì¶”ì¶œëœ ì¼ë¶€ ë‚´ìš©:\n" + text_content.strip()
                
                result["text"] = fallback_text
                result["metadata"].update({
                    "slide_count": slide_count,
                    "slides": slides_data,  # âœ… ì¶”ê°€
                    "shape_count": shape_count,
                    "total_tables": sum(s['tables_count'] for s in slides_data),
                    "total_charts": sum(s['charts_count'] for s in slides_data),
                    "extraction_method": "python-pptx-enhanced",
                    "char_count": len(fallback_text),
                    "meaningful_text_length": total_text_length,
                    "extraction_note": "PPTX íŒŒì¼ì´ì§€ë§Œ ì¶”ì¶œ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ê°€ ì œí•œì ì„"
                })
                logger.info(f"PPTX ì²˜ë¦¬ ì™„ë£Œ: {slide_count}ìŠ¬ë¼ì´ë“œ, ì¶”ì¶œëœ í…ìŠ¤íŠ¸ {total_text_length}ì (ì œí•œì )")
                
        except ImportError:
            result["success"] = False
            result["error"] = "python-pptx ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install python-pptx"
            logger.error("python-pptx ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ")
        except Exception as e:
            result["success"] = False
            result["error"] = f"PPTX íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            logger.error(f"PPTX í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return result

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
text_extractor_service = TextExtractorService()
