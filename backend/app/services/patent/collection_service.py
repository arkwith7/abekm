"""
íŠ¹í—ˆ ìˆ˜ì§‘ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
- ìˆ˜ì§‘ ì„¤ì • CRUD
- ì‘ì—… ìƒíƒœ ê´€ë¦¬
- íŠ¹í—ˆ ë°ì´í„° ì €ì¥ (ì„œì§€ì •ë³´ + ë¬¸ì„œ ë ˆì½”ë“œ)
"""
from __future__ import annotations
from typing import List, Optional, Dict, Any
from datetime import datetime, date
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update, or_
from loguru import logger

from app.models.patent import (
    TbPatentCollectionSettings,
    TbPatentCollectionTasks,
    TbPatentBibliographicInfo,
)
# ë¬¸ì„œ ë©”íƒ€ ëª¨ë¸ (íŒŒì¼ ê¸°ë³¸ ì •ë³´)
from app.models.document import TbFileBssInfo, TbDocumentSearchIndex
from app.models.document.multimodal_models import DocEmbedding, DocChunk, DocChunkSession
# S3 ë° ì„ë² ë”© ì„œë¹„ìŠ¤
from app.services.core.aws_service import S3Service
from app.services.core.embedding_service import EmbeddingService
import os
from pathlib import Path


class PatentCollectionService:
    """íŠ¹í—ˆ ìˆ˜ì§‘ ì„œë¹„ìŠ¤"""

    def __init__(self, session: AsyncSession):
        self.session = session

    @staticmethod
    def _parse_date(date_str: Optional[str]) -> Optional[date]:
        """
        KIPRIS ë‚ ì§œ ë¬¸ìì—´(YYYYMMDD)ì„ date ê°ì²´ë¡œ ë³€í™˜
        
        Args:
            date_str: YYYYMMDD í˜•ì‹ì˜ ë¬¸ìì—´ (ì˜ˆ: '20230614')
            
        Returns:
            date ê°ì²´ ë˜ëŠ” None
        """
        if not date_str:
            return None
        
        try:
            # YYYYMMDD í˜•ì‹
            if len(date_str) == 8:
                return datetime.strptime(date_str, '%Y%m%d').date()
            # YYYY-MM-DD í˜•ì‹ (ì´ë¯¸ í‘œì¤€ í˜•ì‹ì¸ ê²½ìš°)
            elif '-' in date_str:
                return datetime.strptime(date_str, '%Y-%m-%d').date()
            else:
                logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë‚ ì§œ í˜•ì‹: {date_str}")
                return None
        except Exception as e:
            logger.warning(f"âš ï¸ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_str}, {e}")
            return None

    # ---------------------------
    # ì„¤ì • ê´€ë¦¬
    # ---------------------------
    async def create_collection_setting(
        self,
        user_emp_no: str,
        container_id: str,
        search_config: Dict[str, Any],
        max_results: int = 100,
        auto_download_pdf: bool = False,
        auto_generate_embeddings: bool = True,
        schedule_type: str = "manual",
        schedule_config: Optional[Dict[str, Any]] = None,
    ) -> TbPatentCollectionSettings:
        setting = TbPatentCollectionSettings(
            user_emp_no=user_emp_no,
            container_id=container_id,
            search_config=search_config,
            max_results=max_results,
            auto_download_pdf=auto_download_pdf,
            auto_generate_embeddings=auto_generate_embeddings,
            schedule_type=schedule_type,
            schedule_config=schedule_config,
        )
        self.session.add(setting)
        await self.session.commit()
        await self.session.refresh(setting)
        logger.info(f"âœ… íŠ¹í—ˆ ìˆ˜ì§‘ ì„¤ì • ìƒì„±: {setting.setting_id}")
        return setting

    async def get_user_settings(
        self,
        user_emp_no: str,
        container_id: Optional[str] = None,
    ) -> List[TbPatentCollectionSettings]:
        query = select(TbPatentCollectionSettings).where(
            TbPatentCollectionSettings.user_emp_no == user_emp_no,
            TbPatentCollectionSettings.is_active.is_(True),
        )
        if container_id:
            query = query.where(TbPatentCollectionSettings.container_id == container_id)
        result = await self.session.execute(query)
        return list(result.scalars().all())

    async def get_user_setting_by_id(
        self,
        user_emp_no: str,
        setting_id: int,
        include_inactive: bool = False,
    ) -> Optional[TbPatentCollectionSettings]:
        query = select(TbPatentCollectionSettings).where(
            TbPatentCollectionSettings.setting_id == setting_id,
            TbPatentCollectionSettings.user_emp_no == user_emp_no,
        )
        if not include_inactive:
            query = query.where(TbPatentCollectionSettings.is_active.is_(True))
        result = await self.session.execute(query)
        return result.scalar_one_or_none()

    async def update_collection_setting(
        self,
        user_emp_no: str,
        setting_id: int,
        *,
        container_id: Optional[str] = None,
        search_config: Optional[Dict[str, Any]] = None,
        max_results: Optional[int] = None,
        auto_download_pdf: Optional[bool] = None,
        auto_generate_embeddings: Optional[bool] = None,
        schedule_type: Optional[str] = None,
        schedule_config: Optional[Dict[str, Any]] = None,
    ) -> Optional[TbPatentCollectionSettings]:
        setting = await self.get_user_setting_by_id(user_emp_no, setting_id)
        if not setting:
            return None

        values: Dict[str, Any] = {}
        if container_id is not None:
            values["container_id"] = container_id
        if search_config is not None:
            values["search_config"] = search_config
        if max_results is not None:
            values["max_results"] = max_results
        if auto_download_pdf is not None:
            values["auto_download_pdf"] = auto_download_pdf
        if auto_generate_embeddings is not None:
            values["auto_generate_embeddings"] = auto_generate_embeddings
        if schedule_type is not None:
            values["schedule_type"] = schedule_type
        if schedule_config is not None:
            values["schedule_config"] = schedule_config

        if not values:
            return setting

        await self.session.execute(
            update(TbPatentCollectionSettings)
            .where(
                TbPatentCollectionSettings.setting_id == setting_id,
                TbPatentCollectionSettings.user_emp_no == user_emp_no,
                TbPatentCollectionSettings.is_active.is_(True),
            )
            .values(**values)
        )
        await self.session.commit()
        updated = await self.get_user_setting_by_id(user_emp_no, setting_id)
        if updated:
            logger.info(f"âœ… íŠ¹í—ˆ ìˆ˜ì§‘ ì„¤ì • ìˆ˜ì •: {setting_id}")
        return updated

    async def deactivate_collection_setting(
        self,
        user_emp_no: str,
        setting_id: int,
    ) -> bool:
        setting = await self.get_user_setting_by_id(user_emp_no, setting_id)
        if not setting:
            return False

        await self.session.execute(
            update(TbPatentCollectionSettings)
            .where(
                TbPatentCollectionSettings.setting_id == setting_id,
                TbPatentCollectionSettings.user_emp_no == user_emp_no,
                TbPatentCollectionSettings.is_active.is_(True),
            )
            .values(is_active=False)
        )
        await self.session.commit()
        logger.info(f"âœ… íŠ¹í—ˆ ìˆ˜ì§‘ ì„¤ì • ë¹„í™œì„±í™”(ì‚­ì œ): {setting_id}")
        return True

    # ---------------------------
    # ì‘ì—… ê´€ë¦¬
    # ---------------------------
    async def create_task_record(
        self,
        task_id: str,
        setting_id: Optional[int],
        user_emp_no: str,
    ) -> TbPatentCollectionTasks:
        task = TbPatentCollectionTasks(
            task_id=task_id,
            setting_id=setting_id,
            user_emp_no=user_emp_no,
            status="pending",
            progress_current=0,
            progress_total=0,
        )
        self.session.add(task)
        await self.session.commit()
        await self.session.refresh(task)
        return task

    async def update_task_progress(
        self,
        task_id: str,
        progress_current: int,
        progress_total: int,
        status: str = "running",
        collected_count: Optional[int] = None,
        skipped_count: Optional[int] = None,
        error_count: Optional[int] = None,
    ) -> None:
        values: Dict[str, Any] = {
            "status": status,
            "progress_current": progress_current,
            "progress_total": progress_total,
        }
        if collected_count is not None:
            values["collected_count"] = collected_count
        if error_count is not None:
            values["error_count"] = error_count
        await self.session.execute(
            update(TbPatentCollectionTasks)
            .where(TbPatentCollectionTasks.task_id == task_id)
            .values(**values)
        )
        await self.session.commit()

        # ì™„ë£Œ ì‹œ ì„¤ì •ì˜ last_collection_result ì—…ë°ì´íŠ¸
        if status == "completed":
            # taskì—ì„œ setting_id ê°€ì ¸ì˜¤ê¸°
            task_result = await self.session.execute(
                select(TbPatentCollectionTasks).where(
                    TbPatentCollectionTasks.task_id == task_id
                )
            )
            task = task_result.scalar_one_or_none()
            if task and task.setting_id:
                # ì´ ë³´ìœ  ê±´ìˆ˜ ê³„ì‚° (ì‹ ê·œ + ìŠ¤í‚µ = í•´ë‹¹ ì¡°ê±´ìœ¼ë¡œ ë³´ìœ  ì¤‘ì¸ íŠ¹í—ˆ)
                total_owned = (collected_count or 0) + (skipped_count or 0)
                await self.session.execute(
                    update(TbPatentCollectionSettings)
                    .where(TbPatentCollectionSettings.setting_id == task.setting_id)
                    .values(
                        last_collection_date=datetime.utcnow(),
                        last_collection_result={
                            "new": collected_count or 0,      # ì‹ ê·œ ì €ì¥
                            "skipped": skipped_count or 0,    # ì´ë¯¸ ì¡´ì¬
                            "errors": error_count or 0,       # ì˜¤ë¥˜
                            "total_owned": total_owned,       # ì´ ë³´ìœ 
                            "searched": progress_total,       # ê²€ìƒ‰ ê²°ê³¼
                        }
                    )
                )
                await self.session.commit()
                logger.info(f"âœ… ì„¤ì • {task.setting_id} ìˆ˜ì§‘ ê²°ê³¼: ì‹ ê·œ={collected_count}, ìŠ¤í‚µ={skipped_count}, ì´ ë³´ìœ ={total_owned}")

    # ---------------------------
    # íŠ¹í—ˆ ë°ì´í„° ì €ì¥
    # ---------------------------
    async def save_patent_to_database(
        self,
        patent_data: Dict[str, Any],
        container_id: str,
        user_emp_no: str,
        auto_generate_embeddings: bool = True,
    ) -> tuple[Optional[int], bool]:
        """
        1) ì„œì§€ì •ë³´ ì €ì¥
        2) ë¬¸ì„œ ë©”íƒ€ ì €ì¥ (tb_file_bss_info)
        3) (file_sno, is_new) íŠœí”Œ ë°˜í™˜
           - is_new=True: ì‹ ê·œ ì €ì¥ë¨
           - is_new=False: ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ìŠ¤í‚µë¨
        """
        app_no = patent_data.get("applicationNumber")
        if not app_no:
            logger.warning("âš ï¸ applicationNumber ëˆ„ë½ìœ¼ë¡œ ìŠ¤í‚µ")
            return (None, False)

        # ì¤‘ë³µ ì²´í¬ (ì„œì§€ì •ë³´ ê¸°ì¤€). ì´ë¯¸ ì¡´ì¬í•˜ë”ë¼ë„ ë¬¸ì„œ ëª©ë¡ ì—”íŠ¸ë¦¬(TbFileBssInfo)ê°€ ì—†ìœ¼ë©´ ìƒì„±í•œë‹¤.
        existing_biblio_result = await self.session.execute(
            select(TbPatentBibliographicInfo).where(
                TbPatentBibliographicInfo.application_number == app_no
            )
        )
        existing_biblio = existing_biblio_result.scalar_one_or_none()

        # íŠ¹í—ˆ ì ‘ê·¼ URL ìƒì„± (ì›ë³¸ íŒŒì¼ ì €ì¥í•˜ì§€ ì•Šê³  URLë§Œ ì €ì¥)
        pub_no = str(patent_data.get('publicationNumber') or '').strip()
        # Google Patents URLì—ëŠ” KR ì ‘ë‘ì‚¬ í•„ìš”!
        if pub_no:
            source_url = f"https://patents.google.com/?q=KR{pub_no}"
        else:
            source_url = f"https://patents.google.com/?q=KR{app_no}"

        # ğŸ” ì‚¬ìš©ì ê¸°ì¤€ ì „ì—­ ì¤‘ë³µ ì²´í¬ (ëª¨ë“  ì»¨í…Œì´ë„ˆ ëŒ€ìƒ)
        # ë™ì¼ ì‚¬ìš©ìê°€ ì´ë¯¸ í•´ë‹¹ íŠ¹í—ˆë¥¼ ì–´ëŠ ì»¨í…Œì´ë„ˆì—ë“  ë“±ë¡í–ˆëŠ”ì§€ í™•ì¸
        # âœ… ì¤‘ë³µ ì²´í¬ëŠ” .url ë¿ ì•„ë‹ˆë¼, ì´ë¯¸ PDFë¡œ ë³€í™˜ëœ ê²½ìš°(.pdf)ë„ í¬í•¨í•´ì•¼ í•¨
        # (PDF ë‹¤ìš´ë¡œë“œ ì˜µì…˜ìœ¼ë¡œ ê¸°ì¡´ .url ë ˆì½”ë“œê°€ .pdfë¡œ ë³€ê²½ë  ìˆ˜ ìˆìŒ)
        existing_file_result = await self.session.execute(
            select(TbFileBssInfo).where(
                TbFileBssInfo.document_type == 'patent',
                TbFileBssInfo.owner_emp_no == user_emp_no,  # ì‚¬ìš©ì ê¸°ì¤€ ì „ì—­ ì²´í¬
                TbFileBssInfo.del_yn != 'Y',
                or_(
                TbFileBssInfo.file_psl_nm == f"{app_no}.url",
                    TbFileBssInfo.file_psl_nm == f"{app_no}.pdf",
                ),
            )
        )
        existing_file = existing_file_result.scalar_one_or_none()
        if existing_file:
            existing_container = existing_file.knowledge_container_id
            if existing_container == container_id:
                logger.info(f"â„¹ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŠ¹í—ˆ: {app_no} (ë™ì¼ ì»¨í…Œì´ë„ˆ) â†’ file_sno={existing_file.file_bss_info_sno}")
            else:
                logger.info(f"â„¹ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŠ¹í—ˆ: {app_no} (ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆ: {existing_container}) â†’ file_sno={existing_file.file_bss_info_sno}")
            return (int(existing_file.file_bss_info_sno), False)  # ìŠ¤í‚µë¨

        try:
            # 1. ì„œì§€ì •ë³´ ì €ì¥ (ë‚ ì§œ ë³€í™˜ í¬í•¨)
            if not existing_biblio:
                biblio = TbPatentBibliographicInfo(
                    application_number=app_no,
                    publication_number=patent_data.get("publicationNumber"),
                    title=patent_data.get("inventionTitle") or app_no,
                    abstract=patent_data.get("abstract"),
                    # ë‚ ì§œ í•„ë“œ - ë¬¸ìì—´ì„ date ê°ì²´ë¡œ ë³€í™˜
                    application_date=self._parse_date(patent_data.get("applicationDate")),
                    publication_date=self._parse_date(patent_data.get("publicationDate")),
                    registration_date=self._parse_date(patent_data.get("registrationDate")),
                    # ê¸°íƒ€ í•„ë“œ
                    jurisdiction=patent_data.get("country", "KR"),
                    legal_status=patent_data.get("legalStatus", "APPLICATION"),
                    data_source="KIPRIS",
                    source_url=source_url,
                    knowledge_container_id=container_id,
                    imported_by=user_emp_no,
                )
                self.session.add(biblio)
                await self.session.flush()
            else:
                # ê¸°ì¡´ ì„œì§€ì •ë³´ì— URL/ì»¨í…Œì´ë„ˆ/ìˆ˜ì§‘ì ì •ë³´ê°€ ë¹„ì–´ìˆìœ¼ë©´ ë³´ê°•
                await self.session.execute(
                    update(TbPatentBibliographicInfo)
                    .where(TbPatentBibliographicInfo.patent_id == existing_biblio.patent_id)
                    .values(
                        knowledge_container_id=existing_biblio.knowledge_container_id or container_id,
                        imported_by=existing_biblio.imported_by or user_emp_no,
                        source_url=existing_biblio.source_url or source_url,
                    )
                )

            # 2. ë¬¸ì„œ ë©”íƒ€ ì €ì¥
            title = (patent_data.get("inventionTitle") or "").strip() or app_no
            file_lgc_nm = title
            file_psl_nm = f"{app_no}.url"
            file_extsn = "url"
            
            file_record = TbFileBssInfo(
                drcy_sno=1,
                file_lgc_nm=file_lgc_nm,
                file_psl_nm=file_psl_nm,
                file_extsn=file_extsn,
                path=source_url,
                knowledge_container_id=container_id,
                document_type="patent",
                owner_emp_no=user_emp_no,
                created_by=user_emp_no,
                processing_status="completed",  # ì„œì§€ ì„ë² ë”©/ì¸ë±ì‹± ì™„ë£Œ ê¸°ì¤€ìœ¼ë¡œ completed
                processing_completed_at=datetime.utcnow(),
                korean_metadata={
                    "applicationNumber": app_no,
                    "publicationNumber": pub_no or None,
                    "data_source": "KIPRIS",
                    "source_url": source_url,
                },
            )
            self.session.add(file_record)
            await self.session.flush()  # file_sno ìƒì„±
            
            # 3. ì„ë² ë”© ìƒì„± (ì œëª© + ì´ˆë¡)
            if auto_generate_embeddings:
                await self._generate_patent_embeddings(
                    file_record.file_bss_info_sno,
                    patent_data,
                    container_id,
                    user_emp_no
                )
            
            await self.session.commit()
            await self.session.refresh(file_record)

            logger.info(f"âœ… íŠ¹í—ˆ ì €ì¥ ì™„ë£Œ: {app_no} â†’ file_sno={file_record.file_bss_info_sno}")
            return (file_record.file_bss_info_sno, True)  # ì‹ ê·œ ì €ì¥ë¨

        except Exception as e:
            logger.error(f"âŒ íŠ¹í—ˆ ì €ì¥ ì‹¤íŒ¨: {app_no}, {e}")
            await self.session.rollback()
            return (None, False)

    async def _generate_patent_embeddings(
        self,
        file_sno: int,
        patent_data: Dict[str, Any],
        container_id: str,
        user_emp_no: str,
    ) -> None:
        """
        íŠ¹í—ˆ ì„œì§€ì •ë³´(ì œëª©+ì´ˆë¡)ë¡œë¶€í„° ì„ë² ë”© ìƒì„± ë° ê²€ìƒ‰ ì¸ë±ìŠ¤ ì €ì¥
        
        Args:
            file_sno: íŒŒì¼ ì¼ë ¨ë²ˆí˜¸
            patent_data: íŠ¹í—ˆ ë°ì´í„°
            container_id: ì»¨í…Œì´ë„ˆ ID
            user_emp_no: ì‚¬ìš©ì ì‚¬ë²ˆ
        """
        try:
            # 1. í…ìŠ¤íŠ¸ ê²°í•© (ì œëª© + ì´ˆë¡)
            title = patent_data.get("inventionTitle", "")
            abstract = patent_data.get("abstract", "")
            
            if not title and not abstract:
                logger.warning(f"âš ï¸ íŠ¹í—ˆ {file_sno}: ì œëª©ê³¼ ì´ˆë¡ì´ ëª¨ë‘ ë¹„ì–´ìˆì–´ ì„ë² ë”© ìŠ¤í‚µ")
                return
            
            combined_text = f"{title}\n\n{abstract}".strip()
            
            # 2. ì„ë² ë”© ìƒì„± (EmbeddingService ê¸°ë³¸ ì„¤ì • ì‚¬ìš©)
            embedding_service = EmbeddingService()
            try:
                embeddings = await embedding_service.get_embeddings_batch(
                    texts=[combined_text]
                )
                embedding_vector = embeddings[0] if embeddings else None
            except Exception as e:
                logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
                embedding_vector = None
            
            if not embedding_vector:
                logger.error(f"âŒ íŠ¹í—ˆ {file_sno}: ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                return
            
            # 3. ì¶”ì¶œ ì„¸ì…˜ ìƒì„± (íŠ¹í—ˆìš© - ì²­í¬ ì„¸ì…˜ FK ì¶©ì¡±)
            from datetime import datetime as dt
            from app.models.document.multimodal_models import DocExtractionSession
            
            extraction_session = DocExtractionSession(
                file_bss_info_sno=file_sno,
                provider="kipris",  # íŠ¹í—ˆ ë°ì´í„° ì œê³µì
                model_profile="patent_bibliographic",
                pipeline_type="patent",
                started_at=dt.now(),
                completed_at=dt.now(),
                status="success",
                page_count_detected=1,
            )
            self.session.add(extraction_session)
            await self.session.flush()
            
            # 4. ì²­í¬ ì„¸ì…˜ ìƒì„± (ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í˜¸í™˜)
            chunk_session = DocChunkSession(
                file_bss_info_sno=file_sno,
                extraction_session_id=extraction_session.extraction_session_id,  # FK ì—°ê²°
                strategy_name="patent_bibliographic",
                params_json={"source": "KIPRIS", "fields": ["title", "abstract"]},
                started_at=dt.now(),
                completed_at=dt.now(),
                status="success",
                chunk_count=1,
            )
            self.session.add(chunk_session)
            await self.session.flush()
            
            # 5. ì²­í¬ ìƒì„±
            chunk = DocChunk(
                chunk_session_id=chunk_session.chunk_session_id,
                file_bss_info_sno=file_sno,
                chunk_index=0,
                source_object_ids=[],  # íŠ¹í—ˆëŠ” ê°ì²´ ì¶”ì¶œ ì—†ìŒ
                content_text=combined_text,
                token_count=len(combined_text.split()),
                modality="text",
                section_heading=title,
            )
            self.session.add(chunk)
            await self.session.flush()
            
            # 6. ì„ë² ë”© ì €ì¥ (DocEmbedding)
            from app.core.config import settings
            provider = getattr(settings, 'default_embedding_provider', 'bedrock')
            dimension = len(embedding_vector)
            
            # ë²¤ë”ë³„ ì»¬ëŸ¼ í• ë‹¹
            embedding_data = {
                "chunk_id": chunk.chunk_id,
                "file_bss_info_sno": file_sno,
                "provider": provider,
                "model_name": "amazon.titan-embed-text-v2:0" if provider == "bedrock" else "text-embedding-3-small",
                "modality": "text",
                "dimension": dimension,
            }
            
            if provider == "bedrock" and dimension == 1024:
                embedding_data["aws_vector_1024"] = embedding_vector
            elif provider == "azure_openai" and dimension == 1536:
                embedding_data["azure_vector_1536"] = embedding_vector
            else:
                # ë ˆê±°ì‹œ ë™ì  ë²¡í„°
                embedding_data["vector"] = embedding_vector
            
            doc_embedding = DocEmbedding(**embedding_data)
            self.session.add(doc_embedding)
            
            # 7. ê²€ìƒ‰ ì¸ë±ìŠ¤ ì €ì¥ (TbDocumentSearchIndex)
            search_index = TbDocumentSearchIndex(
                file_bss_info_sno=file_sno,
                knowledge_container_id=container_id,
                document_title=title[:500] if title else "",  # ì œëª© (ìµœëŒ€ 500ì)
                full_content=combined_text,  # ì „ì²´ ë‚´ìš©
                content_summary=combined_text[:1000],  # ìš”ì•½ (ìµœëŒ€ 1000ì)
                document_type="patent",  # ë¬¸ì„œ ìœ í˜•
                language_code="ko",
                has_images=False,  # íŠ¹í—ˆ ì„œì§€ì •ë³´ëŠ” ì´ë¯¸ì§€ ì—†ìŒ
                has_tables=False,
                indexing_status="indexed",
                access_level="normal",
            )
            self.session.add(search_index)
            
            logger.info(f"âœ… íŠ¹í—ˆ ì„ë² ë”© ìƒì„± ì™„ë£Œ: file_sno={file_sno}, dim={len(embedding_vector)}")
            
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            # ì„ë² ë”© ì‹¤íŒ¨í•´ë„ íŠ¹í—ˆ ì €ì¥ì€ ìœ ì§€ (rollback í•˜ì§€ ì•ŠìŒ)

    async def download_and_upload_patent_pdf(
        self,
        application_number: str,
        file_sno: int,
        kipris_client,
    ) -> bool:
        """
        KIPRISì—ì„œ ê³µê°œì „ë¬¸ PDF ë‹¤ìš´ë¡œë“œ í›„ S3 ì—…ë¡œë“œ ë° DB ì—…ë°ì´íŠ¸
        
        KIPRIS Plus APIì˜ getPubFullTextInfoSearchë¥¼ ì‚¬ìš©í•˜ì—¬:
        1. PDF ë‹¤ìš´ë¡œë“œ URL ì¡°íšŒ
        2. PDF ë‹¤ìš´ë¡œë“œ
        3. S3 ì—…ë¡œë“œ
        4. DBì˜ file_extsn, path ì—…ë°ì´íŠ¸
        
        Args:
            application_number: ì¶œì›ë²ˆí˜¸
            file_sno: íŒŒì¼ ì¼ë ¨ë²ˆí˜¸
            kipris_client: KIPRIS API í´ë¼ì´ì–¸íŠ¸
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            # 1. ë¡œì»¬ ê²½ë¡œ ìƒì„±
            upload_dir = Path("uploads/patents")
            upload_dir.mkdir(parents=True, exist_ok=True)
            local_path = upload_dir / f"{application_number}.pdf"
            
            # 2. KIPRISì—ì„œ ê³µê°œì „ë¬¸ PDF ë‹¤ìš´ë¡œë“œ (ìƒˆ API ì‚¬ìš©)
            success = await kipris_client.download_full_text_pdf(
                application_number=application_number,
                save_path=str(local_path)
            )
            
            if not success or not local_path.exists():
                logger.warning(f"âš ï¸ PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ê³µê°œ ì „ë¬¸ ì—†ì„ ìˆ˜ ìˆìŒ): {application_number}")
                return False
            
            file_size = local_path.stat().st_size
            logger.info(f"ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {application_number} ({file_size/1024:.1f} KB)")
            
            # 3. S3 ì—…ë¡œë“œ ì‹œë„ (S3 ì„¤ì •ì´ ì—†ìœ¼ë©´ ë¡œì»¬ ê²½ë¡œ ì‚¬ìš©)
            final_path = str(local_path)
            try:
                s3_service = S3Service()
                s3_key = f"patents/{application_number}.pdf"
                s3_url = await s3_service.upload_file(
                    file_path=str(local_path),
                    object_key=s3_key
                )
                if s3_url:
                    final_path = s3_url
                    # S3 ì—…ë¡œë“œ ì„±ê³µ ì‹œ ë¡œì»¬ íŒŒì¼ ì‚­ì œ
                    try:
                        local_path.unlink()
                    except Exception:
                        pass
                    logger.info(f"â˜ï¸ S3 ì—…ë¡œë“œ ì™„ë£Œ: {application_number} â†’ {s3_url}")
            except Exception as s3_err:
                logger.warning(f"âš ï¸ S3 ì—…ë¡œë“œ ì‹¤íŒ¨ (ë¡œì»¬ íŒŒì¼ ìœ ì§€): {s3_err}")
                # S3 ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ê²½ë¡œ ì‚¬ìš©
                final_path = f"/uploads/patents/{application_number}.pdf"
            
            # 4. DB ì—…ë°ì´íŠ¸ (PDF ê²½ë¡œ, í™•ì¥ì ë³€ê²½)
            stmt = (
                update(TbFileBssInfo)
                .where(TbFileBssInfo.file_bss_info_sno == file_sno)
                .values(
                    file_psl_nm=f"{application_number}.pdf",
                    file_extsn="pdf",
                    path=final_path,
                    processing_status="completed",
                )
            )
            await self.session.execute(stmt)
            await self.session.commit()
            
            logger.info(f"âœ… PDF ì²˜ë¦¬ ì™„ë£Œ: {application_number} â†’ {final_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ PDF ë‹¤ìš´ë¡œë“œ/ì—…ë¡œë“œ ì‹¤íŒ¨: {application_number}, {e}")
            return False
