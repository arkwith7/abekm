"""
Multimodal Search Tool
ì´ë¯¸ì§€ ì¿¼ë¦¬ë¡œ ì´ë¯¸ì§€ ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ ìˆ˜í–‰
"""
from typing import Any, Dict, List, Optional
import base64
import uuid
from datetime import datetime
from langchain_core.tools import BaseTool
from pydantic import BaseModel, Field
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
from loguru import logger

from app.tools.contracts import SearchChunk, SearchToolResult, ToolMetrics
from app.services.document.vision.image_embedding_service import ImageEmbeddingService


class MultimodalSearchInput(BaseModel):
    """ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ë„êµ¬ ì…ë ¥"""
    image_data: str = Field(description="ê²€ìƒ‰í•  ì´ë¯¸ì§€ ë°ì´í„° (base64 ì¸ì½”ë”©)")
    query: str = Field(default="", description="í…ìŠ¤íŠ¸ ì¿¼ë¦¬ (ì„ íƒì‚¬í•­)")
    top_k: int = Field(default=10, description="ë°˜í™˜í•  ê²°ê³¼ ìˆ˜")
    container_ids: List[str] = Field(default_factory=list, description="ê²€ìƒ‰ ëŒ€ìƒ ì»¨í…Œì´ë„ˆ ID")


class MultimodalSearchTool(BaseTool):
    """
    ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ë„êµ¬ - ì´ë¯¸ì§€ ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰
    
    ì‚¬ìš© ì‹œì :
    - ì‚¬ìš©ìê°€ ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•œ ê²½ìš°
    - ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ/ì´ë¯¸ì§€ë¥¼ ì°¾ì•„ì•¼ í•˜ëŠ” ê²½ìš°
    - "ì´ ì´ë¯¸ì§€ì™€ ë¹„ìŠ·í•œ ë¬¸ì„œ" ì§ˆë¬¸
    
    ë™ì‘:
    1. ì´ë¯¸ì§€ â†’ CLIP ì„ë² ë”© ìƒì„±
    2. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (ì´ë¯¸ì§€ ì²­í¬)
    3. ê´€ë ¨ ë¬¸ì„œ ë°˜í™˜
    """
    
    name: str = "multimodal_search"
    description: str = """
    ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ìœ ì‚¬í•œ ì´ë¯¸ì§€/ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    CLIP ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ë©€í‹°ëª¨ë‹¬ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    ì…ë ¥: image_data (base64), query (optional), top_k, container_ids
    ì¶œë ¥: ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼
    """
    args_schema: type[BaseModel] = MultimodalSearchInput
    version: str = "1.0.0"
    
    db_session: Optional[AsyncSession] = Field(default=None, exclude=True)
    
    class Config:
        arbitrary_types_allowed = True

    def _run(self, *args, **kwargs) -> str:
        """ë™ê¸° ì‹¤í–‰ (ë¯¸ì§€ì›)"""
        raise NotImplementedError("ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ì€ ë¹„ë™ê¸°ë¡œë§Œ ì‹¤í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    async def _arun(
        self,
        image_data: str,
        query: str = "",
        top_k: int = 10,
        container_ids: Optional[List[str]] = None,
        db_session: Optional[AsyncSession] = None,
        **kwargs
    ) -> SearchToolResult:
        """
        ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì‹¤í–‰
        
        Args:
            image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„°
            query: í…ìŠ¤íŠ¸ ì¿¼ë¦¬ (ì„ íƒ)
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            container_ids: ê²€ìƒ‰ ëŒ€ìƒ ì»¨í…Œì´ë„ˆ
            db_session: DB ì„¸ì…˜
            
        Returns:
            ToolResult: ê²€ìƒ‰ ê²°ê³¼ (SearchChunk ë¦¬ìŠ¤íŠ¸)
        """
        start_time = datetime.utcnow()
        trace_id = str(uuid.uuid4())
        normalized_containers = [str(cid) for cid in (container_ids or [])]
        db = db_session or self.db_session

        if not db:
            logger.error("âŒ [MultimodalSearch] DB ì„¸ì…˜ ëˆ„ë½")
            return SearchToolResult(
                success=False,
                data=[],
                total_found=0,
                filtered_count=0,
                search_params={},
                metrics=ToolMetrics(latency_ms=0, provider="internal", trace_id=trace_id),
                errors=["DB ì„¸ì…˜ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."],
                trace_id=trace_id,
                tool_name=self.name,
                tool_version=self.version
            )

        if not image_data:
            logger.warning("ğŸ“· [MultimodalSearch] ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ")
            return SearchToolResult(
                success=True,
                data=[],
                total_found=0,
                filtered_count=0,
                search_params={"reason": "no_image"},
                metrics=ToolMetrics(latency_ms=0, provider="internal", trace_id=trace_id),
                errors=[],
                trace_id=trace_id,
                tool_name=self.name,
                tool_version=self.version
            )

        try:
            logger.info(
                f"ğŸ“· [MultimodalSearch] ì‹œì‘: top_k={top_k}, containers={len(normalized_containers)}"
            )

            if image_data.startswith('data:image'):
                image_data = image_data.split(',', 1)[1]
            image_bytes = base64.b64decode(image_data)

            embedding_service = ImageEmbeddingService()
            clip_embedding = await embedding_service.generate_image_embedding(image_bytes=image_bytes)

            if not clip_embedding:
                logger.warning("ğŸ“· [MultimodalSearch] CLIP ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                latency_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
                return SearchToolResult(
                    success=True,
                    data=[],
                    total_found=0,
                    filtered_count=0,
                    search_params={"reason": "embedding_failed"},
                    metrics=ToolMetrics(latency_ms=latency_ms, provider="bedrock", trace_id=trace_id),
                    errors=[],
                    trace_id=trace_id,
                    tool_name=self.name,
                    tool_version=self.version
                )

            clip_dim = 512
            if len(clip_embedding) < clip_dim:
                clip_embedding = clip_embedding + [0.0] * (clip_dim - len(clip_embedding))
            elif len(clip_embedding) > clip_dim:
                clip_embedding = clip_embedding[:clip_dim]

            vector_literal = "[" + ",".join(map(str, clip_embedding)) + "]"

            from app.core.config import settings
            provider = settings.get_current_embedding_provider()

            if provider == 'bedrock':
                vector_column = "de.aws_marengo_vector_512"
                vector_not_null = f"{vector_column} IS NOT NULL"
            else:
                vector_column = "COALESCE(de.azure_clip_vector, de.clip_vector)"
                vector_not_null = "(de.azure_clip_vector IS NOT NULL OR de.clip_vector IS NOT NULL)"

            sql_parts = [
                f"""
                SELECT 
                    dc.chunk_id,
                    dc.file_bss_info_sno as file_id,
                    dc.chunk_index,
                    dc.content_text,
                    dc.modality,
                    dc.blob_key,
                    fbi.file_lgc_nm as file_name,
                    fbi.knowledge_container_id as container_id,
                    1 - ({vector_column} <=> CAST(:vector_literal AS vector)) as similarity
                FROM doc_chunk dc
                JOIN doc_embedding de ON dc.chunk_id = de.chunk_id
                LEFT JOIN tb_file_bss_info fbi ON dc.file_bss_info_sno = fbi.file_bss_info_sno
                WHERE {vector_not_null}
                  AND COALESCE(de.modality, dc.modality) = 'image'
                  AND fbi.del_yn = 'N'
                """
            ]

            params: Dict[str, Any] = {
                "vector_literal": vector_literal,
                "top_k": top_k
            }

            if normalized_containers:
                sql_parts.append("AND fbi.knowledge_container_id = ANY(:container_ids)")
                params["container_ids"] = normalized_containers

            sql_parts.append("ORDER BY similarity DESC LIMIT :top_k")
            query_sql = text(" ".join(sql_parts))

            result = await db.execute(query_sql, params)
            rows = result.fetchall()

            if not rows:
                latency_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
                logger.info("ğŸ“· [MultimodalSearch] ê²°ê³¼ ì—†ìŒ")
                return SearchToolResult(
                    success=True,
                    data=[],
                    total_found=0,
                    filtered_count=0,
                    search_params={
                        "top_k": top_k,
                        "container_ids": normalized_containers,
                        "has_text_query": bool(query)
                    },
                    metrics=ToolMetrics(latency_ms=latency_ms, provider="internal", trace_id=trace_id),
                    errors=[],
                    trace_id=trace_id,
                    tool_name=self.name,
                    tool_version=self.version
                )

            chunks = []
            for row in rows:
                chunk = SearchChunk(
                    chunk_id=str(row.chunk_id),
                    file_id=str(row.file_id),
                    content=row.content_text or "[ì´ë¯¸ì§€ ìº¡ì…˜ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤]",
                    score=float(row.similarity),
                    match_type="multimodal",
                    metadata={
                        'file_name': row.file_name,
                        'container_id': row.container_id,
                        'blob_key': row.blob_key,
                        'chunk_index': row.chunk_index,
                        'modality': row.modality,
                        'search_type': 'multimodal'
                    }
                )
                chunks.append(chunk)

            latency_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            logger.info(f"âœ… [MultimodalSearch] ì™„ë£Œ: {len(chunks)}ê°œ ë°œê²¬")

            return SearchToolResult(
                success=True,
                data=chunks,
                total_found=len(chunks),
                filtered_count=len(chunks),
                search_params={
                    "top_k": top_k,
                    "container_ids": normalized_containers,
                    "has_text_query": bool(query)
                },
                metrics=ToolMetrics(
                    latency_ms=latency_ms,
                    provider="internal",
                    items_returned=len(chunks),
                    trace_id=trace_id
                ),
                errors=[],
                trace_id=trace_id,
                tool_name=self.name,
                tool_version=self.version
            )

        except Exception as e:
            latency_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            error_msg = f"ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"
            logger.error(f"âŒ [MultimodalSearch] {error_msg}", exc_info=True)
            if db:
                try:
                    await db.rollback()
                except Exception as rollback_error:
                    logger.error(f"âš ï¸ [MultimodalSearch] ë¡¤ë°± ì‹¤íŒ¨: {rollback_error}")
            return SearchToolResult(
                success=False,
                data=[],
                total_found=0,
                filtered_count=0,
                search_params={
                    "top_k": top_k,
                    "container_ids": normalized_containers
                },
                metrics=ToolMetrics(latency_ms=latency_ms, provider="internal", trace_id=trace_id),
                errors=[error_msg],
                trace_id=trace_id,
                tool_name=self.name,
                tool_version=self.version
            )


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_multimodal_search_tool_instance: Optional[MultimodalSearchTool] = None


def get_multimodal_search_tool() -> MultimodalSearchTool:
    """ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ ë„êµ¬ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _multimodal_search_tool_instance
    if _multimodal_search_tool_instance is None:
        _multimodal_search_tool_instance = MultimodalSearchTool()
    return _multimodal_search_tool_instance


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
multimodal_search_tool = get_multimodal_search_tool()
