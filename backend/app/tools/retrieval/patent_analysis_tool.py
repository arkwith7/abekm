"""
Patent Analysis Tool - íŠ¹í—ˆ ë¶„ì„ ë„êµ¬
íŠ¹í—ˆ ë°ì´í„° ì‹¬ì¸µ ë¶„ì„ (ê¸°ìˆ  í† í”½, ì¸ìš©, ì‹œê³„ì—´, ê²½ìŸ ë¹„êµ)
"""
import asyncio
import uuid
from typing import List, Optional, Dict, Any, Tuple
from datetime import datetime
from enum import Enum
from collections import Counter, defaultdict
from loguru import logger
from pydantic import BaseModel, Field

try:
    from langchain_core.tools import BaseTool
except ImportError:
    from langchain.tools import BaseTool

from app.tools.contracts import ToolResult, ToolMetrics
from app.tools.retrieval.patent_search_tool import PatentData, PatentJurisdiction, PatentStatus


# =============================================================================
# Analysis Types
# =============================================================================

class PatentAnalysisType(str, Enum):
    """íŠ¹í—ˆ ë¶„ì„ ìœ í˜•"""
    TOPIC_EXTRACTION = "topic"           # ê¸°ìˆ  í† í”½ ì¶”ì¶œ
    TIMELINE_TREND = "timeline"          # ì‹œê³„ì—´ íŠ¸ë Œë“œ
    COMPETITOR_COMPARISON = "comparison" # ê²½ìŸì‚¬ ë¹„êµ
    CITATION_NETWORK = "citation"        # ì¸ìš© ë„¤íŠ¸ì›Œí¬
    WHITE_SPACE = "gap"                  # ê¸°ìˆ  ê³µë°± ë¶„ì„
    PORTFOLIO_OVERVIEW = "portfolio"     # í¬íŠ¸í´ë¦¬ì˜¤ ê°œìš”


# =============================================================================
# Analysis Result Models
# =============================================================================

class TechTopic(BaseModel):
    """ê¸°ìˆ  í† í”½"""
    name: str = Field(description="í† í”½ ì´ë¦„")
    keywords: List[str] = Field(description="ê´€ë ¨ í‚¤ì›Œë“œ")
    patent_count: int = Field(description="ê´€ë ¨ íŠ¹í—ˆ ìˆ˜")
    ipc_codes: List[str] = Field(description="ê´€ë ¨ IPC ì½”ë“œ")
    representative_patents: List[str] = Field(description="ëŒ€í‘œ íŠ¹í—ˆ ë²ˆí˜¸")
    trend: str = Field(default="stable", description="íŠ¸ë Œë“œ (growing/stable/declining)")


class TimelinePoint(BaseModel):
    """ì‹œê³„ì—´ í¬ì¸íŠ¸"""
    year: int = Field(description="ì—°ë„")
    patent_count: int = Field(description="íŠ¹í—ˆ ìˆ˜")
    topics: List[str] = Field(default_factory=list, description="ì£¼ìš” í† í”½")
    notable_patents: List[str] = Field(default_factory=list, description="ì£¼ëª©í•  íŠ¹í—ˆ")


class CompetitorMetrics(BaseModel):
    """ê²½ìŸì‚¬ ì§€í‘œ"""
    name: str = Field(description="íšŒì‚¬ëª…")
    total_patents: int = Field(description="ì´ íŠ¹í—ˆ ìˆ˜")
    granted_patents: int = Field(description="ë“±ë¡ íŠ¹í—ˆ ìˆ˜")
    pending_patents: int = Field(description="ì¶œì› ì¤‘ íŠ¹í—ˆ ìˆ˜")
    avg_citations: float = Field(default=0.0, description="í‰ê·  í”¼ì¸ìš© ìˆ˜")
    top_ipc_codes: List[str] = Field(default_factory=list, description="ì£¼ìš” IPC ì½”ë“œ")
    recent_growth_rate: float = Field(default=0.0, description="ìµœê·¼ ì„±ì¥ë¥  (%)")
    key_technologies: List[str] = Field(default_factory=list, description="í•µì‹¬ ê¸°ìˆ ")


class GapAnalysisItem(BaseModel):
    """ê¸°ìˆ  ê³µë°± ë¶„ì„ í•­ëª©"""
    ipc_code: str = Field(description="IPC ì½”ë“œ")
    technology_name: str = Field(description="ê¸°ìˆ  ë¶„ì•¼ëª…")
    our_count: int = Field(description="ìš°ë¦¬ íŠ¹í—ˆ ìˆ˜")
    competitor_count: int = Field(description="ê²½ìŸì‚¬ íŠ¹í—ˆ ìˆ˜")
    gap_level: str = Field(description="ê³µë°± ìˆ˜ì¤€ (high/medium/low/advantage)")
    recommendation: str = Field(description="ê¶Œê³ ì‚¬í•­")


class PatentAnalysisResult(ToolResult):
    """íŠ¹í—ˆ ë¶„ì„ ê²°ê³¼"""
    analysis_type: PatentAnalysisType = Field(description="ë¶„ì„ ìœ í˜•")
    summary: str = Field(description="ë¶„ì„ ìš”ì•½")
    
    # ë¶„ì„ ìœ í˜•ë³„ ê²°ê³¼
    topics: Optional[List[TechTopic]] = Field(default=None, description="ê¸°ìˆ  í† í”½ (TOPIC)")
    timeline: Optional[List[TimelinePoint]] = Field(default=None, description="ì‹œê³„ì—´ (TIMELINE)")
    competitors: Optional[List[CompetitorMetrics]] = Field(default=None, description="ê²½ìŸì‚¬ ë¹„êµ (COMPARISON)")
    gaps: Optional[List[GapAnalysisItem]] = Field(default=None, description="ê¸°ìˆ  ê³µë°± (GAP)")
    
    # ì‹œê°í™” ë°ì´í„°
    visualization_data: Dict[str, Any] = Field(default_factory=dict, description="ì‹œê°í™”ìš© ë°ì´í„°")
    
    # ì¸ì‚¬ì´íŠ¸
    key_insights: List[str] = Field(default_factory=list, description="í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
    recommendations: List[str] = Field(default_factory=list, description="ì „ëµì  ì œì–¸")


# =============================================================================
# IPC Code Mappings
# =============================================================================

IPC_CODE_NAMES = {
    "G06N": "AI/ê¸°ê³„í•™ìŠµ",
    "G06F": "ì»´í“¨íŒ…/ë°ì´í„°ì²˜ë¦¬",
    "G06Q": "ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œìŠ¤í…œ",
    "G06T": "ì´ë¯¸ì§€ ì²˜ë¦¬",
    "G06V": "íŒ¨í„´ ì¸ì‹",
    "G06K": "ë°ì´í„° ì¸ì‹",
    "H01L": "ë°˜ë„ì²´ ì†Œì",
    "H04L": "í†µì‹ /ë„¤íŠ¸ì›Œí¬",
    "H04N": "ì˜ìƒ í†µì‹ ",
    "H04W": "ë¬´ì„  í†µì‹ ",
    "B25J": "ë¡œë³´í‹±ìŠ¤",
    "G16H": "í—¬ìŠ¤ì¼€ì–´ ICT",
    "G16B": "ë°”ì´ì˜¤ì¸í¬ë§¤í‹±ìŠ¤",
    "G01N": "ì¬ë£Œ ë¶„ì„",
    "G01R": "ì „ê¸° ì¸¡ì •",
}


def get_ipc_name(ipc_code: str) -> str:
    """IPC ì½”ë“œì—ì„œ ê¸°ìˆ  ë¶„ì•¼ëª… ë°˜í™˜"""
    prefix = ipc_code[:4] if len(ipc_code) >= 4 else ipc_code
    return IPC_CODE_NAMES.get(prefix, f"ê¸°íƒ€ ({prefix})")


# =============================================================================
# Patent Analysis Tool
# =============================================================================

class PatentAnalysisTool(BaseTool):
    """
    íŠ¹í—ˆ ë¶„ì„ ë„êµ¬
    
    ë¶„ì„ ê¸°ëŠ¥:
    - ê¸°ìˆ  í† í”½ ì¶”ì¶œ ë° í´ëŸ¬ìŠ¤í„°ë§
    - ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„
    - ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„
    - ì¸ìš© ë„¤íŠ¸ì›Œí¬ ë¶„ì„
    - ê¸°ìˆ  ê³µë°± ë¶„ì„
    """
    name: str = "patent_analysis"
    description: str = """íŠ¹í—ˆ ë°ì´í„° ì‹¬ì¸µ ë¶„ì„ ë„êµ¬.

ë¶„ì„ ìœ í˜•:
- topic: ê¸°ìˆ  í† í”½ ì¶”ì¶œ (í•µì‹¬ ê¸°ìˆ  ë¶„ì•¼, í‚¤ì›Œë“œ)
- timeline: ì‹œê³„ì—´ íŠ¸ë Œë“œ (ì—°ë„ë³„ ì¶œì› ë™í–¥)
- comparison: ê²½ìŸì‚¬ ë¹„êµ (íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„êµ)
- gap: ê¸°ìˆ  ê³µë°± ë¶„ì„ (ê²½ìŸì‚¬ ëŒ€ë¹„ ë¶€ì¡±í•œ ì˜ì—­)
- portfolio: í¬íŠ¸í´ë¦¬ì˜¤ ê°œìš” (ì „ì²´ í˜„í™©)

ì‚¬ìš© ì˜ˆ:
- "ì‚¼ì„±ì „ìì™€ ì• í”Œì˜ AI íŠ¹í—ˆ ë¹„êµ"
- "ìµœê·¼ 5ë…„ê°„ ë°˜ë„ì²´ íŠ¹í—ˆ íŠ¸ë Œë“œ"
- "ê²½ìŸì‚¬ ëŒ€ë¹„ ê¸°ìˆ  ê³µë°± ë¶„ì„"
"""
    version: str = "1.0.0"
    
    async def _arun(
        self,
        patents: List[PatentData],
        analysis_type: str = "portfolio",
        comparison_target: Optional[str] = None,
        our_company: Optional[str] = None,
        time_range_years: int = 5,
        **kwargs
    ) -> PatentAnalysisResult:
        """
        íŠ¹í—ˆ ë¶„ì„ ì‹¤í–‰
        
        Args:
            patents: ë¶„ì„í•  íŠ¹í—ˆ ëª©ë¡
            analysis_type: ë¶„ì„ ìœ í˜• (topic/timeline/comparison/gap/portfolio)
            comparison_target: ë¹„êµ ëŒ€ìƒ (ê²½ìŸì‚¬ëª…, comparison/gapì— í•„ìš”)
            our_company: ìš°ë¦¬ íšŒì‚¬ëª… (comparison/gapì— í•„ìš”)
            time_range_years: ë¶„ì„ ê¸°ê°„ (ë…„)
        
        Returns:
            PatentAnalysisResult: ë¶„ì„ ê²°ê³¼
        """
        start_time = datetime.utcnow()
        trace_id = str(uuid.uuid4())
        
        try:
            analysis_type_enum = PatentAnalysisType(analysis_type)
        except ValueError:
            analysis_type_enum = PatentAnalysisType.PORTFOLIO_OVERVIEW
        
        logger.info(f"ğŸ“Š [PatentAnalysis] ë¶„ì„ ì‹œì‘: type={analysis_type}, patents={len(patents)}")
        
        try:
            if analysis_type_enum == PatentAnalysisType.TOPIC_EXTRACTION:
                result = await self._analyze_topics(patents)
            elif analysis_type_enum == PatentAnalysisType.TIMELINE_TREND:
                result = await self._analyze_timeline(patents, time_range_years)
            elif analysis_type_enum == PatentAnalysisType.COMPETITOR_COMPARISON:
                result = await self._analyze_competitors(patents, our_company, comparison_target)
            elif analysis_type_enum == PatentAnalysisType.WHITE_SPACE:
                result = await self._analyze_gaps(patents, our_company, comparison_target)
            else:  # PORTFOLIO_OVERVIEW
                result = await self._analyze_portfolio(patents)
            
            elapsed_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            
            result.metrics = ToolMetrics(
                latency_ms=elapsed_ms,
                provider="patent_analysis",
                items_returned=len(patents),
                trace_id=trace_id
            )
            result.trace_id = trace_id
            result.tool_name = self.name
            result.tool_version = self.version
            result.success = True
            
            logger.info(f"âœ… [PatentAnalysis] ì™„ë£Œ: {elapsed_ms:.0f}ms")
            return result
            
        except Exception as e:
            elapsed_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            logger.error(f"âŒ [PatentAnalysis] ì˜¤ë¥˜: {e}")
            
            return PatentAnalysisResult(
                success=False,
                data=None,
                analysis_type=analysis_type_enum,
                summary=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                metrics=ToolMetrics(
                    latency_ms=elapsed_ms,
                    provider="patent_analysis",
                    trace_id=trace_id
                ),
                errors=[str(e)],
                trace_id=trace_id,
                tool_name=self.name,
                tool_version=self.version
            )
    
    async def _analyze_topics(self, patents: List[PatentData]) -> PatentAnalysisResult:
        """ê¸°ìˆ  í† í”½ ì¶”ì¶œ"""
        # IPC ì½”ë“œë³„ ê·¸ë£¹í™”
        ipc_groups: Dict[str, List[PatentData]] = defaultdict(list)
        for patent in patents:
            for ipc in patent.ipc_codes:
                prefix = ipc[:4] if len(ipc) >= 4 else ipc
                ipc_groups[prefix].append(patent)
        
        topics = []
        for ipc_code, group_patents in sorted(ipc_groups.items(), key=lambda x: -len(x[1])):
            # í‚¤ì›Œë“œ ì¶”ì¶œ (ì œëª©ì—ì„œ)
            words = []
            for p in group_patents:
                words.extend(p.title.split())
            
            word_counts = Counter(words)
            top_keywords = [w for w, _ in word_counts.most_common(5) if len(w) > 1]
            
            topic = TechTopic(
                name=get_ipc_name(ipc_code),
                keywords=top_keywords,
                patent_count=len(group_patents),
                ipc_codes=[ipc_code],
                representative_patents=[p.patent_number for p in group_patents[:3]],
                trend=self._calculate_trend(group_patents)
            )
            topics.append(topic)
        
        # ì‹œê°í™” ë°ì´í„°
        viz_data = {
            "type": "pie_chart",
            "data": [{"name": t.name, "value": t.patent_count} for t in topics[:10]]
        }
        
        return PatentAnalysisResult(
            success=True,
            data=topics,
            analysis_type=PatentAnalysisType.TOPIC_EXTRACTION,
            summary=f"ì´ {len(patents)}ê±´ì˜ íŠ¹í—ˆì—ì„œ {len(topics)}ê°œì˜ ê¸°ìˆ  í† í”½ ì¶”ì¶œ",
            topics=topics,
            visualization_data=viz_data,
            key_insights=[
                f"ê°€ì¥ ë§ì€ íŠ¹í—ˆê°€ ìˆëŠ” ë¶„ì•¼: {topics[0].name} ({topics[0].patent_count}ê±´)" if topics else "",
                f"ì´ {len(set(ipc for p in patents for ipc in p.ipc_codes))}ê°œì˜ IPC ë¶„ë¥˜ ì»¤ë²„"
            ],
            metrics=ToolMetrics(latency_ms=0, provider="patent_analysis"),
            errors=[],
            trace_id="",
            tool_name=self.name,
            tool_version=self.version
        )
    
    async def _analyze_timeline(
        self, 
        patents: List[PatentData], 
        years: int = 5
    ) -> PatentAnalysisResult:
        """ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„"""
        current_year = datetime.now().year
        
        # ì—°ë„ë³„ ê·¸ë£¹í™”
        year_groups: Dict[int, List[PatentData]] = defaultdict(list)
        for patent in patents:
            if patent.application_date:
                try:
                    year = int(patent.application_date[:4])
                    if year >= current_year - years:
                        year_groups[year].append(patent)
                except (ValueError, IndexError):
                    pass
        
        timeline = []
        for year in sorted(year_groups.keys()):
            year_patents = year_groups[year]
            
            # í•´ë‹¹ ì—°ë„ ì£¼ìš” í† í”½
            ipc_counts = Counter()
            for p in year_patents:
                for ipc in p.ipc_codes:
                    ipc_counts[ipc[:4]] += 1
            
            top_topics = [get_ipc_name(ipc) for ipc, _ in ipc_counts.most_common(3)]
            
            point = TimelinePoint(
                year=year,
                patent_count=len(year_patents),
                topics=top_topics,
                notable_patents=[p.patent_number for p in year_patents[:2]]
            )
            timeline.append(point)
        
        # íŠ¸ë Œë“œ ë¶„ì„
        if len(timeline) >= 2:
            recent_avg = sum(t.patent_count for t in timeline[-2:]) / 2
            older_avg = sum(t.patent_count for t in timeline[:-2]) / max(len(timeline) - 2, 1)
            growth = ((recent_avg - older_avg) / max(older_avg, 1)) * 100
            trend_text = "ì¦ê°€" if growth > 10 else "ê°ì†Œ" if growth < -10 else "ìœ ì§€"
        else:
            growth = 0
            trend_text = "ë°ì´í„° ë¶€ì¡±"
        
        # ì‹œê°í™” ë°ì´í„°
        viz_data = {
            "type": "line_chart",
            "data": [{"year": t.year, "count": t.patent_count} for t in timeline]
        }
        
        return PatentAnalysisResult(
            success=True,
            data=timeline,
            analysis_type=PatentAnalysisType.TIMELINE_TREND,
            summary=f"{years}ë…„ê°„ íŠ¹í—ˆ ì¶œì› íŠ¸ë Œë“œ ë¶„ì„ (ì´ {len(patents)}ê±´)",
            timeline=timeline,
            visualization_data=viz_data,
            key_insights=[
                f"ìµœê·¼ íŠ¸ë Œë“œ: {trend_text} ({growth:+.1f}%)",
                f"ê°€ì¥ í™œë°œí•œ ì—°ë„: {max(timeline, key=lambda x: x.patent_count).year if timeline else 'N/A'}",
                f"ìµœê·¼ ì£¼ìš” ê¸°ìˆ : {', '.join(timeline[-1].topics) if timeline else 'N/A'}"
            ],
            metrics=ToolMetrics(latency_ms=0, provider="patent_analysis"),
            errors=[],
            trace_id="",
            tool_name=self.name,
            tool_version=self.version
        )
    
    async def _analyze_competitors(
        self,
        patents: List[PatentData],
        our_company: Optional[str],
        competitor: Optional[str]
    ) -> PatentAnalysisResult:
        """ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„"""
        # ì¶œì›ì¸ë³„ ê·¸ë£¹í™”
        applicant_groups: Dict[str, List[PatentData]] = defaultdict(list)
        for patent in patents:
            applicant_groups[patent.applicant].append(patent)
        
        competitors = []
        for applicant, group_patents in sorted(applicant_groups.items(), key=lambda x: -len(x[1])):
            granted = sum(1 for p in group_patents if p.status == PatentStatus.GRANTED)
            pending = sum(1 for p in group_patents if p.status in [PatentStatus.APPLICATION, PatentStatus.PUBLISHED])
            
            # IPC ë¶„ì„
            ipc_counts = Counter()
            for p in group_patents:
                for ipc in p.ipc_codes:
                    ipc_counts[ipc[:4]] += 1
            
            top_ipcs = [ipc for ipc, _ in ipc_counts.most_common(5)]
            key_techs = [get_ipc_name(ipc) for ipc in top_ipcs[:3]]
            
            # í”¼ì¸ìš© ìˆ˜ í‰ê· 
            citations = [p.cited_by_count or 0 for p in group_patents]
            avg_citations = sum(citations) / max(len(citations), 1)
            
            metrics = CompetitorMetrics(
                name=applicant,
                total_patents=len(group_patents),
                granted_patents=granted,
                pending_patents=pending,
                avg_citations=avg_citations,
                top_ipc_codes=top_ipcs,
                key_technologies=key_techs,
                recent_growth_rate=self._calculate_growth_rate(group_patents)
            )
            competitors.append(metrics)
        
        # ì‹œê°í™” ë°ì´í„° (ë ˆì´ë” ì°¨íŠ¸ìš©)
        if len(competitors) >= 2:
            viz_data = {
                "type": "radar_chart",
                "data": [
                    {
                        "name": c.name,
                        "values": {
                            "ì¶œì›ëŸ‰": min(c.total_patents / 100, 1),  # ì •ê·œí™”
                            "ë“±ë¡ë¥ ": c.granted_patents / max(c.total_patents, 1),
                            "í”¼ì¸ìš©ìˆ˜": min(c.avg_citations / 50, 1),
                            "ê¸°ìˆ ë‹¤ì–‘ì„±": len(c.top_ipc_codes) / 10,
                            "ì„±ì¥ë¥ ": min(max(c.recent_growth_rate + 50, 0) / 100, 1)
                        }
                    }
                    for c in competitors[:5]
                ]
            }
        else:
            viz_data = {}
        
        return PatentAnalysisResult(
            success=True,
            data=competitors,
            analysis_type=PatentAnalysisType.COMPETITOR_COMPARISON,
            summary=f"{len(competitors)}ê°œ ì¶œì›ì¸ì˜ íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„êµ",
            competitors=competitors,
            visualization_data=viz_data,
            key_insights=[
                f"ê°€ì¥ ë§ì€ íŠ¹í—ˆ: {competitors[0].name} ({competitors[0].total_patents}ê±´)" if competitors else "",
                f"ê°€ì¥ ë†’ì€ ë“±ë¡ë¥ : {max(competitors, key=lambda x: x.granted_patents/max(x.total_patents,1)).name if competitors else 'N/A'}",
                f"ê°€ì¥ ë¹ ë¥¸ ì„±ì¥: {max(competitors, key=lambda x: x.recent_growth_rate).name if competitors else 'N/A'}"
            ],
            recommendations=[
                f"{our_company}ì˜ íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ ê°•í™” í•„ìš”" if our_company else "ê²½ìŸì‚¬ ë™í–¥ ì§€ì† ëª¨ë‹ˆí„°ë§ ê¶Œê³ "
            ],
            metrics=ToolMetrics(latency_ms=0, provider="patent_analysis"),
            errors=[],
            trace_id="",
            tool_name=self.name,
            tool_version=self.version
        )
    
    async def _analyze_gaps(
        self,
        patents: List[PatentData],
        our_company: Optional[str],
        competitor: Optional[str]
    ) -> PatentAnalysisResult:
        """ê¸°ìˆ  ê³µë°± ë¶„ì„"""
        if not our_company or not competitor:
            return PatentAnalysisResult(
                success=False,
                data=None,
                analysis_type=PatentAnalysisType.WHITE_SPACE,
                summary="ê¸°ìˆ  ê³µë°± ë¶„ì„ì—ëŠ” our_companyì™€ comparison_targetì´ í•„ìš”í•©ë‹ˆë‹¤.",
                metrics=ToolMetrics(latency_ms=0, provider="patent_analysis"),
                errors=["our_companyì™€ comparison_target íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."],
                trace_id="",
                tool_name=self.name,
                tool_version=self.version
            )
        
        # íšŒì‚¬ë³„ IPC ë¶„ë¥˜
        our_ipcs: Dict[str, int] = defaultdict(int)
        competitor_ipcs: Dict[str, int] = defaultdict(int)
        
        for patent in patents:
            is_ours = our_company.lower() in patent.applicant.lower()
            is_competitor = competitor.lower() in patent.applicant.lower()
            
            for ipc in patent.ipc_codes:
                prefix = ipc[:4] if len(ipc) >= 4 else ipc
                if is_ours:
                    our_ipcs[prefix] += 1
                if is_competitor:
                    competitor_ipcs[prefix] += 1
        
        # ëª¨ë“  IPC ì½”ë“œ í†µí•©
        all_ipcs = set(our_ipcs.keys()) | set(competitor_ipcs.keys())
        
        gaps = []
        for ipc in all_ipcs:
            our_count = our_ipcs.get(ipc, 0)
            comp_count = competitor_ipcs.get(ipc, 0)
            
            # ê³µë°± ìˆ˜ì¤€ ê³„ì‚°
            if our_count == 0 and comp_count > 0:
                gap_level = "high"
                recommendation = f"{get_ipc_name(ipc)} ë¶„ì•¼ R&D íˆ¬ì ê¶Œê³ "
            elif comp_count > our_count * 2:
                gap_level = "medium"
                recommendation = f"{get_ipc_name(ipc)} ë¶„ì•¼ íŠ¹í—ˆ ì¶œì› ê°•í™” í•„ìš”"
            elif our_count > comp_count * 2:
                gap_level = "advantage"
                recommendation = f"{get_ipc_name(ipc)} ë¶„ì•¼ ìš°ìœ„ ìœ ì§€"
            else:
                gap_level = "low"
                recommendation = "í˜„ ìˆ˜ì¤€ ìœ ì§€"
            
            gap_item = GapAnalysisItem(
                ipc_code=ipc,
                technology_name=get_ipc_name(ipc),
                our_count=our_count,
                competitor_count=comp_count,
                gap_level=gap_level,
                recommendation=recommendation
            )
            gaps.append(gap_item)
        
        # ê³µë°± ìˆ˜ì¤€ë³„ ì •ë ¬
        gap_priority = {"high": 0, "medium": 1, "low": 2, "advantage": 3}
        gaps.sort(key=lambda x: (gap_priority.get(x.gap_level, 9), -x.competitor_count))
        
        # ì‹œê°í™” ë°ì´í„°
        viz_data = {
            "type": "gap_matrix",
            "data": [
                {
                    "ipc": g.ipc_code,
                    "name": g.technology_name,
                    "our": g.our_count,
                    "competitor": g.competitor_count,
                    "level": g.gap_level
                }
                for g in gaps
            ]
        }
        
        high_gaps = [g for g in gaps if g.gap_level == "high"]
        advantages = [g for g in gaps if g.gap_level == "advantage"]
        
        return PatentAnalysisResult(
            success=True,
            data=gaps,
            analysis_type=PatentAnalysisType.WHITE_SPACE,
            summary=f"{our_company} vs {competitor} ê¸°ìˆ  ê³µë°± ë¶„ì„ ({len(gaps)}ê°œ ê¸°ìˆ  ë¶„ì•¼)",
            gaps=gaps,
            visualization_data=viz_data,
            key_insights=[
                f"ğŸ”´ ë†’ì€ ê³µë°±: {len(high_gaps)}ê°œ ë¶„ì•¼",
                f"ğŸŸ¢ ìš°ìœ„ ë¶„ì•¼: {len(advantages)}ê°œ ë¶„ì•¼",
                f"ê°€ì¥ í° ê³µë°±: {high_gaps[0].technology_name if high_gaps else 'N/A'}"
            ],
            recommendations=[g.recommendation for g in gaps if g.gap_level in ["high", "medium"]][:5],
            metrics=ToolMetrics(latency_ms=0, provider="patent_analysis"),
            errors=[],
            trace_id="",
            tool_name=self.name,
            tool_version=self.version
        )
    
    async def _analyze_portfolio(self, patents: List[PatentData]) -> PatentAnalysisResult:
        """í¬íŠ¸í´ë¦¬ì˜¤ ê°œìš”"""
        total = len(patents)
        granted = sum(1 for p in patents if p.status == PatentStatus.GRANTED)
        pending = sum(1 for p in patents if p.status in [PatentStatus.APPLICATION, PatentStatus.PUBLISHED])
        
        # ê´€í• ê¶Œë³„ ë¶„í¬
        jurisdiction_counts = Counter(p.jurisdiction.value for p in patents)
        
        # IPC ë¶„í¬
        ipc_counts = Counter()
        for p in patents:
            for ipc in p.ipc_codes:
                ipc_counts[ipc[:4]] += 1
        
        top_ipcs = [f"{ipc} ({get_ipc_name(ipc)})" for ipc, _ in ipc_counts.most_common(5)]
        
        # ì¶œì›ì¸ ë¶„í¬
        applicant_counts = Counter(p.applicant for p in patents)
        top_applicants = [name for name, _ in applicant_counts.most_common(5)]
        
        summary_data = {
            "total_patents": total,
            "granted": granted,
            "pending": pending,
            "grant_rate": granted / max(total, 1) * 100,
            "jurisdictions": dict(jurisdiction_counts),
            "top_ipc_codes": top_ipcs,
            "top_applicants": top_applicants
        }
        
        viz_data = {
            "type": "dashboard",
            "metrics": summary_data,
            "charts": {
                "jurisdiction_pie": [{"name": k, "value": v} for k, v in jurisdiction_counts.items()],
                "ipc_bar": [{"name": get_ipc_name(ipc), "value": cnt} for ipc, cnt in ipc_counts.most_common(10)]
            }
        }
        
        return PatentAnalysisResult(
            success=True,
            data=summary_data,
            analysis_type=PatentAnalysisType.PORTFOLIO_OVERVIEW,
            summary=f"íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ ê°œìš”: ì´ {total}ê±´ (ë“±ë¡ {granted}, ì¶œì› {pending})",
            visualization_data=viz_data,
            key_insights=[
                f"ë“±ë¡ë¥ : {granted/max(total,1)*100:.1f}%",
                f"ì£¼ìš” ê¸°ìˆ  ë¶„ì•¼: {', '.join(top_ipcs[:3])}",
                f"ì£¼ìš” ì¶œì›ì¸: {', '.join(top_applicants[:3])}"
            ],
            metrics=ToolMetrics(latency_ms=0, provider="patent_analysis"),
            errors=[],
            trace_id="",
            tool_name=self.name,
            tool_version=self.version
        )
    
    def _calculate_trend(self, patents: List[PatentData]) -> str:
        """íŠ¸ë Œë“œ ê³„ì‚°"""
        current_year = datetime.now().year
        recent = sum(1 for p in patents if p.application_date and int(p.application_date[:4]) >= current_year - 2)
        older = sum(1 for p in patents if p.application_date and int(p.application_date[:4]) < current_year - 2)
        
        if recent > older * 1.5:
            return "growing"
        elif recent < older * 0.5:
            return "declining"
        return "stable"
    
    def _calculate_growth_rate(self, patents: List[PatentData]) -> float:
        """ì„±ì¥ë¥  ê³„ì‚°"""
        current_year = datetime.now().year
        recent = sum(1 for p in patents if p.application_date and int(p.application_date[:4]) >= current_year - 2)
        older = sum(1 for p in patents if p.application_date and current_year - 4 <= int(p.application_date[:4]) < current_year - 2)
        
        if older == 0:
            return 0.0
        return ((recent - older) / older) * 100
    
    def _run(self, patents: List[PatentData], **kwargs) -> PatentAnalysisResult:
        """ë™ê¸° ì‹¤í–‰"""
        return asyncio.run(self._arun(patents, **kwargs))


# =============================================================================
# Factory Function & Singleton Instance
# =============================================================================

def get_patent_analysis_tool() -> PatentAnalysisTool:
    """PatentAnalysisTool ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return PatentAnalysisTool()


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ (import ì‹œ ì‚¬ìš©)
patent_analysis_tool = PatentAnalysisTool()
