"""
Celery ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
===========================

ë¹„ë™ê¸° ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì²˜ë¦¬ë¥¼ ìœ„í•œ Celery ì„¤ì •
- ë¬¸ì„œ ì²˜ë¦¬ (DI ë¶„ì„, ì„ë² ë”© ìƒì„±)
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬
- ì¥ì‹œê°„ ì‹¤í–‰ ì‘ì—…

ì‚¬ìš©ë²•:
-------
# Celery Worker ì‹¤í–‰
celery -A app.core.celery_app worker --loglevel=info

# Flower ëª¨ë‹ˆí„°ë§ (ì„ íƒ)
celery -A app.core.celery_app flower --port=5555
"""

from celery import Celery
from celery.signals import worker_process_init
import os

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ Redis URL ê°€ì ¸ì˜¤ê¸°
# ìš°ì„ ìˆœìœ„:
# 1) REDIS_URL (ì»¨í…Œì´ë„ˆ/ìš´ì˜ì—ì„œ composeë¡œ ì£¼ì…í•˜ê¸° ì‰¬ì›€)
# 2) REDIS_HOST/REDIS_PORT/REDIS_DB (ë¡œì»¬ ê°œë°œ/ì„¸ë¶€ ì„¤ì •ìš©)
REDIS_URL = os.getenv("REDIS_URL")
if not REDIS_URL:
    redis_host = os.getenv("REDIS_HOST", "localhost")
    redis_port = os.getenv("REDIS_PORT", "6379")
    redis_db = os.getenv("REDIS_DB", "0")
    REDIS_URL = f"redis://{redis_host}:{redis_port}/{redis_db}"

# Celery ì•± ì´ˆê¸°í™”
celery_app = Celery(
    "wkms",
    broker=REDIS_URL,
    backend=REDIS_URL,
    include=['app.tasks.document_tasks']  # íƒœìŠ¤í¬ ëª¨ë“ˆ ìë™ ë¡œë“œ
)

# Celery ì„¤ì •
celery_app.conf.update(
    # ì§ë ¬í™” ì„¤ì •
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    
    # ì‹œê°„ëŒ€ ì„¤ì •
    timezone='Asia/Seoul',
    enable_utc=True,
    
    # ì‘ì—… ì¶”ì 
    task_track_started=True,
    task_time_limit=3600,  # 1ì‹œê°„ ì œí•œ (ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ê³ ë ¤)
    task_soft_time_limit=3300,  # 55ë¶„ ì†Œí”„íŠ¸ ì œí•œ (ê²½ê³ )
    
    # ê²°ê³¼ ë°±ì—”ë“œ ì„¤ì •
    result_expires=3600,  # ê²°ê³¼ 1ì‹œê°„ ë³´ê´€
    result_extended=True,  # í™•ì¥ ê²°ê³¼ ì •ë³´ í¬í•¨
    
    # Worker ì„¤ì •
    worker_prefetch_multiplier=1,  # í•œ ë²ˆì— 1ê°œ ì‘ì—…ë§Œ ê°€ì ¸ì˜¤ê¸° (ë©”ëª¨ë¦¬ ì ˆì•½)
    worker_max_tasks_per_child=50,  # Worker í”„ë¡œì„¸ìŠ¤ ì¬ì‹œì‘ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
    
    # ì¬ì‹œë„ ì„¤ì •
    task_acks_late=True,  # ì‘ì—… ì™„ë£Œ í›„ ACK
    task_reject_on_worker_lost=True,  # Worker ì†ì‹¤ ì‹œ ì‘ì—… ì¬í• ë‹¹
)

# Celery Beat ìŠ¤ì¼€ì¤„ (ì£¼ê¸°ì  ì‘ì—… - ì„ íƒ)
celery_app.conf.beat_schedule = {
    # ì˜ˆ: ë§¤ì¼ ìì • Orphan íŒŒì¼ ì •ë¦¬
    # 'cleanup-orphan-files': {
    #     'task': 'app.tasks.document_tasks.cleanup_orphan_files',
    #     'schedule': crontab(hour=0, minute=0),
    # },
}

# Celery Worker í”„ë¡œì„¸ìŠ¤ ì´ˆê¸°í™” ì‹œ ë¬´ê±°ìš´ ì„œë¹„ìŠ¤ í”„ë¦¬ë¡œë“œ
@worker_process_init.connect
def init_worker_process_handler(**kwargs):
    """
    Celery Worker í”„ë¡œì„¸ìŠ¤ê°€ ì‹œì‘ë  ë•Œ í•œ ë²ˆë§Œ ì‹¤í–‰
    
    ë¬´ê±°ìš´ ì„œë¹„ìŠ¤ë“¤ì„ ë¯¸ë¦¬ ì´ˆê¸°í™”í•˜ì—¬ íƒœìŠ¤í¬ ì‹¤í–‰ ì‹œ ì§€ì—° ì œê±°:
    - Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° (~5ì´ˆ)
    - KSS ë¬¸ì¥ ë¶„ë¦¬ê¸° (~5ì´ˆ)
    - Azure/AWS AI í´ë¼ì´ì–¸íŠ¸ (~2ì´ˆ)
    
    ì˜ˆìƒ íš¨ê³¼: ë§¤ íƒœìŠ¤í¬ë§ˆë‹¤ 17ì´ˆ ì´ˆê¸°í™” ì‹œê°„ ì œê±°
    """
    import logging
    import time
    logger = logging.getLogger(__name__)
    
    start_time = time.time()
    logger.info("ğŸ”§ [WORKER-INIT] Celery Worker í”„ë¡œì„¸ìŠ¤ ì´ˆê¸°í™” ì‹œì‘...")
    
    try:
        # 0. Config ë¡œë“œ (settings ê°ì²´ëŠ” ì—¬ê¸°ì„œ importí•´ì•¼ .envë¥¼ ì œëŒ€ë¡œ ì½ìŒ)
        from app.core.config import settings
        
        # 1. Korean NLP Service (Kiwi, KSS) í”„ë¦¬ë¡œë“œ
        from app.services.core.korean_nlp_service import KoreanNLPService
        nlp_start = time.time()
        nlp_service = KoreanNLPService()
        nlp_time = time.time() - nlp_start
        logger.info(f"âœ… [WORKER-INIT] KoreanNLPService ì´ˆê¸°í™” ì™„ë£Œ ({nlp_time:.2f}ì´ˆ)")
        
        # 2. Embedding Service (Azure OpenAI, Bedrock) í”„ë¦¬ë¡œë“œ
        from app.services.core.embedding_service import EmbeddingService
        emb_start = time.time()
        emb_service = EmbeddingService()
        emb_time = time.time() - emb_start
        logger.info(f"âœ… [WORKER-INIT] EmbeddingService ì´ˆê¸°í™” ì™„ë£Œ ({emb_time:.2f}ì´ˆ)")
        
        # 3. Document Processing Service í”„ë¦¬ë¡œë“œ (providerì— ë”°ë¼ ì„ íƒ)
        doc_provider = settings.document_processing_provider.lower()
        logger.info(f"ğŸ“„ [WORKER-INIT] ë¬¸ì„œ ì²˜ë¦¬ ì œê³µì: {doc_provider}")
        
        if doc_provider == "upstage":
            from app.services.document.extraction.upstage_document_service import UpstageDocumentService
            doc_start = time.time()
            doc_service = UpstageDocumentService()
            doc_time = time.time() - doc_start
            logger.info(f"âœ… [WORKER-INIT] UpstageDocumentService ì´ˆê¸°í™” ì™„ë£Œ ({doc_time:.2f}ì´ˆ)")
        elif doc_provider == "azure_di":
            from app.services.document.extraction.azure_document_intelligence_service import AzureDocumentIntelligenceService
            doc_start = time.time()
            doc_service = AzureDocumentIntelligenceService()
            doc_time = time.time() - doc_start
            logger.info(f"âœ… [WORKER-INIT] AzureDocumentIntelligenceService ì´ˆê¸°í™” ì™„ë£Œ ({doc_time:.2f}ì´ˆ)")
        else:
            logger.warning(f"âš ï¸ [WORKER-INIT] ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ì„œ ì²˜ë¦¬ ì œê³µì: {doc_provider}")
        
        total_time = time.time() - start_time
        logger.info(f"ğŸ‰ [WORKER-INIT] ì „ì²´ ì´ˆê¸°í™” ì™„ë£Œ ({total_time:.2f}ì´ˆ)")
        logger.info(f"ğŸ“Š [WORKER-INIT] ì´ì œ íƒœìŠ¤í¬ê°€ ì¦‰ì‹œ ì‹¤í–‰ë©ë‹ˆë‹¤ (ì´ˆê¸°í™” ì§€ì—° ì—†ìŒ)")
        
    except Exception as e:
        logger.error(f"âŒ [WORKER-INIT] ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        logger.error(traceback.format_exc())


if __name__ == '__main__':
    celery_app.start()
