"""
Orphan íŒŒì¼ ì •ë¦¬ ëª…ë ¹ì–´

DBì—ëŠ” ì—†ìœ¼ë‚˜ Azure Blob Storageì— ë‚¨ì•„ìˆëŠ” íŒŒì¼ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
ì‹¤í–‰ ë°©ë²•: python -m app.management.commands.cleanup_orphan_files [--dry-run] [--purpose raw|intermediate|derived]
"""
import asyncio
import argparse
import logging
from datetime import datetime, timedelta
from typing import Set, List
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.database import get_async_session_local
from app.models import TbFileBssInfo
from app.services.core.azure_blob_service import get_azure_blob_service
from app.core.config import settings

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def get_db_file_paths(session: AsyncSession, purpose: str = 'raw') -> Set[str]:
    """
    DBì— ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ëª©ë¡ ì¡°íšŒ
    
    Args:
        session: DB ì„¸ì…˜
        purpose: Azure Blob purpose (raw/intermediate/derived)
    
    Returns:
        DBì— ì¡´ì¬í•˜ëŠ” íŒŒì¼ ê²½ë¡œ ì§‘í•©
    """
    logger.info(f"ğŸ“Š DB íŒŒì¼ ê²½ë¡œ ì¡°íšŒ ì‹œì‘ (purpose={purpose})...")
    
    # ì‚­ì œë˜ì§€ ì•Šì€ íŒŒì¼ë§Œ ì¡°íšŒ
    query = select(TbFileBssInfo.path).where(TbFileBssInfo.del_yn != 'Y')
    result = await session.execute(query)
    all_paths = result.scalars().all()
    
    # purpose prefixì™€ ì¼ì¹˜í•˜ëŠ” ê²½ë¡œë§Œ í•„í„°ë§
    purpose_prefix = f"{purpose}/"
    db_file_paths = set()
    
    for path in all_paths:
        if not path:
            continue
        # ì ˆëŒ€ ê²½ë¡œëŠ” ì œì™¸ (ë¡œì»¬ íŒŒì¼)
        if path.startswith('/'):
            continue
        # purpose prefixë¡œ ì‹œì‘í•˜ëŠ” ê²½ë¡œ
        if path.startswith(purpose_prefix):
            # prefix ì œê±° í›„ blob_pathë§Œ ì €ì¥
            blob_path = path[len(purpose_prefix):]
            db_file_paths.add(blob_path)
        # prefix ì—†ëŠ” ë ˆê±°ì‹œ ê²½ë¡œ (ê¸°ë³¸ rawë¡œ ê°„ì£¼)
        elif purpose == 'raw' and '/' in path and not path.startswith(('intermediate/', 'derived/')):
            db_file_paths.add(path)
    
    logger.info(f"âœ… DBì—ì„œ {len(db_file_paths)}ê°œ íŒŒì¼ ê²½ë¡œ ë°œê²¬ (purpose={purpose})")
    return db_file_paths


def get_blob_file_paths(purpose: str = 'raw') -> Set[str]:
    """
    Azure Blob Storageì˜ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
    
    Args:
        purpose: Azure Blob purpose (raw/intermediate/derived)
    
    Returns:
        Blob Storageì— ì¡´ì¬í•˜ëŠ” íŒŒì¼ ê²½ë¡œ ì§‘í•©
    """
    logger.info(f"â˜ï¸ Azure Blob íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹œì‘ (purpose={purpose})...")
    
    azure_blob = get_azure_blob_service()
    blob_paths = azure_blob.list_blobs(purpose=purpose)
    
    logger.info(f"âœ… Azure Blobì—ì„œ {len(blob_paths)}ê°œ íŒŒì¼ ë°œê²¬ (purpose={purpose})")
    return set(blob_paths)


async def find_orphan_files(
    session: AsyncSession,
    purpose: str = 'raw',
    min_age_hours: int = 24
) -> List[str]:
    """
    Orphan íŒŒì¼ ì°¾ê¸° (Blobì—ëŠ” ìˆì§€ë§Œ DBì— ì—†ëŠ” íŒŒì¼)
    
    Args:
        session: DB ì„¸ì…˜
        purpose: Azure Blob purpose
        min_age_hours: ìµœì†Œ íŒŒì¼ ìƒì„± í›„ ê²½ê³¼ ì‹œê°„ (ì‹œê°„)
    
    Returns:
        Orphan íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    logger.info(f"ğŸ” Orphan íŒŒì¼ ê²€ìƒ‰ ì‹œì‘ (purpose={purpose}, min_age={min_age_hours}h)...")
    
    db_paths = await get_db_file_paths(session, purpose)
    blob_paths = get_blob_file_paths(purpose)
    
    # Blobì—ëŠ” ìˆì§€ë§Œ DBì— ì—†ëŠ” íŒŒì¼
    orphan_candidates = blob_paths - db_paths
    
    if not orphan_candidates:
        logger.info("âœ… Orphan íŒŒì¼ ì—†ìŒ")
        return []
    
    logger.info(f"ğŸ” {len(orphan_candidates)}ê°œ Orphan í›„ë³´ ë°œê²¬, ìƒì„± ì‹œê°„ í™•ì¸ ì¤‘...")
    
    # íŒŒì¼ ìƒì„± ì‹œê°„ í™•ì¸ (ìµœì†Œ ê²½ê³¼ ì‹œê°„ ì²´í¬)
    azure_blob = get_azure_blob_service()
    min_creation_time = datetime.now() - timedelta(hours=min_age_hours)
    orphan_files = []
    
    for blob_path in orphan_candidates:
        try:
            # Blob ë©”íƒ€ë°ì´í„° ì¡°íšŒ
            blob_client = azure_blob._get_blob_client(blob_path, purpose)
            properties = blob_client.get_blob_properties()
            
            # ìƒì„± ì‹œê°„ì´ min_age_hours ì´ìƒ ê²½ê³¼í•œ íŒŒì¼ë§Œ orphanìœ¼ë¡œ íŒì •
            if properties.creation_time and properties.creation_time < min_creation_time:
                orphan_files.append(blob_path)
                logger.info(
                    f"  ğŸ—‘ï¸ Orphan: {blob_path} "
                    f"(ìƒì„±: {properties.creation_time.strftime('%Y-%m-%d %H:%M:%S')})"
                )
        except Exception as e:
            logger.warning(f"  âš ï¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {blob_path}, {e}")
            # ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ ì œì™¸
            continue
    
    logger.info(f"âœ… {len(orphan_files)}ê°œ Orphan íŒŒì¼ í™•ì¸ ì™„ë£Œ")
    return orphan_files


async def cleanup_orphan_files_async(
    purpose: str = 'raw',
    min_age_hours: int = 24,
    dry_run: bool = True,
    max_files: int = 100
):
    """
    Orphan íŒŒì¼ ì •ë¦¬ ì‹¤í–‰
    
    Args:
        purpose: Azure Blob purpose
        min_age_hours: ìµœì†Œ íŒŒì¼ ìƒì„± í›„ ê²½ê³¼ ì‹œê°„
        dry_run: Trueì´ë©´ ì‚­ì œí•˜ì§€ ì•Šê³  ë¡œê·¸ë§Œ ì¶œë ¥
        max_files: í•œ ë²ˆì— ì •ë¦¬í•  ìµœëŒ€ íŒŒì¼ ê°œìˆ˜
    """
    logger.info("=" * 80)
    logger.info("ğŸ§¹ Orphan íŒŒì¼ ì •ë¦¬ ì‹œì‘")
    logger.info(f"  - Purpose: {purpose}")
    logger.info(f"  - Min Age: {min_age_hours}h")
    logger.info(f"  - Dry Run: {dry_run}")
    logger.info(f"  - Max Files: {max_files}")
    logger.info("=" * 80)
    
    # DB ì„¸ì…˜ ìƒì„±
    async_session_factory = get_async_session_local()
    async with async_session_factory() as session:
        # Orphan íŒŒì¼ ì°¾ê¸°
        orphan_files = await find_orphan_files(session, purpose, min_age_hours)
        
        if not orphan_files:
            logger.info("âœ… ì •ë¦¬í•  Orphan íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
        if len(orphan_files) > max_files:
            logger.warning(
                f"âš ï¸ Orphan íŒŒì¼ì´ {len(orphan_files)}ê°œë¡œ max_files({max_files})ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. "
                f"ì²˜ìŒ {max_files}ê°œë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤."
            )
            orphan_files = orphan_files[:max_files]
        
        if dry_run:
            logger.info(f"ğŸ” [DRY RUN] {len(orphan_files)}ê°œ íŒŒì¼ì„ ì‚­ì œí•  ì˜ˆì •ì…ë‹ˆë‹¤:")
            for blob_path in orphan_files:
                logger.info(f"  - {purpose}/{blob_path}")
            logger.info("ğŸ” [DRY RUN] ì‹¤ì œ ì‚­ì œí•˜ë ¤ë©´ --no-dry-run ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        else:
            logger.info(f"ğŸ—‘ï¸ {len(orphan_files)}ê°œ Orphan íŒŒì¼ ì‚­ì œ ì‹œì‘...")
            azure_blob = get_azure_blob_service()
            deleted_count = 0
            failed_count = 0
            
            for blob_path in orphan_files:
                try:
                    if azure_blob.delete_blob(blob_path, purpose=purpose):
                        deleted_count += 1
                        logger.info(f"  âœ… ì‚­ì œ ì™„ë£Œ: {purpose}/{blob_path}")
                    else:
                        failed_count += 1
                        logger.warning(f"  âš ï¸ ì‚­ì œ ì‹¤íŒ¨: {purpose}/{blob_path}")
                except Exception as e:
                    failed_count += 1
                    logger.error(f"  âŒ ì‚­ì œ ì˜ˆì™¸: {purpose}/{blob_path}, {e}")
            
            logger.info("=" * 80)
            logger.info(f"ğŸ‰ Orphan íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
            logger.info(f"  - ì‚­ì œ ì„±ê³µ: {deleted_count}ê°œ")
            logger.info(f"  - ì‚­ì œ ì‹¤íŒ¨: {failed_count}ê°œ")
            logger.info("=" * 80)


def main():
    """ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤"""
    parser = argparse.ArgumentParser(
        description='Azure Blob Storage Orphan íŒŒì¼ ì •ë¦¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # Dry run (ì‚­ì œí•˜ì§€ ì•Šê³  ë¡œê·¸ë§Œ ì¶œë ¥)
  python -m app.management.commands.cleanup_orphan_files --purpose raw --dry-run
  
  # ì‹¤ì œ ì‚­ì œ ì‹¤í–‰
  python -m app.management.commands.cleanup_orphan_files --purpose raw --no-dry-run --min-age 48
  
  # Intermediate íŒŒì¼ ì •ë¦¬
  python -m app.management.commands.cleanup_orphan_files --purpose intermediate --no-dry-run
        """
    )
    
    parser.add_argument(
        '--purpose',
        type=str,
        choices=['raw', 'intermediate', 'derived'],
        default='raw',
        help='Azure Blob purpose (default: raw)'
    )
    
    parser.add_argument(
        '--min-age',
        type=int,
        default=24,
        help='ìµœì†Œ íŒŒì¼ ìƒì„± í›„ ê²½ê³¼ ì‹œê°„(ì‹œê°„) (default: 24)'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        default=True,
        help='ì‚­ì œí•˜ì§€ ì•Šê³  ë¡œê·¸ë§Œ ì¶œë ¥ (default: True)'
    )
    
    parser.add_argument(
        '--no-dry-run',
        action='store_false',
        dest='dry_run',
        help='ì‹¤ì œë¡œ íŒŒì¼ ì‚­ì œ'
    )
    
    parser.add_argument(
        '--max-files',
        type=int,
        default=100,
        help='í•œ ë²ˆì— ì •ë¦¬í•  ìµœëŒ€ íŒŒì¼ ê°œìˆ˜ (default: 100)'
    )
    
    args = parser.parse_args()
    
    # ì‹¤í–‰
    asyncio.run(cleanup_orphan_files_async(
        purpose=args.purpose,
        min_age_hours=args.min_age,
        dry_run=args.dry_run,
        max_files=args.max_files
    ))


if __name__ == '__main__':
    main()
