"""
Unified Agent Protocol for LangChain 1.X

ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ì¤€ìˆ˜í•´ì•¼ í•˜ëŠ” í‘œì¤€ ì¸í„°íŽ˜ì´ìŠ¤
"""
from __future__ import annotations

from abc import ABC, abstractmethod
from datetime import datetime
from typing import Any, Dict, List, Optional, Sequence, Type
from enum import Enum

from pydantic import BaseModel, Field
from loguru import logger

try:
    from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
    from langchain_core.tools import BaseTool
    from langchain_core.language_models import BaseLanguageModel
except ImportError:
    from langchain.schema import BaseMessage, HumanMessage, AIMessage
    from langchain_core.tools import BaseTool
    from langchain.llms import BaseLanguageModel


# =============================================================================
# Enums
# =============================================================================

class AgentMode(str, Enum):
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ëª¨ë“œ"""
    REACT = "react"  # ReAct (Reasoning + Acting)
    PLAN_EXECUTE = "plan_execute"  # Plan-and-Execute
    TOOL_CALLING = "tool_calling"  # Native tool-calling
    GRAPH = "graph"  # LangGraph ê¸°ë°˜


class AgentStatus(str, Enum):
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ìƒíƒœ"""
    IDLE = "idle"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"


# =============================================================================
# Context & Configuration
# =============================================================================

class AgentExecutionContext(BaseModel):
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸"""
    
    request_id: str = Field(default_factory=lambda: f"req_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{id(object())}")
    session_id: Optional[str] = Field(None, description="ì„¸ì…˜ ID (ë©€í‹°í„´ ëŒ€í™”)")
    user_id: Optional[int] = Field(None, description="ì‚¬ìš©ìž ID")
    
    # ë¶€ëª¨-ìžì‹ ê´€ê³„ (ì—ì´ì „íŠ¸ ì²´ì¸)
    parent_agent: Optional[str] = Field(None, description="ë¶€ëª¨ ì—ì´ì „íŠ¸ ì´ë¦„")
    execution_depth: int = Field(0, ge=0, le=5, description="ì‹¤í–‰ ê¹Šì´ (ë¬´í•œ ë£¨í”„ ë°©ì§€)")
    
    # ì‹¤í–‰ ì œì•½
    timeout_seconds: int = Field(120, ge=10, le=600, description="ìµœëŒ€ ì‹¤í–‰ ì‹œê°„ (ì´ˆ)")
    max_iterations: int = Field(10, ge=1, le=50, description="ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜")
    max_tokens: int = Field(4000, ge=100, le=16000, description="ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ í† í°")
    
    # ê³µìœ  ë°ì´í„°
    shared_context: Dict[str, Any] = Field(default_factory=dict, description="ì—ì´ì „íŠ¸ ê°„ ê³µìœ  ë°ì´í„°")
    
    # ë©”íƒ€ë°ì´í„°
    metadata: Dict[str, Any] = Field(default_factory=dict, description="ì¶”ê°€ ë©”íƒ€ë°ì´í„°")
    
    class Config:
        arbitrary_types_allowed = True


class AgentCapability(BaseModel):
    """ì—ì´ì „íŠ¸ ì—­ëŸ‰ ì •ì˜"""
    
    name: str = Field(..., description="ì—­ëŸ‰ ì´ë¦„")
    description: str = Field(..., description="ì—­ëŸ‰ ì„¤ëª…")
    input_schema: Optional[Type[BaseModel]] = Field(None, description="ìž…ë ¥ ìŠ¤í‚¤ë§ˆ")
    output_schema: Optional[Type[BaseModel]] = Field(None, description="ì¶œë ¥ ìŠ¤í‚¤ë§ˆ")
    supported_modes: List[AgentMode] = Field(
        default_factory=lambda: [AgentMode.REACT],
        description="ì§€ì›í•˜ëŠ” ì‹¤í–‰ ëª¨ë“œ"
    )
    estimated_latency_ms: Optional[int] = Field(None, description="ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„ (ms)")
    requires_internet: bool = Field(False, description="ì¸í„°ë„· ì—°ê²° í•„ìš” ì—¬ë¶€")
    requires_database: bool = Field(False, description="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•„ìš” ì—¬ë¶€")
    
    class Config:
        arbitrary_types_allowed = True


# =============================================================================
# Execution Result
# =============================================================================

class AgentStep(BaseModel):
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ë‹¨ê³„"""
    
    step_number: int
    timestamp: str = Field(default_factory=lambda: datetime.utcnow().isoformat())
    action: str = Field(..., description="ìˆ˜í–‰í•œ ì•¡ì…˜ (ë„êµ¬ ì´ë¦„ ë˜ëŠ” 'reasoning')")
    reasoning: Optional[str] = Field(None, description="ì‚¬ê³  ê³¼ì •")
    tool_input: Optional[Dict[str, Any]] = Field(None, description="ë„êµ¬ ìž…ë ¥")
    tool_output: Optional[Any] = Field(None, description="ë„êµ¬ ì¶œë ¥")
    latency_ms: float = Field(..., description="ì‹¤í–‰ ì‹œê°„ (ë°€ë¦¬ì´ˆ)")
    success: bool = Field(True, description="ì„±ê³µ ì—¬ë¶€")
    error: Optional[str] = Field(None, description="ì—ëŸ¬ ë©”ì‹œì§€")


class AgentExecutionResult(BaseModel):
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼"""
    
    success: bool = Field(..., description="ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€")
    output: Any = Field(..., description="ìµœì¢… ì¶œë ¥")
    
    # ì‹¤í–‰ ì •ë³´
    agent_name: str
    mode: AgentMode
    status: AgentStatus
    
    # ì‹¤í–‰ ì¶”ì 
    steps: List[AgentStep] = Field(default_factory=list)
    tools_used: List[str] = Field(default_factory=list)
    
    # ë©”íŠ¸ë¦­
    total_latency_ms: float
    llm_calls: int = Field(0, description="LLM í˜¸ì¶œ íšŸìˆ˜")
    tool_calls: int = Field(0, description="ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜")
    tokens_used: int = Field(0, description="ì‚¬ìš©í•œ í† í° ìˆ˜")
    
    # ì—ëŸ¬ ì²˜ë¦¬
    errors: List[str] = Field(default_factory=list)
    warnings: List[str] = Field(default_factory=list)
    
    # ë©”íƒ€ë°ì´í„°
    context: AgentExecutionContext
    timestamp: str = Field(default_factory=lambda: datetime.utcnow().isoformat())


# =============================================================================
# Base Agent Protocol
# =============================================================================

class BaseAutonomousAgent(ABC):
    """
    LangChain 1.X ê¸°ë°˜ ìžìœ¨ ì—ì´ì „íŠ¸ ë² ì´ìŠ¤ í´ëž˜ìŠ¤
    
    ëª¨ë“  ì—ì´ì „íŠ¸ëŠ” ì´ í´ëž˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ êµ¬í˜„í•©ë‹ˆë‹¤.
    """
    
    # ì—ì´ì „íŠ¸ ë©”íƒ€ë°ì´í„°
    name: str = "base_agent"
    description: str = "Base autonomous agent"
    version: str = "1.0.0"
    
    def __init__(self) -> None:
        self.tools: Dict[str, BaseTool] = {}
        self.llm: Optional[BaseLanguageModel] = None
        self._capabilities: List[AgentCapability] = []
    
    # ===== í•„ìˆ˜ êµ¬í˜„ ë©”ì„œë“œ =====
    
    @abstractmethod
    async def execute(
        self,
        input_data: Dict[str, Any],
        context: AgentExecutionContext,
        mode: AgentMode = AgentMode.REACT,
    ) -> AgentExecutionResult:
        """
        ì—ì´ì „íŠ¸ ì‹¤í–‰ (ë¹„ë™ê¸°)
        
        Args:
            input_data: ìž…ë ¥ ë°ì´í„°
            context: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸
            mode: ì‹¤í–‰ ëª¨ë“œ
        
        Returns:
            ì‹¤í–‰ ê²°ê³¼
        """
        pass
    
    @abstractmethod
    def get_capabilities(self) -> List[AgentCapability]:
        """ì—ì´ì „íŠ¸ê°€ ì œê³µí•˜ëŠ” ì—­ëŸ‰ ëª©ë¡"""
        pass
    
    # ===== ê³µí†µ ë©”ì„œë“œ =====
    
    async def health_check(self) -> Dict[str, Any]:
        """
        ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸
        
        Returns:
            ìƒíƒœ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # LLM ì—°ê²° í™•ì¸
            llm_status = "available" if self.llm else "not_configured"
            
            # ë„êµ¬ ìƒíƒœ í™•ì¸
            tools_status = {}
            for tool_name, tool in self.tools.items():
                try:
                    # ê°„ë‹¨í•œ ë„êµ¬ ì²´í¬ (ì‹¤ì œ ì‹¤í–‰ì€ í•˜ì§€ ì•ŠìŒ)
                    tools_status[tool_name] = "available"
                except Exception as e:
                    tools_status[tool_name] = f"error: {str(e)}"
            
            return {
                "healthy": True,
                "agent_name": self.name,
                "version": self.version,
                "llm_status": llm_status,
                "tools": tools_status,
                "capabilities": len(self._capabilities),
                "timestamp": datetime.utcnow().isoformat(),
            }
            
        except Exception as e:
            logger.error(f"âŒ [{self.name}] Health check failed: {e}")
            return {
                "healthy": False,
                "agent_name": self.name,
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat(),
            }
    
    def register_tool(self, tool: BaseTool) -> None:
        """ë„êµ¬ ë“±ë¡"""
        self.tools[tool.name] = tool
        logger.info(f"âœ… [{self.name}] Tool registered: {tool.name}")
    
    def set_llm(self, llm: BaseLanguageModel) -> None:
        """LLM ì„¤ì •"""
        self.llm = llm
        logger.info(f"âœ… [{self.name}] LLM configured")
    
    async def _execute_tool(
        self,
        tool_name: str,
        tool_input: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        ë„êµ¬ ì‹¤í–‰ (ê³µí†µ ë¡œì§)
        
        Args:
            tool_name: ë„êµ¬ ì´ë¦„
            tool_input: ë„êµ¬ ìž…ë ¥
        
        Returns:
            ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
        """
        if tool_name not in self.tools:
            error_msg = f"Unknown tool: {tool_name}"
            logger.error(f"âŒ [{self.name}] {error_msg}")
            return {
                "success": False,
                "error": error_msg,
            }
        
        tool = self.tools[tool_name]
        start_time = datetime.utcnow()
        
        try:
            logger.info(f"ðŸ”§ [{self.name}] Executing tool: {tool_name}")
            
            # ë¹„ë™ê¸°/ë™ê¸° ì‹¤í–‰
            if hasattr(tool, "_arun"):
                result = await tool._arun(**tool_input)
            else:
                result = tool._run(**tool_input)
            
            latency_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            logger.info(f"âœ… [{self.name}] Tool completed: {tool_name} ({latency_ms:.1f}ms)")
            
            # ê²°ê³¼ ì •ê·œí™”
            if isinstance(result, dict):
                result["latency_ms"] = latency_ms
                if "success" not in result:
                    result["success"] = True
                return result
            else:
                return {
                    "success": True,
                    "result": result,
                    "latency_ms": latency_ms,
                }
                
        except Exception as e:
            latency_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            error_msg = f"Tool execution failed: {str(e)}"
            logger.error(f"âŒ [{self.name}] {tool_name}: {error_msg}")
            
            return {
                "success": False,
                "error": error_msg,
                "latency_ms": latency_ms,
            }
    
    def _log_step(
        self,
        action: str,
        reasoning: Optional[str] = None,
        tool_input: Optional[Dict] = None,
        tool_output: Optional[Any] = None,
        latency_ms: float = 0.0,
        success: bool = True,
        error: Optional[str] = None,
    ) -> AgentStep:
        """ì‹¤í–‰ ë‹¨ê³„ ë¡œê¹…"""
        step = AgentStep(
            step_number=len(getattr(self, "_steps", [])) + 1,
            action=action,
            reasoning=reasoning,
            tool_input=tool_input,
            tool_output=tool_output,
            latency_ms=latency_ms,
            success=success,
            error=error,
        )
        
        if not hasattr(self, "_steps"):
            self._steps = []
        self._steps.append(step)
        
        return step
