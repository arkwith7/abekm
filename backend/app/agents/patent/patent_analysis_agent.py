"""
Patent Analysis Agent - íŠ¹í—ˆ ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸

ì—”í„°í”„ë¼ì´ì¦ˆ ê²½ìŸ ì¸í…”ë¦¬ì „ìŠ¤ë¥¼ ìœ„í•œ íŠ¹í—ˆ ë°ì´í„° ê²€ìƒ‰, ë¶„ì„, ì‹œê°í™”

ì£¼ìš” ê¸°ëŠ¥:
1. íŠ¹í—ˆ ê²€ìƒ‰ (KIPRIS, Google Patents via SerpAPI)
2. ê²½ìŸì‚¬ íŠ¹í—ˆ ë¹„êµ ë¶„ì„
3. ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„ (ì‹œê³„ì—´)
4. íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„
5. ê¸°ìˆ  ê³µë°±(White Space) ë¶„ì„
6. ì‹œê°í™” ë°ì´í„° ìƒì„± (ì°¨íŠ¸, ê·¸ë˜í”„)
7. LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ìƒì„±
"""
from __future__ import annotations

import asyncio
import os
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Type

from loguru import logger
from pydantic import BaseModel, Field, PrivateAttr

try:
    from langchain_core.tools import BaseTool
except ImportError:
    from langchain.tools import BaseTool

from app.tools.retrieval.patent_search_tool import (
    PatentSearchTool, 
    PatentData,
    PatentSearchResult,
    PatentJurisdiction,
    PatentStatus
)
from app.tools.retrieval.patent_analysis_tool import (
    PatentAnalysisTool,
    PatentAnalysisType,
    PatentAnalysisResult
)
from app.services.core.ai_service import ai_service


# =============================================================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë”©
# =============================================================================

def load_patent_analysis_prompt() -> str:
    """íŠ¹í—ˆ ë¶„ì„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë”©"""
    prompt_path = Path(__file__).parent.parent.parent.parent / "prompts" / "patent-analysis.prompt"
    
    if prompt_path.exists():
        with open(prompt_path, "r", encoding="utf-8") as f:
            return f.read()
    else:
        logger.warning(f"âš ï¸ íŠ¹í—ˆ ë¶„ì„ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prompt_path}")
        return DEFAULT_PATENT_ANALYSIS_PROMPT


DEFAULT_PATENT_ANALYSIS_PROMPT = """ë‹¹ì‹ ì€ íŠ¹í—ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì œê³µëœ íŠ¹í—ˆ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê¸°ìˆ  íŠ¸ë Œë“œ, ê²½ìŸë ¥ ë¶„ì„, ì‹œì¥ ì¸ì‚¬ì´íŠ¸, ì „ëµì  ê¶Œê³ ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ë¶„ì„ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ë¹„ì „ë¬¸ê°€ë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…í•´ ì£¼ì„¸ìš”."""


# =============================================================================
# Input/Output Models
# =============================================================================

class PatentAnalysisAgentInput(BaseModel):
    """íŠ¹í—ˆ ë¶„ì„ ì—ì´ì „íŠ¸ ì…ë ¥ ìŠ¤í‚¤ë§ˆ"""
    
    query: str = Field(
        ..., 
        description="ê²€ìƒ‰ ì¿¼ë¦¬ ë˜ëŠ” ë¶„ì„ ìš”ì²­ (ì˜ˆ: 'ì‚¼ì„±ì „ì AI ë°˜ë„ì²´ íŠ¹í—ˆ')"
    )
    analysis_type: str = Field(
        default="search",
        description="ë¶„ì„ ìœ í˜•: search(ê²€ìƒ‰), comparison(ê²½ìŸì‚¬ë¹„êµ), trend(íŠ¸ë Œë“œ), portfolio(í¬íŠ¸í´ë¦¬ì˜¤), gap(ê¸°ìˆ ê³µë°±)"
    )
    our_company: Optional[str] = Field(
        default=None,
        description="ìš°ë¦¬ íšŒì‚¬ëª… (ê²½ìŸì‚¬ ë¹„êµ ì‹œ í•„ìˆ˜)"
    )
    competitor: Optional[str] = Field(
        default=None,
        description="ê²½ìŸì‚¬ëª… (ê²½ìŸì‚¬ ë¹„êµ ì‹œ í•„ìˆ˜)"
    )
    jurisdiction: str = Field(
        default="KR",
        description="ê´€í• ê¶Œ: KR(í•œêµ­), US(ë¯¸êµ­), EP(ìœ ëŸ½), ALL(ì „ì²´)"
    )
    date_from: Optional[str] = Field(
        default=None,
        description="ì¶œì›ì¼ ì‹œì‘ (YYYY-MM-DD)"
    )
    date_to: Optional[str] = Field(
        default=None,
        description="ì¶œì›ì¼ ì¢…ë£Œ (YYYY-MM-DD)"
    )
    ipc_codes: Optional[List[str]] = Field(
        default=None,
        description="IPC ë¶„ë¥˜ ì½”ë“œ í•„í„° (ì˜ˆ: ['G06N', 'H01L'])"
    )
    max_results: int = Field(
        default=50,
        description="ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜"
    )
    include_visualization: bool = Field(
        default=True,
        description="ì‹œê°í™” ë°ì´í„° í¬í•¨ ì—¬ë¶€"
    )
    time_range_years: int = Field(
        default=5,
        description="íŠ¸ë Œë“œ ë¶„ì„ ì‹œ ê¸°ê°„ (ë…„)"
    )


class VisualizationData(BaseModel):
    """ì‹œê°í™” ë°ì´í„° ëª¨ë¸"""
    
    chart_type: str = Field(description="ì°¨íŠ¸ ìœ í˜•: bar, line, pie, radar, timeline, network")
    title: str = Field(description="ì°¨íŠ¸ ì œëª©")
    data: Dict[str, Any] = Field(description="ì°¨íŠ¸ ë°ì´í„°")
    options: Dict[str, Any] = Field(default_factory=dict, description="ì°¨íŠ¸ ì˜µì…˜")


class PatentAnalysisAgentOutput(BaseModel):
    """íŠ¹í—ˆ ë¶„ì„ ì—ì´ì „íŠ¸ ì¶œë ¥"""
    
    success: bool = Field(description="ì„±ê³µ ì—¬ë¶€")
    analysis_type: str = Field(description="ìˆ˜í–‰ëœ ë¶„ì„ ìœ í˜•")
    summary: str = Field(description="ë¶„ì„ ê²°ê³¼ ìš”ì•½ (ìì—°ì–´)")
    patents: List[Dict[str, Any]] = Field(default_factory=list, description="ê²€ìƒ‰ëœ íŠ¹í—ˆ ëª©ë¡")
    total_patents: int = Field(default=0, description="ì´ íŠ¹í—ˆ ìˆ˜")
    analysis_result: Optional[Dict[str, Any]] = Field(default=None, description="ìƒì„¸ ë¶„ì„ ê²°ê³¼")
    visualizations: List[VisualizationData] = Field(default_factory=list, description="ì‹œê°í™” ë°ì´í„°")
    insights: List[str] = Field(default_factory=list, description="í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
    recommendations: List[str] = Field(default_factory=list, description="ê¶Œì¥ ì‚¬í•­")
    trace_id: str = Field(description="ì¶”ì  ID")
    elapsed_ms: float = Field(description="ì²˜ë¦¬ ì‹œê°„ (ms)")
    errors: List[str] = Field(default_factory=list, description="ì˜¤ë¥˜ ëª©ë¡")


# =============================================================================
# Patent Analysis Agent Tool
# =============================================================================

class PatentAnalysisAgentTool(BaseTool):
    """
    íŠ¹í—ˆ ë¶„ì„ AI ì—ì´ì „íŠ¸
    
    LangChain Tool ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•˜ì—¬ SupervisorAgentì—ì„œ í˜¸ì¶œ ê°€ëŠ¥
    
    ì§€ì› ë¶„ì„ ìœ í˜•:
    1. search: íŠ¹í—ˆ ê²€ìƒ‰
    2. comparison: ê²½ìŸì‚¬ íŠ¹í—ˆ ë¹„êµ
    3. trend: ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„
    4. portfolio: í¬íŠ¸í´ë¦¬ì˜¤ ê°œìš”
    5. gap: ê¸°ìˆ  ê³µë°± ë¶„ì„
    """
    
    name: str = "patent_analysis_agent"
    description: str = """íŠ¹í—ˆ ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸ - ì—”í„°í”„ë¼ì´ì¦ˆ ê²½ìŸ ì¸í…”ë¦¬ì „ìŠ¤.

ê¸°ëŠ¥:
- íŠ¹í—ˆ ê²€ìƒ‰ (KIPRIS í•œêµ­, SerpAPI Google Patents ê¸€ë¡œë²Œ)
- ê²½ìŸì‚¬ íŠ¹í—ˆ ë¹„êµ ë¶„ì„ ("ì‚¼ì„±ì „ì vs LGì „ì AI íŠ¹í—ˆ ë¹„êµ")
- ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„ (ì‹œê³„ì—´ ë³€í™”)
- íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„
- ê¸°ìˆ  ê³µë°±(White Space) ë¶„ì„
- ì‹œê°í™” ë°ì´í„° ìƒì„± (ì°¨íŠ¸, ê·¸ë˜í”„)

ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
- "ì‚¼ì„±ì „ìì˜ AI ë°˜ë„ì²´ ê´€ë ¨ íŠ¹í—ˆë¥¼ ê²€ìƒ‰í•´ì¤˜"
- "ìš°ë¦¬íšŒì‚¬ì™€ ì‚¼ì„±ì „ìì˜ íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ë¹„êµí•´ì¤˜"
- "ìµœê·¼ 5ë…„ê°„ AI ë°˜ë„ì²´ íŠ¹í—ˆ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•´ì¤˜"
- "ê²½ìŸì‚¬ ëŒ€ë¹„ ìš°ë¦¬ê°€ ë¶€ì¡±í•œ ê¸°ìˆ  ë¶„ì•¼ëŠ”?"
"""
    args_schema: Type[BaseModel] = PatentAnalysisAgentInput
    
    # ë‚´ë¶€ ë„êµ¬ (PrivateAttrë¡œ pydantic í˜¸í™˜)
    _search_tool: PatentSearchTool = PrivateAttr()
    _analysis_tool: PatentAnalysisTool = PrivateAttr()
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._search_tool = PatentSearchTool()
        self._analysis_tool = PatentAnalysisTool()
    
    async def _arun(
        self,
        query: str,
        analysis_type: str = "search",
        our_company: Optional[str] = None,
        competitor: Optional[str] = None,
        jurisdiction: str = "KR",
        date_from: Optional[str] = None,
        date_to: Optional[str] = None,
        ipc_codes: Optional[List[str]] = None,
        max_results: int = 50,
        include_visualization: bool = True,
        time_range_years: int = 5,
        **kwargs
    ) -> Dict[str, Any]:
        """
        íŠ¹í—ˆ ë¶„ì„ ì‹¤í–‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ ë˜ëŠ” ë¶„ì„ ìš”ì²­
            analysis_type: ë¶„ì„ ìœ í˜• (search/comparison/trend/portfolio/gap)
            our_company: ìš°ë¦¬ íšŒì‚¬ëª… (ë¹„êµ ë¶„ì„ ì‹œ)
            competitor: ê²½ìŸì‚¬ëª… (ë¹„êµ ë¶„ì„ ì‹œ)
            jurisdiction: ê´€í• ê¶Œ (KR/US/EP/ALL)
            date_from: ì¶œì›ì¼ ì‹œì‘
            date_to: ì¶œì›ì¼ ì¢…ë£Œ
            ipc_codes: IPC í•„í„°
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            include_visualization: ì‹œê°í™” í¬í•¨ ì—¬ë¶€
            time_range_years: íŠ¸ë Œë“œ ë¶„ì„ ê¸°ê°„
        
        Returns:
            Dict: ë¶„ì„ ê²°ê³¼ (PatentAnalysisAgentOutput í˜•íƒœ)
        """
        start_time = datetime.utcnow()
        trace_id = str(uuid.uuid4())
        
        logger.info(
            f"ğŸ”¬ [PatentAnalysisAgent] ë¶„ì„ ì‹œì‘: type={analysis_type}, query='{query[:50]}...'"
        )
        
        try:
            # ë¶„ì„ ìœ í˜•ì— ë”°ë¼ ì²˜ë¦¬
            if analysis_type == "search":
                result = await self._execute_search(
                    query=query,
                    jurisdiction=jurisdiction,
                    date_from=date_from,
                    date_to=date_to,
                    ipc_codes=ipc_codes,
                    max_results=max_results,
                    include_visualization=include_visualization
                )
            elif analysis_type == "comparison":
                result = await self._execute_comparison(
                    query=query,
                    our_company=our_company,
                    competitor=competitor,
                    jurisdiction=jurisdiction,
                    date_from=date_from,
                    date_to=date_to,
                    max_results=max_results,
                    include_visualization=include_visualization
                )
            elif analysis_type == "trend":
                result = await self._execute_trend_analysis(
                    query=query,
                    jurisdiction=jurisdiction,
                    time_range_years=time_range_years,
                    max_results=max_results,
                    include_visualization=include_visualization
                )
            elif analysis_type == "portfolio":
                result = await self._execute_portfolio_analysis(
                    query=query,
                    company=our_company or competitor,
                    jurisdiction=jurisdiction,
                    max_results=max_results,
                    include_visualization=include_visualization
                )
            elif analysis_type == "gap":
                result = await self._execute_gap_analysis(
                    query=query,
                    our_company=our_company,
                    competitor=competitor,
                    jurisdiction=jurisdiction,
                    max_results=max_results,
                    include_visualization=include_visualization
                )
            else:
                # ê¸°ë³¸: ê²€ìƒ‰
                result = await self._execute_search(
                    query=query,
                    jurisdiction=jurisdiction,
                    max_results=max_results,
                    include_visualization=include_visualization
                )
            
            elapsed_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            result["trace_id"] = trace_id
            result["elapsed_ms"] = elapsed_ms
            result["success"] = True
            
            logger.info(f"âœ… [PatentAnalysisAgent] ì™„ë£Œ: {elapsed_ms:.0f}ms")
            
            return result
            
        except Exception as e:
            elapsed_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            logger.error(f"âŒ [PatentAnalysisAgent] ì˜¤ë¥˜: {e}")
            
            return {
                "success": False,
                "analysis_type": analysis_type,
                "summary": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "patents": [],
                "total_patents": 0,
                "analysis_result": None,
                "visualizations": [],
                "insights": [],
                "recommendations": [],
                "trace_id": trace_id,
                "elapsed_ms": elapsed_ms,
                "errors": [str(e)]
            }
    
    def _run(
        self,
        query: str,
        **kwargs
    ) -> Dict[str, Any]:
        """ë™ê¸° ì‹¤í–‰ (í´ë°±)"""
        return asyncio.run(self._arun(query, **kwargs))
    
    # =========================================================================
    # ë¶„ì„ ìœ í˜•ë³„ ì‹¤í–‰ ë©”ì„œë“œ
    # =========================================================================
    
    async def _execute_search(
        self,
        query: str,
        jurisdiction: str = "KR",
        date_from: Optional[str] = None,
        date_to: Optional[str] = None,
        ipc_codes: Optional[List[str]] = None,
        max_results: int = 50,
        include_visualization: bool = True
    ) -> Dict[str, Any]:
        """íŠ¹í—ˆ ê²€ìƒ‰ ì‹¤í–‰"""
        import re
        
        # ì¿¼ë¦¬ì—ì„œ ì¶œì›ì¸ ì¶”ì¶œ ì‹œë„
        applicant = self._extract_applicant_from_query(query)
        clean_query = self._clean_query(query, applicant)
        
        # ğŸ”§ ë””ë²„ê·¸: clean_query ê°’ í™•ì¸
        logger.info(f"ğŸ”§ [PatentAnalysisAgent] ì¿¼ë¦¬ ì •ì œ: '{query}' â†’ clean='{clean_query}', applicant='{applicant}'")
        
        # ğŸ†• ì¿¼ë¦¬ì—ì„œ ì—°ë„ ì •ë³´ ì¶”ì¶œ
        year_match = re.search(r'(\d{4})ë…„', query)
        if year_match and not date_from:
            year = year_match.group(1)
            date_from = f"{year}-01-01"
            date_to = f"{year}-12-31"
            logger.info(f"ğŸ“… ì—°ë„ í•„í„° ì ìš©: {date_from} ~ {date_to}")
        
        # íŠ¹í—ˆ ê²€ìƒ‰
        search_result: PatentSearchResult = await self._search_tool._arun(
            query=clean_query,
            applicant=applicant,
            jurisdiction=jurisdiction,
            date_from=date_from,
            date_to=date_to,
            ipc_codes=ipc_codes,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        patents = search_result.data
        
        # ğŸ†• ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì¶œì›ì¸ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì¸í„°ë„· ê²€ìƒ‰ í´ë°±
        if not patents and applicant:
            logger.warning(f"âš ï¸ [PatentAnalysisAgent] KIPRISì—ì„œ '{applicant}' íŠ¹í—ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ â†’ ì¸í„°ë„· ê²€ìƒ‰ í´ë°±")
            return await self._fallback_to_internet_search(query, applicant, date_from)
        
        # ğŸ†• ì—°ë„ í•„í„°ë§ (ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¶”ê°€ í•„í„°)
        if date_from and date_to:
            target_year = date_from[:4]
            filtered_patents = [
                p for p in patents 
                if p.application_date and p.application_date.startswith(target_year)
            ]
            if filtered_patents:
                patents = filtered_patents
                logger.info(f"ğŸ“… {target_year}ë…„ íŠ¹í—ˆ í•„í„°ë§: {len(patents)}ê±´")
        
        # ì‹œê°í™” ë°ì´í„° ìƒì„±
        visualizations = []
        if include_visualization and patents:
            visualizations = self._generate_search_visualizations(patents)
        
        # ğŸ†• ìƒì„¸ ìš”ì•½ ìƒì„± (ì›ë³¸ ì¿¼ë¦¬, ê²€ìƒ‰ ë§¥ë½ í¬í•¨)
        summary = await self._generate_search_summary(
            original_query=query,
            patents=patents,
            applicant=applicant,
            year_filter=date_from[:4] if date_from else None
        )
        
        # ğŸ†• ìƒì„¸ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        insights = self._extract_search_insights(patents, applicant)
        
        return {
            "analysis_type": "search",
            "summary": summary,
            "patents": [p.model_dump() for p in patents],
            "total_patents": search_result.total_found,
            "analysis_result": {
                "search_params": search_result.search_params,
                "source": search_result.source,
                "year_filter": date_from[:4] if date_from else None
            },
            "visualizations": [v.model_dump() for v in visualizations],
            "insights": insights,
            "recommendations": [],
            "errors": search_result.errors
        }
    
    async def _fallback_to_internet_search(
        self,
        query: str,
        applicant: str,
        date_from: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        KIPRIS ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì¸í„°ë„· ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
        
        ì •í™•í•œ ì¶œì›ì¸ì˜ íŠ¹í—ˆë¥¼ ì°¾ì§€ ëª»í•˜ë©´, ì˜ëª»ëœ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒë³´ë‹¤
        ì¸í„°ë„·ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì œê³µí•˜ëŠ” ê²ƒì´ ë” ë‚«ìŠµë‹ˆë‹¤.
        """
        try:
            from app.tools.retrieval.internet_search_tool import internet_search_tool
            
            # ì¸í„°ë„· ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
            year_str = date_from[:4] if date_from else ""
            search_query = f"{applicant} {year_str} íŠ¹í—ˆ ì¶œì› í˜„í™©"
            
            logger.info(f"ğŸŒ [PatentAnalysisAgent] ì¸í„°ë„· ê²€ìƒ‰: '{search_query}'")
            
            # ì¸í„°ë„· ê²€ìƒ‰ ì‹¤í–‰
            search_result = await internet_search_tool._arun(query=search_query)
            
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            internet_summary = ""
            if search_result.success and search_result.data:
                for item in search_result.data[:5]:  # ìƒìœ„ 5ê°œë§Œ
                    # SearchChunk ê°ì²´ì—ì„œ ì†ì„± ì¶”ì¶œ
                    title = getattr(item, 'title', '') or ''
                    content = getattr(item, 'content', '') or ''
                    url = getattr(item, 'url', '') or getattr(item, 'source_url', '') or ''
                    if title:
                        internet_summary += f"- **{title}**\n"
                        if content:
                            internet_summary += f"  {content[:200]}...\n"
                        if url:
                            internet_summary += f"  [ë§í¬]({url})\n"
                        internet_summary += "\n"
            
            if not internet_summary:
                internet_summary = "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš”ì•½ í˜•íƒœë¡œ ë°˜í™˜
            summary = f"""## ğŸ“‹ íŠ¹í—ˆ ê²€ìƒ‰ ê²°ê³¼

### âš ï¸ KIPRIS ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ

**'{applicant}'**ì˜ íŠ¹í—ˆë¥¼ KIPRIS(í•œêµ­íŠ¹í—ˆì •ë³´ì›)ì—ì„œ ì§ì ‘ ê²€ìƒ‰í•˜ì˜€ìœ¼ë‚˜, 
ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì¶œì›ì¸ì˜ íŠ¹í—ˆë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

**ê°€ëŠ¥í•œ ì›ì¸:**
- íšŒì‚¬ëª…ì´ KIPRISì— ë“±ë¡ëœ ì •ì‹ ëª…ì¹­ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- í•´ë‹¹ ê¸°ê°„ì— ì¶œì›ëœ íŠ¹í—ˆê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì•„ì§ ê³µê°œë˜ì§€ ì•Šì€ íŠ¹í—ˆì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì¶œì› í›„ 18ê°œì›” ì´ë‚´)

---

### ğŸŒ ì¸í„°ë„· ê²€ìƒ‰ ê²°ê³¼

ë‹¤ìŒì€ ì¸í„°ë„·ì—ì„œ ì°¾ì€ **'{applicant}'** ê´€ë ¨ íŠ¹í—ˆ ì •ë³´ì…ë‹ˆë‹¤:

{internet_summary}

---

### ğŸ’¡ ê¶Œì¥ ì‚¬í•­

1. **ì •í™•í•œ íšŒì‚¬ëª… í™•ì¸**: KIPRISì—ì„œ ì§ì ‘ '{applicant}' ê²€ìƒ‰í•˜ì—¬ ì •ì‹ ì¶œì›ì¸ëª… í™•ì¸
2. **KIPRIS ì§ì ‘ ê²€ìƒ‰**: [KIPRIS](https://www.kipris.or.kr) ì‚¬ì´íŠ¸ì—ì„œ ì§ì ‘ ê²€ìƒ‰
3. **ê¸°ê°„ ì¡°ì •**: ë” ë„“ì€ ê¸°ê°„ìœ¼ë¡œ ê²€ìƒ‰ ì‹œë„
"""
            
            return {
                "analysis_type": "search",
                "summary": summary,
                "patents": [],
                "total_patents": 0,
                "analysis_result": {
                    "source": "internet_search_fallback",
                    "reason": "KIPRISì—ì„œ ì •í™•í•œ ì¶œì›ì¸ ë§¤ì¹­ ì‹¤íŒ¨",
                    "applicant": applicant
                },
                "visualizations": [],
                "insights": [
                    f"KIPRISì—ì„œ '{applicant}'ì˜ íŠ¹í—ˆë¥¼ ì°¾ì§€ ëª»í•¨",
                    "ì¸í„°ë„· ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´ ì •ë³´ ì œê³µ",
                    "ì •í™•í•œ íŠ¹í—ˆ ì •ë³´ëŠ” KIPRIS ì§ì ‘ ê²€ìƒ‰ ê¶Œì¥"
                ],
                "recommendations": [
                    f"KIPRISì—ì„œ '{applicant}' ì •ì‹ ì¶œì›ì¸ëª… í™•ì¸",
                    "íŠ¹í—ˆì²­ íŠ¹í—ˆë¡œ ì‚¬ì´íŠ¸ì—ì„œ ì§ì ‘ ê²€ìƒ‰"
                ],
                "errors": []
            }
            
        except Exception as e:
            logger.error(f"âŒ [PatentAnalysisAgent] ì¸í„°ë„· ê²€ìƒ‰ í´ë°± ì‹¤íŒ¨: {e}")
            return {
                "analysis_type": "search",
                "summary": f"## âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨\n\n'{applicant}'ì˜ íŠ¹í—ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n**ê¶Œì¥ ì‚¬í•­:**\n- KIPRIS(https://www.kipris.or.kr)ì—ì„œ ì§ì ‘ ê²€ìƒ‰í•˜ì„¸ìš”\n- ì •í™•í•œ ì¶œì›ì¸ëª…ì„ í™•ì¸í•´ ì£¼ì„¸ìš”",
                "patents": [],
                "total_patents": 0,
                "analysis_result": {"source": "error", "error": str(e)},
                "visualizations": [],
                "insights": [],
                "recommendations": ["KIPRISì—ì„œ ì§ì ‘ ê²€ìƒ‰"],
                "errors": [str(e)]
            }

    async def _execute_comparison(
        self,
        query: str,
        our_company: Optional[str],
        competitor: Optional[str],
        jurisdiction: str = "KR",
        date_from: Optional[str] = None,
        date_to: Optional[str] = None,
        max_results: int = 50,
        include_visualization: bool = True
    ) -> Dict[str, Any]:
        """ê²½ìŸì‚¬ íŠ¹í—ˆ ë¹„êµ ë¶„ì„"""
        
        if not our_company or not competitor:
            return {
                "analysis_type": "comparison",
                "summary": "ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìš°ë¦¬ íšŒì‚¬ëª…(our_company)ê³¼ ê²½ìŸì‚¬ëª…(competitor)ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "patents": [],
                "total_patents": 0,
                "analysis_result": None,
                "visualizations": [],
                "insights": [],
                "recommendations": ["our_companyì™€ competitor íŒŒë¼ë¯¸í„°ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."],
                "errors": ["Missing required parameters: our_company, competitor"]
            }
        
        # ì–‘ì¸¡ íŠ¹í—ˆ ê²€ìƒ‰
        our_result = await self._search_tool._arun(
            query=query,
            applicant=our_company,
            jurisdiction=jurisdiction,
            date_from=date_from,
            date_to=date_to,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        competitor_result = await self._search_tool._arun(
            query=query,
            applicant=competitor,
            jurisdiction=jurisdiction,
            date_from=date_from,
            date_to=date_to,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        our_patents = our_result.data
        competitor_patents = competitor_result.data
        all_patents = our_patents + competitor_patents
        
        # ë¹„êµ ë¶„ì„ ìˆ˜í–‰
        analysis_result = await self._analysis_tool._arun(
            patents=all_patents,
            analysis_type="comparison",
            our_company=our_company,
            comparison_target=competitor
        )
        
        # ì‹œê°í™” ë°ì´í„° ìƒì„±
        visualizations = []
        if include_visualization:
            visualizations = self._generate_comparison_visualizations(
                our_patents, competitor_patents, our_company, competitor
            )
        
        # ìš”ì•½ ìƒì„±
        summary = await self._generate_comparison_summary(
            query, our_company, competitor, our_patents, competitor_patents, analysis_result
        )
        
        # ì¸ì‚¬ì´íŠ¸ ë° ê¶Œì¥ì‚¬í•­
        insights = self._extract_comparison_insights(our_patents, competitor_patents, our_company, competitor)
        recommendations = self._generate_comparison_recommendations(analysis_result)
        
        return {
            "analysis_type": "comparison",
            "summary": summary,
            "patents": [p.model_dump() for p in all_patents],
            "total_patents": len(all_patents),
            "analysis_result": analysis_result.model_dump() if hasattr(analysis_result, 'model_dump') else analysis_result,
            "visualizations": [v.model_dump() for v in visualizations],
            "insights": insights,
            "recommendations": recommendations,
            "errors": our_result.errors + competitor_result.errors
        }
    
    async def _execute_trend_analysis(
        self,
        query: str,
        jurisdiction: str = "KR",
        time_range_years: int = 5,
        max_results: int = 100,
        include_visualization: bool = True
    ) -> Dict[str, Any]:
        """ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„"""
        
        # ê¸°ê°„ ê³„ì‚°
        from datetime import datetime, timedelta
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365 * time_range_years)
        
        date_from = start_date.strftime("%Y-%m-%d")
        date_to = end_date.strftime("%Y-%m-%d")
        
        # íŠ¹í—ˆ ê²€ìƒ‰
        search_result = await self._search_tool._arun(
            query=query,
            jurisdiction=jurisdiction,
            date_from=date_from,
            date_to=date_to,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        patents = search_result.data
        
        # íŠ¸ë Œë“œ ë¶„ì„ ìˆ˜í–‰
        analysis_result = await self._analysis_tool._arun(
            patents=patents,
            analysis_type="timeline",
            time_range_years=time_range_years
        )
        
        # ì‹œê°í™” ë°ì´í„° ìƒì„±
        visualizations = []
        if include_visualization and patents:
            visualizations = self._generate_trend_visualizations(patents, time_range_years)
        
        # ìš”ì•½ ìƒì„±
        summary = await self._generate_trend_summary(query, patents, time_range_years, analysis_result)
        
        # ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        insights = self._extract_trend_insights(patents, time_range_years)
        
        return {
            "analysis_type": "trend",
            "summary": summary,
            "patents": [p.model_dump() for p in patents],
            "total_patents": len(patents),
            "analysis_result": analysis_result.model_dump() if hasattr(analysis_result, 'model_dump') else analysis_result,
            "visualizations": [v.model_dump() for v in visualizations],
            "insights": insights,
            "recommendations": [],
            "errors": search_result.errors
        }
    
    async def _execute_portfolio_analysis(
        self,
        query: str,
        company: Optional[str],
        jurisdiction: str = "KR",
        max_results: int = 100,
        include_visualization: bool = True
    ) -> Dict[str, Any]:
        """í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„"""
        
        # íŠ¹í—ˆ ê²€ìƒ‰
        search_result = await self._search_tool._arun(
            query=query,
            applicant=company,
            jurisdiction=jurisdiction,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        patents = search_result.data
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ìˆ˜í–‰
        analysis_result = await self._analysis_tool._arun(
            patents=patents,
            analysis_type="portfolio"
        )
        
        # í† í”½ ë¶„ì„ë„ ìˆ˜í–‰
        topic_result = await self._analysis_tool._arun(
            patents=patents,
            analysis_type="topic"
        )
        
        # ì‹œê°í™” ë°ì´í„° ìƒì„±
        visualizations = []
        if include_visualization and patents:
            visualizations = self._generate_portfolio_visualizations(patents, company)
        
        # ìš”ì•½ ìƒì„±
        summary = await self._generate_portfolio_summary(query, company, patents, analysis_result, topic_result)
        
        # ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        insights = self._extract_portfolio_insights(patents, company)
        
        return {
            "analysis_type": "portfolio",
            "summary": summary,
            "patents": [p.model_dump() for p in patents],
            "total_patents": len(patents),
            "analysis_result": {
                "portfolio": analysis_result.model_dump() if hasattr(analysis_result, 'model_dump') else analysis_result,
                "topics": topic_result.model_dump() if hasattr(topic_result, 'model_dump') else topic_result
            },
            "visualizations": [v.model_dump() for v in visualizations],
            "insights": insights,
            "recommendations": [],
            "errors": search_result.errors
        }
    
    async def _execute_gap_analysis(
        self,
        query: str,
        our_company: Optional[str],
        competitor: Optional[str],
        jurisdiction: str = "KR",
        max_results: int = 100,
        include_visualization: bool = True
    ) -> Dict[str, Any]:
        """ê¸°ìˆ  ê³µë°± ë¶„ì„"""
        
        if not our_company or not competitor:
            return {
                "analysis_type": "gap",
                "summary": "ê¸°ìˆ  ê³µë°± ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìš°ë¦¬ íšŒì‚¬ëª…(our_company)ê³¼ ê²½ìŸì‚¬ëª…(competitor)ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "patents": [],
                "total_patents": 0,
                "analysis_result": None,
                "visualizations": [],
                "insights": [],
                "recommendations": ["our_companyì™€ competitor íŒŒë¼ë¯¸í„°ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."],
                "errors": ["Missing required parameters"]
            }
        
        # ì–‘ì¸¡ íŠ¹í—ˆ ê²€ìƒ‰
        our_result = await self._search_tool._arun(
            query=query,
            applicant=our_company,
            jurisdiction=jurisdiction,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        competitor_result = await self._search_tool._arun(
            query=query,
            applicant=competitor,
            jurisdiction=jurisdiction,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        all_patents = our_result.data + competitor_result.data
        
        # ê¸°ìˆ  ê³µë°± ë¶„ì„ ìˆ˜í–‰
        analysis_result = await self._analysis_tool._arun(
            patents=all_patents,
            analysis_type="gap",
            our_company=our_company,
            comparison_target=competitor
        )
        
        # ì‹œê°í™” ë°ì´í„° ìƒì„±
        visualizations = []
        if include_visualization:
            visualizations = self._generate_gap_visualizations(
                our_result.data, competitor_result.data, our_company, competitor
            )
        
        # ìš”ì•½ ìƒì„±
        summary = await self._generate_gap_summary(query, our_company, competitor, analysis_result)
        
        # ì¸ì‚¬ì´íŠ¸ ë° ê¶Œì¥ì‚¬í•­
        insights = self._extract_gap_insights(analysis_result)
        recommendations = self._generate_gap_recommendations(analysis_result)
        
        return {
            "analysis_type": "gap",
            "summary": summary,
            "patents": [p.model_dump() for p in all_patents],
            "total_patents": len(all_patents),
            "analysis_result": analysis_result.model_dump() if hasattr(analysis_result, 'model_dump') else analysis_result,
            "visualizations": [v.model_dump() for v in visualizations],
            "insights": insights,
            "recommendations": recommendations,
            "errors": our_result.errors + competitor_result.errors
        }
    
    # =========================================================================
    # í—¬í¼ ë©”ì„œë“œ
    # =========================================================================
    
    def _extract_applicant_from_query(self, query: str) -> Optional[str]:
        """ì¿¼ë¦¬ì—ì„œ ì¶œì›ì¸(íšŒì‚¬ëª…) ì¶”ì¶œ"""
        import re
        
        # 1. ì•Œë ¤ì§„ í•œêµ­ ëŒ€ê¸°ì—… íŒ¨í„´ (ì •í™•í•œ ë§¤ì¹­)
        korean_companies = [
            "ì‚¼ì„±ì „ì", "ì‚¼ì„±SDI", "ì‚¼ì„±ë””ìŠ¤í”Œë ˆì´", "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", "ì‚¼ì„±SDS",
            "LGì „ì", "LGí™”í•™", "LGì—ë„ˆì§€ì†”ë£¨ì…˜", "LGë””ìŠ¤í”Œë ˆì´", "LGì´ë…¸í…",
            "SKí•˜ì´ë‹‰ìŠ¤", "SKì´ë…¸ë² ì´ì…˜", "SKí…”ë ˆì½¤", "SKC",
            "í˜„ëŒ€ìë™ì°¨", "í˜„ëŒ€ëª¨ë¹„ìŠ¤", "ê¸°ì•„", "í˜„ëŒ€ê±´ì„¤",
            "ë„¤ì´ë²„", "ì¹´ì¹´ì˜¤", "ì¿ íŒ¡", "í† ìŠ¤", "ë°°ë‹¬ì˜ë¯¼ì¡±",
            "í¬ìŠ¤ì½”", "ë¡¯ë°ì¼€ë¯¸ì¹¼", "í•œí™”ì†”ë£¨ì…˜", "ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°", "CJì œì¼ì œë‹¹"
        ]
        
        for company in korean_companies:
            if company in query:
                logger.debug(f"ğŸ“Œ ì¶œì›ì¸ ì¶”ì¶œ (ì•Œë ¤ì§„ ê¸°ì—…): {company}")
                return company
        
        # 2. "~ì˜ íŠ¹í—ˆ", "~ê°€ ì¶œì›í•œ", "~ì—ì„œ ê°œë°œí•œ" íŒ¨í„´
        patterns = [
            r'([ê°€-í£A-Za-z0-9]+(?:ì „ì|ê·¸ë£¹|ì „ê¸°|í†µì‹ |ë°˜ë„ì²´|ë©”ë””ì»¬|ë°”ì´ì˜¤|í…Œí¬|ì†Œí”„íŠ¸|ì‹œìŠ¤í…œì¦ˆ?|ì†”ë£¨ì…˜|ì´ë…¸ë² ì´ì…˜|ì—ë„ˆì§€))(?:ì˜|ê°€|ì—ì„œ|ì´|ëŠ”)',
            r'([ê°€-í£A-Za-z0-9]+(?:ì£¼ì‹íšŒì‚¬|ãˆœ|\(ì£¼\)|Inc\.|Corp\.|Ltd\.?))(?:ì˜|ê°€|ì—ì„œ|ì´|ëŠ”)?',
            r'([ê°€-í£]{2,}(?:ì „ì|í™”í•™|ê±´ì„¤|ì œì•½|ë°”ì´ì˜¤|í…Œí¬|ë©”ë””ì»¬))(?:ì˜|ê°€|ì—ì„œ)?',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, query, re.IGNORECASE)
            if match:
                company = match.group(1).strip()
                # ë„ˆë¬´ ì§§ê±°ë‚˜ ì¼ë°˜ ëª…ì‚¬ëŠ” ì œì™¸
                if len(company) >= 3 and company not in ['íŠ¹í—ˆ', 'ì¶œì›', 'ë¶„ì„', 'ê²€ìƒ‰']:
                    logger.debug(f"ğŸ“Œ ì¶œì›ì¸ ì¶”ì¶œ (íŒ¨í„´ ë§¤ì¹­): {company}")
                    return company
        
        # 3. "íšŒì‚¬ëª… + ì—°ë„ + íŠ¹í—ˆ" íŒ¨í„´ (ì˜ˆ: "ì œì´ì‹œìŠ¤ë©”ë””ì»¬ 2024ë…„ ì¶œì› íŠ¹í—ˆ")
        match = re.search(r'([ê°€-í£A-Za-z0-9]+)\s+\d{4}ë…„\s*(?:ì¶œì›|ë“±ë¡|ê³µê°œ)?\s*íŠ¹í—ˆ', query)
        if match:
            company = match.group(1).strip()
            if len(company) >= 2 and company not in ['íŠ¹í—ˆ', 'ì¶œì›', 'ë¶„ì„', 'ê²€ìƒ‰', 'ë…„']:
                logger.debug(f"ğŸ“Œ ì¶œì›ì¸ ì¶”ì¶œ (ì—°ë„+íŠ¹í—ˆ íŒ¨í„´): {company}")
                return company
        
        # 4. ì¿¼ë¦¬ ì‹œì‘ ë¶€ë¶„ì˜ ê³ ìœ ëª…ì‚¬ ì¶”ì¶œ (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
        # "ì œì´ì‹œìŠ¤ë©”ë””ì»¬ íŠ¹í—ˆ ë¶„ì„" â†’ "ì œì´ì‹œìŠ¤ë©”ë””ì»¬"
        words = query.split()
        if words:
            first_word = words[0]
            # ì²« ë‹¨ì–´ê°€ 3ê¸€ì ì´ìƒì´ê³ , ì¼ë°˜ ëª…ì‚¬ê°€ ì•„ë‹ˆë©´ íšŒì‚¬ëª…ìœ¼ë¡œ ì¶”ì •
            if len(first_word) >= 3 and first_word not in ['íŠ¹í—ˆ', 'ì¶œì›', 'ë¶„ì„', 'ê²€ìƒ‰', 'ìµœê·¼', 'ì˜¬í•´', 'ì‘ë…„']:
                # í•œê¸€+ì˜ë¬¸ ì¡°í•©ì´ê±°ë‚˜ íŠ¹ì • ì ‘ë¯¸ì‚¬ê°€ ìˆìœ¼ë©´ íšŒì‚¬ëª… ê°€ëŠ¥ì„± ë†’ìŒ
                if re.match(r'^[ê°€-í£A-Za-z0-9]+$', first_word):
                    logger.debug(f"ğŸ“Œ ì¶œì›ì¸ ì¶”ì¶œ (ì²« ë‹¨ì–´): {first_word}")
                    return first_word
        
        logger.debug(f"âš ï¸ ì¶œì›ì¸ ì¶”ì¶œ ì‹¤íŒ¨: '{query}'")
        return None
    
    def _clean_query(self, query: str, applicant: Optional[str]) -> str:
        """ì¿¼ë¦¬ì—ì„œ íšŒì‚¬ëª…ê³¼ ìš”ì²­ë¬¸ ì œê±°í•˜ì—¬ ê²€ìƒ‰ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ"""
        import re
        
        clean = query
        
        # íšŒì‚¬ëª… ì œê±°
        if applicant:
            clean = clean.replace(applicant, "").strip()
        
        # ìš”ì²­ë¬¸/ëª…ë ¹ì–´ íŒ¨í„´ ì œê±° (ë” í¬ê´„ì )
        request_patterns = [
            r'ë¶„ì„\s*í•´\s*ì£¼\s*ì„¸\s*ìš”', r'ë¶„ì„í•´ì£¼ì„¸ìš”', r'ë¶„ì„í•´ì¤˜',
            r'ê²€ìƒ‰\s*í•´\s*ì£¼\s*ì„¸\s*ìš”', r'ê²€ìƒ‰í•´ì£¼ì„¸ìš”', r'ê²€ìƒ‰í•´ì¤˜',
            r'í•´\s*ì£¼\s*ì„¸\s*ìš”', r'í•´ì£¼ì„¸ìš”', r'í•´\s*ì¤˜',
            r'ì•Œë ¤\s*ì£¼\s*ì„¸\s*ìš”', r'ì•Œë ¤ì£¼ì„¸ìš”', r'ì•Œë ¤\s*ì¤˜',
            r'ì°¾ì•„\s*ì£¼\s*ì„¸\s*ìš”', r'ì°¾ì•„ì£¼ì„¸ìš”', r'ì°¾ì•„\s*ì¤˜',
            r'ì¡°ì‚¬\s*í•´\s*ì£¼\s*ì„¸\s*ìš”', r'ì¡°ì‚¬í•´ì£¼ì„¸ìš”',
            r'ë³´ì—¬\s*ì£¼\s*ì„¸\s*ìš”', r'ë³´ì—¬ì£¼ì„¸ìš”', r'ë³´ì—¬\s*ì¤˜',
            r'í™•ì¸\s*í•´\s*ì£¼\s*ì„¸\s*ìš”', r'í™•ì¸í•´ì£¼ì„¸ìš”',
            r'\?$', r'\.$'
        ]
        for pattern in request_patterns:
            clean = re.sub(pattern, '', clean, flags=re.IGNORECASE)
        
        # "~ì˜", "~ê°€", "~ì—ì„œ" ë“± ì¡°ì‚¬ ì œê±°
        clean = re.sub(r'^[ì˜ê°€ì—ì„œì€ëŠ”ì„ë¥¼ì´]\s*', '', clean)
        clean = re.sub(r'[ì˜ê°€ì—ì„œì€ëŠ”ì„ë¥¼ì´]\s*$', '', clean)
        
        # "íŠ¹í—ˆë¶„ì„", "íŠ¹í—ˆê²€ìƒ‰" ë“± ë©”íƒ€ ë‹¨ì–´ëŠ” ìœ ì§€í•˜ë˜ "íŠ¹í—ˆ" ë‹¨ë…ì€ ì œê±°
        clean = re.sub(r'\s+íŠ¹í—ˆ\s*$', '', clean)
        clean = re.sub(r'^íŠ¹í—ˆ\s+', '', clean)
        
        # "ì¶œì›" í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì—°ë„ ì •ë³´ ì¶”ì¶œ ì‹œë„
        year_match = re.search(r'(\d{4})\s*ë…„', clean)
        year_filter = year_match.group(1) if year_match else None
        
        # ì—°ë„ í‘œí˜„ ì •ë¦¬ ("2024ë…„ ì¶œì›" â†’ "2024"ë§Œ ë‚¨ê¸°ê±°ë‚˜ ì œê±°)
        clean = re.sub(r'\d{4}\s*ë…„\s*(ì¶œì›|ë“±ë¡|ê³µê°œ)?', '', clean)
        
        # ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±° (ë” í¬ê´„ì )
        noise_words = [
            'ì¶œì›', 'ë“±ë¡', 'ê³µê°œ', 'ë¶„ì„', 'ê²€ìƒ‰', 'ê´€ë ¨', 'ëŒ€í•œ', 'ì—ëŒ€í•œ',
            'íŠ¹í—ˆ', 'íŠ¹í—ˆë¶„ì„', 'íŠ¹í—ˆê²€ìƒ‰', 'í˜„í™©', 'ë³´ê³ ì„œ', 'ìë£Œ',
            'ì£¼ì„¸ìš”', 'í•´ì¤˜', 'ì£¼ì„¸', 'í•´ì£¼'
        ]
        for word in noise_words:
            clean = clean.replace(word, ' ')
        
        # ì—°ì† ê³µë°± ì •ë¦¬
        clean = re.sub(r'\s+', ' ', clean).strip()
        
        # ê²°ê³¼ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì›ë³¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
        if not clean or len(clean) < 2:
            # ì›ë³¸ ì¿¼ë¦¬ì—ì„œ ê¸°ìˆ  ê´€ë ¨ ëª…ì‚¬ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´)
            tech_nouns = re.findall(r'[ê°€-í£]{2,}(?:ì „ì|ê¸°ìˆ |ì‹œìŠ¤í…œ|ë°°í„°ë¦¬|ë°˜ë„ì²´|ë””ìŠ¤í”Œë ˆì´|ìë™ì°¨|ë¡œë´‡|AI|ì¸ê³µì§€ëŠ¥)?', query)
            if tech_nouns:
                # íšŒì‚¬ëª…ê³¼ ì¼ë°˜ ë‹¨ì–´ ì œì™¸
                exclude_words = [applicant, 'íŠ¹í—ˆ', 'ì¶œì›', 'ë¶„ì„', 'ê²€ìƒ‰', 'í•´ì£¼ì„¸ìš”', 'ì£¼ì„¸ìš”'] if applicant else ['íŠ¹í—ˆ', 'ì¶œì›', 'ë¶„ì„', 'ê²€ìƒ‰', 'í•´ì£¼ì„¸ìš”', 'ì£¼ì„¸ìš”']
                tech_nouns = [n for n in tech_nouns if n not in exclude_words and len(n) >= 2]
                if tech_nouns:
                    clean = ' '.join(tech_nouns[:3])  # ìƒìœ„ 3ê°œ
        
        # ğŸ†• ì¶œì›ì¸ë§Œ ê²€ìƒ‰í•˜ëŠ” ê²½ìš° (ê¸°ìˆ  í‚¤ì›Œë“œ ì—†ìŒ) - ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        # ì´ë ‡ê²Œ í•˜ë©´ KIPRIS/SerpAPIê°€ ì¶œì›ì¸ ê¸°ë°˜ìœ¼ë¡œë§Œ ê²€ìƒ‰
        noise_check = ['íŠ¹í—ˆ', 'ë¶„ì„', 'ê²€ìƒ‰', 'í˜„í™©', 'ìë£Œ', 'ë³´ê³ ì„œ']
        if not clean or len(clean) < 2 or clean in noise_check or clean == applicant:
            logger.debug(f"ğŸ” ì¶œì›ì¸ë§Œ ê²€ìƒ‰: '{applicant}', ì›ë³¸ ì¿¼ë¦¬: '{query}'")
            return ""
        
        return clean.strip()
    
    # =========================================================================
    # ì‹œê°í™” ìƒì„± ë©”ì„œë“œ
    # =========================================================================
    
    def _generate_search_visualizations(self, patents: List[PatentData]) -> List[VisualizationData]:
        """ê²€ìƒ‰ ê²°ê³¼ ì‹œê°í™” ìƒì„±"""
        visualizations = []
        
        # 1. ì¶œì›ì¸ë³„ íŠ¹í—ˆ ìˆ˜ (íŒŒì´ ì°¨íŠ¸)
        applicant_counts = {}
        for p in patents:
            applicant = p.applicant or "Unknown"
            applicant_counts[applicant] = applicant_counts.get(applicant, 0) + 1
        
        visualizations.append(VisualizationData(
            chart_type="pie",
            title="ì¶œì›ì¸ë³„ íŠ¹í—ˆ ë¶„í¬",
            data={
                "labels": list(applicant_counts.keys()),
                "values": list(applicant_counts.values())
            },
            options={"showLegend": True}
        ))
        
        # 2. ì—°ë„ë³„ ì¶œì› ì¶”ì´ (ë¼ì¸ ì°¨íŠ¸)
        year_counts = {}
        for p in patents:
            if p.application_date:
                year = p.application_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        sorted_years = sorted(year_counts.keys())
        visualizations.append(VisualizationData(
            chart_type="line",
            title="ì—°ë„ë³„ íŠ¹í—ˆ ì¶œì› ì¶”ì´",
            data={
                "labels": sorted_years,
                "datasets": [{
                    "label": "íŠ¹í—ˆ ìˆ˜",
                    "data": [year_counts[y] for y in sorted_years]
                }]
            },
            options={"xAxisLabel": "ë…„ë„", "yAxisLabel": "íŠ¹í—ˆ ìˆ˜"}
        ))
        
        # 3. IPC ë¶„ë¥˜ë³„ ë¶„í¬ (ë°” ì°¨íŠ¸)
        ipc_counts = {}
        for p in patents:
            for ipc in (p.ipc_codes or [])[:1]:  # ì²« ë²ˆì§¸ IPCë§Œ
                main_class = ipc[:4] if len(ipc) >= 4 else ipc
                ipc_counts[main_class] = ipc_counts.get(main_class, 0) + 1
        
        sorted_ipc = sorted(ipc_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        visualizations.append(VisualizationData(
            chart_type="bar",
            title="IPC ë¶„ë¥˜ë³„ íŠ¹í—ˆ ë¶„í¬ (Top 10)",
            data={
                "labels": [x[0] for x in sorted_ipc],
                "datasets": [{
                    "label": "íŠ¹í—ˆ ìˆ˜",
                    "data": [x[1] for x in sorted_ipc]
                }]
            },
            options={"horizontal": True}
        ))
        
        return visualizations
    
    def _generate_comparison_visualizations(
        self,
        our_patents: List[PatentData],
        competitor_patents: List[PatentData],
        our_company: str,
        competitor: str
    ) -> List[VisualizationData]:
        """ê²½ìŸì‚¬ ë¹„êµ ì‹œê°í™” ìƒì„±"""
        visualizations = []
        
        # 1. íŠ¹í—ˆ ìˆ˜ ë¹„êµ (ë°” ì°¨íŠ¸)
        visualizations.append(VisualizationData(
            chart_type="bar",
            title="íŠ¹í—ˆ ìˆ˜ ë¹„êµ",
            data={
                "labels": [our_company, competitor],
                "datasets": [{
                    "label": "íŠ¹í—ˆ ìˆ˜",
                    "data": [len(our_patents), len(competitor_patents)]
                }]
            },
            options={"colors": ["#4CAF50", "#2196F3"]}
        ))
        
        # 2. ì—°ë„ë³„ ë¹„êµ (ê·¸ë£¹ ë°” ì°¨íŠ¸)
        our_years = {}
        comp_years = {}
        
        for p in our_patents:
            if p.application_date:
                year = p.application_date[:4]
                our_years[year] = our_years.get(year, 0) + 1
        
        for p in competitor_patents:
            if p.application_date:
                year = p.application_date[:4]
                comp_years[year] = comp_years.get(year, 0) + 1
        
        all_years = sorted(set(our_years.keys()) | set(comp_years.keys()))
        
        visualizations.append(VisualizationData(
            chart_type="bar",
            title="ì—°ë„ë³„ íŠ¹í—ˆ ì¶œì› ë¹„êµ",
            data={
                "labels": all_years,
                "datasets": [
                    {
                        "label": our_company,
                        "data": [our_years.get(y, 0) for y in all_years]
                    },
                    {
                        "label": competitor,
                        "data": [comp_years.get(y, 0) for y in all_years]
                    }
                ]
            },
            options={"grouped": True}
        ))
        
        # 3. IPC ë¶„ë¥˜ ë¹„êµ (ë ˆì´ë” ì°¨íŠ¸)
        our_ipc = {}
        comp_ipc = {}
        
        for p in our_patents:
            for ipc in (p.ipc_codes or [])[:1]:
                main_class = ipc[:4] if len(ipc) >= 4 else ipc
                our_ipc[main_class] = our_ipc.get(main_class, 0) + 1
        
        for p in competitor_patents:
            for ipc in (p.ipc_codes or [])[:1]:
                main_class = ipc[:4] if len(ipc) >= 4 else ipc
                comp_ipc[main_class] = comp_ipc.get(main_class, 0) + 1
        
        all_ipc = list(set(our_ipc.keys()) | set(comp_ipc.keys()))[:8]
        
        visualizations.append(VisualizationData(
            chart_type="radar",
            title="ê¸°ìˆ  ë¶„ì•¼ë³„ íŠ¹í—ˆ ë¹„êµ",
            data={
                "labels": all_ipc,
                "datasets": [
                    {
                        "label": our_company,
                        "data": [our_ipc.get(ipc, 0) for ipc in all_ipc]
                    },
                    {
                        "label": competitor,
                        "data": [comp_ipc.get(ipc, 0) for ipc in all_ipc]
                    }
                ]
            },
            options={}
        ))
        
        return visualizations
    
    def _generate_trend_visualizations(
        self,
        patents: List[PatentData],
        time_range_years: int
    ) -> List[VisualizationData]:
        """íŠ¸ë Œë“œ ì‹œê°í™” ìƒì„±"""
        visualizations = []
        
        # ì—°ë„ë³„ ì¶œì› ì¶”ì´
        year_counts = {}
        for p in patents:
            if p.application_date:
                year = p.application_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        sorted_years = sorted(year_counts.keys())
        
        visualizations.append(VisualizationData(
            chart_type="line",
            title=f"ìµœê·¼ {time_range_years}ë…„ íŠ¹í—ˆ ì¶œì› íŠ¸ë Œë“œ",
            data={
                "labels": sorted_years,
                "datasets": [{
                    "label": "ì¶œì› ìˆ˜",
                    "data": [year_counts[y] for y in sorted_years],
                    "fill": True
                }]
            },
            options={"xAxisLabel": "ë…„ë„", "yAxisLabel": "ì¶œì› ìˆ˜", "tension": 0.4}
        ))
        
        return visualizations
    
    def _generate_portfolio_visualizations(
        self,
        patents: List[PatentData],
        company: Optional[str]
    ) -> List[VisualizationData]:
        """í¬íŠ¸í´ë¦¬ì˜¤ ì‹œê°í™” ìƒì„±"""
        visualizations = []
        
        # ìƒíƒœë³„ ë¶„í¬
        status_counts = {}
        for p in patents:
            status = p.status.value if p.status else "unknown"
            status_counts[status] = status_counts.get(status, 0) + 1
        
        visualizations.append(VisualizationData(
            chart_type="pie",
            title=f"{company or 'ì „ì²´'} íŠ¹í—ˆ ìƒíƒœ ë¶„í¬",
            data={
                "labels": list(status_counts.keys()),
                "values": list(status_counts.values())
            },
            options={"showLegend": True}
        ))
        
        return visualizations
    
    def _generate_gap_visualizations(
        self,
        our_patents: List[PatentData],
        competitor_patents: List[PatentData],
        our_company: str,
        competitor: str
    ) -> List[VisualizationData]:
        """ê¸°ìˆ  ê³µë°± ì‹œê°í™” ìƒì„±"""
        # ê²½ìŸì‚¬ ë¹„êµì™€ ìœ ì‚¬í•˜ì§€ë§Œ ê³µë°± ê°•ì¡°
        return self._generate_comparison_visualizations(
            our_patents, competitor_patents, our_company, competitor
        )
    
    # =========================================================================
    # ìš”ì•½ ìƒì„± ë©”ì„œë“œ
    # =========================================================================
    
    async def _generate_search_summary(
        self,
        original_query: str,
        patents: List[PatentData],
        applicant: Optional[str],
        year_filter: Optional[str] = None
    ) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ìš”ì•½ ìƒì„±"""
        if not patents:
            no_result_msg = f"'{original_query}' ê²€ìƒ‰ ê²°ê³¼, ê´€ë ¨ íŠ¹í—ˆë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            if applicant:
                no_result_msg += f"\n\n**ì°¸ê³ :** {applicant}ì˜ íŠ¹í—ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë‚˜ ê¸°ê°„ì„ ì‹œë„í•´ ë³´ì„¸ìš”."
            return no_result_msg
        
        # ê¸°ë³¸ ì •ë³´
        summary_parts = []
        
        # í—¤ë”
        if applicant and year_filter:
            summary_parts.append(f"## ğŸ“Š {applicant} {year_filter}ë…„ íŠ¹í—ˆ ë¶„ì„ ê²°ê³¼\n")
        elif applicant:
            summary_parts.append(f"## ğŸ“Š {applicant} íŠ¹í—ˆ ë¶„ì„ ê²°ê³¼\n")
        else:
            summary_parts.append(f"## ğŸ“Š íŠ¹í—ˆ ê²€ìƒ‰ ê²°ê³¼\n")
        
        # ê²€ìƒ‰ ê°œìš”
        summary_parts.append(f"### ğŸ“‹ ê²€ìƒ‰ ê°œìš”")
        summary_parts.append(f"- **ì´ ê²€ìƒ‰ ê²°ê³¼:** {len(patents)}ê±´")
        if applicant:
            summary_parts.append(f"- **ì¶œì›ì¸:** {applicant}")
        if year_filter:
            summary_parts.append(f"- **ë¶„ì„ ê¸°ê°„:** {year_filter}ë…„")
        summary_parts.append("")
        
        # ì—°ë„ë³„ ë¶„í¬ ë¶„ì„
        year_counts = {}
        for p in patents:
            if p.application_date:
                year = p.application_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        if year_counts:
            summary_parts.append(f"### ğŸ“… ì—°ë„ë³„ ì¶œì› í˜„í™©")
            sorted_years = sorted(year_counts.items(), key=lambda x: x[0], reverse=True)
            for year, count in sorted_years[:5]:
                bar = "â–ˆ" * min(count, 20)
                summary_parts.append(f"- **{year}ë…„:** {count}ê±´ {bar}")
            summary_parts.append("")
        
        # ê¸°ìˆ  ë¶„ë¥˜ (IPC) ë¶„ì„
        ipc_counts = {}
        for p in patents:
            if p.ipc_codes:
                for ipc in p.ipc_codes[:2]:  # ìƒìœ„ 2ê°œ IPCë§Œ
                    main_ipc = ipc[:4] if len(ipc) >= 4 else ipc
                    ipc_counts[main_ipc] = ipc_counts.get(main_ipc, 0) + 1
        
        if ipc_counts:
            summary_parts.append(f"### ğŸ”¬ ì£¼ìš” ê¸°ìˆ  ë¶„ë¥˜ (IPC)")
            ipc_descriptions = self._get_ipc_descriptions()
            sorted_ipc = sorted(ipc_counts.items(), key=lambda x: x[1], reverse=True)[:5]
            for ipc, count in sorted_ipc:
                desc = ipc_descriptions.get(ipc[:3], ipc_descriptions.get(ipc[:1], "ê¸°íƒ€"))
                summary_parts.append(f"- **{ipc}** ({desc}): {count}ê±´")
            summary_parts.append("")
        
        # ëŒ€í‘œ íŠ¹í—ˆ ëª©ë¡
        summary_parts.append(f"### ğŸ“„ ì£¼ìš” íŠ¹í—ˆ ({min(5, len(patents))}ê±´)")
        for i, p in enumerate(patents[:5], 1):
            title = p.title[:60] + "..." if len(p.title) > 60 else p.title
            date_info = f", ì¶œì›ì¼: {p.application_date}" if p.application_date else ""
            status = f" [{p.status}]" if p.status else ""
            summary_parts.append(f"{i}. **{title}**{status}")
            summary_parts.append(f"   - ì¶œì›ë²ˆí˜¸: {p.patent_number}{date_info}")
        summary_parts.append("")
        
        # ë¶„ì„ ìš”ì•½
        summary_parts.append(f"### ğŸ’¡ ë¶„ì„ ìš”ì•½")
        
        # ì¶œì› íŠ¸ë Œë“œ ë¶„ì„
        if len(year_counts) >= 2:
            years = sorted(year_counts.keys())
            recent_years = years[-2:]
            if len(recent_years) == 2:
                older, newer = recent_years
                older_count = year_counts.get(older, 0)
                newer_count = year_counts.get(newer, 0)
                if newer_count > older_count:
                    growth = ((newer_count - older_count) / max(older_count, 1)) * 100
                    summary_parts.append(f"- ğŸ“ˆ **ì¶œì› ì¦ê°€ ì¶”ì„¸**: {older}ë…„ ëŒ€ë¹„ {newer}ë…„ {growth:.0f}% ì¦ê°€")
                elif newer_count < older_count:
                    decline = ((older_count - newer_count) / max(older_count, 1)) * 100
                    summary_parts.append(f"- ğŸ“‰ **ì¶œì› ê°ì†Œ ì¶”ì„¸**: {older}ë…„ ëŒ€ë¹„ {newer}ë…„ {decline:.0f}% ê°ì†Œ")
                else:
                    summary_parts.append(f"- â¡ï¸ **ì¶œì› ìœ ì§€**: ì•ˆì •ì ì¸ íŠ¹í—ˆ ì¶œì› í™œë™")
        
        # ê¸°ìˆ  ì§‘ì¤‘ë„
        if ipc_counts:
            top_ipc = sorted(ipc_counts.items(), key=lambda x: x[1], reverse=True)[0]
            concentration = (top_ipc[1] / len(patents)) * 100
            if concentration > 50:
                summary_parts.append(f"- ğŸ¯ **ê¸°ìˆ  ì§‘ì¤‘ë„ ë†’ìŒ**: {top_ipc[0]} ë¶„ì•¼ì— {concentration:.0f}% ì§‘ì¤‘")
            else:
                summary_parts.append(f"- ğŸŒ **ê¸°ìˆ  ë‹¤ê°í™”**: ë‹¤ì–‘í•œ ê¸°ìˆ  ë¶„ì•¼ì— ë¶„ì‚° ì¶œì›")
        
        # ê¸°ë³¸ ìš”ì•½ ìƒì„±
        base_summary = "\n".join(summary_parts)
        
        # ğŸ†• LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ ì¶”ê°€
        try:
            llm_analysis = await self._generate_llm_analysis(
                original_query=original_query,
                patents=patents,
                applicant=applicant,
                year_filter=year_filter,
                year_counts=year_counts,
                ipc_counts=ipc_counts
            )
            if llm_analysis:
                base_summary += f"\n\n{llm_analysis}"
        except Exception as e:
            logger.warning(f"âš ï¸ LLM ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {e}")
        
        return base_summary
    
    async def _generate_llm_analysis(
        self,
        original_query: str,
        patents: List[PatentData],
        applicant: Optional[str],
        year_filter: Optional[str],
        year_counts: Dict[str, int],
        ipc_counts: Dict[str, int]
    ) -> Optional[str]:
        """LLMì„ ì‚¬ìš©í•œ ì‹¬ì¸µ ë¶„ì„ ìƒì„±"""
        if not patents or len(patents) < 3:
            return None
        
        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë”©
            system_prompt = load_patent_analysis_prompt()
            
            # íŠ¹í—ˆ ë°ì´í„° ìš”ì•½ (LLM ì…ë ¥ìš©)
            patent_summary = self._prepare_patents_for_llm(patents[:10])  # ìƒìœ„ 10ê±´ë§Œ
            
            # ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = f"""
## ë¶„ì„ ìš”ì²­
{original_query}

## íŠ¹í—ˆ ë°ì´í„° ìš”ì•½
- ì´ íŠ¹í—ˆ ìˆ˜: {len(patents)}ê±´
- ì¶œì›ì¸: {applicant or 'ì „ì²´'}
- ë¶„ì„ ê¸°ê°„: {year_filter or 'ì „ì²´ ê¸°ê°„'}

## ì—°ë„ë³„ ì¶œì› í˜„í™©
{self._format_year_counts(year_counts)}

## ê¸°ìˆ  ë¶„ë¥˜ (IPC) ë¶„í¬
{self._format_ipc_counts(ipc_counts)}

## ì£¼ìš” íŠ¹í—ˆ ëª©ë¡
{patent_summary}

ìœ„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì œê³µí•´ ì£¼ì„¸ìš”:
1. ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„ (2-3ë¬¸ì¥)
2. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (3ê°œ)
3. ì „ëµì  ê¶Œê³  (2-3ê°œ)
"""
            
            # LLM í˜¸ì¶œ
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": context}
            ]
            
            response = await ai_service.chat_completion(
                messages=messages,
                max_tokens=1500,
                temperature=0.7
            )
            
            if response and response.get("response"):
                return f"### ğŸ¤– AI ì‹¬ì¸µ ë¶„ì„\n\n{response['response']}"
            
        except Exception as e:
            logger.error(f"âŒ LLM ë¶„ì„ ì˜¤ë¥˜: {e}")
        
        return None
    
    def _prepare_patents_for_llm(self, patents: List[PatentData]) -> str:
        """LLM ì…ë ¥ìš© íŠ¹í—ˆ ë°ì´í„° í¬ë§·íŒ…"""
        lines = []
        for i, p in enumerate(patents, 1):
            title = p.title[:80] if p.title else "ì œëª© ì—†ìŒ"
            applicant = p.applicant or "ì¶œì›ì¸ ë¯¸ìƒ"
            date = p.application_date or "ë‚ ì§œ ë¯¸ìƒ"
            ipc = ", ".join(p.ipc_codes[:2]) if p.ipc_codes else "ë¶„ë¥˜ ë¯¸ìƒ"
            abstract = (p.abstract[:150] + "...") if p.abstract and len(p.abstract) > 150 else (p.abstract or "")
            
            lines.append(f"{i}. **{title}**")
            lines.append(f"   - ì¶œì›ì¸: {applicant}, ì¶œì›ì¼: {date}")
            lines.append(f"   - IPC: {ipc}")
            if abstract:
                lines.append(f"   - ìš”ì•½: {abstract}")
        
        return "\n".join(lines)
    
    def _format_year_counts(self, year_counts: Dict[str, int]) -> str:
        """ì—°ë„ë³„ ì¶œì› ìˆ˜ í¬ë§·íŒ…"""
        if not year_counts:
            return "ë°ì´í„° ì—†ìŒ"
        
        sorted_years = sorted(year_counts.items(), key=lambda x: x[0], reverse=True)
        return "\n".join([f"- {year}ë…„: {count}ê±´" for year, count in sorted_years[:5]])
    
    def _format_ipc_counts(self, ipc_counts: Dict[str, int]) -> str:
        """IPC ë¶„í¬ í¬ë§·íŒ…"""
        if not ipc_counts:
            return "ë°ì´í„° ì—†ìŒ"
        
        ipc_desc = self._get_ipc_descriptions()
        sorted_ipc = sorted(ipc_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        lines = []
        for ipc, count in sorted_ipc:
            desc = ipc_desc.get(ipc[:3], ipc_desc.get(ipc[:1], "ê¸°íƒ€"))
            lines.append(f"- {ipc} ({desc}): {count}ê±´")
        return "\n".join(lines)
    
    def _get_ipc_descriptions(self) -> Dict[str, str]:
        """IPC ì½”ë“œ ì„¤ëª…"""
        return {
            "A": "ìƒí™œí•„ìˆ˜í’ˆ",
            "B": "ì²˜ë¦¬ì¡°ì‘/ìš´ìˆ˜",
            "C": "í™”í•™/ì•¼ê¸ˆ",
            "D": "ì„¬ìœ /ì œì§€",
            "E": "ê³ ì •êµ¬ì¡°ë¬¼",
            "F": "ê¸°ê³„ê³µí•™/ì¡°ëª…/ê°€ì—´",
            "G": "ë¬¼ë¦¬í•™",
            "H": "ì „ê¸°",
            "G01": "ì¸¡ì •/ì‹œí—˜",
            "G02": "ê´‘í•™",
            "G06": "ì»´í“¨íŒ…/ê³„ì‚°",
            "G09": "êµìœ¡/ì•”í˜¸",
            "H01": "ì „ê¸°ì†Œì",
            "H02": "ì „ë ¥ìƒì‚°/ë³€í™˜",
            "H04": "ì „ê¸°í†µì‹ ",
            "H05": "ì „ê¸°ê¸°ìˆ ",
            "B60": "ì°¨ëŸ‰ì¼ë°˜",
            "B62": "ë¬´ê¶¤ë„ì°¨ëŸ‰",
            "C07": "ìœ ê¸°í™”í•™",
            "C08": "ìœ ê¸°ê³ ë¶„ìí™”í•©ë¬¼",
            "F16": "ê¸°ê³„ìš”ì†Œ",
        }
    
    async def _generate_comparison_summary(
        self,
        query: str,
        our_company: str,
        competitor: str,
        our_patents: List[PatentData],
        competitor_patents: List[PatentData],
        analysis_result: Any
    ) -> str:
        """ê²½ìŸì‚¬ ë¹„êµ ìš”ì•½ ìƒì„±"""
        summary = f"**'{query}' ê´€ë ¨ íŠ¹í—ˆ ë¹„êµ ë¶„ì„**\n\n"
        summary += f"| êµ¬ë¶„ | {our_company} | {competitor} |\n"
        summary += f"|------|--------|--------|\n"
        summary += f"| íŠ¹í—ˆ ìˆ˜ | {len(our_patents)}ê±´ | {len(competitor_patents)}ê±´ |\n"
        
        # ì°¨ì´ ë¶„ì„
        diff = len(our_patents) - len(competitor_patents)
        if diff > 0:
            summary += f"\nâœ… **{our_company}**ê°€ {abs(diff)}ê±´ ë” ë§ì€ íŠ¹í—ˆë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
        elif diff < 0:
            summary += f"\nâš ï¸ **{competitor}**ê°€ {abs(diff)}ê±´ ë” ë§ì€ íŠ¹í—ˆë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
        else:
            summary += f"\nğŸ”„ ì–‘ì‚¬ì˜ íŠ¹í—ˆ ìˆ˜ê°€ ë™ì¼í•©ë‹ˆë‹¤.\n"
        
        return summary
    
    async def _generate_trend_summary(
        self,
        query: str,
        patents: List[PatentData],
        time_range_years: int,
        analysis_result: Any
    ) -> str:
        """íŠ¸ë Œë“œ ë¶„ì„ ìš”ì•½ ìƒì„±"""
        summary = f"**'{query}' ìµœê·¼ {time_range_years}ë…„ íŠ¹í—ˆ íŠ¸ë Œë“œ**\n\n"
        summary += f"- ë¶„ì„ ëŒ€ìƒ: **{len(patents)}ê±´**\n"
        
        # ì—°ë„ë³„ í†µê³„
        year_counts = {}
        for p in patents:
            if p.application_date:
                year = p.application_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        if year_counts:
            max_year = max(year_counts.items(), key=lambda x: x[1])
            min_year = min(year_counts.items(), key=lambda x: x[1])
            summary += f"- ìµœë‹¤ ì¶œì› ì—°ë„: {max_year[0]} ({max_year[1]}ê±´)\n"
            summary += f"- ìµœì†Œ ì¶œì› ì—°ë„: {min_year[0]} ({min_year[1]}ê±´)\n"
            
            # íŠ¸ë Œë“œ ë°©í–¥
            years = sorted(year_counts.keys())
            if len(years) >= 2:
                recent = year_counts.get(years[-1], 0)
                older = year_counts.get(years[-2], 0)
                if recent > older:
                    summary += f"\nğŸ“ˆ ì¶œì› íŠ¸ë Œë“œ: **ìƒìŠ¹ì„¸** (ì „ë…„ ëŒ€ë¹„ +{recent - older}ê±´)\n"
                elif recent < older:
                    summary += f"\nğŸ“‰ ì¶œì› íŠ¸ë Œë“œ: **í•˜ë½ì„¸** (ì „ë…„ ëŒ€ë¹„ {recent - older}ê±´)\n"
                else:
                    summary += f"\nâ¡ï¸ ì¶œì› íŠ¸ë Œë“œ: **ìœ ì§€**\n"
        
        return summary
    
    async def _generate_portfolio_summary(
        self,
        query: str,
        company: Optional[str],
        patents: List[PatentData],
        portfolio_result: Any,
        topic_result: Any
    ) -> str:
        """í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ìš”ì•½ ìƒì„±"""
        summary = f"**{company or 'ì „ì²´'} íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„**\n\n"
        summary += f"- ì´ íŠ¹í—ˆ: **{len(patents)}ê±´**\n"
        
        # ìƒíƒœë³„ ë¶„í¬
        status_counts = {}
        for p in patents:
            status = p.status.value if p.status else "unknown"
            status_counts[status] = status_counts.get(status, 0) + 1
        
        summary += f"- ë“±ë¡ íŠ¹í—ˆ: {status_counts.get('granted', 0)}ê±´\n"
        summary += f"- ì¶œì› ì¤‘: {status_counts.get('application', 0)}ê±´\n"
        summary += f"- ê³µê°œ: {status_counts.get('published', 0)}ê±´\n"
        
        return summary
    
    async def _generate_gap_summary(
        self,
        query: str,
        our_company: str,
        competitor: str,
        analysis_result: Any
    ) -> str:
        """ê¸°ìˆ  ê³µë°± ë¶„ì„ ìš”ì•½ ìƒì„±"""
        summary = f"**'{query}' ê¸°ìˆ  ê³µë°± ë¶„ì„**\n\n"
        summary += f"- ë¹„êµ ëŒ€ìƒ: **{our_company}** vs **{competitor}**\n\n"
        
        if hasattr(analysis_result, 'data') and analysis_result.data:
            gaps = analysis_result.data.get('gaps', [])
            if gaps:
                summary += "**ìš°ë¦¬ê°€ ë³´ì™„í•´ì•¼ í•  ê¸°ìˆ  ë¶„ì•¼:**\n"
                for gap in gaps[:5]:
                    summary += f"- {gap.get('area', 'N/A')}: {gap.get('description', '')}\n"
        
        return summary
    
    # =========================================================================
    # ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ë©”ì„œë“œ
    # =========================================================================
    
    def _extract_search_insights(self, patents: List[PatentData], applicant: Optional[str] = None) -> List[str]:
        """ê²€ìƒ‰ ê²°ê³¼ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        if not patents:
            return ["ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë‚˜ ê¸°ê°„ì„ ì‹œë„í•´ ë³´ì„¸ìš”."]
        
        # 1. ì¶œì› í™œë™ ë¶„ì„
        year_counts = {}
        for p in patents:
            if p.application_date:
                year = p.application_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        if year_counts:
            sorted_years = sorted(year_counts.keys())
            if len(sorted_years) >= 2:
                recent = sorted_years[-1]
                prev = sorted_years[-2]
                recent_count = year_counts[recent]
                prev_count = year_counts[prev]
                
                if recent_count > prev_count * 1.2:
                    insights.append(f"ğŸ“ˆ {recent}ë…„ ì¶œì›ì´ ì „ë…„ ëŒ€ë¹„ ì¦ê°€í•˜ì—¬ R&D í™œë™ì´ í™œë°œí•´ì§€ê³  ìˆìŠµë‹ˆë‹¤.")
                elif recent_count < prev_count * 0.8:
                    insights.append(f"ğŸ“‰ {recent}ë…„ ì¶œì›ì´ ì „ë…„ ëŒ€ë¹„ ê°ì†Œí•˜ì—¬ í•´ë‹¹ ë¶„ì•¼ íˆ¬ìê°€ ì¤„ì–´ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # 2. ê¸°ìˆ  ì§‘ì¤‘ë„ ë¶„ì„
        ipc_counts = {}
        for p in patents:
            if p.ipc_codes:
                for ipc in p.ipc_codes[:1]:
                    main_ipc = ipc[:4] if len(ipc) >= 4 else ipc
                    ipc_counts[main_ipc] = ipc_counts.get(main_ipc, 0) + 1
        
        if ipc_counts:
            top_ipc = max(ipc_counts.items(), key=lambda x: x[1])
            concentration = (top_ipc[1] / len(patents)) * 100
            ipc_desc = self._get_ipc_descriptions()
            desc = ipc_desc.get(top_ipc[0][:3], ipc_desc.get(top_ipc[0][:1], "ê¸°ìˆ "))
            
            if concentration > 50:
                insights.append(f"ğŸ¯ {desc} ë¶„ì•¼({top_ipc[0]})ì— {concentration:.0f}%ê°€ ì§‘ì¤‘ë˜ì–´ í•µì‹¬ ê¸°ìˆ  ì˜ì—­ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.")
            elif concentration > 30:
                insights.append(f"âš¡ {desc} ë¶„ì•¼({top_ipc[0]})ê°€ ì£¼ë ¥ì´ë‚˜, ë‹¤ë¥¸ ê¸°ìˆ  ë¶„ì•¼ë¡œë„ í™•ì¥ ì¤‘ì…ë‹ˆë‹¤.")
        
        # 3. ìµœê·¼ íŠ¹í—ˆ ë™í–¥
        current_year = str(datetime.now().year)
        recent_patents = [p for p in patents if p.application_date and p.application_date[:4] >= str(int(current_year) - 1)]
        if recent_patents:
            insights.append(f"ğŸ”¥ ìµœê·¼ 2ë…„ ë‚´ {len(recent_patents)}ê±´ì˜ í™œë°œí•œ ì¶œì›ìœ¼ë¡œ ì§€ì†ì ì¸ ê¸°ìˆ  ê°œë°œì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.")
        
        # 4. ì¶œì›ì¸ ë¶„ì„ (íŠ¹ì • ì¶œì›ì¸ ê²€ìƒ‰ì´ ì•„ë‹Œ ê²½ìš°)
        if not applicant:
            applicant_counts = {}
            for p in patents:
                app = p.applicant or "Unknown"
                applicant_counts[app] = applicant_counts.get(app, 0) + 1
            
            if applicant_counts:
                top_app = max(applicant_counts.items(), key=lambda x: x[1])
                if top_app[1] > len(patents) * 0.3:
                    insights.append(f"ğŸ‘‘ {top_app[0]}ì´(ê°€) í•´ë‹¹ ë¶„ì•¼ì—ì„œ {top_app[1]}ê±´({top_app[1]/len(patents)*100:.0f}%)ìœ¼ë¡œ ì„ ë„ì  ìœ„ì¹˜ì…ë‹ˆë‹¤.")
        
        # 5. íŠ¹í—ˆ ìƒíƒœ ë¶„ì„
        status_counts = {}
        for p in patents:
            status = p.status or "Unknown"
            status_counts[status] = status_counts.get(status, 0) + 1
        
        if "ë“±ë¡" in status_counts:
            registered = status_counts["ë“±ë¡"]
            if registered > len(patents) * 0.5:
                insights.append(f"âœ… ë“±ë¡ íŠ¹í—ˆê°€ {registered}ê±´({registered/len(patents)*100:.0f}%)ìœ¼ë¡œ ê¸°ìˆ ë ¥ì´ ì¸ì •ë°›ê³  ìˆìŠµë‹ˆë‹¤.")
        
        if "ê³µê°œ" in status_counts:
            published = status_counts["ê³µê°œ"]
            if published > len(patents) * 0.3:
                insights.append(f"ğŸ“ ê³µê°œ íŠ¹í—ˆê°€ {published}ê±´ìœ¼ë¡œ í–¥í›„ ë“±ë¡ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ê¸°ìˆ ë“¤ì´ ë§ìŠµë‹ˆë‹¤.")
        
        # ì¸ì‚¬ì´íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë©”ì‹œì§€
        if not insights:
            insights.append(f"ğŸ“Š ì´ {len(patents)}ê±´ì˜ íŠ¹í—ˆê°€ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„¸ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        return insights
    
    def _extract_comparison_insights(
        self,
        our_patents: List[PatentData],
        competitor_patents: List[PatentData],
        our_company: str,
        competitor: str
    ) -> List[str]:
        """ê²½ìŸì‚¬ ë¹„êµ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        # ì–‘ì  ë¹„êµ
        if len(our_patents) > len(competitor_patents) * 1.5:
            insights.append(f"{our_company}ê°€ ì–‘ì ìœ¼ë¡œ ìš°ìœ„ (1.5ë°° ì´ìƒ)")
        elif len(competitor_patents) > len(our_patents) * 1.5:
            insights.append(f"{competitor}ê°€ ì–‘ì ìœ¼ë¡œ ìš°ìœ„ - íŠ¹í—ˆ í™•ë³´ ì „ëµ ê²€í†  í•„ìš”")
        
        # IPC ë‹¤ì–‘ì„±
        our_ipc = set()
        comp_ipc = set()
        for p in our_patents:
            our_ipc.update(p.ipc_codes or [])
        for p in competitor_patents:
            comp_ipc.update(p.ipc_codes or [])
        
        if len(our_ipc) > len(comp_ipc) * 1.3:
            insights.append(f"{our_company}ê°€ ë” ë‹¤ì–‘í•œ ê¸°ìˆ  ë¶„ì•¼ì— ì§„ì¶œ")
        elif len(comp_ipc) > len(our_ipc) * 1.3:
            insights.append(f"{competitor}ê°€ ë” ë‹¤ì–‘í•œ ê¸°ìˆ  ë¶„ì•¼ ë³´ìœ  - ê¸°ìˆ  ë‹¤ê°í™” ê²€í†  í•„ìš”")
        
        return insights
    
    def _extract_trend_insights(
        self,
        patents: List[PatentData],
        time_range_years: int
    ) -> List[str]:
        """íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        year_counts = {}
        for p in patents:
            if p.application_date:
                year = p.application_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        if year_counts:
            years = sorted(year_counts.keys())
            if len(years) >= 3:
                recent_avg = sum(year_counts.get(y, 0) for y in years[-2:]) / 2
                older_avg = sum(year_counts.get(y, 0) for y in years[:-2]) / max(len(years) - 2, 1)
                
                if recent_avg > older_avg * 1.5:
                    insights.append("ìµœê·¼ 2ë…„ê°„ ì¶œì›ì´ ê¸‰ì¦ - í•´ë‹¹ ë¶„ì•¼ ê¸°ìˆ  ê²½ìŸ ì‹¬í™”")
                elif recent_avg < older_avg * 0.5:
                    insights.append("ìµœê·¼ ì¶œì› ê°ì†Œ - ê¸°ìˆ  ì„±ìˆ™ê¸° ë˜ëŠ” ì‹œì¥ ì¹¨ì²´ ê°€ëŠ¥ì„±")
        
        return insights
    
    def _extract_portfolio_insights(
        self,
        patents: List[PatentData],
        company: Optional[str]
    ) -> List[str]:
        """í¬íŠ¸í´ë¦¬ì˜¤ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        # ë“±ë¡ë¥ 
        granted = sum(1 for p in patents if p.status == PatentStatus.GRANTED)
        if patents:
            grant_rate = granted / len(patents) * 100
            if grant_rate > 70:
                insights.append(f"ë†’ì€ ë“±ë¡ë¥  ({grant_rate:.0f}%) - ìš°ìˆ˜í•œ íŠ¹í—ˆ í’ˆì§ˆ")
            elif grant_rate < 30:
                insights.append(f"ë‚®ì€ ë“±ë¡ë¥  ({grant_rate:.0f}%) - íŠ¹í—ˆ ì „ëµ ì¬ê²€í†  í•„ìš”")
        
        return insights
    
    def _extract_gap_insights(self, analysis_result: Any) -> List[str]:
        """ê¸°ìˆ  ê³µë°± ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        if hasattr(analysis_result, 'data') and analysis_result.data:
            gaps = analysis_result.data.get('gaps', [])
            if gaps:
                insights.append(f"ì´ {len(gaps)}ê°œ ê¸°ìˆ  ë¶„ì•¼ì—ì„œ ê³µë°± ë°œê²¬")
        
        return insights
    
    def _generate_comparison_recommendations(self, analysis_result: Any) -> List[str]:
        """ê²½ìŸì‚¬ ë¹„êµ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        recommendations.append("ê²½ìŸì‚¬ í•µì‹¬ íŠ¹í—ˆì— ëŒ€í•œ íšŒí”¼ ì„¤ê³„ ê²€í† ")
        recommendations.append("íŠ¹í—ˆ ì¸ìš© ë„¤íŠ¸ì›Œí¬ ë¶„ì„ì„ í†µí•œ í•µì‹¬ ê¸°ìˆ  íŒŒì•…")
        return recommendations
    
    def _generate_gap_recommendations(self, analysis_result: Any) -> List[str]:
        """ê¸°ìˆ  ê³µë°± ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        recommendations.append("ì‹ë³„ëœ ê¸°ìˆ  ê³µë°± ë¶„ì•¼ì— ëŒ€í•œ R&D íˆ¬ì ê²€í† ")
        recommendations.append("ê¸°ìˆ  ë¼ì´ì„ ì‹± ë˜ëŠ” M&Aë¥¼ í†µí•œ ë¹ ë¥¸ ê¸°ìˆ  í™•ë³´ ê³ ë ¤")
        return recommendations


# =============================================================================
# Singleton Instance
# =============================================================================

patent_analysis_agent_tool = PatentAnalysisAgentTool()


__all__ = ["PatentAnalysisAgentTool", "patent_analysis_agent_tool"]
