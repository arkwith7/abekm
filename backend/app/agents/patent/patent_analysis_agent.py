"""
Patent Analysis Agent - νΉν— λ¶„μ„ μ „λ¬Έ μ—μ΄μ „νΈ

μ—”ν„°ν”„λΌμ΄μ¦ κ²½μ μΈν…”λ¦¬μ „μ¤λ¥Ό μ„ν• νΉν— λ°μ΄ν„° κ²€μƒ‰, λ¶„μ„, μ‹κ°ν™”

μ£Όμ” κΈ°λ¥:
1. νΉν— κ²€μƒ‰ (KIPRIS, Google Patents via SerpAPI)
2. κ²½μμ‚¬ νΉν— λΉ„κµ λ¶„μ„
3. κΈ°μ  νΈλ λ“ λ¶„μ„ (μ‹κ³„μ—΄)
4. νΉν— ν¬νΈν΄λ¦¬μ¤ λ¶„μ„
5. κΈ°μ  κ³µλ°±(White Space) λ¶„μ„
6. μ‹κ°ν™” λ°μ΄ν„° μƒμ„± (μ°¨νΈ, κ·Έλν”„)
7. LLM κΈ°λ° μ‹¬μΈµ λ¶„μ„ λ° μΈμ‚¬μ΄νΈ μƒμ„±
"""
from __future__ import annotations

import asyncio
import os
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Type

from loguru import logger
from pydantic import BaseModel, Field, PrivateAttr

try:
    from langchain_core.tools import BaseTool
except ImportError:
    from langchain.tools import BaseTool

from app.tools.retrieval.patent_search_tool import (
    PatentSearchTool, 
    PatentData,
    PatentSearchResult,
    PatentJurisdiction,
    PatentStatus
)
from app.tools.retrieval.patent_functional_tools import (
    PatentDiscoveryTool,
    PatentDetailTool,
    PatentLegalTool
)
from app.tools.retrieval.patent_analysis_tool import (
    PatentAnalysisTool,
    PatentAnalysisType,
    PatentAnalysisResult
)
from app.services.core.ai_service import ai_service


# =============================================================================
# μ‹μ¤ν… ν”„λ΅¬ν”„νΈ λ΅λ”©
# =============================================================================

def load_patent_analysis_prompt() -> str:
    """νΉν— λ¶„μ„ μ‹μ¤ν… ν”„λ΅¬ν”„νΈ λ΅λ”©"""
    prompt_path = Path(__file__).parent.parent.parent.parent / "prompts" / "patent-analysis.prompt"
    
    if prompt_path.exists():
        with open(prompt_path, "r", encoding="utf-8") as f:
            return f.read()
    else:
        logger.warning(f"β οΈ νΉν— λ¶„μ„ ν”„λ΅¬ν”„νΈ νμΌμ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤: {prompt_path}")
        return DEFAULT_PATENT_ANALYSIS_PROMPT


DEFAULT_PATENT_ANALYSIS_PROMPT = """λ‹Ήμ‹ μ€ νΉν— λ¶„μ„ μ „λ¬Έκ°€μ…λ‹λ‹¤. 
μ κ³µλ νΉν— λ°μ΄ν„°λ¥Ό λ¶„μ„ν•μ—¬ κΈ°μ  νΈλ λ“, κ²½μλ ¥ λ¶„μ„, μ‹μ¥ μΈμ‚¬μ΄νΈ, μ „λµμ  κ¶κ³ λ¥Ό μ κ³µν•©λ‹λ‹¤.
λ¶„μ„μ€ ν•κµ­μ–΄λ΅ μ‘μ„±ν•κ³ , λΉ„μ „λ¬Έκ°€λ„ μ΄ν•΄ν•  μ μλ„λ΅ μ„¤λ…ν•΄ μ£Όμ„Έμ”."""


# =============================================================================
# Input/Output Models
# =============================================================================

class PatentAnalysisAgentInput(BaseModel):
    """νΉν— λ¶„μ„ μ—μ΄μ „νΈ μ…λ ¥ μ¤ν‚¤λ§"""
    
    query: str = Field(
        ..., 
        description="κ²€μƒ‰ μΏΌλ¦¬ λλ” λ¶„μ„ μ”μ²­ (μ: 'μ‚Όμ„±μ „μ AI λ°λ„μ²΄ νΉν—')"
    )
    analysis_type: str = Field(
        default="search",
        description="λ¶„μ„ μ ν•: search(κ²€μƒ‰), comparison(κ²½μμ‚¬λΉ„κµ), trend(νΈλ λ“), portfolio(ν¬νΈν΄λ¦¬μ¤), gap(κΈ°μ κ³µλ°±)"
    )
    our_company: Optional[str] = Field(
        default=None,
        description="μ°λ¦¬ νμ‚¬λ… (κ²½μμ‚¬ λΉ„κµ μ‹ ν•„μ)"
    )
    competitor: Optional[str] = Field(
        default=None,
        description="κ²½μμ‚¬λ… (κ²½μμ‚¬ λΉ„κµ μ‹ ν•„μ)"
    )
    jurisdiction: str = Field(
        default="KR",
        description="κ΄€ν• κ¶: KR(ν•κµ­), US(λ―Έκµ­), EP(μ λ½), ALL(μ „μ²΄)"
    )
    date_from: Optional[str] = Field(
        default=None,
        description="μ¶μ›μΌ μ‹μ‘ (YYYY-MM-DD)"
    )
    date_to: Optional[str] = Field(
        default=None,
        description="μ¶μ›μΌ μΆ…λ£ (YYYY-MM-DD)"
    )
    ipc_codes: Optional[List[str]] = Field(
        default=None,
        description="IPC λ¶„λ¥ μ½”λ“ ν•„ν„° (μ: ['G06N', 'H01L'])"
    )
    max_results: int = Field(
        default=50,
        description="μµλ€ κ²€μƒ‰ κ²°κ³Ό μ"
    )
    include_visualization: bool = Field(
        default=True,
        description="μ‹κ°ν™” λ°μ΄ν„° ν¬ν•¨ μ—¬λ¶€"
    )
    time_range_years: int = Field(
        default=5,
        description="νΈλ λ“ λ¶„μ„ μ‹ κΈ°κ°„ (λ…„)"
    )


class VisualizationData(BaseModel):
    """μ‹κ°ν™” λ°μ΄ν„° λ¨λΈ"""
    
    chart_type: str = Field(description="μ°¨νΈ μ ν•: bar, line, pie, radar, timeline, network")
    title: str = Field(description="μ°¨νΈ μ λ©")
    data: Dict[str, Any] = Field(description="μ°¨νΈ λ°μ΄ν„°")
    options: Dict[str, Any] = Field(default_factory=dict, description="μ°¨νΈ μµμ…")


class PatentAnalysisAgentOutput(BaseModel):
    """νΉν— λ¶„μ„ μ—μ΄μ „νΈ μ¶λ ¥"""
    
    success: bool = Field(description="μ„±κ³µ μ—¬λ¶€")
    analysis_type: str = Field(description="μν–‰λ λ¶„μ„ μ ν•")
    summary: str = Field(description="λ¶„μ„ κ²°κ³Ό μ”μ•½ (μμ—°μ–΄)")
    patents: List[Dict[str, Any]] = Field(default_factory=list, description="κ²€μƒ‰λ νΉν— λ©λ΅")
    total_patents: int = Field(default=0, description="μ΄ νΉν— μ")
    analysis_result: Optional[Dict[str, Any]] = Field(default=None, description="μƒμ„Έ λ¶„μ„ κ²°κ³Ό")
    visualizations: List[VisualizationData] = Field(default_factory=list, description="μ‹κ°ν™” λ°μ΄ν„°")
    insights: List[str] = Field(default_factory=list, description="ν•µμ‹¬ μΈμ‚¬μ΄νΈ")
    recommendations: List[str] = Field(default_factory=list, description="κ¶μ¥ μ‚¬ν•­")
    trace_id: str = Field(description="μ¶”μ  ID")
    elapsed_ms: float = Field(description="μ²λ¦¬ μ‹κ°„ (ms)")
    errors: List[str] = Field(default_factory=list, description="μ¤λ¥ λ©λ΅")


# =============================================================================
# Patent Analysis Agent Tool
# =============================================================================

class PatentAnalysisAgentTool(BaseTool):
    """
    νΉν— λ¶„μ„ AI μ—μ΄μ „νΈ
    
    LangChain Tool μΈν„°νμ΄μ¤λ¥Ό κµ¬ν„ν•μ—¬ SupervisorAgentμ—μ„ νΈμ¶ κ°€λ¥
    
    μ§€μ› λ¶„μ„ μ ν•:
    1. search: νΉν— κ²€μƒ‰
    2. comparison: κ²½μμ‚¬ νΉν— λΉ„κµ
    3. trend: μ‹κ³„μ—΄ νΈλ λ“ λ¶„μ„
    4. portfolio: ν¬νΈν΄λ¦¬μ¤ κ°μ”
    5. gap: κΈ°μ  κ³µλ°± λ¶„μ„
    """
    
    name: str = "patent_analysis_agent"
    description: str = """νΉν— λ¶„μ„ μ „λ¬Έ μ—μ΄μ „νΈ - μ—”ν„°ν”„λΌμ΄μ¦ κ²½μ μΈν…”λ¦¬μ „μ¤.

κΈ°λ¥:
- νΉν— κ²€μƒ‰ (KIPRIS ν•κµ­, SerpAPI Google Patents κΈ€λ΅λ²)
- κ²½μμ‚¬ νΉν— λΉ„κµ λ¶„μ„ ("μ‚Όμ„±μ „μ vs LGμ „μ AI νΉν— λΉ„κµ")
- κΈ°μ  νΈλ λ“ λ¶„μ„ (μ‹κ³„μ—΄ λ³€ν™”)
- νΉν— ν¬νΈν΄λ¦¬μ¤ λ¶„μ„
- κΈ°μ  κ³µλ°±(White Space) λ¶„μ„
- μ‹κ°ν™” λ°μ΄ν„° μƒμ„± (μ°¨νΈ, κ·Έλν”„)

μ‚¬μ© μ‹λ‚λ¦¬μ¤:
- "μ‚Όμ„±μ „μμ AI λ°λ„μ²΄ κ΄€λ ¨ νΉν—λ¥Ό κ²€μƒ‰ν•΄μ¤"
- "μ°λ¦¬νμ‚¬μ™€ μ‚Όμ„±μ „μμ νΉν— ν¬νΈν΄λ¦¬μ¤λ¥Ό λΉ„κµν•΄μ¤"
- "μµκ·Ό 5λ…„κ°„ AI λ°λ„μ²΄ νΉν— νΈλ λ“λ¥Ό λ¶„μ„ν•΄μ¤"
- "κ²½μμ‚¬ λ€λΉ„ μ°λ¦¬κ°€ λ¶€μ΅±ν• κΈ°μ  λ¶„μ•Όλ”?"
"""
    args_schema: Type[BaseModel] = PatentAnalysisAgentInput
    
    # λ‚΄λ¶€ λ„κµ¬ (PrivateAttrλ΅ pydantic νΈν™)
    _search_tool: PatentSearchTool = PrivateAttr()
    _analysis_tool: PatentAnalysisTool = PrivateAttr()
    _discovery_tool: PatentDiscoveryTool = PrivateAttr()
    _detail_tool: PatentDetailTool = PrivateAttr()
    _legal_tool: PatentLegalTool = PrivateAttr()
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._search_tool = PatentSearchTool()
        self._analysis_tool = PatentAnalysisTool()
        self._discovery_tool = PatentDiscoveryTool()
        self._detail_tool = PatentDetailTool()
        self._legal_tool = PatentLegalTool()
    
    def _map_discovery_to_patent_data(self, item: Dict[str, Any]) -> PatentData:
        """Discovery Tool κ²°κ³Όλ¥Ό PatentDataλ΅ λ³€ν™"""
        # μƒνƒ λ§¤ν•‘
        status_str = item.get("status", "")
        status = PatentStatus.APPLICATION
        if "λ“±λ΅" in status_str:
            status = PatentStatus.GRANTED
        elif "κ³µκ°" in status_str:
            status = PatentStatus.PUBLISHED
        elif "μ·¨ν•" in status_str:
            status = PatentStatus.WITHDRAWN
        elif "μ†λ©Έ" in status_str or "λ§λ£" in status_str:
            status = PatentStatus.EXPIRED
            
        return PatentData(
            patent_number=item.get("application_number", ""),
            title=item.get("title", ""),
            abstract=item.get("abstract", ""),
            applicant=item.get("applicant", ""),
            inventors=[], # Discovery κ²°κ³Όμ—λ” λ°λ…μκ°€ μ—†μ„ μ μμ
            ipc_codes=item.get("ipc_all", []) or ([item.get("ipc_code")] if item.get("ipc_code") else []),
            application_date=item.get("application_date"),
            publication_date=item.get("open_date"),
            grant_date=item.get("register_date"),
            status=status,
            jurisdiction=PatentJurisdiction.KR,
            url=f"https://kpat.kipris.or.kr/kpat/biblioa.do?applno={item.get('application_number', '')}"
        )

    async def _analyze_query_with_llm(self, query: str) -> Dict[str, Any]:
        """LLMμ„ μ‚¬μ©ν•μ—¬ μΏΌλ¦¬ μλ„ λ° νλΌλ―Έν„° μ •λ°€ λ¶„μ„"""
        try:
            system_prompt = """λ‹Ήμ‹ μ€ νΉν— λ¶„μ„ μ”μ²­μ„ κµ¬μ΅°ν™”λ λ°μ΄ν„°λ΅ λ³€ν™ν•λ” μ „λ¬Έκ°€μ…λ‹λ‹¤.
μ‚¬μ©μμ μμ—°μ–΄ μ§μλ¥Ό λ¶„μ„ν•μ—¬ λ‹¤μ JSON ν•μ‹μΌλ΅ μ¶”μ¶ν•΄μ£Όμ„Έμ”.

{
    "is_valid": true/false,
    "reason": "μ ν¨ν•μ§€ μ•μ€ κ²½μ° μ΄μ ",
    "analysis_type": "search" | "comparison" | "trend" | "portfolio" | "gap",
    "applicant": "μ£Ό μ¶μ›μΈ(νμ‚¬λ…) λλ” null",
    "competitor": "λΉ„κµ λ€μƒ κ²½μμ‚¬ λλ” null",
    "keywords": "κΈ°μ  ν‚¤μ›λ“ (νμ‚¬λ…, λ¶μ©μ–΄ μ μ™Έ) λλ” null",
    "date_from": "YYYY-MM-DD λλ” null",
    "date_to": "YYYY-MM-DD λλ” null",
    "jurisdiction": "KR" | "US" | "ALL"
}

λ¶„μ„ κ°€μ΄λ“:
1. **μ¶μ›μΈ(applicant)**: 'μ‚Όμ„±μ „μ', 'LGμ—λ„μ§€μ†”λ£¨μ…' λ“± νμ‚¬λ…μ„ μ •ν™•ν μ¶”μ¶ν•μ„Έμ”. (μ£Ό), μ£Όμ‹νμ‚¬ λ“±μ€ μ μ™Έν•κ³  ν•µμ‹¬ λ…μΉ­λ§ μ¶”μ¶.
2. **λ¶„μ„ μ ν•(analysis_type)**:
   - λ‘ κ° μ΄μƒμ νμ‚¬κ°€ μ–ΈκΈ‰λκ³  λΉ„κµ/λ€μ΅°/μ°¨μ΄ λ“±μ λ‹¨μ–΄κ°€ μμΌλ©΄ "comparison"
   - 'νΈλ λ“', 'λ™ν–¥', 'μ¶”μ΄', 'λ³€ν™”' λ“±μ΄ μμΌλ©΄ "trend"
   - 'ν¬νΈν΄λ¦¬μ¤', 'ν„ν™©', 'λ³΄μ  νΉν—' λ“±μ΄ μμΌλ©΄ "portfolio"
   - 'κ³µλ°±', 'λΉν‹', 'κΈ°ν' λ“±μ΄ μμΌλ©΄ "gap"
   - κ·Έ μ™Έμ—λ” "search"
3. **ν‚¤μ›λ“(keywords)**: 'νΉν—', 'κ²€μƒ‰', 'λ¶„μ„', 'ν•΄μ¤' λ“± λ¶μ©μ–΄λ¥Ό μ μ™Έν• κΈ°μ μ  ν•µμ‹¬ λ‹¨μ–΄λ§ λ‚¨κΈ°μ„Έμ”.
4. **μ ν¨μ„±(is_valid)**: νΉν— λ¶„μ„κ³Ό λ¬΄κ΄€ν• μ§μκ±°λ‚, λ¶„μ„μ— ν•„μ”ν• μµμ†ν•μ μ •λ³΄(ν‚¤μ›λ“ λλ” μ¶μ›μΈ)κ°€ μ—†μΌλ©΄ falseλ΅ μ„¤μ •ν•μ„Έμ”.
"""
            
            response = await ai_service.chat_completion(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": query}
                ],
                temperature=0.0
            )
            
            import json
            content = response.get("response", "{}")
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
                
            result = json.loads(content)
            logger.info(f"π§  [PatentAnalysisAgent] LLM μΏΌλ¦¬ λ¶„μ„ κ²°κ³Ό: {result}")
            return result
            
        except Exception as e:
            logger.error(f"β [PatentAnalysisAgent] LLM μΏΌλ¦¬ λ¶„μ„ μ‹¤ν¨: {e}")
            # μ‹¤ν¨ μ‹ κΈ°λ³Έκ°’ λ°ν™
            return {
                "is_valid": True,
                "analysis_type": "search",
                "applicant": self._extract_applicant_from_query(query),
                "keywords": self._clean_query(query, None),
                "competitor": None,
                "date_from": None,
                "date_to": None,
                "jurisdiction": "KR"
            }

    async def _arun(
        self,
        query: str,
        analysis_type: str = "search",
        our_company: Optional[str] = None,
        competitor: Optional[str] = None,
        jurisdiction: str = "KR",
        date_from: Optional[str] = None,
        date_to: Optional[str] = None,
        ipc_codes: Optional[List[str]] = None,
        max_results: int = 50,
        include_visualization: bool = True,
        time_range_years: int = 5,
        **kwargs
    ) -> Dict[str, Any]:
        """
        νΉν— λ¶„μ„ μ‹¤ν–‰
        
        Args:
            query: κ²€μƒ‰ μΏΌλ¦¬ λλ” λ¶„μ„ μ”μ²­
            analysis_type: λ¶„μ„ μ ν• (search/comparison/trend/portfolio/gap)
            our_company: μ°λ¦¬ νμ‚¬λ… (λΉ„κµ λ¶„μ„ μ‹)
            competitor: κ²½μμ‚¬λ… (λΉ„κµ λ¶„μ„ μ‹)
            jurisdiction: κ΄€ν• κ¶ (KR/US/EP/ALL)
            date_from: μ¶μ›μΌ μ‹μ‘
            date_to: μ¶μ›μΌ μΆ…λ£
            ipc_codes: IPC ν•„ν„°
            max_results: μµλ€ κ²°κ³Ό μ
            include_visualization: μ‹κ°ν™” ν¬ν•¨ μ—¬λ¶€
            time_range_years: νΈλ λ“ λ¶„μ„ κΈ°κ°„
        
        Returns:
            Dict: λ¶„μ„ κ²°κ³Ό (PatentAnalysisAgentOutput ν•νƒ)
        """
        start_time = datetime.utcnow()
        trace_id = str(uuid.uuid4())
        
        logger.info(
            f"π”¬ [PatentAnalysisAgent] λ¶„μ„ μ‹μ‘: type={analysis_type}, query='{query[:50]}...'"
        )
        
        try:
            # 1. LLM κΈ°λ° μΏΌλ¦¬ μ •λ°€ λ¶„μ„ (μ…λ ¥ μ •λ³΄ κ°•ν™”)
            analyzed_query = await self._analyze_query_with_llm(query)
            
            if not analyzed_query.get("is_valid", True):
                return {
                    "success": False,
                    "analysis_type": analysis_type,
                    "summary": f"λ¶„μ„ν•  μ μ—†λ” μ§μμ…λ‹λ‹¤: {analyzed_query.get('reason', 'μ •λ³΄ λ¶€μ΅±')}",
                    "patents": [],
                    "total_patents": 0,
                    "analysis_result": None,
                    "visualizations": [],
                    "insights": [],
                    "recommendations": ["λ” κµ¬μ²΄μ μΈ νμ‚¬λ…μ΄λ‚ κΈ°μ  ν‚¤μ›λ“λ¥Ό μ…λ ¥ν•΄μ£Όμ„Έμ”."],
                    "trace_id": trace_id,
                    "elapsed_ms": 0,
                    "errors": [analyzed_query.get("reason", "Invalid query")]
                }

            # 2. νλΌλ―Έν„° λ³‘ν•© (LLM λ¶„μ„ κ²°κ³Ό μ°μ„  μ μ©)
            # analysis_typeμ΄ κΈ°λ³Έκ°’('search')μΈ κ²½μ° LLM λ¶„μ„ κ²°κ³Ό μ‚¬μ©
            if analysis_type == "search" and analyzed_query.get("analysis_type"):
                analysis_type = analyzed_query["analysis_type"]
            
            # νμ‚¬λ…/κ²½μμ‚¬ μ •λ³΄ λ³΄κ°•
            if not our_company and analyzed_query.get("applicant"):
                our_company = analyzed_query["applicant"]
            if not competitor and analyzed_query.get("competitor"):
                competitor = analyzed_query["competitor"]
                
            # λ‚ μ§ μ •λ³΄ λ³΄κ°•
            if not date_from and analyzed_query.get("date_from"):
                date_from = analyzed_query["date_from"]
            if not date_to and analyzed_query.get("date_to"):
                date_to = analyzed_query["date_to"]
                
            # κ΄€ν• κ¶ μ •λ³΄ λ³΄κ°•
            if jurisdiction == "KR" and analyzed_query.get("jurisdiction"):
                jurisdiction = analyzed_query["jurisdiction"]

            # κ²€μƒ‰μ© ν‚¤μ›λ“ (LLMμ΄ μ¶”μ¶ν• ν‚¤μ›λ“ μ‚¬μ©)
            search_keywords = analyzed_query.get("keywords") or query
            
            logger.info(f"π”§ [PatentAnalysisAgent] νλΌλ―Έν„° ν™•μ •: type={analysis_type}, applicant={our_company}, keywords={search_keywords}")

            # λ¶„μ„ μ ν•μ— λ”°λΌ μ²λ¦¬
            if analysis_type == "search":
                result = await self._execute_search(
                    query=search_keywords,
                    applicant=our_company, # μ¶”μ¶λ μ¶μ›μΈ μ „λ‹¬
                    jurisdiction=jurisdiction,
                    date_from=date_from,
                    date_to=date_to,
                    ipc_codes=ipc_codes,
                    max_results=max_results,
                    include_visualization=include_visualization
                )
            elif analysis_type == "comparison":
                result = await self._execute_comparison(
                    query=search_keywords,
                    our_company=our_company,
                    competitor=competitor,
                    jurisdiction=jurisdiction,
                    date_from=date_from,
                    date_to=date_to,
                    max_results=max_results,
                    include_visualization=include_visualization
                )
            elif analysis_type == "trend":
                result = await self._execute_trend_analysis(
                    query=search_keywords,
                    jurisdiction=jurisdiction,
                    time_range_years=time_range_years,
                    max_results=max_results,
                    include_visualization=include_visualization
                )
            elif analysis_type == "portfolio":
                result = await self._execute_portfolio_analysis(
                    query=search_keywords,
                    company=our_company or competitor,
                    jurisdiction=jurisdiction,
                    max_results=max_results,
                    include_visualization=include_visualization
                )
            elif analysis_type == "gap":
                result = await self._execute_gap_analysis(
                    query=search_keywords,
                    our_company=our_company,
                    competitor=competitor,
                    jurisdiction=jurisdiction,
                    max_results=max_results,
                    include_visualization=include_visualization
                )
            else:
                # κΈ°λ³Έ: κ²€μƒ‰
                result = await self._execute_search(
                    query=search_keywords,
                    applicant=our_company,
                    jurisdiction=jurisdiction,
                    max_results=max_results,
                    include_visualization=include_visualization
                )
            
            elapsed_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            result["trace_id"] = trace_id
            result["elapsed_ms"] = elapsed_ms
            result["success"] = True
            
            logger.info(f"β… [PatentAnalysisAgent] μ™„λ£: {elapsed_ms:.0f}ms")
            
            return result
            
        except Exception as e:
            elapsed_ms = (datetime.utcnow() - start_time).total_seconds() * 1000
            logger.error(f"β [PatentAnalysisAgent] μ¤λ¥: {e}")
            
            return {
                "success": False,
                "analysis_type": analysis_type,
                "summary": f"λ¶„μ„ μ¤‘ μ¤λ¥κ°€ λ°μƒν–μµλ‹λ‹¤: {str(e)}",
                "patents": [],
                "total_patents": 0,
                "analysis_result": None,
                "visualizations": [],
                "insights": [],
                "recommendations": [],
                "trace_id": trace_id,
                "elapsed_ms": elapsed_ms,
                "errors": [str(e)]
            }
    
    def _run(
        self,
        query: str,
        **kwargs
    ) -> Dict[str, Any]:
        """λ™κΈ° μ‹¤ν–‰ (ν΄λ°±)"""
        return asyncio.run(self._arun(query, **kwargs))
    
    # =========================================================================
    # λ¶„μ„ μ ν•λ³„ μ‹¤ν–‰ λ©”μ„λ“
    # =========================================================================
    
    async def _execute_search(
        self,
        query: str,
        applicant: Optional[str] = None,
        jurisdiction: str = "KR",
        date_from: Optional[str] = None,
        date_to: Optional[str] = None,
        ipc_codes: Optional[List[str]] = None,
        max_results: int = 50,
        include_visualization: bool = True
    ) -> Dict[str, Any]:
        """νΉν— κ²€μƒ‰ μ‹¤ν–‰"""
        import re
        
        # μΏΌλ¦¬μ—μ„ μ¶μ›μΈ μ¶”μ¶ μ‹λ„ (μ „λ‹¬λ°›μ§€ λ»ν• κ²½μ° ν΄λ°±)
        if not applicant:
            applicant = self._extract_applicant_from_query(query)
        
        # μΏΌλ¦¬ μ •μ 
        # LLMμ΄ μ΄λ―Έ ν‚¤μ›λ“λ¥Ό μ¶”μ¶ν–λ”λΌλ„, μ¶”κ°€μ μΈ μ •μ (μ΅°μ‚¬ μ κ±° λ“±)λ¥Ό μ„ν•΄ μ‹¤ν–‰
        clean_query = self._clean_query(query, applicant)
        
        # π”§ λ””λ²„κ·Έ: clean_query κ°’ ν™•μΈ
        logger.info(f"π”§ [PatentAnalysisAgent] μΏΌλ¦¬ μ •μ : '{query}' β†’ clean='{clean_query}', applicant='{applicant}'")
        
        # π†• μΏΌλ¦¬μ—μ„ μ—°λ„ μ •λ³΄ μ¶”μ¶ (μ „λ‹¬λ°›μ§€ λ»ν• κ²½μ°)
        if not date_from:
            year_match = re.search(r'(\d{4})λ…„', query)
            if year_match:
                year = year_match.group(1)
                date_from = f"{year}-01-01"
                date_to = f"{year}-12-31"
                logger.info(f"π“… μ—°λ„ ν•„ν„° μ μ©: {date_from} ~ {date_to}")
        
        patents: List[PatentData] = []
        errors: List[str] = []
        total_count = 0
        
        search_params = {
            "query": clean_query,
            "applicant": applicant,
            "jurisdiction": jurisdiction,
            "date_from": date_from,
            "date_to": date_to
        }
        
        # 1. KR κ²€μƒ‰ (Discovery Tool μ‚¬μ©)
        if jurisdiction in ["KR", "ALL"]:
            try:
                discovery_results = await self._discovery_tool._arun(
                    query=clean_query,
                    applicant=applicant,
                    date_from=date_from,
                    date_to=date_to,
                    ipc_code=ipc_codes[0] if ipc_codes else None,
                    max_results=max_results
                )
                
                # Handle new dict return format with total_count
                kr_patents_list = []
                kr_total = 0
                
                if isinstance(discovery_results, dict) and "patents" in discovery_results:
                    kr_patents_list = discovery_results["patents"]
                    kr_total = discovery_results.get("total_count", 0)
                elif isinstance(discovery_results, list):
                    kr_patents_list = discovery_results
                    kr_total = len(discovery_results)
                
                for item in kr_patents_list:
                    patents.append(self._map_discovery_to_patent_data(item))
                
                # Update total count (use max of retrieved or reported total)
                total_count += max(kr_total, len(kr_patents_list))
                    
                logger.info(f"β… [Discovery] KR νΉν— {len(kr_patents_list)}κ±΄ κ²€μƒ‰ μ™„λ£ (μ΄ {kr_total}κ±΄)")
            except Exception as e:
                logger.error(f"β [Discovery] KR κ²€μƒ‰ μ‹¤ν¨: {e}")
                errors.append(f"KR κ²€μƒ‰ μ‹¤ν¨: {str(e)}")
        
        # 2. Global κ²€μƒ‰ (Legacy Search Tool μ‚¬μ©)
        if jurisdiction != "KR":
            try:
                # KRμ΄ μ•„λ‹κ±°λ‚ ALLμΈ κ²½μ° Global κ²€μƒ‰
                # ALLμΈ κ²½μ° KRμ€ μ„μ—μ„ ν–μΌλ―€λ΅ Globalλ§ μ¶”κ°€
                target_jurisdiction = jurisdiction if jurisdiction != "ALL" else "US" # ALLμΌ λ• Global λ€ν‘λ΅ US κ²€μƒ‰ (μ„μ‹)
                
                global_result = await self._search_tool._arun(
                    query=clean_query,
                    applicant=applicant,
                    jurisdiction=target_jurisdiction,
                    date_from=date_from,
                    date_to=date_to,
                    ipc_codes=ipc_codes,
                    max_results=max_results,
                    include_global=True
                )
                
                if global_result.data:
                    patents.extend(global_result.data)
                    # Add global total count
                    total_count += global_result.total_found
                    logger.info(f"β… [Global] {len(global_result.data)}κ±΄ κ²€μƒ‰ μ™„λ£")
            except Exception as e:
                logger.error(f"β [Global] κ²€μƒ‰ μ‹¤ν¨: {e}")
                errors.append(f"Global κ²€μƒ‰ μ‹¤ν¨: {str(e)}")
        
        # π†• κ²€μƒ‰ κ²°κ³Όκ°€ μ—†κ±°λ‚ μ¶μ›μΈ λ§¤μΉ­ μ‹¤ν¨ μ‹ μΈν„°λ„· κ²€μƒ‰ ν΄λ°±
        if not patents and applicant:
            logger.warning(f"β οΈ [PatentAnalysisAgent] KIPRISμ—μ„ '{applicant}' νΉν—λ¥Ό μ°Ύμ„ μ μ—†μ β†’ μΈν„°λ„· κ²€μƒ‰ ν΄λ°±")
            return await self._fallback_to_internet_search(query, applicant, date_from)
        
        # π†• μ—°λ„ ν•„ν„°λ§ (κ²€μƒ‰ κ²°κ³Όμ—μ„ μ¶”κ°€ ν•„ν„°)
        if date_from and date_to:
            target_year = date_from[:4]
            filtered_patents = [
                p for p in patents 
                if p.application_date and p.application_date.startswith(target_year)
            ]
            if filtered_patents:
                patents = filtered_patents
                logger.info(f"π“… {target_year}λ…„ νΉν— ν•„ν„°λ§: {len(patents)}κ±΄")
        
        # μ‹κ°ν™” λ°μ΄ν„° μƒμ„±
        visualizations = []
        if include_visualization and patents:
            visualizations = self._generate_search_visualizations(patents)
        
        # π†• μƒμ„Έ μ”μ•½ μƒμ„± (μ›λ³Έ μΏΌλ¦¬, κ²€μƒ‰ λ§¥λ½ ν¬ν•¨)
        summary = await self._generate_search_summary(
            original_query=query,
            patents=patents,
            applicant=applicant,
            year_filter=date_from[:4] if date_from else None
        )
        
        # π†• μƒμ„Έ μΈμ‚¬μ΄νΈ μ¶”μ¶
        insights = self._extract_search_insights(patents, applicant)
        
        return {
            "analysis_type": "search",
            "summary": summary,
            "patents": [p.model_dump() for p in patents],
            "total_patents": total_count if total_count > len(patents) else len(patents),
            "analysis_result": {
                "search_params": search_params,
                "source": "kipris_discovery" if jurisdiction == "KR" else "hybrid",
                "year_filter": date_from[:4] if date_from else None
            },
            "visualizations": [v.model_dump() for v in visualizations],
            "insights": insights,
            "recommendations": [],
            "errors": errors
        }
    
    async def _fallback_to_internet_search(
        self,
        query: str,
        applicant: str,
        date_from: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        KIPRIS κ²€μƒ‰ μ‹¤ν¨ μ‹ μΈν„°λ„· κ²€μƒ‰μΌλ΅ ν΄λ°±
        
        μ •ν™•ν• μ¶μ›μΈμ νΉν—λ¥Ό μ°Ύμ§€ λ»ν•λ©΄, μλ»λ μ •λ³΄λ¥Ό μ κ³µν•λ” κ²ƒλ³΄λ‹¤
        μΈν„°λ„·μ—μ„ κ΄€λ ¨ μ •λ³΄λ¥Ό κ²€μƒ‰ν•μ—¬ μ κ³µν•λ” κ²ƒμ΄ λ” λ‚«μµλ‹λ‹¤.
        """
        try:
            from app.tools.retrieval.internet_search_tool import internet_search_tool
            
            # μΈν„°λ„· κ²€μƒ‰ μΏΌλ¦¬ κµ¬μ„±
            year_str = date_from[:4] if date_from else ""
            search_query = f"{applicant} {year_str} νΉν— μ¶μ› ν„ν™©"
            
            logger.info(f"π [PatentAnalysisAgent] μΈν„°λ„· κ²€μƒ‰: '{search_query}'")
            
            # μΈν„°λ„· κ²€μƒ‰ μ‹¤ν–‰
            search_result = await internet_search_tool._arun(query=search_query)
            
            # κ²€μƒ‰ κ²°κ³Όμ—μ„ ν…μ¤νΈ μ¶”μ¶
            internet_summary = ""
            if search_result.success and search_result.data:
                for item in search_result.data[:5]:  # μƒμ„ 5κ°λ§
                    # SearchChunk κ°μ²΄μ—μ„ μ†μ„± μ¶”μ¶
                    title = getattr(item, 'title', '') or ''
                    content = getattr(item, 'content', '') or ''
                    url = getattr(item, 'url', '') or getattr(item, 'source_url', '') or ''
                    if title:
                        internet_summary += f"- **{title}**\n"
                        if content:
                            internet_summary += f"  {content[:200]}...\n"
                        if url:
                            internet_summary += f"  [λ§ν¬]({url})\n"
                        internet_summary += "\n"
            
            if not internet_summary:
                internet_summary = "κ΄€λ ¨ μ •λ³΄λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤."
            
            # κ²€μƒ‰ κ²°κ³Όλ¥Ό μ”μ•½ ν•νƒλ΅ λ°ν™
            summary = f"""## π“‹ νΉν— κ²€μƒ‰ κ²°κ³Ό

### β οΈ KIPRIS κ²€μƒ‰ κ²°κ³Ό μ—†μ

**'{applicant}'**μ νΉν—λ¥Ό KIPRIS(ν•κµ­νΉν—μ •λ³΄μ›)μ—μ„ μ§μ ‘ κ²€μƒ‰ν•μ€μΌλ‚, 
μ •ν™•ν μΌμΉν•λ” μ¶μ›μΈμ νΉν—λ¥Ό μ°Ύμ§€ λ»ν–μµλ‹λ‹¤.

**κ°€λ¥ν• μ›μΈ:**
- νμ‚¬λ…μ΄ KIPRISμ— λ“±λ΅λ μ •μ‹ λ…μΉ­κ³Ό λ‹¤λ¥Ό μ μμµλ‹λ‹¤
- ν•΄λ‹Ή κΈ°κ°„μ— μ¶μ›λ νΉν—κ°€ μ—†μ„ μ μμµλ‹λ‹¤
- μ•„μ§ κ³µκ°λμ§€ μ•μ€ νΉν—μΌ μ μμµλ‹λ‹¤ (μ¶μ› ν›„ 18κ°μ›” μ΄λ‚΄)

---

### π μΈν„°λ„· κ²€μƒ‰ κ²°κ³Ό

λ‹¤μμ€ μΈν„°λ„·μ—μ„ μ°Ύμ€ **'{applicant}'** κ΄€λ ¨ νΉν— μ •λ³΄μ…λ‹λ‹¤:

{internet_summary}

---

### π’΅ κ¶μ¥ μ‚¬ν•­

1. **μ •ν™•ν• νμ‚¬λ… ν™•μΈ**: KIPRISμ—μ„ μ§μ ‘ '{applicant}' κ²€μƒ‰ν•μ—¬ μ •μ‹ μ¶μ›μΈλ… ν™•μΈ
2. **KIPRIS μ§μ ‘ κ²€μƒ‰**: [KIPRIS](https://www.kipris.or.kr) μ‚¬μ΄νΈμ—μ„ μ§μ ‘ κ²€μƒ‰
3. **κΈ°κ°„ μ΅°μ •**: λ” λ„“μ€ κΈ°κ°„μΌλ΅ κ²€μƒ‰ μ‹λ„
"""
            
            return {
                "analysis_type": "search",
                "summary": summary,
                "patents": [],
                "total_patents": 0,
                "analysis_result": {
                    "source": "internet_search_fallback",
                    "reason": "KIPRISμ—μ„ μ •ν™•ν• μ¶μ›μΈ λ§¤μΉ­ μ‹¤ν¨",
                    "applicant": applicant
                },
                "visualizations": [],
                "insights": [
                    f"KIPRISμ—μ„ '{applicant}'μ νΉν—λ¥Ό μ°Ύμ§€ λ»ν•¨",
                    "μΈν„°λ„· κ²€μƒ‰μΌλ΅ λ€μ²΄ μ •λ³΄ μ κ³µ",
                    "μ •ν™•ν• νΉν— μ •λ³΄λ” KIPRIS μ§μ ‘ κ²€μƒ‰ κ¶μ¥"
                ],
                "recommendations": [
                    f"KIPRISμ—μ„ '{applicant}' μ •μ‹ μ¶μ›μΈλ… ν™•μΈ",
                    "νΉν—μ²­ νΉν—λ΅ μ‚¬μ΄νΈμ—μ„ μ§μ ‘ κ²€μƒ‰"
                ],
                "errors": []
            }
            
        except Exception as e:
            logger.error(f"β [PatentAnalysisAgent] μΈν„°λ„· κ²€μƒ‰ ν΄λ°± μ‹¤ν¨: {e}")
            return {
                "analysis_type": "search",
                "summary": f"## β οΈ κ²€μƒ‰ μ‹¤ν¨\n\n'{applicant}'μ νΉν— μ •λ³΄λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤.\n\n**κ¶μ¥ μ‚¬ν•­:**\n- KIPRIS(https://www.kipris.or.kr)μ—μ„ μ§μ ‘ κ²€μƒ‰ν•μ„Έμ”\n- μ •ν™•ν• μ¶μ›μΈλ…μ„ ν™•μΈν•΄ μ£Όμ„Έμ”",
                "patents": [],
                "total_patents": 0,
                "analysis_result": {"source": "error", "error": str(e)},
                "visualizations": [],
                "insights": [],
                "recommendations": ["KIPRISμ—μ„ μ§μ ‘ κ²€μƒ‰"],
                "errors": [str(e)]
            }

    async def _execute_comparison(
        self,
        query: str,
        our_company: Optional[str],
        competitor: Optional[str],
        jurisdiction: str = "KR",
        date_from: Optional[str] = None,
        date_to: Optional[str] = None,
        max_results: int = 50,
        include_visualization: bool = True
    ) -> Dict[str, Any]:
        """κ²½μμ‚¬ νΉν— λΉ„κµ λ¶„μ„"""
        
        if not our_company or not competitor:
            return {
                "analysis_type": "comparison",
                "summary": "κ²½μμ‚¬ λΉ„κµ λ¶„μ„μ„ μ„ν•΄μ„λ” μ°λ¦¬ νμ‚¬λ…(our_company)κ³Ό κ²½μμ‚¬λ…(competitor)μ΄ ν•„μ”ν•©λ‹λ‹¤.",
                "patents": [],
                "total_patents": 0,
                "analysis_result": None,
                "visualizations": [],
                "insights": [],
                "recommendations": ["our_companyμ™€ competitor νλΌλ―Έν„°λ¥Ό μ κ³µν•΄μ£Όμ„Έμ”."],
                "errors": ["Missing required parameters: our_company, competitor"]
            }
        
        # μ–‘μΈ΅ νΉν— κ²€μƒ‰
        our_result = await self._search_tool._arun(
            query=query,
            applicant=our_company,
            jurisdiction=jurisdiction,
            date_from=date_from,
            date_to=date_to,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        competitor_result = await self._search_tool._arun(
            query=query,
            applicant=competitor,
            jurisdiction=jurisdiction,
            date_from=date_from,
            date_to=date_to,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        our_patents = our_result.data
        competitor_patents = competitor_result.data
        all_patents = our_patents + competitor_patents
        
        # λΉ„κµ λ¶„μ„ μν–‰
        analysis_result = await self._analysis_tool._arun(
            patents=all_patents,
            analysis_type="comparison",
            our_company=our_company,
            comparison_target=competitor
        )
        
        # μ‹κ°ν™” λ°μ΄ν„° μƒμ„±
        visualizations = []
        if include_visualization:
            visualizations = self._generate_comparison_visualizations(
                our_patents, competitor_patents, our_company, competitor
            )
        
        # μ”μ•½ μƒμ„±
        summary = await self._generate_comparison_summary(
            query, our_company, competitor, our_patents, competitor_patents, analysis_result
        )
        
        # μΈμ‚¬μ΄νΈ λ° κ¶μ¥μ‚¬ν•­
        insights = self._extract_comparison_insights(our_patents, competitor_patents, our_company, competitor)
        recommendations = self._generate_comparison_recommendations(analysis_result)
        
        return {
            "analysis_type": "comparison",
            "summary": summary,
            "patents": [p.model_dump() for p in all_patents],
            "total_patents": len(all_patents),
            "analysis_result": analysis_result.model_dump() if hasattr(analysis_result, 'model_dump') else analysis_result,
            "visualizations": [v.model_dump() for v in visualizations],
            "insights": insights,
            "recommendations": recommendations,
            "errors": our_result.errors + competitor_result.errors
        }
    
    async def _execute_trend_analysis(
        self,
        query: str,
        jurisdiction: str = "KR",
        time_range_years: int = 5,
        max_results: int = 100,
        include_visualization: bool = True
    ) -> Dict[str, Any]:
        """μ‹κ³„μ—΄ νΈλ λ“ λ¶„μ„"""
        
        # κΈ°κ°„ κ³„μ‚°
        from datetime import datetime, timedelta
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365 * time_range_years)
        
        date_from = start_date.strftime("%Y-%m-%d")
        date_to = end_date.strftime("%Y-%m-%d")
        
        # νΉν— κ²€μƒ‰
        search_result = await self._search_tool._arun(
            query=query,
            jurisdiction=jurisdiction,
            date_from=date_from,
            date_to=date_to,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        patents = search_result.data
        
        # νΈλ λ“ λ¶„μ„ μν–‰
        analysis_result = await self._analysis_tool._arun(
            patents=patents,
            analysis_type="timeline",
            time_range_years=time_range_years
        )
        
        # μ‹κ°ν™” λ°μ΄ν„° μƒμ„±
        visualizations = []
        if include_visualization and patents:
            visualizations = self._generate_trend_visualizations(patents, time_range_years)
        
        # μ”μ•½ μƒμ„±
        summary = await self._generate_trend_summary(query, patents, time_range_years, analysis_result)
        
        # μΈμ‚¬μ΄νΈ μ¶”μ¶
        insights = self._extract_trend_insights(patents, time_range_years)
        
        return {
            "analysis_type": "trend",
            "summary": summary,
            "patents": [p.model_dump() for p in patents],
            "total_patents": len(patents),
            "analysis_result": analysis_result.model_dump() if hasattr(analysis_result, 'model_dump') else analysis_result,
            "visualizations": [v.model_dump() for v in visualizations],
            "insights": insights,
            "recommendations": [],
            "errors": search_result.errors
        }
    
    async def _execute_portfolio_analysis(
        self,
        query: str,
        company: Optional[str],
        jurisdiction: str = "KR",
        max_results: int = 100,
        include_visualization: bool = True
    ) -> Dict[str, Any]:
        """ν¬νΈν΄λ¦¬μ¤ λ¶„μ„"""
        
        # νΉν— κ²€μƒ‰
        search_result = await self._search_tool._arun(
            query=query,
            applicant=company,
            jurisdiction=jurisdiction,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        patents = search_result.data
        
        # ν¬νΈν΄λ¦¬μ¤ λ¶„μ„ μν–‰
        analysis_result = await self._analysis_tool._arun(
            patents=patents,
            analysis_type="portfolio"
        )
        
        # ν† ν”½ λ¶„μ„λ„ μν–‰
        topic_result = await self._analysis_tool._arun(
            patents=patents,
            analysis_type="topic"
        )
        
        # μ‹κ°ν™” λ°μ΄ν„° μƒμ„±
        visualizations = []
        if include_visualization and patents:
            visualizations = self._generate_portfolio_visualizations(patents, company)
        
        # μ”μ•½ μƒμ„±
        summary = await self._generate_portfolio_summary(query, company, patents, analysis_result, topic_result)
        
        # μΈμ‚¬μ΄νΈ μ¶”μ¶
        insights = self._extract_portfolio_insights(patents, company)
        
        return {
            "analysis_type": "portfolio",
            "summary": summary,
            "patents": [p.model_dump() for p in patents],
            "total_patents": len(patents),
            "analysis_result": {
                "portfolio": analysis_result.model_dump() if hasattr(analysis_result, 'model_dump') else analysis_result,
                "topics": topic_result.model_dump() if hasattr(topic_result, 'model_dump') else topic_result
            },
            "visualizations": [v.model_dump() for v in visualizations],
            "insights": insights,
            "recommendations": [],
            "errors": search_result.errors
        }
    
    async def _execute_gap_analysis(
        self,
        query: str,
        our_company: Optional[str],
        competitor: Optional[str],
        jurisdiction: str = "KR",
        max_results: int = 100,
        include_visualization: bool = True
    ) -> Dict[str, Any]:
        """κΈ°μ  κ³µλ°± λ¶„μ„"""
        
        if not our_company or not competitor:
            return {
                "analysis_type": "gap",
                "summary": "κΈ°μ  κ³µλ°± λ¶„μ„μ„ μ„ν•΄μ„λ” μ°λ¦¬ νμ‚¬λ…(our_company)κ³Ό κ²½μμ‚¬λ…(competitor)μ΄ ν•„μ”ν•©λ‹λ‹¤.",
                "patents": [],
                "total_patents": 0,
                "analysis_result": None,
                "visualizations": [],
                "insights": [],
                "recommendations": ["our_companyμ™€ competitor νλΌλ―Έν„°λ¥Ό μ κ³µν•΄μ£Όμ„Έμ”."],
                "errors": ["Missing required parameters"]
            }
        
        # μ–‘μΈ΅ νΉν— κ²€μƒ‰
        our_result = await self._search_tool._arun(
            query=query,
            applicant=our_company,
            jurisdiction=jurisdiction,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        competitor_result = await self._search_tool._arun(
            query=query,
            applicant=competitor,
            jurisdiction=jurisdiction,
            max_results=max_results,
            include_global=(jurisdiction != "KR")
        )
        
        all_patents = our_result.data + competitor_result.data
        
        # κΈ°μ  κ³µλ°± λ¶„μ„ μν–‰
        analysis_result = await self._analysis_tool._arun(
            patents=all_patents,
            analysis_type="gap",
            our_company=our_company,
            comparison_target=competitor
        )
        
        # μ‹κ°ν™” λ°μ΄ν„° μƒμ„±
        visualizations = []
        if include_visualization:
            visualizations = self._generate_gap_visualizations(
                our_result.data, competitor_result.data, our_company, competitor
            )
        
        # μ”μ•½ μƒμ„±
        summary = await self._generate_gap_summary(query, our_company, competitor, analysis_result)
        
        # μΈμ‚¬μ΄νΈ λ° κ¶μ¥μ‚¬ν•­
        insights = self._extract_gap_insights(analysis_result)
        recommendations = self._generate_gap_recommendations(analysis_result)
        
        return {
            "analysis_type": "gap",
            "summary": summary,
            "patents": [p.model_dump() for p in all_patents],
            "total_patents": len(all_patents),
            "analysis_result": analysis_result.model_dump() if hasattr(analysis_result, 'model_dump') else analysis_result,
            "visualizations": [v.model_dump() for v in visualizations],
            "insights": insights,
            "recommendations": recommendations,
            "errors": our_result.errors + competitor_result.errors
        }
    
    # =========================================================================
    # ν—¬νΌ λ©”μ„λ“
    # =========================================================================
    
    def _extract_applicant_from_query(self, query: str) -> Optional[str]:
        """μΏΌλ¦¬μ—μ„ μ¶μ›μΈ(νμ‚¬λ…) μ¶”μ¶"""
        import re
        
        # 1. μ•λ ¤μ§„ ν•κµ­ λ€κΈ°μ—… ν¨ν„΄ (μ •ν™•ν• λ§¤μΉ­)
        korean_companies = [
            "μ‚Όμ„±μ „μ", "μ‚Όμ„±SDI", "μ‚Όμ„±λ””μ¤ν”λ μ΄", "μ‚Όμ„±λ°”μ΄μ¤λ΅μ§μ¤", "μ‚Όμ„±SDS",
            "LGμ „μ", "LGν™”ν•™", "LGμ—λ„μ§€μ†”λ£¨μ…", "LGλ””μ¤ν”λ μ΄", "LGμ΄λ…Έν…",
            "SKν•μ΄λ‹‰μ¤", "SKμ΄λ…Έλ² μ΄μ…", "SKν…”λ μ½¤", "SKC",
            "ν„λ€μλ™μ°¨", "ν„λ€λ¨λΉ„μ¤", "κΈ°μ•„", "ν„λ€κ±΄μ„¤",
            "λ„¤μ΄λ²„", "μΉ΄μΉ΄μ¤", "μΏ ν΅", "ν† μ¤", "λ°°λ‹¬μλ―Όμ΅±",
            "ν¬μ¤μ½”", "λ΅―λ°μΌ€λ―ΈμΉΌ", "ν•ν™”μ†”λ£¨μ…", "λ‘μ‚°μ—λ„λΉλ¦¬ν‹°", "CJμ μΌμ λ‹Ή"
        ]
        
        for company in korean_companies:
            if company in query:
                logger.debug(f"π“ μ¶μ›μΈ μ¶”μ¶ (μ•λ ¤μ§„ κΈ°μ—…): {company}")
                return company
        
        # 2. "~μ νΉν—", "~κ°€ μ¶μ›ν•", "~μ—μ„ κ°λ°ν•" ν¨ν„΄
        patterns = [
            r'([κ°€-ν£A-Za-z0-9]+(?:μ „μ|κ·Έλ£Ή|μ „κΈ°|ν†µμ‹ |λ°λ„μ²΄|λ©”λ””μ»¬|λ°”μ΄μ¤|ν…ν¬|μ†ν”„νΈ|μ‹μ¤ν…μ¦?|μ†”λ£¨μ…|μ΄λ…Έλ² μ΄μ…|μ—λ„μ§€))(?:μ|κ°€|μ—μ„|μ΄|λ”)',
            r'([κ°€-ν£A-Za-z0-9]+(?:μ£Όμ‹νμ‚¬|γ|\(μ£Ό\)|Inc\.|Corp\.|Ltd\.?))(?:μ|κ°€|μ—μ„|μ΄|λ”)?',
            r'([κ°€-ν£]{2,}(?:μ „μ|ν™”ν•™|κ±΄μ„¤|μ μ•½|λ°”μ΄μ¤|ν…ν¬|λ©”λ””μ»¬))(?:μ|κ°€|μ—μ„)?',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, query, re.IGNORECASE)
            if match:
                company = match.group(1).strip()
                # λ„λ¬΄ μ§§κ±°λ‚ μΌλ° λ…μ‚¬λ” μ μ™Έ
                if len(company) >= 3 and company not in ['νΉν—', 'μ¶μ›', 'λ¶„μ„', 'κ²€μƒ‰']:
                    logger.debug(f"π“ μ¶μ›μΈ μ¶”μ¶ (ν¨ν„΄ λ§¤μΉ­): {company}")
                    return company
        
        # 3. "νμ‚¬λ… + μ—°λ„ + νΉν—" ν¨ν„΄ (μ: "μ μ΄μ‹μ¤λ©”λ””μ»¬ 2024λ…„ μ¶μ› νΉν—")
        match = re.search(r'([κ°€-ν£A-Za-z0-9]+)\s+\d{4}λ…„\s*(?:μ¶μ›|λ“±λ΅|κ³µκ°)?\s*νΉν—', query)
        if match:
            company = match.group(1).strip()
            if len(company) >= 2 and company not in ['νΉν—', 'μ¶μ›', 'λ¶„μ„', 'κ²€μƒ‰', 'λ…„']:
                logger.debug(f"π“ μ¶μ›μΈ μ¶”μ¶ (μ—°λ„+νΉν— ν¨ν„΄): {company}")
                return company
        
        # 4. μΏΌλ¦¬ μ‹μ‘ λ¶€λ¶„μ κ³ μ λ…μ‚¬ μ¶”μ¶ (λ§μ§€λ§‰ μλ‹¨)
        # "μ μ΄μ‹μ¤λ©”λ””μ»¬ νΉν— λ¶„μ„" β†’ "μ μ΄μ‹μ¤λ©”λ””μ»¬"
        words = query.split()
        if words:
            first_word = words[0]
            # μ²« λ‹¨μ–΄κ°€ 3κΈ€μ μ΄μƒμ΄κ³ , μΌλ° λ…μ‚¬κ°€ μ•„λ‹λ©΄ νμ‚¬λ…μΌλ΅ μ¶”μ •
            if len(first_word) >= 3 and first_word not in ['νΉν—', 'μ¶μ›', 'λ¶„μ„', 'κ²€μƒ‰', 'μµκ·Ό', 'μ¬ν•΄', 'μ‘λ…„']:
                # ν•κΈ€+μλ¬Έ μ΅°ν•©μ΄κ±°λ‚ νΉμ • μ ‘λ―Έμ‚¬κ°€ μμΌλ©΄ νμ‚¬λ… κ°€λ¥μ„± λ†’μ
                if re.match(r'^[κ°€-ν£A-Za-z0-9]+$', first_word):
                    logger.debug(f"π“ μ¶μ›μΈ μ¶”μ¶ (μ²« λ‹¨μ–΄): {first_word}")
                    return first_word
        
        logger.debug(f"β οΈ μ¶μ›μΈ μ¶”μ¶ μ‹¤ν¨: '{query}'")
        return None
    
    def _clean_query(self, query: str, applicant: Optional[str]) -> str:
        """μΏΌλ¦¬μ—μ„ νμ‚¬λ…κ³Ό μ”μ²­λ¬Έ μ κ±°ν•μ—¬ κ²€μƒ‰ ν‚¤μ›λ“λ§ μ¶”μ¶"""
        import re
        
        clean = query
        
        # νμ‚¬λ… μ κ±°
        if applicant:
            clean = clean.replace(applicant, "").strip()
        
        # μ”μ²­λ¬Έ/λ…λ Ήμ–΄ ν¨ν„΄ μ κ±° (λ” ν¬κ΄„μ )
        request_patterns = [
            r'λ¶„μ„\s*ν•΄\s*μ£Ό\s*μ„Έ\s*μ”', r'λ¶„μ„ν•΄μ£Όμ„Έμ”', r'λ¶„μ„ν•΄μ¤',
            r'κ²€μƒ‰\s*ν•΄\s*μ£Ό\s*μ„Έ\s*μ”', r'κ²€μƒ‰ν•΄μ£Όμ„Έμ”', r'κ²€μƒ‰ν•΄μ¤',
            r'ν•΄\s*μ£Ό\s*μ„Έ\s*μ”', r'ν•΄μ£Όμ„Έμ”', r'ν•΄\s*μ¤',
            r'μ•λ ¤\s*μ£Ό\s*μ„Έ\s*μ”', r'μ•λ ¤μ£Όμ„Έμ”', r'μ•λ ¤\s*μ¤',
            r'μ°Ύμ•„\s*μ£Ό\s*μ„Έ\s*μ”', r'μ°Ύμ•„μ£Όμ„Έμ”', r'μ°Ύμ•„\s*μ¤',
            r'μ΅°μ‚¬\s*ν•΄\s*μ£Ό\s*μ„Έ\s*μ”', r'μ΅°μ‚¬ν•΄μ£Όμ„Έμ”',
            r'λ³΄μ—¬\s*μ£Ό\s*μ„Έ\s*μ”', r'λ³΄μ—¬μ£Όμ„Έμ”', r'λ³΄μ—¬\s*μ¤',
            r'ν™•μΈ\s*ν•΄\s*μ£Ό\s*μ„Έ\s*μ”', r'ν™•μΈν•΄μ£Όμ„Έμ”',
            r'\?$', r'\.$'
        ]
        for pattern in request_patterns:
            clean = re.sub(pattern, '', clean, flags=re.IGNORECASE)
        
        # "~μ", "~κ°€", "~μ—μ„" λ“± μ΅°μ‚¬ μ κ±°
        clean = re.sub(r'^[μκ°€μ—μ„μ€λ”μ„λ¥Όμ΄]\s*', '', clean)
        clean = re.sub(r'[μκ°€μ—μ„μ€λ”μ„λ¥Όμ΄]\s*$', '', clean)
        
        # "νΉν—λ¶„μ„", "νΉν—κ²€μƒ‰" λ“± λ©”νƒ€ λ‹¨μ–΄λ” μ μ§€ν•λ "νΉν—" λ‹¨λ…μ€ μ κ±°
        clean = re.sub(r'\s+νΉν—\s*$', '', clean)
        clean = re.sub(r'^νΉν—\s+', '', clean)
        
        # "μ¶μ›" ν‚¤μ›λ“κ°€ μμΌλ©΄ μ—°λ„ μ •λ³΄ μ¶”μ¶ μ‹λ„
        year_match = re.search(r'(\d{4})\s*λ…„', clean)
        year_filter = year_match.group(1) if year_match else None
        
        # μ—°λ„ ν‘ν„ μ •λ¦¬ ("2024λ…„ μ¶μ›" β†’ "2024"λ§ λ‚¨κΈ°κ±°λ‚ μ κ±°)
        clean = re.sub(r'\d{4}\s*λ…„\s*(μ¶μ›|λ“±λ΅|κ³µκ°)?', '', clean)
        
        # λ¶ν•„μ”ν• λ‹¨μ–΄ μ κ±° (λ” ν¬κ΄„μ )
        noise_words = [
            'μ¶μ›', 'λ“±λ΅', 'κ³µκ°', 'λ¶„μ„', 'κ²€μƒ‰', 'κ΄€λ ¨', 'λ€ν•', 'μ—λ€ν•',
            'νΉν—', 'νΉν—λ¶„μ„', 'νΉν—κ²€μƒ‰', 'ν„ν™©', 'λ³΄κ³ μ„', 'μλ£',
            'μ£Όμ„Έμ”', 'ν•΄μ¤', 'μ£Όμ„Έ', 'ν•΄μ£Ό',
            'κ±΄μ', 'κ°μ', 'λ‡κ°', 'μ–Όλ§λ‚', 'μλ‰', 'ν†µκ³„', 'μ•μ', 'μλ‚μ”', 'μμ„κΉμ”', 'κ±΄μλ¥Ό',
            'μ¶μ›κ±΄μ', 'λ“±λ΅κ±΄μ', 'νΉν—μ', 'νΉν—κ±΄μ'
        ]
        for word in noise_words:
            clean = clean.replace(word, ' ')
            
        # νΉμλ¬Έμ μ κ±° (μ‰Όν‘ λ“±)
        clean = re.sub(r'[,;]', ' ', clean)
        
        # μ—°μ† κ³µλ°± μ •λ¦¬
        clean = re.sub(r'\s+', ' ', clean).strip()
        
        # κ²°κ³Όκ°€ λΉ„μ–΄μμΌλ©΄ μ›λ³Έμ—μ„ ν•µμ‹¬ ν‚¤μ›λ“ μ¶”μ¶ μ‹λ„
        if not clean or len(clean) < 2:
            # μ›λ³Έ μΏΌλ¦¬μ—μ„ κΈ°μ  κ΄€λ ¨ λ…μ‚¬ μ¶”μ¶ (κ°„λ‹¨ν• ν¨ν„΄)
            tech_nouns = re.findall(r'[κ°€-ν£]{2,}(?:μ „μ|κΈ°μ |μ‹μ¤ν…|λ°°ν„°λ¦¬|λ°λ„μ²΄|λ””μ¤ν”λ μ΄|μλ™μ°¨|λ΅λ΄‡|AI|μΈκ³µμ§€λ¥)?', query)
            if tech_nouns:
                # νμ‚¬λ…κ³Ό μΌλ° λ‹¨μ–΄ μ μ™Έ
                exclude_words = [applicant, 'νΉν—', 'μ¶μ›', 'λ¶„μ„', 'κ²€μƒ‰', 'ν•΄μ£Όμ„Έμ”', 'μ£Όμ„Έμ”'] if applicant else ['νΉν—', 'μ¶μ›', 'λ¶„μ„', 'κ²€μƒ‰', 'ν•΄μ£Όμ„Έμ”', 'μ£Όμ„Έμ”']
                tech_nouns = [n for n in tech_nouns if n not in exclude_words and len(n) >= 2]
                if tech_nouns:
                    clean = ' '.join(tech_nouns[:3])  # μƒμ„ 3κ°
        
        # π†• μ¶μ›μΈλ§ κ²€μƒ‰ν•λ” κ²½μ° (κΈ°μ  ν‚¤μ›λ“ μ—†μ) - λΉ λ¬Έμμ—΄ λ°ν™
        # μ΄λ ‡κ² ν•λ©΄ KIPRIS/SerpAPIκ°€ μ¶μ›μΈ κΈ°λ°μΌλ΅λ§ κ²€μƒ‰
        noise_check = ['νΉν—', 'λ¶„μ„', 'κ²€μƒ‰', 'ν„ν™©', 'μλ£', 'λ³΄κ³ μ„']
        if not clean or len(clean) < 2 or clean in noise_check or clean == applicant:
            logger.debug(f"π” μ¶μ›μΈλ§ κ²€μƒ‰: '{applicant}', μ›λ³Έ μΏΌλ¦¬: '{query}'")
            return ""
        
        return clean.strip()
    
    # =========================================================================
    # μ‹κ°ν™” μƒμ„± λ©”μ„λ“
    # =========================================================================
    
    def _generate_search_visualizations(self, patents: List[PatentData]) -> List[VisualizationData]:
        """κ²€μƒ‰ κ²°κ³Ό μ‹κ°ν™” μƒμ„±"""
        visualizations = []
        
        # 1. μ¶μ›μΈλ³„ νΉν— μ (νμ΄ μ°¨νΈ)
        applicant_counts = {}
        for p in patents:
            applicant = p.applicant or "Unknown"
            applicant_counts[applicant] = applicant_counts.get(applicant, 0) + 1
        
        visualizations.append(VisualizationData(
            chart_type="pie",
            title="μ¶μ›μΈλ³„ νΉν— λ¶„ν¬",
            data={
                "labels": list(applicant_counts.keys()),
                "values": list(applicant_counts.values())
            },
            options={"showLegend": True}
        ))
        
        # 2. μ—°λ„λ³„ μ¶μ› μ¶”μ΄ (λΌμΈ μ°¨νΈ)
        year_counts = {}
        for p in patents:
            if p.application_date:
                year = p.application_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        sorted_years = sorted(year_counts.keys())
        visualizations.append(VisualizationData(
            chart_type="line",
            title="μ—°λ„λ³„ νΉν— μ¶μ› μ¶”μ΄",
            data={
                "labels": sorted_years,
                "datasets": [{
                    "label": "νΉν— μ",
                    "data": [year_counts[y] for y in sorted_years]
                }]
            },
            options={"xAxisLabel": "λ…„λ„", "yAxisLabel": "νΉν— μ"}
        ))
        
        # 3. IPC λ¶„λ¥λ³„ λ¶„ν¬ (λ°” μ°¨νΈ)
        ipc_counts = {}
        for p in patents:
            for ipc in (p.ipc_codes or [])[:1]:  # μ²« λ²μ§Έ IPCλ§
                main_class = ipc[:4] if len(ipc) >= 4 else ipc
                ipc_counts[main_class] = ipc_counts.get(main_class, 0) + 1
        
        sorted_ipc = sorted(ipc_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        visualizations.append(VisualizationData(
            chart_type="bar",
            title="IPC λ¶„λ¥λ³„ νΉν— λ¶„ν¬ (Top 10)",
            data={
                "labels": [x[0] for x in sorted_ipc],
                "datasets": [{
                    "label": "νΉν— μ",
                    "data": [x[1] for x in sorted_ipc]
                }]
            },
            options={"horizontal": True}
        ))
        
        return visualizations
    
    def _generate_comparison_visualizations(
        self,
        our_patents: List[PatentData],
        competitor_patents: List[PatentData],
        our_company: str,
        competitor: str
    ) -> List[VisualizationData]:
        """κ²½μμ‚¬ λΉ„κµ μ‹κ°ν™” μƒμ„±"""
        visualizations = []
        
        # 1. νΉν— μ λΉ„κµ (λ°” μ°¨νΈ)
        visualizations.append(VisualizationData(
            chart_type="bar",
            title="νΉν— μ λΉ„κµ",
            data={
                "labels": [our_company, competitor],
                "datasets": [{
                    "label": "νΉν— μ",
                    "data": [len(our_patents), len(competitor_patents)]
                }]
            },
            options={"colors": ["#4CAF50", "#2196F3"]}
        ))
        
        # 2. μ—°λ„λ³„ λΉ„κµ (κ·Έλ£Ή λ°” μ°¨νΈ)
        our_years = {}
        comp_years = {}
        
        for p in our_patents:
            if p.application_date:
                year = p.application_date[:4]
                our_years[year] = our_years.get(year, 0) + 1
        
        for p in competitor_patents:
            if p.application_date:
                year = p.application_date[:4]
                comp_years[year] = comp_years.get(year, 0) + 1
        
        all_years = sorted(set(our_years.keys()) | set(comp_years.keys()))
        
        visualizations.append(VisualizationData(
            chart_type="bar",
            title="μ—°λ„λ³„ νΉν— μ¶μ› λΉ„κµ",
            data={
                "labels": all_years,
                "datasets": [
                    {
                        "label": our_company,
                        "data": [our_years.get(y, 0) for y in all_years]
                    },
                    {
                        "label": competitor,
                        "data": [comp_years.get(y, 0) for y in all_years]
                    }
                ]
            },
            options={"grouped": True}
        ))
        
        # 3. IPC λ¶„λ¥ λΉ„κµ (λ μ΄λ” μ°¨νΈ)
        our_ipc = {}
        comp_ipc = {}
        
        for p in our_patents:
            for ipc in (p.ipc_codes or [])[:1]:
                main_class = ipc[:4] if len(ipc) >= 4 else ipc
                our_ipc[main_class] = our_ipc.get(main_class, 0) + 1
        
        for p in competitor_patents:
            for ipc in (p.ipc_codes or [])[:1]:
                main_class = ipc[:4] if len(ipc) >= 4 else ipc
                comp_ipc[main_class] = comp_ipc.get(main_class, 0) + 1
        
        all_ipc = list(set(our_ipc.keys()) | set(comp_ipc.keys()))[:8]
        
        visualizations.append(VisualizationData(
            chart_type="radar",
            title="κΈ°μ  λ¶„μ•Όλ³„ νΉν— λΉ„κµ",
            data={
                "labels": all_ipc,
                "datasets": [
                    {
                        "label": our_company,
                        "data": [our_ipc.get(ipc, 0) for ipc in all_ipc]
                    },
                    {
                        "label": competitor,
                        "data": [comp_ipc.get(ipc, 0) for ipc in all_ipc]
                    }
                ]
            },
            options={}
        ))
        
        return visualizations
    
    def _generate_trend_visualizations(
        self,
        patents: List[PatentData],
        time_range_years: int
    ) -> List[VisualizationData]:
        """νΈλ λ“ μ‹κ°ν™” μƒμ„±"""
        visualizations = []
        
        # μ—°λ„λ³„ μ¶μ› μ¶”μ΄
        year_counts = {}
        for p in patents:
            if p.application_date:
                year = p.application_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        sorted_years = sorted(year_counts.keys())
        
        visualizations.append(VisualizationData(
            chart_type="line",
            title=f"μµκ·Ό {time_range_years}λ…„ νΉν— μ¶μ› νΈλ λ“",
            data={
                "labels": sorted_years,
                "datasets": [{
                    "label": "μ¶μ› μ",
                    "data": [year_counts[y] for y in sorted_years],
                    "fill": True
                }]
            },
            options={"xAxisLabel": "λ…„λ„", "yAxisLabel": "μ¶μ› μ", "tension": 0.4}
        ))
        
        return visualizations
    
    def _generate_portfolio_visualizations(
        self,
        patents: List[PatentData],
        company: Optional[str]
    ) -> List[VisualizationData]:
        """ν¬νΈν΄λ¦¬μ¤ μ‹κ°ν™” μƒμ„±"""
        visualizations = []
        
        # μƒνƒλ³„ λ¶„ν¬
        status_counts = {}
        for p in patents:
            status = p.status.value if p.status else "unknown"
            status_counts[status] = status_counts.get(status, 0) + 1
        
        visualizations.append(VisualizationData(
            chart_type="pie",
            title=f"{company or 'μ „μ²΄'} νΉν— μƒνƒ λ¶„ν¬",
            data={
                "labels": list(status_counts.keys()),
                "values": list(status_counts.values())
            },
            options={"showLegend": True}
        ))
        
        return visualizations
    
    def _generate_gap_visualizations(
        self,
        our_patents: List[PatentData],
        competitor_patents: List[PatentData],
        our_company: str,
        competitor: str
    ) -> List[VisualizationData]:
        """κΈ°μ  κ³µλ°± μ‹κ°ν™” μƒμ„±"""
        # κ²½μμ‚¬ λΉ„κµμ™€ μ μ‚¬ν•μ§€λ§ κ³µλ°± κ°•μ΅°
        return self._generate_comparison_visualizations(
            our_patents, competitor_patents, our_company, competitor
        )
    
    # =========================================================================
    # μ”μ•½ μƒμ„± λ©”μ„λ“
    # =========================================================================
    
    async def _generate_search_summary(
        self,
        original_query: str,
        patents: List[PatentData],
        applicant: Optional[str],
        year_filter: Optional[str] = None
    ) -> str:
        """κ²€μƒ‰ κ²°κ³Ό μƒμ„Έ μ”μ•½ μƒμ„±"""
        if not patents:
            no_result_msg = f"'{original_query}' κ²€μƒ‰ κ²°κ³Ό, κ΄€λ ¨ νΉν—λ¥Ό μ°Ύμ§€ λ»ν–μµλ‹λ‹¤."
            if applicant:
                no_result_msg += f"\n\n**μ°Έκ³ :** {applicant}μ νΉν—λ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤. λ‹¤λ¥Έ κ²€μƒ‰μ–΄λ‚ κΈ°κ°„μ„ μ‹λ„ν•΄ λ³΄μ„Έμ”."
            return no_result_msg
        
        # κΈ°λ³Έ μ •λ³΄
        summary_parts = []
        
        # ν—¤λ”
        if applicant and year_filter:
            summary_parts.append(f"## π“ {applicant} {year_filter}λ…„ νΉν— λ¶„μ„ κ²°κ³Ό\n")
        elif applicant:
            summary_parts.append(f"## π“ {applicant} νΉν— λ¶„μ„ κ²°κ³Ό\n")
        else:
            summary_parts.append(f"## π“ νΉν— κ²€μƒ‰ κ²°κ³Ό\n")
        
        # κ²€μƒ‰ κ°μ”
        summary_parts.append(f"### π“‹ κ²€μƒ‰ κ°μ”")
        summary_parts.append(f"- **μ΄ κ²€μƒ‰ κ²°κ³Ό:** {len(patents)}κ±΄")
        if applicant:
            summary_parts.append(f"- **μ¶μ›μΈ:** {applicant}")
        if year_filter:
            summary_parts.append(f"- **λ¶„μ„ κΈ°κ°„:** {year_filter}λ…„")
        summary_parts.append("")
        
        # μ—°λ„λ³„ λ¶„ν¬ λ¶„μ„
        year_counts = {}
        for p in patents:
            if p.application_date:
                year = p.application_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        if year_counts:
            summary_parts.append(f"### π“… μ—°λ„λ³„ μ¶μ› ν„ν™©")
            sorted_years = sorted(year_counts.items(), key=lambda x: x[0], reverse=True)
            for year, count in sorted_years[:5]:
                bar = "β–" * min(count, 20)
                summary_parts.append(f"- **{year}λ…„:** {count}κ±΄ {bar}")
            summary_parts.append("")
        
        # κΈ°μ  λ¶„λ¥ (IPC) λ¶„μ„
        ipc_counts = {}
        for p in patents:
            if p.ipc_codes:
                for ipc in p.ipc_codes[:2]:  # μƒμ„ 2κ° IPCλ§
                    main_ipc = ipc[:4] if len(ipc) >= 4 else ipc
                    ipc_counts[main_ipc] = ipc_counts.get(main_ipc, 0) + 1
        
        if ipc_counts:
            summary_parts.append(f"### π”¬ μ£Όμ” κΈ°μ  λ¶„λ¥ (IPC)")
            ipc_descriptions = self._get_ipc_descriptions()
            sorted_ipc = sorted(ipc_counts.items(), key=lambda x: x[1], reverse=True)[:5]
            for ipc, count in sorted_ipc:
                desc = ipc_descriptions.get(ipc[:3], ipc_descriptions.get(ipc[:1], "κΈ°νƒ€"))
                summary_parts.append(f"- **{ipc}** ({desc}): {count}κ±΄")
            summary_parts.append("")
        
        # λ€ν‘ νΉν— λ©λ΅
        summary_parts.append(f"### π“„ μ£Όμ” νΉν— ({min(5, len(patents))}κ±΄)")
        for i, p in enumerate(patents[:5], 1):
            title = p.title[:60] + "..." if len(p.title) > 60 else p.title
            date_info = f", μ¶μ›μΌ: {p.application_date}" if p.application_date else ""
            status = f" [{p.status}]" if p.status else ""
            summary_parts.append(f"{i}. **{title}**{status}")
            summary_parts.append(f"   - μ¶μ›λ²νΈ: {p.patent_number}{date_info}")
        summary_parts.append("")
        
        # λ¶„μ„ μ”μ•½
        summary_parts.append(f"### π’΅ λ¶„μ„ μ”μ•½")
        
        # μ¶μ› νΈλ λ“ λ¶„μ„
        if len(year_counts) >= 2:
            years = sorted(year_counts.keys())
            recent_years = years[-2:]
            if len(recent_years) == 2:
                older, newer = recent_years
                older_count = year_counts.get(older, 0)
                newer_count = year_counts.get(newer, 0)
                if newer_count > older_count:
                    growth = ((newer_count - older_count) / max(older_count, 1)) * 100
                    summary_parts.append(f"- π“ **μ¶μ› μ¦κ°€ μ¶”μ„Έ**: {older}λ…„ λ€λΉ„ {newer}λ…„ {growth:.0f}% μ¦κ°€")
                elif newer_count < older_count:
                    decline = ((older_count - newer_count) / max(older_count, 1)) * 100
                    summary_parts.append(f"- π“‰ **μ¶μ› κ°μ† μ¶”μ„Έ**: {older}λ…„ λ€λΉ„ {newer}λ…„ {decline:.0f}% κ°μ†")
                else:
                    summary_parts.append(f"- β΅οΈ **μ¶μ› μ μ§€**: μ•μ •μ μΈ νΉν— μ¶μ› ν™λ™")
        
        # κΈ°μ  μ§‘μ¤‘λ„
        if ipc_counts:
            top_ipc = sorted(ipc_counts.items(), key=lambda x: x[1], reverse=True)[0]
            concentration = (top_ipc[1] / len(patents)) * 100
            if concentration > 50:
                summary_parts.append(f"- π― **κΈ°μ  μ§‘μ¤‘λ„ λ†’μ**: {top_ipc[0]} λ¶„μ•Όμ— {concentration:.0f}% μ§‘μ¤‘")
            else:
                summary_parts.append(f"- π **κΈ°μ  λ‹¤κ°ν™”**: λ‹¤μ–‘ν• κΈ°μ  λ¶„μ•Όμ— λ¶„μ‚° μ¶μ›")
        
        # κΈ°λ³Έ μ”μ•½ μƒμ„±
        base_summary = "\n".join(summary_parts)
        
        # π†• LLM κΈ°λ° μ‹¬μΈµ λ¶„μ„ μ¶”κ°€
        try:
            llm_analysis = await self._generate_llm_analysis(
                original_query=original_query,
                patents=patents,
                applicant=applicant,
                year_filter=year_filter,
                year_counts=year_counts,
                ipc_counts=ipc_counts
            )
            if llm_analysis:
                base_summary += f"\n\n{llm_analysis}"
        except Exception as e:
            logger.warning(f"β οΈ LLM λ¶„μ„ μƒμ„± μ‹¤ν¨: {e}")
        
        return base_summary
    
    async def _generate_llm_analysis(
        self,
        original_query: str,
        patents: List[PatentData],
        applicant: Optional[str],
        year_filter: Optional[str],
        year_counts: Dict[str, int],
        ipc_counts: Dict[str, int]
    ) -> Optional[str]:
        """LLMμ„ μ‚¬μ©ν• μ‹¬μΈµ λ¶„μ„ μƒμ„±"""
        if not patents or len(patents) < 3:
            return None
        
        try:
            # μ‹μ¤ν… ν”„λ΅¬ν”„νΈ λ΅λ”©
            system_prompt = load_patent_analysis_prompt()
            
            # νΉν— λ°μ΄ν„° μ”μ•½ (LLM μ…λ ¥μ©)
            patent_summary = self._prepare_patents_for_llm(patents[:10])  # μƒμ„ 10κ±΄λ§
            
            # λ¶„μ„ μ»¨ν…μ¤νΈ κµ¬μ„±
            context = f"""
## λ¶„μ„ μ”μ²­
{original_query}

## νΉν— λ°μ΄ν„° μ”μ•½
- μ΄ νΉν— μ: {len(patents)}κ±΄
- μ¶μ›μΈ: {applicant or 'μ „μ²΄'}
- λ¶„μ„ κΈ°κ°„: {year_filter or 'μ „μ²΄ κΈ°κ°„'}

## μ—°λ„λ³„ μ¶μ› ν„ν™©
{self._format_year_counts(year_counts)}

## κΈ°μ  λ¶„λ¥ (IPC) λ¶„ν¬
{self._format_ipc_counts(ipc_counts)}

## μ£Όμ” νΉν— λ©λ΅
{patent_summary}

μ„ λ°μ΄ν„°λ¥Ό λ¶„μ„ν•μ—¬ λ‹¤μμ„ μ κ³µν•΄ μ£Όμ„Έμ”:
1. κΈ°μ  νΈλ λ“ λ¶„μ„ (2-3λ¬Έμ¥)
2. ν•µμ‹¬ μΈμ‚¬μ΄νΈ (3κ°)
3. μ „λµμ  κ¶κ³  (2-3κ°)
"""
            
            # LLM νΈμ¶
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": context}
            ]
            
            response = await ai_service.chat_completion(
                messages=messages,
                max_tokens=1500,
                temperature=0.7
            )
            
            if response and response.get("response"):
                return f"### π¤– AI μ‹¬μΈµ λ¶„μ„\n\n{response['response']}"
            
        except Exception as e:
            logger.error(f"β LLM λ¶„μ„ μ¤λ¥: {e}")
        
        return None
    
    def _prepare_patents_for_llm(self, patents: List[PatentData]) -> str:
        """LLM μ…λ ¥μ© νΉν— λ°μ΄ν„° ν¬λ§·ν…"""
        lines = []
        for i, p in enumerate(patents, 1):
            title = p.title[:80] if p.title else "μ λ© μ—†μ"
            applicant = p.applicant or "μ¶μ›μΈ λ―Έμƒ"
            date = p.application_date or "λ‚ μ§ λ―Έμƒ"
            ipc = ", ".join(p.ipc_codes[:2]) if p.ipc_codes else "λ¶„λ¥ λ―Έμƒ"
            abstract = (p.abstract[:150] + "...") if p.abstract and len(p.abstract) > 150 else (p.abstract or "")
            
            lines.append(f"{i}. **{title}**")
            lines.append(f"   - μ¶μ›μΈ: {applicant}, μ¶μ›μΌ: {date}")
            lines.append(f"   - IPC: {ipc}")
            if abstract:
                lines.append(f"   - μ”μ•½: {abstract}")
        
        return "\n".join(lines)
    
    def _format_year_counts(self, year_counts: Dict[str, int]) -> str:
        """μ—°λ„λ³„ μ¶μ› μ ν¬λ§·ν…"""
        if not year_counts:
            return "λ°μ΄ν„° μ—†μ"
        
        sorted_years = sorted(year_counts.items(), key=lambda x: x[0], reverse=True)
        return "\n".join([f"- {year}λ…„: {count}κ±΄" for year, count in sorted_years[:5]])
    
    def _format_ipc_counts(self, ipc_counts: Dict[str, int]) -> str:
        """IPC λ¶„ν¬ ν¬λ§·ν…"""
        if not ipc_counts:
            return "λ°μ΄ν„° μ—†μ"
        
        ipc_desc = self._get_ipc_descriptions()
        sorted_ipc = sorted(ipc_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        lines = []
        for ipc, count in sorted_ipc:
            desc = ipc_desc.get(ipc[:3], ipc_desc.get(ipc[:1], "κΈ°νƒ€"))
            lines.append(f"- {ipc} ({desc}): {count}κ±΄")
        return "\n".join(lines)
    
    def _get_ipc_descriptions(self) -> Dict[str, str]:
        """IPC μ½”λ“ μ„¤λ…"""
        return {
            "A": "μƒν™ν•„μν’",
            "B": "μ²λ¦¬μ΅°μ‘/μ΄μ",
            "C": "ν™”ν•™/μ•ΌκΈ",
            "D": "μ„¬μ /μ μ§€",
            "E": "κ³ μ •κµ¬μ΅°λ¬Ό",
            "F": "κΈ°κ³„κ³µν•™/μ΅°λ…/κ°€μ—΄",
            "G": "λ¬Όλ¦¬ν•™",
            "H": "μ „κΈ°",
            "G01": "μΈ΅μ •/μ‹ν—",
            "G02": "κ΄‘ν•™",
            "G06": "μ»΄ν“¨ν…/κ³„μ‚°",
            "G09": "κµμ΅/μ•”νΈ",
            "H01": "μ „κΈ°μ†μ",
            "H02": "μ „λ ¥μƒμ‚°/λ³€ν™",
            "H04": "μ „κΈ°ν†µμ‹ ",
            "H05": "μ „κΈ°κΈ°μ ",
            "B60": "μ°¨λ‰μΌλ°",
            "B62": "λ¬΄κ¶¤λ„μ°¨λ‰",
            "C07": "μ κΈ°ν™”ν•™",
            "C08": "μ κΈ°κ³ λ¶„μν™”ν•©λ¬Ό",
            "F16": "κΈ°κ³„μ”μ†",
        }
    
    async def _generate_comparison_summary(
        self,
        query: str,
        our_company: str,
        competitor: str,
        our_patents: List[PatentData],
        competitor_patents: List[PatentData],
        analysis_result: Any
    ) -> str:
        """κ²½μμ‚¬ λΉ„κµ μ”μ•½ μƒμ„±"""
        summary = f"**'{query}' κ΄€λ ¨ νΉν— λΉ„κµ λ¶„μ„**\n\n"
        summary += f"| κµ¬λ¶„ | {our_company} | {competitor} |\n"
        summary += f"|------|--------|--------|\n"
        summary += f"| νΉν— μ | {len(our_patents)}κ±΄ | {len(competitor_patents)}κ±΄ |\n"
        
        # μ°¨μ΄ λ¶„μ„
        diff = len(our_patents) - len(competitor_patents)
        if diff > 0:
            summary += f"\nβ… **{our_company}**κ°€ {abs(diff)}κ±΄ λ” λ§μ€ νΉν—λ¥Ό λ³΄μ ν•κ³  μμµλ‹λ‹¤.\n"
        elif diff < 0:
            summary += f"\nβ οΈ **{competitor}**κ°€ {abs(diff)}κ±΄ λ” λ§μ€ νΉν—λ¥Ό λ³΄μ ν•κ³  μμµλ‹λ‹¤.\n"
        else:
            summary += f"\nπ”„ μ–‘μ‚¬μ νΉν— μκ°€ λ™μΌν•©λ‹λ‹¤.\n"
        
        return summary
    
    async def _generate_trend_summary(
        self,
        query: str,
        patents: List[PatentData],
        time_range_years: int,
        analysis_result: Any
    ) -> str:
        """νΈλ λ“ λ¶„μ„ μ”μ•½ μƒμ„±"""
        summary = f"**'{query}' μµκ·Ό {time_range_years}λ…„ νΉν— νΈλ λ“**\n\n"
        summary += f"- λ¶„μ„ λ€μƒ: **{len(patents)}κ±΄**\n"
        
        # μ—°λ„λ³„ ν†µκ³„
        year_counts = {}
        for p in patents:
            if p.application_date:
                year = p.application_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        if year_counts:
            max_year = max(year_counts.items(), key=lambda x: x[1])
            min_year = min(year_counts.items(), key=lambda x: x[1])
            summary += f"- μµλ‹¤ μ¶μ› μ—°λ„: {max_year[0]} ({max_year[1]}κ±΄)\n"
            summary += f"- μµμ† μ¶μ› μ—°λ„: {min_year[0]} ({min_year[1]}κ±΄)\n"
            
            # νΈλ λ“ λ°©ν–¥
            years = sorted(year_counts.keys())
            if len(years) >= 2:
                recent = year_counts.get(years[-1], 0)
                older = year_counts.get(years[-2], 0)
                if recent > older:
                    summary += f"\nπ“ μ¶μ› νΈλ λ“: **μƒμΉμ„Έ** (μ „λ…„ λ€λΉ„ +{recent - older}κ±΄)\n"
                elif recent < older:
                    summary += f"\nπ“‰ μ¶μ› νΈλ λ“: **ν•λ½μ„Έ** (μ „λ…„ λ€λΉ„ {recent - older}κ±΄)\n"
                else:
                    summary += f"\nβ΅οΈ μ¶μ› νΈλ λ“: **μ μ§€**\n"
        
        return summary
    
    async def _generate_portfolio_summary(
        self,
        query: str,
        company: Optional[str],
        patents: List[PatentData],
        portfolio_result: Any,
        topic_result: Any
    ) -> str:
        """ν¬νΈν΄λ¦¬μ¤ λ¶„μ„ μ”μ•½ μƒμ„±"""
        summary = f"**{company or 'μ „μ²΄'} νΉν— ν¬νΈν΄λ¦¬μ¤ λ¶„μ„**\n\n"
        summary += f"- μ΄ νΉν—: **{len(patents)}κ±΄**\n"
        
        # μƒνƒλ³„ λ¶„ν¬
        status_counts = {}
        for p in patents:
            status = p.status.value if p.status else "unknown"
            status_counts[status] = status_counts.get(status, 0) + 1
        
        summary += f"- λ“±λ΅ νΉν—: {status_counts.get('granted', 0)}κ±΄\n"
        summary += f"- μ¶μ› μ¤‘: {status_counts.get('application', 0)}κ±΄\n"
        summary += f"- κ³µκ°: {status_counts.get('published', 0)}κ±΄\n"
        
        return summary
    
    async def _generate_gap_summary(
        self,
        query: str,
        our_company: str,
        competitor: str,
        analysis_result: Any
    ) -> str:
        """κΈ°μ  κ³µλ°± λ¶„μ„ μ”μ•½ μƒμ„±"""
        summary = f"**'{query}' κΈ°μ  κ³µλ°± λ¶„μ„**\n\n"
        summary += f"- λΉ„κµ λ€μƒ: **{our_company}** vs **{competitor}**\n\n"
        
        if hasattr(analysis_result, 'data') and analysis_result.data:
            gaps = analysis_result.data.get('gaps', [])
            if gaps:
                summary += "**μ°λ¦¬κ°€ λ³΄μ™„ν•΄μ•Ό ν•  κΈ°μ  λ¶„μ•Ό:**\n"
                for gap in gaps[:5]:
                    summary += f"- {gap.get('area', 'N/A')}: {gap.get('description', '')}\n"
        
        return summary
    
    # =========================================================================
    # μΈμ‚¬μ΄νΈ μ¶”μ¶ λ©”μ„λ“
    # =========================================================================
    
    def _extract_search_insights(self, patents: List[PatentData], applicant: Optional[str] = None) -> List[str]:
        """κ²€μƒ‰ κ²°κ³Ό μΈμ‚¬μ΄νΈ μ¶”μ¶"""
        insights = []
        
        if not patents:
            return ["κ²€μƒ‰ κ²°κ³Όκ°€ μ—†μµλ‹λ‹¤. λ‹¤λ¥Έ κ²€μƒ‰μ–΄λ‚ κΈ°κ°„μ„ μ‹λ„ν•΄ λ³΄μ„Έμ”."]
        
        # 1. μ¶μ› ν™λ™ λ¶„μ„
        year_counts = {}
        for p in patents:
            if p.application_date:
                year = p.application_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        if year_counts:
            sorted_years = sorted(year_counts.keys())
            if len(sorted_years) >= 2:
                recent = sorted_years[-1]
                prev = sorted_years[-2]
                recent_count = year_counts[recent]
                prev_count = year_counts[prev]
                
                if recent_count > prev_count * 1.2:
                    insights.append(f"π“ {recent}λ…„ μ¶μ›μ΄ μ „λ…„ λ€λΉ„ μ¦κ°€ν•μ—¬ R&D ν™λ™μ΄ ν™λ°ν•΄μ§€κ³  μμµλ‹λ‹¤.")
                elif recent_count < prev_count * 0.8:
                    insights.append(f"π“‰ {recent}λ…„ μ¶μ›μ΄ μ „λ…„ λ€λΉ„ κ°μ†ν•μ—¬ ν•΄λ‹Ή λ¶„μ•Ό ν¬μκ°€ μ¤„μ–΄λ“¤ μ μμµλ‹λ‹¤.")
        
        # 2. κΈ°μ  μ§‘μ¤‘λ„ λ¶„μ„
        ipc_counts = {}
        for p in patents:
            if p.ipc_codes:
                for ipc in p.ipc_codes[:1]:
                    main_ipc = ipc[:4] if len(ipc) >= 4 else ipc
                    ipc_counts[main_ipc] = ipc_counts.get(main_ipc, 0) + 1
        
        if ipc_counts:
            top_ipc = max(ipc_counts.items(), key=lambda x: x[1])
            concentration = (top_ipc[1] / len(patents)) * 100
            ipc_desc = self._get_ipc_descriptions()
            desc = ipc_desc.get(top_ipc[0][:3], ipc_desc.get(top_ipc[0][:1], "κΈ°μ "))
            
            if concentration > 50:
                insights.append(f"π― {desc} λ¶„μ•Ό({top_ipc[0]})μ— {concentration:.0f}%κ°€ μ§‘μ¤‘λμ–΄ ν•µμ‹¬ κΈ°μ  μμ—­μΌλ΅ λ³΄μ…λ‹λ‹¤.")
            elif concentration > 30:
                insights.append(f"β΅ {desc} λ¶„μ•Ό({top_ipc[0]})κ°€ μ£Όλ ¥μ΄λ‚, λ‹¤λ¥Έ κΈ°μ  λ¶„μ•Όλ΅λ„ ν™•μ¥ μ¤‘μ…λ‹λ‹¤.")
        
        # 3. μµκ·Ό νΉν— λ™ν–¥
        current_year = str(datetime.now().year)
        recent_patents = [p for p in patents if p.application_date and p.application_date[:4] >= str(int(current_year) - 1)]
        if recent_patents:
            insights.append(f"π”¥ μµκ·Ό 2λ…„ λ‚΄ {len(recent_patents)}κ±΄μ ν™λ°ν• μ¶μ›μΌλ΅ μ§€μ†μ μΈ κΈ°μ  κ°λ°μ΄ μ§„ν–‰ μ¤‘μ…λ‹λ‹¤.")
        
        # 4. μ¶μ›μΈ λ¶„μ„ (νΉμ • μ¶μ›μΈ κ²€μƒ‰μ΄ μ•„λ‹ κ²½μ°)
        if not applicant:
            applicant_counts = {}
            for p in patents:
                app = p.applicant or "Unknown"
                applicant_counts[app] = applicant_counts.get(app, 0) + 1
            
            if applicant_counts:
                top_app = max(applicant_counts.items(), key=lambda x: x[1])
                if top_app[1] > len(patents) * 0.3:
                    insights.append(f"π‘‘ {top_app[0]}μ΄(κ°€) ν•΄λ‹Ή λ¶„μ•Όμ—μ„ {top_app[1]}κ±΄({top_app[1]/len(patents)*100:.0f}%)μΌλ΅ μ„ λ„μ  μ„μΉμ…λ‹λ‹¤.")
        
        # 5. νΉν— μƒνƒ λ¶„μ„
        status_counts = {}
        for p in patents:
            status = p.status or "Unknown"
            status_counts[status] = status_counts.get(status, 0) + 1
        
        if "λ“±λ΅" in status_counts:
            registered = status_counts["λ“±λ΅"]
            if registered > len(patents) * 0.5:
                insights.append(f"β… λ“±λ΅ νΉν—κ°€ {registered}κ±΄({registered/len(patents)*100:.0f}%)μΌλ΅ κΈ°μ λ ¥μ΄ μΈμ •λ°›κ³  μμµλ‹λ‹¤.")
        
        if "κ³µκ°" in status_counts:
            published = status_counts["κ³µκ°"]
            if published > len(patents) * 0.3:
                insights.append(f"π“ κ³µκ° νΉν—κ°€ {published}κ±΄μΌλ΅ ν–¥ν›„ λ“±λ΅ κ°€λ¥μ„±μ΄ μλ” κΈ°μ λ“¤μ΄ λ§μµλ‹λ‹¤.")
        
        # μΈμ‚¬μ΄νΈκ°€ μ—†μΌλ©΄ κΈ°λ³Έ λ©”μ‹μ§€
        if not insights:
            insights.append(f"π“ μ΄ {len(patents)}κ±΄μ νΉν—κ°€ κ²€μƒ‰λμ—μµλ‹λ‹¤. μƒμ„Έ λ¶„μ„μ΄ ν•„μ”ν•©λ‹λ‹¤.")
        
        return insights
    
    def _extract_comparison_insights(
        self,
        our_patents: List[PatentData],
        competitor_patents: List[PatentData],
        our_company: str,
        competitor: str
    ) -> List[str]:
        """κ²½μμ‚¬ λΉ„κµ μΈμ‚¬μ΄νΈ μ¶”μ¶"""
        insights = []
        
        # μ–‘μ  λΉ„κµ
        if len(our_patents) > len(competitor_patents) * 1.5:
            insights.append(f"{our_company}κ°€ μ–‘μ μΌλ΅ μ°μ„ (1.5λ°° μ΄μƒ)")
        elif len(competitor_patents) > len(our_patents) * 1.5:
            insights.append(f"{competitor}κ°€ μ–‘μ μΌλ΅ μ°μ„ - νΉν— ν™•λ³΄ μ „λµ κ²€ν†  ν•„μ”")
        
        # IPC λ‹¤μ–‘μ„±
        our_ipc = set()
        comp_ipc = set()
        for p in our_patents:
            our_ipc.update(p.ipc_codes or [])
        for p in competitor_patents:
            comp_ipc.update(p.ipc_codes or [])
        
        if len(our_ipc) > len(comp_ipc) * 1.3:
            insights.append(f"{our_company}κ°€ λ” λ‹¤μ–‘ν• κΈ°μ  λ¶„μ•Όμ— μ§„μ¶")
        elif len(comp_ipc) > len(our_ipc) * 1.3:
            insights.append(f"{competitor}κ°€ λ” λ‹¤μ–‘ν• κΈ°μ  λ¶„μ•Ό λ³΄μ  - κΈ°μ  λ‹¤κ°ν™” κ²€ν†  ν•„μ”")
        
        return insights
    
    def _extract_trend_insights(
        self,
        patents: List[PatentData],
        time_range_years: int
    ) -> List[str]:
        """νΈλ λ“ μΈμ‚¬μ΄νΈ μ¶”μ¶"""
        insights = []
        
        year_counts = {}
        for p in patents:
            if p.application_date:
                year = p.application_date[:4]
                year_counts[year] = year_counts.get(year, 0) + 1
        
        if year_counts:
            years = sorted(year_counts.keys())
            if len(years) >= 3:
                recent_avg = sum(year_counts.get(y, 0) for y in years[-2:]) / 2
                older_avg = sum(year_counts.get(y, 0) for y in years[:-2]) / max(len(years) - 2, 1)
                
                if recent_avg > older_avg * 1.5:
                    insights.append("μµκ·Ό 2λ…„κ°„ μ¶μ›μ΄ κΈ‰μ¦ - ν•΄λ‹Ή λ¶„μ•Ό κΈ°μ  κ²½μ μ‹¬ν™”")
                elif recent_avg < older_avg * 0.5:
                    insights.append("μµκ·Ό μ¶μ› κ°μ† - κΈ°μ  μ„±μ™κΈ° λλ” μ‹μ¥ μΉ¨μ²΄ κ°€λ¥μ„±")
        
        return insights
    
    def _extract_portfolio_insights(
        self,
        patents: List[PatentData],
        company: Optional[str]
    ) -> List[str]:
        """ν¬νΈν΄λ¦¬μ¤ μΈμ‚¬μ΄νΈ μ¶”μ¶"""
        insights = []
        
        # λ“±λ΅λ¥ 
        granted = sum(1 for p in patents if p.status == PatentStatus.GRANTED)
        if patents:
            grant_rate = granted / len(patents) * 100
            if grant_rate > 70:
                insights.append(f"λ†’μ€ λ“±λ΅λ¥  ({grant_rate:.0f}%) - μ°μν• νΉν— ν’μ§")
            elif grant_rate < 30:
                insights.append(f"λ‚®μ€ λ“±λ΅λ¥  ({grant_rate:.0f}%) - νΉν— μ „λµ μ¬κ²€ν†  ν•„μ”")
        
        return insights
    
    def _extract_gap_insights(self, analysis_result: Any) -> List[str]:
        """κΈ°μ  κ³µλ°± μΈμ‚¬μ΄νΈ μ¶”μ¶"""
        insights = []
        
        if hasattr(analysis_result, 'data') and analysis_result.data:
            gaps = analysis_result.data.get('gaps', [])
            if gaps:
                insights.append(f"μ΄ {len(gaps)}κ° κΈ°μ  λ¶„μ•Όμ—μ„ κ³µλ°± λ°κ²¬")
        
        return insights
    
    def _generate_comparison_recommendations(self, analysis_result: Any) -> List[str]:
        """κ²½μμ‚¬ λΉ„κµ κ¶μ¥μ‚¬ν•­ μƒμ„±"""
        recommendations = []
        recommendations.append("κ²½μμ‚¬ ν•µμ‹¬ νΉν—μ— λ€ν• νν”Ό μ„¤κ³„ κ²€ν† ")
        recommendations.append("νΉν— μΈμ© λ„¤νΈμ›ν¬ λ¶„μ„μ„ ν†µν• ν•µμ‹¬ κΈ°μ  νμ•…")
        return recommendations
    
    def _generate_gap_recommendations(self, analysis_result: Any) -> List[str]:
        """κΈ°μ  κ³µλ°± κ¶μ¥μ‚¬ν•­ μƒμ„±"""
        recommendations = []
        recommendations.append("μ‹λ³„λ κΈ°μ  κ³µλ°± λ¶„μ•Όμ— λ€ν• R&D ν¬μ κ²€ν† ")
        recommendations.append("κΈ°μ  λΌμ΄μ„ μ‹± λλ” M&Aλ¥Ό ν†µν• λΉ λ¥Έ κΈ°μ  ν™•λ³΄ κ³ λ ¤")
        return recommendations


# =============================================================================
# Singleton Instance
# =============================================================================

patent_analysis_agent_tool = PatentAnalysisAgentTool()


__all__ = ["PatentAnalysisAgentTool", "patent_analysis_agent_tool"]
