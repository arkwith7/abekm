from typing import TypedDict, Annotated, List, Dict, Any, Optional, Sequence, Literal
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from app.core.config import settings
from app.agents import paper_search_agent
from app.agents import presentation_agent_tool
from app.core.database import get_async_engine
from sqlalchemy.ext.asyncio import async_sessionmaker
from contextlib import asynccontextmanager
import json
import operator
from loguru import logger
from pydantic import BaseModel

# DB Session Helper
@asynccontextmanager
async def get_db_session_context():
    engine = get_async_engine()
    async_session = async_sessionmaker(engine, expire_on_commit=False)
    async with async_session() as session:
        yield session

# State ì •ì˜
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    next: str
    shared_context: Dict[str, Any]

# Supervisor LLM - Use Azure OpenAI
try:
    from app.services.core.ai_service import ai_service
    llm = ai_service.get_chat_model(temperature=0)
    logger.info("âœ… SupervisorAgent initialized with ai_service")
except Exception as e:
    logger.warning(f"âš ï¸ Failed to initialize ai_service, falling back to direct OpenAI: {e}")
    api_key = settings.openai_api_key or settings.azure_openai_api_key
    if not api_key:
        logger.error("âŒ No OpenAI/Azure API key found. SupervisorAgent will not work.")
        llm = None
    else:
        llm = ChatOpenAI(
            model=settings.openai_llm_model or "gpt-4o",
            api_key=api_key,
            temperature=0
        )

# Supervisor Prompt
system_prompt = (
    "You are a supervisor tasked with managing a conversation between the"
    " following workers: {members}. Given the following user request,"
    " respond with the worker to act next. Each worker will perform a"
    " task and respond with their results and status. When finished,"
    " respond with FINISH."
    " If the user asks to create a presentation based on search results,"
    " first call 'SearchAgent', then call 'PresentationAgent'."
    " If the user just asks for a presentation without search context,"
    " you can call 'PresentationAgent' directly."
)

options = ["SearchAgent", "PresentationAgent", "FINISH"]


class RouteDecision(BaseModel):
    next: Literal["SearchAgent", "PresentationAgent", "FINISH"]

# Function definition for routing
function_def = {
    "name": "route",
    "description": "Select the next role.",
    "parameters": {
        "title": "routeSchema",
        "type": "object",
        "properties": {
            "next": {
                "title": "Next",
                "anyOf": [
                    {"enum": options},
                ],
            }
        },
        "required": ["next"],
    },
}

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="messages"),
        (
            "system",
            "Given the conversation above, who should act next?"
            " Or should we FINISH? Select one of: {options}",
        ),
    ]
).partial(options=str(options), members=", ".join(options))

supervisor_chain = (
    prompt
    | llm.with_structured_output(RouteDecision)
)

# Nodes
async def supervisor_node(state: AgentState):
    decision = await supervisor_chain.ainvoke(state)
    return {"next": decision.next}

async def search_node(state: AgentState):
    messages = state["messages"]
    last_message = messages[-1].content
    
    logger.info(f"Supervisor routing to SearchAgent: {last_message[:50]}...")
    
    async with get_db_session_context() as db_session:
        # ê²€ìƒ‰ ì‹¤í–‰
        # constraints ë“±ì€ ê¸°ë³¸ê°’ ì‚¬ìš©
        # history ë³€í™˜ í•„ìš” (BaseMessage -> Dict)
        history_dicts = []
        for msg in messages[:-1]: # ë§ˆì§€ë§‰ ë©”ì‹œì§€ëŠ” queryì´ë¯€ë¡œ ì œì™¸
            role = "user" if isinstance(msg, HumanMessage) else "assistant"
            history_dicts.append({"role": role, "content": msg.content})

        result = await paper_search_agent.execute(
            query=last_message,
            db_session=db_session,
            history=history_dicts
        )
    
    response_content = result.answer
    
    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ shared_contextì— ì €ì¥
    # AgentResult ê°ì²´ ìì²´ë¥¼ ì €ì¥í•˜ì—¬ ë©”íƒ€ë°ì´í„° ë³´ì¡´
    return {
        "messages": [AIMessage(content=response_content, name="SearchAgent")],
        "shared_context": {
            "search_result": response_content,
            "search_agent_result": result  # AgentResult ê°ì²´ ì €ì¥
        }
    }

async def presentation_node(state: AgentState):
    messages = state["messages"]
    # messagesì—ëŠ” User -> SearchAgent(AI) -> ... ìˆœìœ¼ë¡œ ìŒ“ì—¬ìˆìŒ.
    # PresentationAgentì—ê²Œ ì „ë‹¬í•  ë•ŒëŠ” "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ PPT ë§Œë“¤ì–´ì¤˜"ë¼ëŠ” ì˜ë„ê°€ ì „ë‹¬ë˜ì–´ì•¼ í•¨.
    
    shared_context = state.get("shared_context", {})
    search_result = shared_context.get("search_result", "")
    
    logger.info(f"Supervisor routing to PresentationAgent. Context len: {len(search_result)}")
    
    # PresentationAgent Tool ì‹¤í–‰ (New Tool-based Architecture)
    context_text = search_result if search_result else "Create a presentation based on the conversation."
    
    # ì›ë˜ ì‚¬ìš©ì ìš”ì²­ì—ì„œ ì£¼ì œ ì¶”ì¶œ ì‹œë„
    original_query = messages[0].content if messages else ""
    
    try:
        tool_result = await presentation_agent_tool._arun(
            context_text=context_text,
            topic=None,  # ìë™ ì¶”ë¡ 
            documents=[],
            options={},
            template_style="business",
            presentation_type="general",
            quick_mode=False
        )
        
        if tool_result.get("success"):
            file_name = tool_result.get("file_name", "presentation.pptx")
            file_path = tool_result.get("file_path", "")
            final_response = f"âœ… PPT ìƒì„± ì™„ë£Œ!\n\nğŸ“„ íŒŒì¼ëª…: {file_name}\nğŸ’¾ ê²½ë¡œ: {file_path}"
        else:
            error_msg = tool_result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
            final_response = f"âŒ PPT ìƒì„± ì‹¤íŒ¨: {error_msg}"
    
    except Exception as e:
        logger.error(f"PresentationAgent Tool ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        final_response = f"âŒ Presentation generation failed: {str(e)}"
    
    return {
        "messages": [AIMessage(content=final_response, name="PresentationAgent")]
    }

# Graph êµ¬ì„±
workflow = StateGraph(AgentState)
workflow.add_node("supervisor", supervisor_node)
workflow.add_node("SearchAgent", search_node)
workflow.add_node("PresentationAgent", presentation_node)

for member in options[:-1]:
    workflow.add_edge(member, "supervisor")

workflow.add_conditional_edges(
    "supervisor",
    lambda x: END if x["next"] == "FINISH" else x["next"],
)

workflow.set_entry_point("supervisor")

supervisor_agent = workflow.compile()
