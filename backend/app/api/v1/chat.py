from fastapi import APIRouter, Depends, HTTPException, status, Request
from fastapi import UploadFile, File, Form, Query, Header
from fastapi.exceptions import RequestValidationError
from fastapi.responses import StreamingResponse, FileResponse
from pydantic import BaseModel
from typing import List, Optional, Any, Dict
import re
from pydantic import BaseModel
import json
import asyncio
import aiofiles
import base64
import os
import tempfile
from pathlib import Path
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text, select, desc, func, delete
from app.core.database import get_db
from app.services.core.ai_service import ai_service
from app.services.core.vision_service import vision_service
from app.services.search.search_service import search_service
from app.services.chat.rag_search_service import rag_search_service, RAGSearchParams
from app.services.chat.query_classification_service import query_classification_service
from app.services.chat.ai_agent_service import ai_agent_service
from app.services.chat.chat_attachment_service import chat_attachment_service
from app.services.core.audio_transcription_service import audio_transcription_service
from app.core.config import settings

from app.services.multi_agent.integrated_service import integrated_multi_agent_service
from app.schemas.chat import SelectedDocument
from app.core.dependencies import get_current_user
from app.models.chat.redis_schemas import MessageType
from app.models import User, TbChatSessions, TbChatHistory
from app.models.chat import (
    RedisChatManager,
    get_redis_client,
    MessageType,
    ChatSessionStatus,
    RedisKeyPatterns,
    RedisChatTTL,
)

import uuid
from datetime import datetime, timedelta
from loguru import logger


def build_conversation_state(
    response_text: str,
    context_info: Optional[Dict[str, Any]],
    references: Optional[List[Dict[str, Any]]]
) -> Dict[str, Any]:
    summary_source = (response_text or "").strip()
    summary = summary_source[:400].strip() if summary_source else ""

    if not summary and summary_source:
        summary = summary_source

    keywords: List[str] = []
    topic_continuity = 0.0
    last_intent: Optional[str] = None
    hints: List[str] = []
    relevant_documents: List[Dict[str, Any]] = []

    if isinstance(context_info, dict):
        keywords = context_info.get("accumulated_keywords") or context_info.get("keywords") or []
        topic_continuity = context_info.get("topic_continuity") or context_info.get("topic_continuity_score") or 0.0
        last_intent = context_info.get("last_intent") or context_info.get("intent")
        hints = context_info.get("follow_up_questions") or context_info.get("next_questions") or []

        ctx_docs = context_info.get("relevant_documents") or []
        for doc in ctx_docs:
            if isinstance(doc, dict):
                doc_id = doc.get("id") or doc.get("document_id") or doc.get("file_id")
                relevant_documents.append({
                    "id": str(doc_id) if doc_id is not None else uuid.uuid4().hex,
                    "title": doc.get("title") or doc.get("file_name") or "ê´€ë ¨ ë¬¸ì„œ",
                    "containerName": doc.get("container_name"),
                    "similarity": doc.get("similarity") or doc.get("score")
                })
            else:
                relevant_documents.append({
                    "id": str(doc),
                    "title": str(doc),
                })

    if not relevant_documents and references:
        for ref in references[:5]:
            doc_id = ref.get("document_id") or ref.get("file_bss_info_sno") or ref.get("file_id") or uuid.uuid4().hex
            relevant_documents.append({
                "id": str(doc_id),
                "title": ref.get("title") or ref.get("file_name") or "ê´€ë ¨ ë¬¸ì„œ",
                "containerName": ref.get("container_name"),
                "similarity": ref.get("similarity_score")
            })

    state = {
        "updatedAt": datetime.utcnow().isoformat(),
        "summary": summary,
        "keywords": keywords[:10] if keywords else [],
        "topicContinuity": float(topic_continuity) if topic_continuity is not None else 0.0,
        "lastIntent": last_intent,
        "relevantDocuments": relevant_documents,
        "hints": hints or []
    }

    return state


def detect_ppt_format(text: str) -> bool:
    """
    AI ì‘ë‹µì´ PPT í˜•ì‹ì¸ì§€ ê°ì§€í•˜ëŠ” í•¨ìˆ˜
    ë…¸íŠ¸ë¶ì˜ is_ppt_format() í•¨ìˆ˜ì™€ ë™ì¼í•œ ë¡œì§
    
    Args:
        text: ê²€ì‚¬í•  AI ì‘ë‹µ í…ìŠ¤íŠ¸
    
    Returns:
        bool: PPT í˜•ì‹ì´ë©´ True, ì•„ë‹ˆë©´ False
    """
    if not isinstance(text, str) or not text.strip():
        return False
    
    # PPT ëª¨ë“œì—ì„œ ì‚¬ìš©ë˜ëŠ” íŠ¹ì§•ì  í‚¤ì›Œë“œë“¤
    ppt_indicators = ['í‚¤ ë©”ì‹œì§€', 'ìƒì„¸ ì„¤ëª…', 'ğŸ”‘', 'ğŸ“']
    
    # ì¡°ê±´ 1: H2 ì œëª©ì´ ë¬¸ì„œ ì•ìª½(ì²« 500ì ë‚´)ì— ì¡´ì¬
    first_part = text[:500]
    has_h2_early = '## ' in first_part
    
    # ì¡°ê±´ 2: H3 ìŠ¬ë¼ì´ë“œ 1ê°œ ì´ìƒ
    h3_count = text.count('### ')
    many_h3 = h3_count >= 1
    
    # ì¡°ê±´ 3: PPT íŠ¹ì§• í‚¤ì›Œë“œ í¬í•¨
    has_keyblocks = any(keyword in text for keyword in ppt_indicators)
    
    # ëª¨ë“  ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ PPT í˜•ì‹ìœ¼ë¡œ íŒë‹¨
    return has_h2_early and many_h3 and has_keyblocks


def detect_ppt_intent_in_query(query: str) -> bool:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ PPT ìƒì„± ì˜ë„ë¥¼ ê°ì§€í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸ í…ìŠ¤íŠ¸
    
    Returns:
        bool: PPT ìƒì„± ì˜ë„ê°€ ìˆìœ¼ë©´ True, ì•„ë‹ˆë©´ False
    """
    if not isinstance(query, str):
        return False
    
    query_lower = query.lower()
    
    # PPT ìƒì„± í‚¤ì›Œë“œë“¤
    ppt_keywords = ['ppt', 'pptx', 'í”„ë ˆì  í…Œì´ì…˜', 'í”„ë¦¬ì  í…Œì´ì…˜', 'ë°œí‘œ ìë£Œ', 'ë°œí‘œìë£Œ', 'ìŠ¬ë¼ì´ë“œ']
    creation_keywords = ['ë§Œë“¤ì–´', 'ì‘ì„±', 'ìƒì„±', 'ì œì‘', 'ë§Œë“¤']
    
    # PPT í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
    has_ppt_keyword = any(keyword in query_lower for keyword in ppt_keywords)
    
    # ìƒì„± ì˜ë„ê°€ ìˆëŠ”ì§€ í™•ì¸
    has_creation_intent = any(keyword in query_lower for keyword in creation_keywords)
    
    # ë‘˜ ë‹¤ ìˆì–´ì•¼ PPT ìƒì„± ì˜ë„ë¡œ íŒë‹¨
    return has_ppt_keyword and has_creation_intent


def fix_markdown_formatting(text: str) -> str:
    """
    LLM ì‘ë‹µì˜ ë§ˆí¬ë‹¤ìš´ ì„œì‹ì„ ì •êµí•˜ê²Œ êµì •í•©ë‹ˆë‹¤.
    "## ì¸ìŠë¦° íŒí”„ì¸ìŠë¦° íŒí”„ëŠ”..." ê°™ì€ ë³µì¡í•œ ì¤‘ë³µ íŒ¨í„´ì„ í•´ê²°í•©ë‹ˆë‹¤.
    """
    if not text:
        return text

    import re

    # 1) ê°œí–‰ ì •ê·œí™”
    s = text.replace('\r\n', '\n').replace('\r', '\n')
    
    logger.info(f"ğŸ”§ [í›„ì²˜ë¦¬] ì›ë³¸: {repr(s[:100])}")

    # 2) ê°€ì¥ ë³µì¡í•œ ì¼€ì´ìŠ¤: "## ì¸ìŠë¦° íŒí”„ì¸ìŠë¦° íŒí”„ëŠ”..."
    def fix_complex_duplication(match):
        header_mark = match.group(1)  # ##
        content = match.group(2)      # "ì¸ìŠë¦° íŒí”„ì¸ìŠë¦° íŒí”„ëŠ”..."
        
        # ê³µë°±ìœ¼ë¡œ ë‹¨ì–´ ë¶„ë¦¬
        words = content.split()
        
        # ì—°ì†ëœ ê°™ì€ ë‹¨ì–´/êµ¬ë¬¸ íŒ¨í„´ ì°¾ê¸°
        if len(words) >= 4:  # ìµœì†Œ 4ë‹¨ì–´ ì´ìƒ
            # "A B A BëŠ”" íŒ¨í„´ ì°¾ê¸°
            for i in range(len(words) - 3):
                word1 = words[i]
                word2 = words[i + 1] if i + 1 < len(words) else ""
                word3 = words[i + 2] if i + 2 < len(words) else ""
                word4 = words[i + 3] if i + 3 < len(words) else ""
                
                # "ì¸ìŠë¦° íŒí”„ ì¸ìŠë¦° íŒí”„ëŠ”" íŒ¨í„´
                if word1 == word3 and word2 == word4.rstrip('ëŠ”ì€ì´ê°€ì„ë¥¼'):
                    header_text = f"{word1} {word2}"
                    remaining_words = words[i + 2:]  # "ì¸ìŠë¦° íŒí”„ëŠ”..."ë¶€í„°
                    content_text = ' '.join(remaining_words)
                    
                    logger.info(f"ğŸ”§ [í›„ì²˜ë¦¬] ë³µì¡í•œ ì¤‘ë³µ ë°œê²¬: '{word1} {word2}' ë°˜ë³µ")
                    return f"{header_mark} {header_text}\n\n{content_text}"
        
        # ê°„ë‹¨í•œ ì¤‘ë³µ íŒ¨í„´: "## ì¸ìŠë¦°ì¸ìŠë¦°ì€"
        for word in words:
            if len(word) > 2:
                clean_word = word.rstrip('ëŠ”ì€ì´ê°€ì„ë¥¼ì—ê³¼ì™€ì˜ë¡œìœ¼ë¡œì—ì„œ')
                if content.count(clean_word) >= 2:
                    # ì²« ë²ˆì§¸ ë“±ì¥ì„ í—¤ë”ë¡œ
                    parts = content.split(clean_word, 1)
                    if len(parts) > 1 and parts[1]:
                        header_text = clean_word
                        content_text = clean_word + parts[1]
                        
                        logger.info(f"ğŸ”§ [í›„ì²˜ë¦¬] ë‹¨ìˆœ ì¤‘ë³µ ë°œê²¬: '{clean_word}'")
                        return f"{header_mark} {header_text}\n\n{content_text}"
        
        # ë¶„ë¦¬í•˜ì§€ ëª»í•œ ê²½ìš° ì›ë³¸ ë°˜í™˜
        return match.group(0)
    
    # í—¤ë” íŒ¨í„´ ì²˜ë¦¬
    s = re.sub(r'^(#{1,6})\s*(.+)$', fix_complex_duplication, s, flags=re.MULTILINE)

    # 3) í—¤ë” ë’¤ ë¹ˆ ì¤„ ê°•ì œ
    s = re.sub(r'(?m)^(#{1,6}\s+[^\n]+)\n(?=\S)', r'\1\n\n', s)

    # 4) ëª©ë¡ ì• ë¹ˆ ì¤„ ê°•ì œ
    s = re.sub(r'(?m)([^\n]\n)([-*]\s)', r'\1\n\2', s)
    s = re.sub(r'(?m)([^\n]\n)(\d+\.\s)', r'\1\n\2', s)

    # 5) ë¹ˆ í—¤ë” ì œê±°
    s = re.sub(r'^#{1,6}\s*$', '', s, flags=re.MULTILINE)
    
    # 6) ê³¼ë„í•œ ì—°ì† ê°œí–‰ ì •ë¦¬
    s = re.sub(r'\n{3,}', '\n\n', s)
    
    logger.info(f"ğŸ”§ [í›„ì²˜ë¦¬] ê²°ê³¼: {repr(s[:100])}")

    return s.strip()
    # "### ì •ë³´-" -> "### ì •ë³´\n\n-"
    s = re.sub(r'^(#{1,6}\s+[^\n]*?)([-*]\s)', r'\1\n\n\2', s, flags=re.MULTILINE)

    # 5) í—¤ë” ë’¤ ë¹ˆ ì¤„ ê°•ì œ (lookahead ì‚¬ìš©)
    s = re.sub(r'(?m)^(#{1,6}\s+[^\n]+)\n(?=\S)', r'\1\n\n', s)

    # 6) ëª©ë¡ ì• ë¹ˆ ì¤„ ê°•ì œ
    s = re.sub(r'(?m)([^\n]\n)([-*]\s)', r'\1\n\2', s)   # ë¶ˆë¦¿ ëª©ë¡
    s = re.sub(r'(?m)([^\n]\n)(\d+\.\s)', r'\1\n\2', s)  # ë²ˆí˜¸ ëª©ë¡

    # 7) ê³¼ë„í•œ ì—°ì† ê°œí–‰ ì •ë¦¬
    s = re.sub(r'\n{3,}', '\n\n', s)

    return s.strip()


def sanitize_ppt_markdown(text: str) -> str:
    """
    PPT ì˜ë„ ì¶œë ¥ì—ì„œ í”íˆ ì„ì´ëŠ” ì½”ë“œ íœìŠ¤(``` ... ```), ë¶ˆí•„ìš”í•œ ì¥ì‹, ì¤‘ë³µ í—¤ë”©ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
    - ì‚¼ì¤‘ ë°±í‹± ë¼ì¸ì€ ì œê±°í•˜ë˜ ë‚´ë¶€ ë‚´ìš©ì€ ìœ ì§€
    - "## ì œëª© ìŠ¬ë¼ì´ë“œ" ê°™ì€ ì œë„¤ë¦­ í—¤ë”©ì€ ì œê±° (ì‹¤ì œ ì œëª© í˜¼ë™ ë°©ì§€)
    - ì—°ì†ëœ ë™ì¼ í—¤ë”© ì œê±° (ì²« ë²ˆì§¸ë§Œ ìœ ì§€)
    - í—¤ë”© ì•ë’¤ ê³µë°± ì •ë¦¬ ë° ê³¼ë„í•œ ë¹ˆ ì¤„ ì¶•ì†Œ
    """
    if not isinstance(text, str) or not text.strip():
        return text

    s = text.replace('\r\n', '\n').replace('\r', '\n')

    # 1) ì½”ë“œ íœìŠ¤ ë¼ì¸ ì œê±° (ë‚´ìš©ì€ ìœ ì§€)
    # ```lang  ë˜ëŠ” ``` ë§Œ ìˆëŠ” ë¼ì¸ì„ ì œê±°
    s = re.sub(r"^```[a-zA-Z0-9_-]*\s*$", "", s, flags=re.MULTILINE)

    # 2) ì œë„¤ë¦­ ì œëª© í—¤ë”© ì œê±°: "## ì œëª© ìŠ¬ë¼ì´ë“œ" (ë¬¸ì„œ ì œëª©ìœ¼ë¡œ ì˜ëª» ì¸ì‹ë¨)
    s = re.sub(r"(?m)^##\s*ì œëª©\s*ìŠ¬ë¼ì´ë“œ\s*$", "", s)

    # 3) ì—°ì†ëœ ë™ì¼ í—¤ë”© ì œê±° (ì²« ë²ˆì§¸ë§Œ ìœ ì§€)
    def remove_duplicate_headings(text):
        lines = text.split('\n')
        processed_lines = []
        last_heading = None
        
        for line in lines:
            # í—¤ë”©ì¸ì§€ í™•ì¸ (### ë¶€í„° ###### ê¹Œì§€)
            heading_match = re.match(r'^(#{3,6})\s+(.+)', line.strip())
            if heading_match:
                heading_level = heading_match.group(1)
                heading_text = heading_match.group(2).strip()
                current_heading = (heading_level, heading_text)
                
                # ì´ì „ í—¤ë”©ê³¼ ë™ì¼í•œì§€ í™•ì¸
                if current_heading != last_heading:
                    processed_lines.append(line)
                    last_heading = current_heading
                # ë™ì¼í•œ í—¤ë”©ì´ë©´ ìŠ¤í‚µ (ì¤‘ë³µ ì œê±°)
            else:
                # í—¤ë”©ì´ ì•„ë‹Œ ë¼ì¸ì€ ê·¸ëŒ€ë¡œ ì¶”ê°€
                processed_lines.append(line)
                # í—¤ë”©ì´ ì•„ë‹Œ ë‚´ìš©ì´ ë‚˜ì˜¤ë©´ ì—°ì† í—¤ë”© ì²´í¬ ë¦¬ì…‹
                if line.strip():  # ë¹ˆ ì¤„ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                    last_heading = None
                    
        return '\n'.join(processed_lines)
    
    s = remove_duplicate_headings(s)

    # 4) í—¤ë”© ë’¤ ìµœì†Œ í•œ ì¤„ ê³µë°± ë³´ì¥
    s = re.sub(r"(?m)^(#{2,6}\s+[^\n]+)\n(?=\S)", r"\1\n\n", s)

    # 5) ê³¼ë„í•œ ì—°ì† ê°œí–‰ ì¶•ì†Œ
    s = re.sub(r"\n{3,}", "\n\n", s)

    return s.strip()


from loguru import logger
from sqlalchemy import text
from fastapi.responses import FileResponse

def safe_json_serialize(obj):
    """JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ê°ì²´ ë³€í™˜"""
    if isinstance(obj, dict):
        return {k: safe_json_serialize(v) for k, v in obj.items() if not k.startswith('_')}
    elif isinstance(obj, list):
        return [safe_json_serialize(item) for item in obj]
    elif hasattr(obj, '__dict__'):
        return safe_json_serialize(obj.__dict__)
    elif hasattr(obj, 'isoformat'):  # datetime ê°ì²´
        return obj.isoformat()
    elif hasattr(obj, '__str__') and not hasattr(obj, '__call__'):  # ë©”ì„œë“œê°€ ì•„ë‹Œ ê°ì²´ë§Œ
        return str(obj)
    elif isinstance(obj, (str, int, float, bool, type(None))):
        return obj
    else:
        return str(obj)

def clean_references_for_json(references):
    """ì°¸ì¡° ë°ì´í„°ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬"""
    import math
    
    if not references:
        return []
    
    cleaned = []
    for ref in references:
        cleaned_ref = {}
        for key, value in ref.items():
            if key.startswith('_'):
                continue
            if hasattr(value, '__call__'):
                continue
            if isinstance(value, (str, int, bool, type(None))):
                cleaned_ref[key] = value
            elif isinstance(value, float):
                # NaNì´ë‚˜ Infinity ê°’ ì²˜ë¦¬
                if math.isnan(value) or math.isinf(value):
                    cleaned_ref[key] = None
                else:
                    cleaned_ref[key] = value
            elif isinstance(value, list):
                cleaned_ref[key] = [str(item) if hasattr(item, '__call__') else item for item in value]
            else:
                cleaned_ref[key] = str(value)
        cleaned.append(cleaned_ref)
    
    return cleaned

def clean_stats_for_json(stats):
    """í†µê³„ ë°ì´í„°ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬"""
    import math
    
    if not stats:
        return {}
    
    cleaned = {}
    for key, value in stats.items():
        if key.startswith('_'):
            continue
        if hasattr(value, '__call__'):
            continue
        if isinstance(value, (str, int, bool, type(None))):
            cleaned[key] = value
        elif isinstance(value, float):
            # NaNì´ë‚˜ Infinity ê°’ ì²˜ë¦¬
            if math.isnan(value) or math.isinf(value):
                cleaned[key] = None
            else:
                cleaned[key] = value
        else:
            cleaned[key] = str(value)
    
    return cleaned

router = APIRouter(tags=["ğŸ’¬ Chat & QA"])

# Redis ì±„íŒ… ë§¤ë‹ˆì € ì˜ì¡´ì„±
def get_redis_chat_manager() -> RedisChatManager:
    """Redis ì±„íŒ… ë§¤ë‹ˆì € ì˜ì¡´ì„± ì£¼ì…"""
    redis_client = get_redis_client()
    return RedisChatManager(redis_client)

async def save_chat_session(
    db: AsyncSession, 
    session_id: str, 
    user_emp_no: str, 
    message: str,
    response: str,
    referenced_documents: Optional[List[int]] = None,
    search_results: Optional[dict] = None,
    conversation_context: Optional[dict] = None
) -> bool:
    """
    ì±„íŒ… ì„¸ì…˜ì„ tb_chat_sessionsì™€ tb_chat_historyì— ì €ì¥/ì—…ë°ì´íŠ¸
    - ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ì €ì¥ (tb_chat_sessions)
    - ì‹¤ì œ ë©”ì‹œì§€ ë‚´ìš© ì €ì¥ (tb_chat_history)
    """
    try:
        # 1. ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ì €ì¥/ì—…ë°ì´íŠ¸
        check_query = text("""
            SELECT session_id FROM tb_chat_sessions 
            WHERE session_id = :session_id AND user_emp_no = :user_emp_no
        """)
        
        result = await db.execute(check_query, {
            "session_id": session_id,
            "user_emp_no": user_emp_no
        })
        
        existing_session = result.fetchone()
        
        if existing_session:
            # ê¸°ì¡´ ì„¸ì…˜ ì—…ë°ì´íŠ¸
            update_query = text("""
                UPDATE tb_chat_sessions 
                SET 
                    message_count = message_count + 1,
                    last_activity = NOW(),
                    last_modified_date = NOW()
                WHERE session_id = :session_id AND user_emp_no = :user_emp_no
            """)
            
            await db.execute(update_query, {
                "session_id": session_id,
                "user_emp_no": user_emp_no
            })
        else:
            # ìƒˆ ì„¸ì…˜ ìƒì„±
            # ì²« ë²ˆì§¸ ë©”ì‹œì§€ì—ì„œ ì˜ë¯¸ìˆëŠ” ì œëª© ìƒì„±
            session_title = message.strip()
            # ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ë¬¸ì ì¼ë¶€ ì œê±°
            import re
            session_title = re.sub(r'[ğŸ”ğŸ“„ğŸ’¬ğŸ¯ğŸ“ŠğŸ¤–âœ¨ğŸš€]+', '', session_title)
            # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜
            session_title = ' '.join(session_title.split())
            # ìµœëŒ€ 100ìë¡œ ì œí•œ
            if len(session_title) > 100:
                session_title = session_title[:97] + "..."
            # ì œëª©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ê¸°ë³¸ê°’
            if len(session_title) < 3:
                session_title = f"ëŒ€í™” {session_id[:8]}"
            
            insert_query = text("""
                INSERT INTO tb_chat_sessions (
                    session_id, user_emp_no, session_name, message_count,
                    max_messages, session_timeout_minutes,
                    is_active, last_activity, created_date, last_modified_date
                ) VALUES (
                    :session_id, :user_emp_no, :session_name, 1,
                    100, 60,
                    true, NOW(), NOW(), NOW()
                )
            """)
            
            await db.execute(insert_query, {
                "session_id": session_id,
                "user_emp_no": user_emp_no,
                "session_name": session_title
            })
        
        # 2. ğŸ†• ì‹¤ì œ ë©”ì‹œì§€ ë‚´ìš©ì„ tb_chat_historyì— ì €ì¥
        insert_message_query = text("""
            INSERT INTO tb_chat_history (
                session_id,
                user_emp_no,
                user_message,
                assistant_response,
                referenced_documents,
                search_results,
                conversation_context,
                created_date
            ) VALUES (
                :session_id,
                :user_emp_no,
                :user_message,
                :assistant_response,
                :referenced_documents,
                :search_results,
                :conversation_context,
                NOW()
            )
        """)
        
        # JSONB í•„ë“œë¥¼ ìœ„í•œ JSON ì§ë ¬í™”
        import json
        search_results_json = json.dumps(search_results) if search_results else None
        conversation_context_json = json.dumps(conversation_context) if conversation_context else None
        
        await db.execute(insert_message_query, {
            "session_id": session_id,
            "user_emp_no": user_emp_no,
            "user_message": message,
            "assistant_response": response,
            "referenced_documents": referenced_documents,
            "search_results": search_results_json,
            "conversation_context": conversation_context_json
        })
        
        await db.commit()
        logger.info(f"âœ… ì±„íŒ… ì„¸ì…˜ ë° ë©”ì‹œì§€ ì €ì¥ ì™„ë£Œ: {session_id}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì±„íŒ… ì„¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {e}")
        await db.rollback()
        return False

class ChatAttachmentPayload(BaseModel):
    asset_id: str
    category: Optional[str] = "document"
    file_name: Optional[str] = None


class ChatRequest(BaseModel):
    message: str
    provider: Optional[str] = None
    session_id: Optional[str] = None
    user_id: Optional[str] = None
    use_rag: bool = True  # RAG ì‚¬ìš© ì—¬ë¶€
    container_ids: Optional[List[str]] = None  # ê²€ìƒ‰ ëŒ€ìƒ ì»¨í…Œì´ë„ˆ
    include_references: bool = True  # ì°¸ì¡° ì •ë³´ í¬í•¨ ì—¬ë¶€
    attachments: Optional[List[ChatAttachmentPayload]] = None
    voice_asset_id: Optional[str] = None
    # RAG ì „ìš© ë§¤ê°œë³€ìˆ˜
    max_chunks: int = 10
    similarity_threshold: float = 0.4  # ê´€ë ¨ì„± ì—†ëŠ” ë¬¸ì„œ í•„í„°ë§ì„ ìœ„í•œ ì—„ê²©í•œ ì„ê³„ê°’
    search_mode: str = "hybrid"  # "semantic", "keyword", "hybrid"
    use_reranking: bool = True
    context_window: int = 4000

class ChatStreamRequest(BaseModel):
    """ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ìš”ì²­"""
    message: str
    agent_type: Optional[str] = 'general'  # AI Agent íƒ€ì…
    selected_documents: Optional[List[SelectedDocument]] = []  # ì„ íƒëœ ë¬¸ì„œë“¤
    provider: Optional[str] = None
    providers: Optional[List[str]] = None  # ë³µìˆ˜ í”„ë¡œë°”ì´ë” ì§€ì›
    session_id: Optional[str] = None
    user_id: Optional[str] = None
    use_rag: bool = True
    container_ids: Optional[List[str]] = None
    include_references: bool = True
    max_chunks: int = 10
    max_tokens: Optional[int] = 4000  # ì¼ë°˜ ì±„íŒ…: 2000 â†’ 4000 (ì¶©ë¶„í•œ ë‹µë³€ ìƒì„±)
    temperature: Optional[float] = 0.7
    similarity_threshold: float = 0.4  # ê´€ë ¨ì„± ì—†ëŠ” ë¬¸ì„œ í•„í„°ë§ì„ ìœ„í•œ ì—„ê²©í•œ ì„ê³„ê°’
    search_mode: str = "hybrid"
    use_reranking: bool = True
    context_window: int = 4000
    attachments: Optional[List[ChatAttachmentPayload]] = None
    voice_asset_id: Optional[str] = None



class ChatResponse(BaseModel):
    response: str
    provider: str
    session_id: Optional[str] = None
    references: Optional[List[dict]] = None  # RAG ì°¸ì¡° ì •ë³´
    context_info: Optional[dict] = None  # ì»¨í…ìŠ¤íŠ¸ ì •ë³´
    rag_stats: Optional[dict] = None  # RAG ê²€ìƒ‰ í†µê³„

class EmbeddingRequest(BaseModel):
    texts: List[str]
    provider: Optional[str] = None

class EmbeddingResponse(BaseModel):
    embeddings: List[List[float]]
    provider: str

class SearchRequest(BaseModel):
    query: str
    provider: Optional[str] = None

class SearchResponse(BaseModel):
    embedding: List[float]
    provider: str

class RAGSearchRequest(BaseModel):
    """RAG ì „ìš© ê²€ìƒ‰ ìš”ì²­"""
    query: str
    container_ids: Optional[List[str]] = None
    max_chunks: int = 10
    similarity_threshold: float = 0.4  # ê´€ë ¨ì„± ì—†ëŠ” ë¬¸ì„œ í•„í„°ë§ì„ ìœ„í•œ ì—„ê²©í•œ ì„ê³„ê°’
    search_mode: str = "hybrid"
    use_reranking: bool = True
    context_window: int = 4000

class RAGSearchResponse(BaseModel):
    """RAG ì „ìš© ê²€ìƒ‰ ì‘ë‹µ"""
    success: bool
    chunks: List[dict]
    context_text: str
    total_tokens: int
    search_stats: dict
    reranking_applied: bool


@router.post("/chat/assets")
async def upload_chat_assets(
    files: List[UploadFile] = File(...),
    current_user: User = Depends(get_current_user)
):
    if not files:
        raise HTTPException(status_code=400, detail="ì—…ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    assets = []
    for upload in files:
        try:
            stored = await chat_attachment_service.save(upload, str(current_user.emp_no))
            assets.append({
                "asset_id": stored.asset_id,
                "file_name": stored.file_name,
                "mime_type": stored.mime_type,
                "size": stored.size,
                "category": stored.category,
                "preview_url": stored.preview_url,
                "download_url": stored.download_url
            })
        except Exception as exc:
            logger.error(f"âŒ ì²¨ë¶€ íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {exc}")
            raise HTTPException(status_code=500, detail="ì²¨ë¶€ íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    return {"success": True, "assets": assets}


@router.get("/chat/assets/{asset_id}")
async def download_chat_asset(
    asset_id: str,
    current_user: User = Depends(get_current_user)
):
    stored = chat_attachment_service.get(asset_id)
    if not stored:
        raise HTTPException(status_code=404, detail="ì²¨ë¶€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if stored.owner_emp_no != str(current_user.emp_no):
        raise HTTPException(status_code=403, detail="ì²¨ë¶€ íŒŒì¼ì— ëŒ€í•œ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")

    return FileResponse(
        path=stored.path,
        media_type=stored.mime_type,
        filename=stored.file_name
    )


@router.post("/chat/transcribe")
async def transcribe_chat_audio(
    file: UploadFile = File(...),
    current_user: User = Depends(get_current_user)
):
    if not audio_transcription_service.enabled:
        raise HTTPException(status_code=503, detail="ì˜¤ë””ì˜¤ ì „ì‚¬ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    suffix = Path(file.filename or "audio.webm").suffix or ".webm"
    temp_fd, temp_path_str = tempfile.mkstemp(suffix=suffix)
    os.close(temp_fd)
    temp_path = Path(temp_path_str)

    try:
        async with aiofiles.open(temp_path, "wb") as out_file:
            while True:
                chunk = await file.read(1024 * 1024)
                if not chunk:
                    break
                await out_file.write(chunk)

        transcript = await asyncio.to_thread(audio_transcription_service.transcribe, temp_path)
        return {"success": True, "transcript": transcript}
    except Exception as exc:
        logger.error(f"âŒ ì˜¤ë””ì˜¤ ì „ì‚¬ ì‹¤íŒ¨: {exc}")
        raise HTTPException(status_code=500, detail="ìŒì„± í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    finally:
        try:
            await file.close()
        except Exception:
            pass
        temp_path.unlink(missing_ok=True)


# ===== CORE CHAT ENDPOINTS =====

@router.post("/chat/stream")
async def chat_stream(
    raw_request: Request,
    request: ChatStreamRequest,
    current_user: User = Depends(get_current_user),
    chat_manager: RedisChatManager = Depends(get_redis_chat_manager)
):
    """ì±„íŒ… ìŠ¤íŠ¸ë¦¼ ì—”ë“œí¬ì¸íŠ¸ (RAG + ì—ì´ì „íŠ¸ ì»¨í…ìŠ¤íŠ¸ ë°˜ì˜) - generate_stream í•¨ìˆ˜ ì‚¬ìš©"""
    try:
        logger.info(f"ğŸš€ ì±„íŒ… ìŠ¤íŠ¸ë¦¼ ìš”ì²­: ë©”ì‹œì§€='{request.message}', ì„¸ì…˜={request.session_id}, ì œê³µì={request.provider}")
        logger.info(f"ğŸ” ì„ íƒëœ ë¬¸ì„œ: {request.selected_documents}")
        logger.info(f"ğŸ” ì„ íƒëœ ë¬¸ì„œ ê°œìˆ˜: {len(request.selected_documents) if request.selected_documents else 0}")
        
        # ì„ íƒëœ ë¬¸ì„œ ê²€ì¦ ë¡œê¹…
        if request.selected_documents:
            for idx, doc in enumerate(request.selected_documents):
                logger.info(f"  ğŸ“„ ë¬¸ì„œ {idx+1}: id={doc.id}, fileName={doc.fileName}, fileType={doc.fileType}")
        
        # ProviderëŠ” .env ì„¤ì •ì„ ìµœìš°ì„  ì ìš© (ì¼ê´€ì„± í™•ë³´)
        effective_provider = settings.get_current_llm_provider()
        if request.provider and request.provider != effective_provider:
            logger.warning(f"âš ï¸ ìš”ì²­ provider '{request.provider}'ë¥¼ ë¬´ì‹œí•˜ê³  ì„¤ì •ê°’ '{effective_provider}' ì‚¬ìš©")
        
        # ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„°ë¥¼ ì¦‰ì‹œ ì‹¤í–‰í•˜ë„ë¡ ë˜í¼ í•¨ìˆ˜ ì‚¬ìš©
        async def stream_wrapper():
            try:
                async for chunk in generate_stream(
                    message=request.message,
                    session_id=request.session_id or str(uuid.uuid4()),
                    current_user=current_user,
                    provider=effective_provider,
                    selected_documents=request.selected_documents if request.selected_documents else None,
                    chat_manager=chat_manager,
                    agent_type=request.agent_type or 'general',
                    container_ids=request.container_ids,
                    attachments=request.attachments,
                    voice_asset_id=request.voice_asset_id,
                    max_tokens=request.max_tokens,
                    temperature=request.temperature
                ):
                    yield chunk
            except Exception as e:
                logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                error_event = {"type": "error", "content": str(e)}
                yield f"data: {json.dumps(error_event, ensure_ascii=False)}\n\n"
        
        return StreamingResponse(
            stream_wrapper(),
            media_type="text/event-stream; charset=utf-8",
            headers={
                "Cache-Control": "no-cache, no-transform",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*"
            }
        )
        
    except Exception as e:
        logger.error(f"ì±„íŒ… ìŠ¤íŠ¸ë¦¼ ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ê°„ë‹¨ ì„¸ì…˜ ë¡œë“œ/ë³´ê´€ ì—”ë“œí¬ì¸íŠ¸ (í”„ë¡ íŠ¸ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ìš©)
@router.get("/chat/sessions/{session_id}")
async def get_chat_session(
    session_id: str, 
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    ì„¸ì…˜ì˜ ëŒ€í™” ë‚´ì—­ ì¡°íšŒ
    - PostgreSQL ìš°ì„  ì¡°íšŒ (ì˜êµ¬ ì €ì¥ëœ ë©”ì‹œì§€)
    - Redis í´ë°± (ìµœê·¼ ë©”ì‹œì§€, TTL ë‚´)
    - ë©”ì‹œì§€ ëª©ë¡, ì°¸ê³ ìë£Œ ëª©ë¡, ì„ íƒëœ ë¬¸ì„œ ëª©ë¡ ë°˜í™˜
    """
    try:
        # 1. ì„¸ì…˜ ì¡´ì¬ í™•ì¸
        session_query = text("""
            SELECT * FROM tb_chat_sessions 
            WHERE session_id = :session_id AND user_emp_no = :user_emp_no
        """)
        session_result = await db.execute(session_query, {
            "session_id": session_id,
            "user_emp_no": str(current_user.emp_no)
        })
        session = session_result.fetchone()
        
        if not session:
            logger.warning(f"âš ï¸ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {session_id}")
            return {'success': False, 'session_id': session_id, 'messages': []}
        
        # 2. PostgreSQLì—ì„œ ë©”ì‹œì§€ ì¡°íšŒ (ìš°ì„ )
        messages_query = text("""
            SELECT 
                chat_id,
                user_message,
                assistant_response,
                referenced_documents,
                search_results,
                conversation_context,
                created_date
            FROM tb_chat_history
            WHERE session_id = :session_id
            ORDER BY created_date
        """)
        messages_result = await db.execute(messages_query, {
            "session_id": session_id
        })
        db_messages = messages_result.fetchall()
        
        logger.info(f"ğŸ“¦ PostgreSQLì—ì„œ {len(db_messages)}ê°œ ë©”ì‹œì§€ ì¡°íšŒ: {session_id}")
        
        # 3. PostgreSQLì— ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ Redis í´ë°±
        if db_messages and len(db_messages) > 0:
            # PostgreSQL ë©”ì‹œì§€ ì‚¬ìš©
            frontend_msgs = []
            all_referenced_doc_ids = set()
            selected_documents = []
            
            for i, row in enumerate(db_messages):
                # ì‚¬ìš©ì ë©”ì‹œì§€
                frontend_msgs.append({
                    'id': f"user_{i}",
                    'role': 'user',
                    'content': row.user_message,
                    'timestamp': row.created_date.isoformat()
                })
                
                # AI ì‘ë‹µ
                assistant_msg = {
                    'id': f"assistant_{i}",
                    'role': 'assistant',
                    'content': row.assistant_response,
                    'timestamp': row.created_date.isoformat()
                }
                
                # ì°¸ê³ ìë£Œ í¬í•¨
                if row.referenced_documents:
                    assistant_msg['referenced_documents'] = row.referenced_documents
                    all_referenced_doc_ids.update(row.referenced_documents)
                
                # ê²€ìƒ‰ ê²°ê³¼/ì»¨í…ìŠ¤íŠ¸ í¬í•¨ (JSONB)
                if row.search_results:
                    try:
                        import json
                        search_data = json.loads(row.search_results) if isinstance(row.search_results, str) else row.search_results
                        assistant_msg['context_info'] = search_data
                        
                        # ğŸ†• ì²­í¬ ìƒì„¸ ì •ë³´ ì¶”ì¶œ ë° í¬í•¨
                        if isinstance(search_data, dict) and 'detailed_chunks' in search_data:
                            assistant_msg['detailed_chunks'] = search_data['detailed_chunks']
                            logger.debug(f"ğŸ“‹ ë©”ì‹œì§€ {i}ì— {len(search_data['detailed_chunks'])}ê°œ ì²­í¬ ì •ë³´ ë³µì›")
                    except Exception as e:
                        logger.warning(f"search_results JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                
                frontend_msgs.append(assistant_msg)
                
                # ğŸ†• ëª¨ë“  ë©”ì‹œì§€ì—ì„œ ì„ íƒëœ ë¬¸ì„œ ìˆ˜ì§‘ (ê°€ì¥ ìµœê·¼ ê²ƒì´ ìš°ì„ )
                if row.conversation_context:
                    try:
                        import json
                        ctx = json.loads(row.conversation_context) if isinstance(row.conversation_context, str) else row.conversation_context
                        if isinstance(ctx, dict) and 'selected_documents' in ctx:
                            # ê°€ì¥ ìµœê·¼ selected_documentsë¡œ ì—…ë°ì´íŠ¸
                            current_docs = ctx.get('selected_documents', [])
                            if current_docs:
                                selected_documents = current_docs
                                logger.debug(f"ğŸ“„ ë©”ì‹œì§€ {i}ì—ì„œ {len(current_docs)}ê°œ ì„ íƒ ë¬¸ì„œ ë°œê²¬")
                    except Exception as e:
                        logger.warning(f"conversation_context íŒŒì‹± ì‹¤íŒ¨: {e}")
            
            logger.info(f"âœ… PostgreSQL ë©”ì‹œì§€ ë³€í™˜ ì™„ë£Œ: {len(frontend_msgs)}ê°œ, ì„ íƒ ë¬¸ì„œ: {len(selected_documents)}ê°œ")
            
        else:
            # PostgreSQLì— ë©”ì‹œì§€ ì—†ìŒ â†’ Redis í´ë°±
            logger.warning(f"âš ï¸ PostgreSQLì— ë©”ì‹œì§€ ì—†ìŒ, Redis í´ë°± ì‹œë„: {session_id}")
            
            chat_manager = get_redis_chat_manager()
            redis_session = await chat_manager.get_chat_session(session_id)
            
            if not redis_session or str(redis_session.user_emp_no) != str(current_user.emp_no):
                logger.warning(f"âš ï¸ Redisì—ì„œë„ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {session_id}")
                return {'success': False, 'session_id': session_id, 'messages': []}
            
            messages = await chat_manager.get_recent_messages(session_id, limit=200)
            
            all_referenced_doc_ids = set()
            selected_documents = []
            frontend_msgs = []
            
            for idx, m in enumerate(messages):
                role = 'assistant' if m.message_type.value == 'assistant' else ('user' if m.message_type.value == 'user' else 'system')
                
                if hasattr(m, 'referenced_documents') and m.referenced_documents:
                    all_referenced_doc_ids.update(m.referenced_documents)
                
                if idx == 0 and role == 'user' and hasattr(m, 'search_context') and m.search_context:
                    if 'selected_documents' in m.search_context:
                        selected_documents = m.search_context.get('selected_documents', [])
                
                msg_data = {
                    'id': f"{role}_{m.sequence_number}",
                    'message_id': getattr(m, 'message_id', None),
                    'role': role,
                    'content': m.content,
                    'timestamp': m.timestamp.isoformat(),
                    'context_info': getattr(m, 'search_context', None) or {},
                }
                
                if role == 'assistant' and hasattr(m, 'referenced_documents') and m.referenced_documents:
                    msg_data['referenced_documents'] = m.referenced_documents
                
                frontend_msgs.append(msg_data)
            
            logger.info(f"âœ… Redis ë©”ì‹œì§€ ë³€í™˜ ì™„ë£Œ: {len(frontend_msgs)}ê°œ")

        # 4. ì°¸ê³ ìë£Œ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ê³µí†µ)
        referenced_docs_detail = []
        if all_referenced_doc_ids:
            try:
                from sqlalchemy import select
                from app.models.document.file_models import TbFileBssInfo
                
                query = select(TbFileBssInfo).where(
                    TbFileBssInfo.file_bss_info_sno.in_(list(all_referenced_doc_ids))
                )
                result = await db.execute(query)
                docs = result.scalars().all()
                
                for doc in docs:
                    referenced_docs_detail.append({
                        'fileId': str(doc.file_bss_info_sno),
                        'fileName': doc.file_lgc_nm,  # file_logic_name â†’ file_lgc_nm
                        'fileType': doc.file_extsn, 
                        'containerName': getattr(doc, 'knowledge_container_id', '') or '', 
                        'uploadDate': doc.created_date.isoformat() if getattr(doc, 'created_date', None) is not None else None
                    })
                
                logger.info(f"ğŸ“„ ì°¸ê³ ìë£Œ ìƒì„¸ ì •ë³´ {len(referenced_docs_detail)}ê°œ ì¡°íšŒ ì™„ë£Œ")
            except Exception as doc_error:
                logger.warning(f"ì°¸ê³ ìë£Œ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {doc_error}")

        return { 
            'success': True, 
            'session_id': session_id, 
            'messages': frontend_msgs,
            'referenced_documents': referenced_docs_detail,
            'selected_documents': selected_documents
        }
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ì„¸ì…˜ ì¡°íšŒ ì‹¤íŒ¨ ìƒì„¸:\n{traceback.format_exc()}")
        return {'success': False, 'session_id': session_id, 'messages': []}

@router.post("/chat/sessions/{session_id}/archive")
async def archive_chat_session(session_id: str, current_user: User = Depends(get_current_user)):
    # Redis ì„¸ì…˜ì„ ë¹„í™œì„±í™” ìƒíƒœë¡œ ì „í™˜í•˜ê±°ë‚˜, ë‚˜ì¤‘ì— RDBë¡œ ì˜êµ¬ ì €ì¥í•˜ë„ë¡ í‘œì‹œ
    try:
        chat_manager = get_redis_chat_manager()
        session = await chat_manager.get_chat_session(session_id)
        if not session or str(session.user_emp_no) != str(current_user.emp_no):
            return { 'success': False, 'message': 'ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' }
        # ë‹¨ìˆœíˆ ì„¸ì…˜ ìƒíƒœë¥¼ idleë¡œ í‘œê¸° (ì‹¤ì œ RDB ì•„ì¹´ì´ë¸ŒëŠ” ë³„ë„ ë°°ì¹˜ì—ì„œ ìˆ˜í–‰ ê°€ëŠ¥)
        session.status = ChatSessionStatus.ARCHIVED
        session_key = RedisKeyPatterns.CHAT_SESSION.format(session_id=session_id)
        await chat_manager.redis.setex(session_key, RedisChatTTL.CHAT_SESSION, json.dumps(session.to_dict()))
        return { 'success': True, 'message': f'ì„¸ì…˜ {session_id} ì €ì¥(ë³´ê´€) ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.' }
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ì•„ì¹´ì´ë¸Œ ì‹¤íŒ¨: {e}")
        return { 'success': False, 'message': 'ì„¸ì…˜ ì €ì¥ ì‹¤íŒ¨' }

class ChatMessageRequest(BaseModel):
    session_id: str
    message: str
    provider: Optional[str] = None
    # ì›ì¹™ 1/2 ì¤€ìˆ˜ë¥¼ ìœ„í•´ ì„ íƒ ë¬¸ì„œ ì…ë ¥ì„ í—ˆìš©
    selected_documents: Optional[List[SelectedDocument]] = []
    attachments: Optional[List[ChatAttachmentPayload]] = None
    voice_asset_id: Optional[str] = None

@router.post("/chat/message")
async def send_message(
    request: ChatMessageRequest,
    current_user: User = Depends(get_current_user),
    chat_manager: RedisChatManager = Depends(get_redis_chat_manager)
):
    """
    ë™ê¸° ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡ - ì™„ë£Œëœ ì‘ë‹µì„ í•œ ë²ˆì— ë°˜í™˜
    ìŠ¤íŠ¸ë¦¬ë°ê³¼ ë™ì¼í•œ ë¡œì§ì„ ì‚¬ìš©í•˜ë˜ ìµœì¢… ê²°ê³¼ë§Œ JSONìœ¼ë¡œ ë°˜í™˜
    """
    try:
        # 1. ì‚¬ìš©ì ì •ë³´ ì¤€ë¹„
        user_emp_no = str(current_user.emp_no)
        user_name = str(current_user.username)
        user_department = "ê¸°ë³¸ë¶€ì„œ"
        
        session_id = request.session_id or str(uuid.uuid4())
        message = request.message
        
        # ProviderëŠ” .env ì„¤ì •ì„ ìµœìš°ì„  ì ìš© (ì¼ê´€ì„± í™•ë³´)
        provider = settings.get_current_llm_provider()
        if request.provider and request.provider != provider:
            logger.warning(f"âš ï¸ ìš”ì²­ provider '{request.provider}'ë¥¼ ë¬´ì‹œí•˜ê³  ì„¤ì •ê°’ '{provider}' ì‚¬ìš©")
        
        logger.info(f"ğŸš€ ë™ê¸° ì±„íŒ… ìš”ì²­: ì‚¬ìš©ì {user_emp_no}, ì„¸ì…˜ {session_id}, ì œê³µì={provider}")
        
        attachment_metadata: List[Dict[str, Any]] = []
        if request.attachments:
            for payload in request.attachments:
                try:
                    stored = chat_attachment_service.get(payload.asset_id)
                    if not stored:
                        logger.warning(f"âš ï¸ ì²¨ë¶€ ìì‚°ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {payload.asset_id}")
                        continue
                    if stored.owner_emp_no != str(current_user.emp_no):
                        logger.warning(f"âš ï¸ ì²¨ë¶€ ìì‚° ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ: {payload.asset_id}")
                        continue
                    attachment_metadata.append({
                        "asset_id": stored.asset_id,
                        "file_name": stored.file_name,
                        "mime_type": stored.mime_type,
                        "size": stored.size,
                        "category": stored.category,
                        "download_url": stored.download_url,
                        "preview_url": stored.preview_url
                    })
                except Exception as exc:
                    logger.error(f"ì²¨ë¶€ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {exc}")

        # 2. ì„¸ì…˜ ìƒì„±/í™•ì¸
        existing_session = await chat_manager.get_chat_session(session_id)
        if not existing_session:
            logger.info(f"ìƒˆ ì„¸ì…˜ ìƒì„±: {session_id}")
            await chat_manager.create_chat_session(
                user_emp_no=user_emp_no,
                user_name=user_name,
                department=user_department,
                session_id=session_id
            )
        
        # 3. ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        user_context = {}
        if request.selected_documents:
            user_context["selected_documents"] = request.selected_documents
        if attachment_metadata:
            user_context["attachments"] = attachment_metadata
        if request.voice_asset_id:
            user_context["voice_asset_id"] = request.voice_asset_id

        await chat_manager.add_message(
            session_id=session_id,
            content=message,
            message_type=MessageType.USER,
            user_emp_no=user_emp_no,
            user_name=user_name,
            search_context=user_context or None
        )
        
        # 4. ë©€í‹°í„´ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
        history_messages = []
        try:
            recent_messages = await chat_manager.get_recent_messages(session_id, limit=4)
            if recent_messages:
                for msg in recent_messages:
                    history_messages.append({
                        "role": "user" if msg.message_type.value == "user" else "assistant",
                        "content": msg.content
                    })
        except Exception as e:
            logger.warning(f"ì±„íŒ… ê¸°ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # 5. RAG ê²€ìƒ‰ ë° ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        references = []
        context_info = {"rag_used": False}
        rag_stats = {"provider": provider}
        final_response = ""
        
        try:
            # AI ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ë¡œ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            prepared_prompt, references, context_info, rag_stats = await ai_agent_service.prepare_context_with_documents(
                query=message,
                selected_documents=request.selected_documents if request.selected_documents else None,
                chat_history=history_messages,
                agent_type='general',
                container_ids=None
            )
            
            # 6. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
            system_prompt = None
            try:
                prompt_path = Path("/home/admin/wkms-aws/backend/prompts/general.prompt")
                if prompt_path.exists():
                    system_prompt = prompt_path.read_text(encoding='utf-8').strip()
            except Exception as e:
                logger.warning(f"ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # 7. ë©”ì‹œì§€ êµ¬ì„± (system + history + user)
            llm_messages = []
            if system_prompt:
                llm_messages.append({"role": "system", "content": system_prompt})
            
            # ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì œì™¸)
            llm_messages.extend(history_messages[:-1] if history_messages else [])
            
            # ì»¨í…ìŠ¤íŠ¸ê°€ ì¤€ë¹„ëœ ë©”ì‹œì§€ ë˜ëŠ” ì›ë³¸ ë©”ì‹œì§€ ì¶”ê°€
            llm_messages.append({"role": "user", "content": prepared_prompt})
            
            # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œì—ëŠ” LLM í˜¸ì¶œ ì—†ì´ ì‹¤íŒ¨ ì•ˆë‚´ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì›ì¹™ ë³´ì¥)
            if isinstance(context_info, dict) and context_info.get('search_failed'):
                final_response = prepared_prompt
            else:
                # 8. AI ì„œë¹„ìŠ¤ í˜¸ì¶œ (ë™ê¸° ë°©ì‹)
                response_content = await ai_service.chat_completion(
                    messages=llm_messages,
                    provider=provider
                )
                # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê°œì„ ëœ ë¡œì§)
                if isinstance(response_content, dict):
                    # AI ì„œë¹„ìŠ¤ê°€ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•˜ëŠ” ê²½ìš°
                    if 'response' in response_content:
                        final_response = response_content['response']
                    elif 'content' in response_content:
                        final_response = response_content['content']
                    else:
                        final_response = str(response_content)
                elif isinstance(response_content, str):
                    final_response = response_content
                elif hasattr(response_content, 'content'):
                    final_response = response_content.content
                else:
                    final_response = str(response_content)
            
            # ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ… ì ìš©
            final_response = fix_markdown_formatting(final_response)
            
            # ğŸ” ëª¨ë“œ ê²€ì¦ ë° Fallback ë©”ì»¤ë‹ˆì¦˜ (ìƒˆë¡œ ì¶”ê°€)
            ppt_intent_detected = detect_ppt_intent_in_query(message)
            ppt_format_detected = detect_ppt_format(final_response)
            
            logger.info(f"ëª¨ë“œ ê²€ì¦: PPT ì˜ë„={ppt_intent_detected}, PPT í˜•ì‹={ppt_format_detected}")
            
            # ì˜ëª»ëœ ëª¨ë“œë¡œ ì‘ë‹µì´ ìƒì„±ëœ ê²½ìš° ì¬ì‹œë„
            needs_retry = False
            retry_reason = ""
            
            if not ppt_intent_detected and ppt_format_detected:
                # ì¼ë°˜ ì§ˆë¬¸ì¸ë° PPT í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•œ ê²½ìš°
                needs_retry = True
                retry_reason = "ì¼ë°˜ ì§ˆë¬¸ì— PPT í˜•ì‹ ì‘ë‹µ ìƒì„±"
            elif ppt_intent_detected and not ppt_format_detected:
                # PPT ìš”ì²­ì¸ë° ì¼ë°˜ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•œ ê²½ìš°
                # RAG ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ì–´ì„œ ì•ˆë‚´ ë©”ì‹œì§€ê°€ ë‚˜ì˜¨ ê²½ìš°ëŠ” ì •ìƒì´ë¯€ë¡œ ì¬ì‹œë„ ì•ˆí•¨
                if "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†" in final_response or "ê´€ë ¨ ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†" in final_response:
                    logger.info("PPT ìš”ì²­ì´ì§€ë§Œ RAG ìë£Œ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì•ˆë‚´ ë©”ì‹œì§€ - ì¬ì‹œë„ ì•ˆí•¨")
                    needs_retry = False
                else:
                    needs_retry = True
                    retry_reason = "PPT ìš”ì²­ì— ì¼ë°˜ í˜•ì‹ ì‘ë‹µ ìƒì„± (RAG ìë£ŒëŠ” ìˆìŒ)"
            
            # ì¬ì‹œë„ ë¡œì§ ì‹¤í–‰
            if needs_retry:
                logger.warning(f"ëª¨ë“œ ë¶ˆì¼ì¹˜ ê°ì§€: {retry_reason} - ì¬ì‹œë„ ì‹¤í–‰")
                
                try:
                    # ê°•í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
                    retry_system_prompt = None
                    try:
                        prompt_path = Path("/home/admin/wkms-aws/backend/prompts/general.prompt")
                        if prompt_path.exists():
                            base_prompt = prompt_path.read_text(encoding='utf-8').strip()
                            
                            # ëª¨ë“œë³„ ê°•í™”ëœ ì§€ì‹œì‚¬í•­ ì¶”ê°€
                            if not ppt_intent_detected:
                                # ì¼ë°˜ ëª¨ë“œ ê°•í™”
                                retry_system_prompt = base_prompt + "\n\nâš ï¸ CRITICAL: ì´ ì§ˆë¬¸ì€ ì¼ë°˜ì ì¸ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì ˆëŒ€ë¡œ ì œëª©(##, ###)ì´ë‚˜ ğŸ”‘ğŸ“ íŒ¨í„´ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. í‰ë¬¸ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”."
                            else:
                                # PPT ëª¨ë“œ ê°•í™”
                                retry_system_prompt = base_prompt + "\n\nâš ï¸ CRITICAL: ì´ ì§ˆë¬¸ì€ PPT ìƒì„± ìš”ì²­ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ## ì œëª©, ### ìŠ¬ë¼ì´ë“œ, ğŸ”‘ğŸ“ íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ìŠ¬ë¼ì´ë“œ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."
                    except Exception:
                        retry_system_prompt = base_prompt if 'base_prompt' in locals() else None
                    
                    # ì¬ì‹œë„ ë©”ì‹œì§€ êµ¬ì„±
                    retry_messages = []
                    if retry_system_prompt:
                        retry_messages.append({"role": "system", "content": retry_system_prompt})
                    
                    # ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì œì™¸)
                    retry_messages.extend(history_messages[:-1] if history_messages else [])
                    retry_messages.append({"role": "user", "content": prepared_prompt})
                    
                    # AI ì„œë¹„ìŠ¤ ì¬í˜¸ì¶œ
                    retry_response = await ai_service.chat_completion(
                        messages=retry_messages,
                        provider=provider
                    )
                    
                    # ì¬ì‹œë„ ì‘ë‹µ ì²˜ë¦¬
                    if isinstance(retry_response, dict):
                        if 'response' in retry_response:
                            retry_final = retry_response['response']
                        elif 'content' in retry_response:
                            retry_final = retry_response['content']
                        else:
                            retry_final = str(retry_response)
                    elif isinstance(retry_response, str):
                        retry_final = retry_response
                    elif hasattr(retry_response, 'content'):
                        retry_final = retry_response.content
                    else:
                        retry_final = str(retry_response)
                    
                    retry_final = fix_markdown_formatting(retry_final)
                    
                    # ì¬ì‹œë„ ê²°ê³¼ ê²€ì¦
                    retry_ppt_format = detect_ppt_format(retry_final)
                    
                    if not ppt_intent_detected and not retry_ppt_format:
                        # ì¼ë°˜ ì§ˆë¬¸ + ì¼ë°˜ ì‘ë‹µ (ì„±ê³µ)
                        final_response = retry_final
                        logger.info("ì¬ì‹œë„ ì„±ê³µ: ì¼ë°˜ ëª¨ë“œë¡œ ì •ìƒ ì‘ë‹µ ìƒì„±")
                    elif ppt_intent_detected and retry_ppt_format:
                        # PPT ìš”ì²­ + PPT ì‘ë‹µ (ì„±ê³µ)
                        final_response = retry_final
                        logger.info("ì¬ì‹œë„ ì„±ê³µ: PPT ëª¨ë“œë¡œ ì •ìƒ ì‘ë‹µ ìƒì„±")
                    else:
                        # ì¬ì‹œë„ë„ ì‹¤íŒ¨í•œ ê²½ìš° ì›ë³¸ ìœ ì§€í•˜ë˜ ë¡œê·¸ ë‚¨ê¹€
                        logger.warning(f"ì¬ì‹œë„ ì‹¤íŒ¨: ì—¬ì „íˆ ëª¨ë“œ ë¶ˆì¼ì¹˜ (PPT ì˜ë„={ppt_intent_detected}, PPT í˜•ì‹={retry_ppt_format})")
                
                except Exception as retry_err:
                    logger.error(f"ëª¨ë“œ ì¬ì‹œë„ ì‹¤íŒ¨: {retry_err}")
                    # ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‘ë‹µ ìœ ì§€
            
        except Exception as e:
            logger.error(f"RAG/AI ì²˜ë¦¬ ì‹¤íŒ¨, fallback ëª¨ë“œ: {e}")
            
            # Fallback: ê¸°ë³¸ AI ì„œë¹„ìŠ¤ ì‚¬ìš©
            try:
                system_prompt = None
                try:
                    prompt_path = Path("/home/admin/wkms-aws/backend/prompts/general.prompt")
                    if prompt_path.exists():
                        system_prompt = prompt_path.read_text(encoding='utf-8').strip()
                except Exception:
                    pass
                
                fallback_messages = []
                if system_prompt:
                    fallback_messages.append({"role": "system", "content": system_prompt})
                fallback_messages.extend(history_messages)
                fallback_messages.append({"role": "user", "content": message})
                
                response_content = await ai_service.chat_completion(
                    messages=fallback_messages,
                    provider=provider
                )
                
                # Fallbackì—ì„œë„ ê°œì„ ëœ ì‘ë‹µ ì²˜ë¦¬ ë¡œì§ ì ìš©
                if isinstance(response_content, dict):
                    if 'response' in response_content:
                        final_response = response_content['response']
                    elif 'content' in response_content:
                        final_response = response_content['content']
                    else:
                        final_response = str(response_content)
                elif isinstance(response_content, str):
                    final_response = response_content
                elif hasattr(response_content, 'content'):
                    final_response = response_content.content
                else:
                    final_response = str(response_content)
                    
                final_response = fix_markdown_formatting(final_response)
                
            except Exception as fallback_err:
                logger.error(f"Fallback AI ì„œë¹„ìŠ¤ ì‹¤íŒ¨: {fallback_err}")
                final_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # 9. AI ì‘ë‹µ ì €ì¥
        try:
            await chat_manager.add_message(
                session_id=session_id,
                content=final_response,
                message_type=MessageType.ASSISTANT,
                user_emp_no=user_emp_no,
                user_name=user_name,
                search_context=context_info
            )
        except Exception as e:
            logger.warning(f"AI ì‘ë‹µ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # 10. JSON ì‘ë‹µ ë°˜í™˜
        return {
            "response": final_response,
            "provider": rag_stats.get("provider", provider),
            "session_id": session_id,
            "references": clean_references_for_json(references) if references else [],
            "context_info": clean_stats_for_json(context_info),
            "rag_stats": rag_stats,
            "attachments": attachment_metadata,
            "voice_asset_id": request.voice_asset_id
        }
        
    except Exception as e:
        logger.error(f"ë™ê¸° ë©”ì‹œì§€ ì „ì†¡ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/chat/sessions")
async def get_chat_sessions(
    limit: int = Query(100, ge=1, le=200),
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db),
    chat_manager: RedisChatManager = Depends(get_redis_chat_manager)
):
    """
    ì±„íŒ… ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ
    - PostgreSQL ìš°ì„  ì¡°íšŒ (ì˜êµ¬ ì €ì¥ëœ ëª¨ë“  ì„¸ì…˜)
    - RedisëŠ” ì¶”ê°€ ì •ë³´ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©
    """
    try:
        # PostgreSQLì—ì„œ ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ
        sessions_query = (
            select(
                TbChatSessions.session_id,
                TbChatSessions.session_name,
                TbChatSessions.message_count,
                TbChatSessions.last_activity,
                TbChatSessions.created_date,
                TbChatSessions.last_modified_date,
                # ì‹¤ì œ ë©”ì‹œì§€ ìˆ˜ ì„œë¸Œì¿¼ë¦¬
                func.count(TbChatHistory.chat_id).label('actual_message_count')
            )
            .select_from(TbChatSessions)
            .outerjoin(
                TbChatHistory,
                TbChatSessions.session_id == TbChatHistory.session_id
            )
            .where(TbChatSessions.user_emp_no == str(current_user.emp_no))
            .where(TbChatSessions.is_active == True)
            .group_by(
                TbChatSessions.session_id,
                TbChatSessions.session_name,
                TbChatSessions.message_count,
                TbChatSessions.last_activity,
                TbChatSessions.created_date,
                TbChatSessions.last_modified_date
            )
            .order_by(desc(TbChatSessions.last_modified_date))
            .limit(limit)
        )
        
        result = await db.execute(sessions_query)
        db_sessions = result.all()
        
        logger.info(f"ğŸ“‹ PostgreSQLì—ì„œ {len(db_sessions)}ê°œ ì„¸ì…˜ ì¡°íšŒ: user={current_user.emp_no}")
        
        sessions = []
        for row in db_sessions:
            session_id = row.session_id
            
            # ì œëª© ì²˜ë¦¬
            title = row.session_name or "ìƒˆ ëŒ€í™”"
            if len(title) > 50:
                title = title[:50] + "..."
            
            # ì‹¤ì œ ë©”ì‹œì§€ ìˆ˜ vs ì„ ì–¸ëœ ë©”ì‹œì§€ ìˆ˜
            declared_count = row.message_count or 0
            actual_count = row.actual_message_count or 0
            
            # ë©”ì‹œì§€ ìˆ˜ëŠ” ì‹¤ì œ ë©”ì‹œì§€ ìˆ˜ ìš°ì„ , ì—†ìœ¼ë©´ ì„ ì–¸ëœ ìˆ˜ ì‚¬ìš©
            message_count = actual_count if actual_count > 0 else declared_count
            
            # ë§ˆì§€ë§‰ í™œë™ ì‹œê°„
            last_activity = row.last_modified_date or row.last_activity or row.created_date
            
            sessions.append({
                'session_id': session_id,
                'title': title,
                'message_count': message_count,
                'last_activity': last_activity.isoformat() if last_activity else None,
                'created_at': row.created_date.isoformat() if row.created_date else None,
                # ë””ë²„ê¹… ì •ë³´ (í”„ë¡ íŠ¸ì—ì„œ ì‚¬ìš© ì•ˆ í•´ë„ ë¨)
                '_debug': {
                    'declared_count': declared_count,
                    'actual_count': actual_count
                }
            })
        
        logger.info(f"âœ… ì„¸ì…˜ ëª©ë¡ ë°˜í™˜: {len(sessions)}ê°œ")
        
        return {
            "success": True,
            "sessions": sessions,
            "total": len(sessions)
        }
        
    except Exception as e:
        logger.error(f"âŒ ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(f"âŒ ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/chat/sessions/{session_id}")
async def delete_chat_session(
    session_id: str,
    current_user: User = Depends(get_current_user),
    chat_manager: RedisChatManager = Depends(get_redis_chat_manager),
    db: AsyncSession = Depends(get_db)
):
    """ì±„íŒ… ì„¸ì…˜ ì‚­ì œ - Redisì™€ PostgreSQL ëª¨ë‘ì—ì„œ ì‚­ì œ"""
    try:
        # PostgreSQLì—ì„œ ì„¸ì…˜ ì¡´ì¬ ì—¬ë¶€ ë° ì†Œìœ ì í™•ì¸ (PostgreSQLì´ ì†ŒìŠ¤ ì˜¤ë¸Œ íŠ¸ë£¨ìŠ¤)
        session_query = (
            select(TbChatSessions)
            .where(
                TbChatSessions.session_id == session_id,
                TbChatSessions.user_emp_no == str(current_user.emp_no),
                TbChatSessions.is_active == True
            )
        )
        session_result = await db.execute(session_query)
        session = session_result.scalars().first()
        if not session:
            logger.warning(f"âš ï¸ ì‚­ì œ ìš”ì²­í•œ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {session_id} (user={current_user.emp_no})")
            return {"success": False, "message": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        # Redisì—ì„œ ì„¸ì…˜ ì œê±° (ìˆì„ ë•Œë§Œ)
        redis_deleted = False
        try:
            redis_session = await chat_manager.get_chat_session(session_id)
            if redis_session:
                redis_deleted = await chat_manager.close_chat_session(session_id)
                logger.info(f"ğŸ—‘ï¸ Redis ì„¸ì…˜ ì‚­ì œ ì™„ë£Œ: {session_id}")
        except Exception as redis_error:
            logger.warning(f"âš ï¸ Redis ì„¸ì…˜ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {redis_error}")

        # PostgreSQLì—ì„œ íˆìŠ¤í† ë¦¬ ë° ì„¸ì…˜ ì‚­ì œ (íŠ¸ëœì­ì…˜)
        try:
            await db.execute(
                delete(TbChatHistory).where(TbChatHistory.session_id == session_id)
            )
            result = await db.execute(
                delete(TbChatSessions).where(
                    TbChatSessions.session_id == session_id,
                    TbChatSessions.user_emp_no == str(current_user.emp_no)
                )
            )
            await db.commit()

            deleted_rows = result.rowcount or 0
            logger.info(f"âœ… PostgreSQL ì„¸ì…˜ ì‚­ì œ ì™„ë£Œ: {session_id} (ì‚­ì œëœ ì„¸ì…˜ ìˆ˜: {deleted_rows})")
        except Exception as pg_error:
            await db.rollback()
            logger.error(f"âŒ PostgreSQL ì„¸ì…˜ ì‚­ì œ ì‹¤íŒ¨: {pg_error}")
            raise HTTPException(status_code=500, detail="ì„¸ì…˜ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

        return {
            "success": True,
            "message": "ì„¸ì…˜ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "removed_from_redis": redis_deleted
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ì‚­ì œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ===== VISION CHAT ENDPOINT =====

@router.post("/chat/vision")
async def chat_with_vision(
    message: str = Form(...),
    images: List[UploadFile] = File(...),
    session_id: Optional[str] = Form(None),
    provider: Optional[str] = Form("azure_openai"),
    container_ids: Optional[str] = Form(None),
    use_rag: bool = Form(True),
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db),
    chat_manager: RedisChatManager = Depends(get_redis_chat_manager)
):
    """
    ì´ë¯¸ì§€ í¬í•¨ ì±„íŒ… (ê°„ì†Œí™” ë²„ì „ - Blob Storage ì—†ì´ Base64 ì‚¬ìš©)
    
    Args:
        message: ì‚¬ìš©ì ì§ˆë¬¸
        images: ì—…ë¡œë“œëœ ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
        session_id: ì±„íŒ… ì„¸ì…˜ ID (ì„ íƒ)
        provider: AI ì œê³µì (azure_openai/bedrock/openai)
        container_ids: ê²€ìƒ‰ ëŒ€ìƒ ì»¨í…Œì´ë„ˆ (ì½¤ë§ˆ êµ¬ë¶„)
        use_rag: RAG ê²€ìƒ‰ ì‚¬ìš© ì—¬ë¶€
        current_user: í˜„ì¬ ì‚¬ìš©ì
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        chat_manager: Redis ì±„íŒ… ë§¤ë‹ˆì €
    
    Returns:
        ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ë° RAG ë‹µë³€
    """
    try:
        logger.info(f"ğŸ“¸ Vision ì±„íŒ… ì‹œì‘: {len(images)}ê°œ ì´ë¯¸ì§€, ì¿¼ë¦¬='{message[:50]}...'")
        
        # 1. ì„¸ì…˜ ID ìƒì„± ë˜ëŠ” í™•ì¸
        if not session_id:
            session_id = f"vision_{uuid.uuid4().hex[:12]}"
            logger.info(f"âœ… ìƒˆ Vision ì„¸ì…˜ ìƒì„±: {session_id}")
        
        # 2. ì»¨í…Œì´ë„ˆ ID íŒŒì‹±
        container_id_list = []
        if container_ids:
            try:
                container_id_list = [int(c.strip()) for c in container_ids.split(',') if c.strip()]
            except:
                logger.warning(f"âš ï¸ ì»¨í…Œì´ë„ˆ ID íŒŒì‹± ì‹¤íŒ¨: {container_ids}")
        
        # 3. ì´ë¯¸ì§€ ë¶„ì„ (Base64 ì‚¬ìš©)
        image_descriptions = []
        image_files_info = []
        
        for i, image in enumerate(images):
            try:
                # ì´ë¯¸ì§€ ë°ì´í„° ì½ê¸°
                image_data = await image.read()
                image_base64 = base64.b64encode(image_data).decode('utf-8')
                
                # Vision API ë¶„ì„
                description = await vision_service.analyze_image_from_base64(
                    base64_image=image_base64,
                    prompt=f"ì´ë¯¸ì§€ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•˜ê³ , ì£¼ìš” í…ìŠ¤íŠ¸ë‚˜ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì¶”ì¶œí•´ì£¼ì„¸ìš”.",
                    max_tokens=500
                )
                
                image_descriptions.append({
                    "image_index": i + 1,
                    "filename": image.filename or f"image_{i+1}",
                    "description": description
                })
                
                image_files_info.append({
                    "filename": image.filename or f"image_{i+1}",
                    "size": len(image_data),
                    "content_type": image.content_type or "image/jpeg"
                })
                
                logger.info(f"âœ… ì´ë¯¸ì§€ {i+1}/{len(images)} ë¶„ì„ ì™„ë£Œ")
                
            except Exception as e:
                logger.error(f"âŒ ì´ë¯¸ì§€ {i+1} ë¶„ì„ ì‹¤íŒ¨: {e}")
                image_descriptions.append({
                    "image_index": i + 1,
                    "filename": image.filename or f"image_{i+1}",
                    "description": f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
                })
        
        # 4. í†µí•© ì¿¼ë¦¬ ìƒì„± (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ì„¤ëª…)
        combined_query = f"{message}\n\n[ì²¨ë¶€ëœ ì´ë¯¸ì§€ ì •ë³´]\n"
        for desc in image_descriptions:
            combined_query += f"\nì´ë¯¸ì§€ {desc['image_index']} ({desc['filename']}):\n{desc['description']}\n"
        
        logger.info(f"âœ… í†µí•© ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ: {len(combined_query)} ê¸€ì")
        
        # 5. AI ë‹µë³€ ìƒì„± (RAGëŠ” ì¶”í›„ í†µí•© ê°€ëŠ¥)
        try:
            prompt = f"""ì§ˆë¬¸: {message}

[ì²¨ë¶€ëœ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼]
{chr(10).join([f"ì´ë¯¸ì§€ {d['image_index']}: {d['description']}" for d in image_descriptions])}

ìœ„ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."""
            
            ai_response = await ai_service.chat(
                message=prompt,
                provider=provider
            )
            
            final_response = ai_response if isinstance(ai_response, str) else ai_response.get("response", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            logger.info(f"âœ… AI ë‹µë³€ ìƒì„± ì™„ë£Œ: {len(final_response)} ê¸€ì")
            
        except Exception as e:
            logger.error(f"âŒ AI ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            final_response = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        
        # 6. ì„¸ì…˜ì— ë©”ì‹œì§€ ì €ì¥
        try:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            await chat_manager.add_message(
                session_id=session_id,
                message_type=MessageType.USER,
                content=message,
                user_emp_no=str(current_user.emp_no),
                user_name=str(current_user.username)
            )
            
            # AI ì‘ë‹µ ì €ì¥
            await chat_manager.add_message(
                session_id=session_id,
                message_type=MessageType.ASSISTANT,
                content=final_response,
                user_emp_no=str(current_user.emp_no),
                user_name=str(current_user.username),
                model_used=provider
            )
            
            logger.info(f"âœ… ì„¸ì…˜ ë©”ì‹œì§€ ì €ì¥ ì™„ë£Œ: {session_id}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì„¸ì…˜ ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # 7. ì‘ë‹µ ë°˜í™˜
        return {
            "response": final_response,
            "session_id": session_id,
            "provider": provider,
            "images": image_files_info,
            "image_descriptions": image_descriptions,
            "references": [],
            "context_info": {},
            "rag_stats": {}
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Vision ì±„íŒ… ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ===== END OF CHAT ENDPOINTS =====

# ===== CORE STREAMING FUNCTION =====

async def generate_stream(
    message: str,
    session_id: str,
    current_user: User,
    provider: Optional[str] = None,
    selected_documents: Optional[list] = None,
    chat_manager: Optional[RedisChatManager] = None,
    agent_type: str = 'general',
    container_ids: Optional[List[str]] = None,
    attachments: Optional[List[ChatAttachmentPayload]] = None,
    voice_asset_id: Optional[str] = None,
    max_tokens: Optional[int] = None,
    temperature: Optional[float] = None
):
    """
    ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± í•¨ìˆ˜ - ì´ì „ ë²„ì „ì—ì„œ ë³µì›
    """
    try:
        # ì‚¬ìš©ì ì •ë³´ë¥¼ async ì»¨í…ìŠ¤íŠ¸ ë°–ì—ì„œ ë¯¸ë¦¬ ì €ì¥
        user_emp_no = str(current_user.emp_no)
        user_name = str(current_user.username)
        user_department = "ê¸°ë³¸ë¶€ì„œ"  # async ì»¨í…ìŠ¤íŠ¸ ë¬¸ì œ ë°©ì§€
        
        # LLM íŒŒë¼ë¯¸í„° ì‚¬ì „ ê³„ì‚°
        effective_provider = provider or settings.get_current_llm_provider()
        effective_max_tokens = max_tokens or settings.max_tokens
        effective_temperature = settings.temperature if temperature is None else temperature

        logger.info(
            f"ğŸš€ ì±„íŒ… ìŠ¤íŠ¸ë¦¼ ì‹œì‘: ì‚¬ìš©ì {user_emp_no}, ì„¸ì…˜ {session_id}, "
            f"provider={effective_provider}, max_tokens={effective_max_tokens}, temperature={effective_temperature}"
        )

        # ì¦‰ì‹œ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸° ì´ë²¤íŠ¸ ì „ì†¡ (í”„ë¡ íŠ¸ê°€ ë¡œë”© ìƒíƒœ ì „í™˜ ê°€ëŠ¥)
        init_event = {"type": "init", "session_id": session_id, "provider": effective_provider}
        yield f"data: {json.dumps(init_event, ensure_ascii=False)}\n\n"

        # ì´í›„ ë¡œì§ì—ì„œ ì¼ê´€ëœ provider ì‚¬ìš©
        provider = effective_provider
        
        # Redis Chat Manager ì´ˆê¸°í™”
        if not chat_manager:
            chat_manager = get_redis_chat_manager()
        
        # ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        if session_id:
            existing_session = await chat_manager.get_chat_session(session_id)
            if not existing_session:
                logger.info(f"ìƒˆ ì„¸ì…˜ ìƒì„±: {session_id}")
                await chat_manager.create_chat_session(
                    user_emp_no=user_emp_no,
                    user_name=user_name,
                    department=user_department,
                    session_id=session_id
                )
        else:
            # ì„¸ì…˜ IDê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            session_id = str(uuid.uuid4())
            logger.info(f"ìƒˆ ì„¸ì…˜ ID ìƒì„±: {session_id}")
            await chat_manager.create_chat_session(
                user_emp_no=user_emp_no,
                user_name=user_name,
                department=user_department,
                session_id=session_id
            )
        
        # ì‹œì‘ ì´ë²¤íŠ¸
        yield f"data: {json.dumps({'type': 'start', 'session_id': session_id}, ensure_ascii=False)}\n\n"
        
        # ì„ íƒëœ ë¬¸ì„œ ì •ë³´ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¤€ë¹„
        selected_docs_context: Optional[Dict[str, Any]] = None
        if selected_documents and len(selected_documents) > 0:
            normalized_selected_docs = []
            for doc in selected_documents:
                if isinstance(doc, dict):
                    normalized_selected_docs.append({
                        'id': doc.get('id'),
                        'fileName': doc.get('fileName'),
                        'fileType': doc.get('fileType'),
                    })
                else:
                    normalized_selected_docs.append({
                        'id': getattr(doc, 'id', None),
                        'fileName': getattr(doc, 'fileName', None),
                        'fileType': getattr(doc, 'fileType', None),
                    })
            selected_docs_context = {'selected_documents': normalized_selected_docs}

        attachment_metadata: List[Dict[str, Any]] = []
        if attachments:
            for payload in attachments:
                try:
                    stored = chat_attachment_service.get(payload.asset_id)
                    if not stored:
                        logger.warning("âš ï¸ ì²¨ë¶€ ìì‚°ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: %s", payload.asset_id)
                        continue
                    if stored.owner_emp_no != str(current_user.emp_no):
                        logger.warning("âš ï¸ ì²¨ë¶€ ìì‚°ì— ëŒ€í•œ ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ: %s", payload.asset_id)
                        continue
                    attachment_metadata.append({
                        "asset_id": stored.asset_id,
                        "file_name": stored.file_name,
                        "mime_type": stored.mime_type,
                        "size": stored.size,
                        "category": stored.category,
                        "download_url": stored.download_url,
                        "preview_url": stored.preview_url
                    })
                except Exception as exc:
                    logger.error("ì²¨ë¶€ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: %s", exc)

        user_context = selected_docs_context.copy() if selected_docs_context else {}
        if attachment_metadata:
            user_context['attachments'] = attachment_metadata
        if voice_asset_id:
            user_context['voice_asset_id'] = voice_asset_id
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ Redisì— ì €ì¥ (ì„ íƒëœ ë¬¸ì„œ í¬í•¨)
        try:
            await chat_manager.add_message(
                session_id=session_id,
                content=message,
                message_type=MessageType.USER,
                user_emp_no=user_emp_no,
                user_name=str(user_name),
                search_context=user_context  # ì„ íƒëœ ë¬¸ì„œ ë° ì²¨ë¶€ ì •ë³´ ì €ì¥
            )
        except Exception as e:
            logger.warning(f"ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # ë©€í‹°í„´ ëŒ€í™”ë¥¼ ìœ„í•œ ì±„íŒ… ê¸°ë¡ ë¯¸ë¦¬ ê°€ì ¸ì˜¤ê¸°
        history_messages = []
        try:
            # ìµœê·¼ 4ê°œ ë©”ì‹œì§€ (2í„´) ê°€ì ¸ì˜¤ê¸°
            recent_messages = await chat_manager.get_recent_messages(session_id, limit=4)
            if recent_messages:
                logger.info(f"âœ… ì„¸ì…˜ {session_id}ì—ì„œ ë©€í‹°í„´ ì»¨í…ìŠ¤íŠ¸ìš© ë©”ì‹œì§€ {len(recent_messages)}ê°œ ë¡œë“œ")
                for msg in recent_messages:
                    history_messages.append({
                        "role": "user" if msg.message_type.value == "user" else "assistant",
                        "content": msg.content
                    })
            else:
                logger.info(f"ì„¸ì…˜ {session_id}ì— ì´ì „ ë©”ì‹œì§€ ì—†ìŒ")
        except Exception as e:
            logger.warning(f"ì±„íŒ… ê¸°ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            history_messages = []

        # AI ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ì„± ê²€ì¦ (ê²½ëŸ‰í™”: ì‚¬ì „ í”„ë¡œë¹™ í˜¸ì¶œ ì œê±°)
        agent_available = True
        
        if not agent_available:
            logger.warning("âŒ AI ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ ì‚¬ìš©ë¶ˆê°€ - ê¸°ë³¸ AI ì„œë¹„ìŠ¤ë¡œ ëŒ€ì²´")
            
            # ë©€í‹°í„´ ëŒ€í™”ë¥¼ ìœ„í•œ ì±„íŒ… ê¸°ë¡ ê°€ì ¸ì˜¤ê¸° (fallbackìš©)
            history_messages = []
            try:
                # ìµœê·¼ 4ê°œ ë©”ì‹œì§€ (2í„´) ê°€ì ¸ì˜¤ê¸°
                recent_messages = await chat_manager.get_recent_messages(session_id, limit=4)
                if recent_messages:
                    logger.info(f"âœ… Fallback - ì„¸ì…˜ {session_id}ì—ì„œ ë©€í‹°í„´ ì»¨í…ìŠ¤íŠ¸ìš© ë©”ì‹œì§€ {len(recent_messages)}ê°œ ë¡œë“œ")
                    for msg in recent_messages:
                        history_messages.append({
                            "role": "user" if msg.message_type.value == "user" else "assistant",
                            "content": msg.content
                        })
                else:
                    logger.info(f"ğŸ” Fallback - ì„¸ì…˜ {session_id}ì— ê¸°ë¡ì´ ì—†ìŒ, ë¹ˆ ê¸°ë¡ìœ¼ë¡œ ì‹œì‘")
            except Exception as e:
                logger.warning(f"âš ï¸ Fallback - ì±„íŒ… ê¸°ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
            system_prompt = None
            try:
                prompt_path = Path("/home/admin/wkms-aws/backend/prompts/general.prompt")
                if prompt_path.exists():
                    system_prompt = prompt_path.read_text(encoding='utf-8').strip()
                    logger.info("âœ… ê¸°ë³¸ ì„œë¹„ìŠ¤ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì„±ê³µ")
            except Exception as e:
                logger.warning(f"âš ï¸ ê¸°ë³¸ ì„œë¹„ìŠ¤ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # ê¸°ë³¸ AI ì„œë¹„ìŠ¤ë¡œ ìŠ¤íŠ¸ë¦¬ë° (ë©€í‹°í„´ ëŒ€í™” ì§€ì›)
            fallback_messages = []
            if system_prompt:
                fallback_messages.append({"role": "system", "content": system_prompt})
            fallback_messages.extend(history_messages)
            fallback_messages.append({"role": "user", "content": message})
            
            async for chunk in ai_service.chat_stream(
                messages=fallback_messages,
                provider=provider
            ):
                if chunk:
                    content = ""
                    if isinstance(chunk, str):
                        content = chunk
                    elif hasattr(chunk, 'content'):
                        content = chunk.content
                    elif hasattr(chunk, 'text'):
                        content = chunk.text
                    elif isinstance(chunk, dict):
                        content = chunk.get('content', '') or chunk.get('text', '') or str(chunk)
                    else:
                        content = str(chunk)
                    
                    if content:
                        response_data = {
                            "type": "content",
                            "content": content
                        }
                        yield f"data: {json.dumps(response_data, ensure_ascii=False)}\n\n"
            
            # ì™„ë£Œ ì´ë²¤íŠ¸
            yield f"data: {json.dumps({'type': 'complete', 'session_id': session_id}, ensure_ascii=False)}\n\n"
            yield "data: [DONE]\n\n"
            return
        
        # ê²€ìƒ‰ ì‹œì‘ ì•Œë¦¼
        yield f"data: {json.dumps({'type': 'searching'}, ensure_ascii=False)}\n\n"
        
        # 2. ì±„íŒ… ê¸°ë¡ ê°€ì ¸ì˜¤ê¸° (RAG ê²€ìƒ‰ìš©ìœ¼ë¡œ ì •ì œ)
        history_for_rag = []
        recent_raw_messages = []
        if chat_manager and session_id:
            try:
                recent_raw_messages = await chat_manager.get_recent_messages(session_id, limit=4)
                for msg in recent_raw_messages:
                    role = 'user' if msg.message_type.value == "user" else 'assistant'
                    # RAG ê²€ìƒ‰ìš© ì»¨í…ìŠ¤íŠ¸ì—ì„œëŠ” ë§ˆí¬ë‹¤ìš´ì„ ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©
                    clean_content = re.sub(r'#+\s*', '', msg.content)
                    history_for_rag.append({"role": role, "content": clean_content})
                logger.info(f"âœ… ì„¸ì…˜ {session_id}ì—ì„œ RAG ê²€ìƒ‰ìš©ìœ¼ë¡œ ì •ì œëœ ë©”ì‹œì§€ {len(history_for_rag)}ê°œ ë¡œë“œ")
            except Exception as e:
                logger.warning(f"ì±„íŒ… ê¸°ë¡ ë¡œë“œ ì‹¤íŒ¨ (RAGìš©): {e}")

        # RAG ê²€ìƒ‰ ë° ì—ì´ì „íŠ¸ ì²˜ë¦¬ (ì •ì œëœ ì±„íŒ… ê¸°ë¡ ì „ë‹¬)
        try:
            logger.info(f"ğŸ” generate_streamì—ì„œ ë°›ì€ selected_documents: {selected_documents}")
            logger.info(f"ğŸ” selected_documents íƒ€ì…: {type(selected_documents)}")
            
            normalized_docs: List[SelectedDocument] = []
            if selected_documents and len(selected_documents) > 0:
                logger.info(f"ğŸ” selected_documents ì •ê·œí™” ì‹œì‘: {len(selected_documents)}ê°œ")
                for d in selected_documents:
                    if isinstance(d, SelectedDocument):
                        normalized_docs.append(d)
                    elif isinstance(d, dict):
                        normalized_docs.append(SelectedDocument(**d))

            # ì„ íƒëœ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ìµœê·¼ ì‚¬ìš©ì ë©”ì‹œì§€ì˜ search_contextì—ì„œ ìƒì†
            if not normalized_docs:
                try:
                    for m in (recent_raw_messages or []):
                        if getattr(m, 'message_type', None) and m.message_type.value == "user":
                            sc = getattr(m, 'search_context', None) or {}
                            if isinstance(sc, dict) and sc.get('selected_documents'):
                                inherited = []
                                for d in sc.get('selected_documents', []):
                                    try:
                                        if isinstance(d, dict):
                                            inherited.append(SelectedDocument(**d))
                                    except Exception:
                                        continue
                                if inherited:
                                    normalized_docs = inherited
                                    logger.info(f"ğŸ“„ ìµœê·¼ ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì„ íƒ ë¬¸ì„œ ìƒì†: {len(normalized_docs)}ê°œ")
                                    break
                except Exception as inh_err:
                    logger.warning(f"ì„ íƒ ë¬¸ì„œ ìƒì† ì¤‘ ê²½ê³ : {inh_err}")

            # ì„ íƒëœ ë¬¸ì„œê°€ ìµœì¢… ì—†ìœ¼ë©´ Noneì„ ì „ë‹¬í•˜ì—¬ ì „ì²´ ë¬¸ì„œ ê²€ìƒ‰
            docs_to_pass = normalized_docs if normalized_docs else None
            logger.info(f"ğŸ” ìµœì¢… docs_to_pass: {docs_to_pass}")
            
            # ì´ë¯¸ì§€ ì²¨ë¶€ ì •ë³´ ë¡œê¹…
            if attachment_metadata:
                logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì²¨ë¶€ ê°ì§€: {len(attachment_metadata)}ê°œ")
                for idx, att in enumerate(attachment_metadata):
                    logger.info(f"  ğŸ“ ì²¨ë¶€ {idx+1}: {att.get('file_name')} ({att.get('mime_type')})")

            prepared_prompt, references, context_info, rag_stats = await ai_agent_service.prepare_context_with_documents(
                query=message,
                selected_documents=docs_to_pass,
                chat_history=history_for_rag,  # ì •ì œëœ ì±„íŒ… ê¸°ë¡ ì „ë‹¬
                agent_type='general',
                container_ids=None,
                attachments=attachment_metadata  # ğŸ†• ì´ë¯¸ì§€ ì²¨ë¶€ ì •ë³´ ì „ë‹¬
            )
            
            chunks_count = len(references or [])
            search_complete_event = {'type': 'search_complete', 'chunks_count': chunks_count}
            yield f"data: {json.dumps(search_complete_event, ensure_ascii=False)}\n\n"
            
            context_event = {
                "type": "metadata",
                "references": clean_references_for_json(references) if not context_info.get('search_failed') else [],
                "context_info": clean_stats_for_json(context_info),
                "rag_stats": clean_stats_for_json({**rag_stats, "provider": settings.get_current_llm_provider()}),
            }
            yield f"data: {json.dumps(context_event, ensure_ascii=False)}\n\n"
            
            # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œì—ë„ ë©€í‹°í„´ íˆìŠ¤í† ë¦¬ë¡œ ë³´ì™„í•˜ì—¬ LLM ìƒì„±ìœ¼ë¡œ ì§„í–‰ (ì¦‰ì‹œ ì¢…ë£Œ ê¸ˆì§€)
            try:
                if isinstance(context_info, dict) and context_info.get('search_failed'):
                    logger.info("ğŸ” ê²€ìƒ‰ ì‹¤íŒ¨ - íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ë³´ì™„ ìƒì„±ìœ¼ë¡œ ì§„í–‰")
                    # ì´í›„ ë‹¨ê³„ì—ì„œ íˆìŠ¤í† ë¦¬ë¥¼ ê°•ì œë¡œ í¬í•¨í•˜ë„ë¡ í”Œë˜ê·¸ë§Œ ë‚¨ê¹€
                    context_info['force_history_fallback'] = True
            except Exception as _e:
                logger.warning(f"ê²€ìƒ‰ ì‹¤íŒ¨ Fallback í‘œì‹œ ì¤‘ ê²½ê³ : {_e}")
            
        except Exception as prep_err:
            logger.error(f"âŒ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ ì‹¤íŒ¨: {prep_err}")
            prepared_prompt, references, context_info, rag_stats = message, [], {"rag_used": False, "error": str(prep_err)}, {}
            search_complete_event = {'type': 'search_complete', 'chunks_count': 0, 'error': str(prep_err)}
            yield f"data: {json.dumps(search_complete_event, ensure_ascii=False)}\n\n"
        
        # ìƒì„± ì‹œì‘ ì•Œë¦¼
        yield f"data: {json.dumps({'type': 'generating'}, ensure_ascii=False)}\n\n"

        # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        system_prompt = None
        try:
            prompt_path = Path("/home/admin/wkms-aws/backend/prompts/general.prompt")
            if prompt_path.exists():
                system_prompt = prompt_path.read_text(encoding='utf-8').strip()
                logger.info("âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            logger.warning(f"âš ï¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

        # 2. LLMìš© ì±„íŒ… ê¸°ë¡ ì¤€ë¹„ (ëª…ì‹œì  ì°¸ì¡° ì—¬ë¶€ì— ë”°ë¼ ì œì–´)
        history_for_llm = []
        
        # ë©€í‹°í„´ ì»¨í…ìŠ¤íŠ¸ ì ìš© ì—¬ë¶€ í™•ì¸
        context_used = isinstance(context_info, dict) and context_info.get('context_used', False)
        explicit_reference = isinstance(context_info, dict) and context_info.get('reason') != 'no_explicit_reference'

        # ì§§ì€ í›„ì† ì§ˆì˜/ëŒ€ëª…ì‚¬ ê¸°ë°˜ ê°•ì œ ë§¥ë½ ì‚¬ìš© ì™„í™” ë¡œì§
        try:
            short_query = len(message.strip()) <= 12
            followup_pattern = re.search(r'(ì´ê±°|ê·¸ê±°|ê·¸ê±´|ê·¸ë¦¬ê³ |ê·¼ë°|ê·¸ë¦¼|í‘œ|ë…¼ë¬¸|ì€ìš”|ëŠ”ìš”|\?$)$', message.strip())
            force_history = bool(short_query or followup_pattern or (isinstance(context_info, dict) and context_info.get('force_history_fallback')))
        except Exception:
            force_history = False
        
        if force_history and not context_used:
            context_used = True
            explicit_reference = True
            if isinstance(context_info, dict):
                context_info['context_used'] = True
        
        if chat_manager and session_id and context_used and explicit_reference:
            try:
                recent_raw_messages = await chat_manager.get_recent_messages(session_id, limit=4)
                for msg in recent_raw_messages:
                    role = 'user' if msg.message_type.value == "user" else 'assistant'
                    # LLMìš© ê¸°ë¡ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€
                    history_for_llm.append({"role": role, "content": msg.content})
                logger.info(f"âœ… ë©€í‹°í„´ ì ìš© - ì„¸ì…˜ {session_id}ì—ì„œ LLMìš© ë©”ì‹œì§€ {len(history_for_llm)}ê°œ ë¡œë“œ")
            except Exception as e:
                logger.warning(f"LLMìš© ì±„íŒ… ê¸°ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            logger.info(f"ğŸ“ ë…ë¦½ì  ì§ˆë¬¸ ì²˜ë¦¬ - ëŒ€í™” íˆìŠ¤í† ë¦¬ ì œì™¸ (context_used={context_used}, explicit_ref={explicit_reference}, force={force_history})")

        # 3. AI ì„œë¹„ìŠ¤ì— ì „ë‹¬í•  ìµœì¢… ë©”ì‹œì§€ ëª©ë¡ êµ¬ì„±
        llm_messages = []
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ í•©ì¹˜ê¸° (Anthropic í˜¸í™˜)
        combined_system_content = ""
        
        # ìƒì„± ëª¨ë“œ(ê²Œì´íŒ…) ì•ˆë‚´ ë¬¸êµ¬ êµ¬ì„±
        mode_instruction = ""
        try:
            mode = context_info.get('selected_mode') if isinstance(context_info, dict) else None
            reason = context_info.get('gating_reason') if isinstance(context_info, dict) else None
            refs_count = 0
            try:
                refs_count = len(references) if references else 0
            except Exception:
                refs_count = 0
            if mode:
                logger.info(f"ğŸ›ï¸ ìƒì„± ëª¨ë“œ: {mode}{' (' + reason + ')' if reason else ''}")
            if mode == 'outline':
                mode_instruction = (
                    "\n\n[ìƒì„± ì§€ì¹¨]\n"
                    "- ì°¸ê³ ìë£Œê°€ ì œí•œì ì´ë¯€ë¡œ ê±°ì ˆí•˜ì§€ ë§ê³  'ì•„ì›ƒë¼ì¸ ìˆ˜ì¤€'ì˜ PPT ê°œìš”ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n"
                    "- Markdown í—¤ë”©(##, ###), ğŸ”‘, ğŸ“ë§Œ ì‚¬ìš©í•˜ê³  ì½”ë“œíœìŠ¤(```), ì¸ë¼ì¸ ì½”ë“œ(`)ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n"
                    "- ê° ìŠ¬ë¼ì´ë“œì˜ ì œëª©ê³¼ 3~5ê°œì˜ í•µì‹¬ ë¶ˆë¦¿ë§Œ ì‘ì„±í•©ë‹ˆë‹¤.\n"
                    "- ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ 'í™•ì¸ í•„ìš”'ë¡œ í‘œì‹œí•˜ê³ , ì¶”ê°€ë¡œ í•„ìš”í•œ ìë£Œ/ì§ˆë¬¸ì„ ì œì•ˆí•˜ì„¸ìš”.\n"
                    "- ì°¸ê³ ìë£Œê°€ 1ê°œ ì´ìƒì´ë©´ ì‚¬ê³¼/ê±°ì ˆ(ìë£Œ ì—†ìŒ)ì€ ê¸ˆì§€ë©ë‹ˆë‹¤. ìµœì†Œí•œ ì•„ì›ƒë¼ì¸ì„ ì‘ì„±í•˜ì„¸ìš”.\n"
                )
            elif mode == 'full':
                mode_instruction = (
                    "\n\n[ìƒì„± ì§€ì¹¨]\n"
                    "- Markdown í—¤ë”©(##, ###), ğŸ”‘, ğŸ“ë§Œ ì‚¬ìš©í•˜ê³  ì½”ë“œíœìŠ¤(```), ì¸ë¼ì¸ ì½”ë“œ(`)ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n"
                    "- ì°¸ê³ ìë£Œê°€ 1ê°œ ì´ìƒì´ë©´ ì‚¬ê³¼/ê±°ì ˆ(ìë£Œ ì—†ìŒ)ì€ ê¸ˆì§€ë©ë‹ˆë‹¤. í•„ìš”í•œ ê²½ìš° 'í™•ì¸ í•„ìš”'ë¡œ í‘œì‹œí•˜ê³  ë‚´ìš©ì„ êµ¬ì„±í•˜ì„¸ìš”.\n"
                )
        except Exception:
            pass

        # prepared_promptê°€ ì¡´ì¬í•˜ë©´ ì´ë¥¼ ìš°ì„  ì‹œìŠ¤í…œ ì»¨í…ì¸ ë¡œ ì‚¬ìš© (ì¤‘ë³µ ë°©ì§€)
        if prepared_prompt and prepared_prompt.strip() and prepared_prompt != message:
            combined_system_content = prepared_prompt
            if mode_instruction:
                combined_system_content += mode_instruction
        else:
            if system_prompt:
                combined_system_content = system_prompt + mode_instruction
        
        # í•©ì³ì§„ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì²« ë²ˆì§¸ì— ì¶”ê°€
        if combined_system_content:
            llm_messages.append({"role": "system", "content": combined_system_content})
        
        # ì±„íŒ… ê¸°ë¡ì„ LLMì— ì „ë‹¬
        llm_messages.extend(history_for_llm)
        
        # ğŸ†• ìš”ì•½ ëª¨ë“œì¼ ë•Œ ì‚¬ìš©ì ë©”ì‹œì§€ ì¬êµ¬ì„±
        is_summarization_mode = isinstance(context_info, dict) and context_info.get('summarization_mode', False)
        
        if is_summarization_mode and prepared_prompt and prepared_prompt != message:
            # ìš”ì•½ ëª¨ë“œ: ì›ë¬¸ ì»¨í…ìŠ¤íŠ¸ + ìš”ì•½ ì§€ì‹œì‚¬í•­
            user_message_content = f"""{prepared_prompt}

ìœ„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ìš”ì²­ì— ë‹µë³€í•´ì£¼ì„¸ìš”:
{message}

ë‹µë³€ ì§€ì¹¨:
- ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”
- ì£¼ìš” ê°œë…, ë°©ë²•ë¡ , ê²°ë¡ ì„ í¬í•¨í•˜ì„¸ìš”
- ì›ë¬¸ì˜ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”
- ì¶œì²˜ëŠ” (íŒŒì¼ëª…, p.í˜ì´ì§€ë²ˆí˜¸) í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”"""
            
            logger.info(f"ğŸ“ ìš”ì•½ ëª¨ë“œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì™„ë£Œ: ì›ë¬¸ {len(prepared_prompt)}ì + ì§€ì‹œì‚¬í•­")
        else:
            # ì¼ë°˜ ëª¨ë“œ: ì›ë³¸ ë©”ì‹œì§€ ë˜ëŠ” prepared_prompt
            user_message_content = prepared_prompt if prepared_prompt else message
        
        llm_messages.append({"role": "user", "content": user_message_content})

        # ë””ë²„ê·¸ ë¡œê¹…
        logger.info(f"ğŸ” LLMì— ì „ë‹¬í•  ì´ ë©”ì‹œì§€ ìˆ˜: {len(llm_messages)}")
        logger.info(f"ğŸ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í¬í•¨: {'YES' if combined_system_content else 'NO'}")
        try:
            rag_included = bool(references and len(references) > 0 and not (isinstance(context_info, dict) and context_info.get('search_failed')))
        except Exception:
            rag_included = False
        logger.info(f"ğŸ” RAG ì»¨í…ìŠ¤íŠ¸ í¬í•¨: {'YES' if rag_included else 'NO'}")
        if llm_messages:
            logger.info(f"ğŸ” ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€: {llm_messages[-1]['content'][:100]}...")

        collected_response = ""
        # PPT ì˜ë„ ì—¬ë¶€ ì‚¬ì „ ê³„ì‚° (ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì½”ë“œíœìŠ¤ ì œê±°ìš©)
        try:
            stream_ppt_intent = detect_ppt_intent_in_query(message)
        except Exception:
            stream_ppt_intent = False
        
        # 5. AI ì„œë¹„ìŠ¤ ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ (ì‹¤ì‹œê°„ í† í°ë³„ ìŠ¤íŠ¸ë¦¬ë°)
        # - LLM ì²­í¬ ìˆ˜ì‹ ì´ ì§€ì—°ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë³„ë„ producer íƒœìŠ¤í¬ + í + í•‘(keepalive) ì´ë²¤íŠ¸ë¡œ ì—°ê²° ìœ ì§€
        queue: asyncio.Queue = asyncio.Queue(maxsize=100)

        async def _producer():
            try:
                async for _chunk in ai_service.chat_stream(
                    messages=llm_messages,
                    provider=provider,
                    max_tokens=effective_max_tokens,
                    temperature=effective_temperature
                ):
                    await queue.put(_chunk)
            except Exception as _e:
                await queue.put({"__error__": str(_e)})
            finally:
                await queue.put(None)  # sentinel

        producer_task = asyncio.create_task(_producer())

        while True:
            try:
                item = await asyncio.wait_for(queue.get(), timeout=2.0)
            except asyncio.TimeoutError:
                # ì£¼ê¸°ì  í•‘ìœ¼ë¡œ ì—°ê²° ìœ ì§€ ë° í”„ë¡ íŠ¸ ì§„í–‰ í‘œì‹œ
                ping_event = {"type": "ping", "ts": datetime.utcnow().isoformat()}
                yield f"data: {json.dumps(ping_event, ensure_ascii=False)}\n\n"
                continue

            if item is None:
                # ìƒì‚° ì¢…ë£Œ
                break

            if isinstance(item, dict) and item.get("__error__"):
                # producerì—ì„œì˜ ì˜ˆì™¸ë¥¼ ìŠ¤íŠ¸ë¦¼ ì—ëŸ¬ë¡œ ì „ë‹¬
                error_event = {"type": "error", "message": item.get("__error__")}
                yield f"data: {json.dumps(error_event, ensure_ascii=False)}\n\n"
                break

            chunk = item
            if not chunk:
                continue
            content = ""
            if isinstance(chunk, str):
                content = chunk
            elif isinstance(chunk, dict):
                content = chunk.get('content', '') or chunk.get('text', '') or str(chunk)
            elif hasattr(chunk, 'content'):
                try:
                    content = chunk.content
                except Exception:
                    content = str(chunk)
            elif hasattr(chunk, 'text'):
                try:
                    content = chunk.text
                except Exception:
                    content = str(chunk)
            else:
                content = str(chunk)

            if content:
                # ì‹¤ì‹œê°„ í‘œì‹œ ê°œì„ : PPT ì˜ë„ ì‹œ ì½”ë“œíœìŠ¤(```) ë§ˆì»¤ ì œê±°
                if stream_ppt_intent:
                    try:
                        content = content.replace("```", "")
                    except Exception:
                        pass
                # ì²­í¬ í¬ê¸° ì œí•œ (í´ë¼ì´ì–¸íŠ¸ ë²„í¼ ì˜¤ë²„í”Œë¡œìš° ë°©ì§€)
                # í° ì²­í¬ë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í•  ì „ì†¡
                chunk_size = 500
                if len(content) > chunk_size:
                    for i in range(0, len(content), chunk_size):
                        sub_content = content[i:i+chunk_size]
                        response_data = {"type": "content", "content": sub_content}
                        yield f"data: {json.dumps(response_data, ensure_ascii=False)}\n\n"
                else:
                    # ì‹¤ì‹œê°„ í† í°ë³„ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡ (í›„ì²˜ë¦¬ ì—†ìŒ)
                    response_data = {
                        "type": "content",
                        "content": content
                    }
                    yield f"data: {json.dumps(response_data, ensure_ascii=False)}\n\n"
                collected_response += content

        # ì¢…ë£Œ ì „ producer_task ì •ë¦¬
        try:
            await producer_task
        except Exception:
            pass
        
        # ğŸ” ë””ë²„ê·¸: LLMì´ ìƒì„±í•œ ì›ë³¸ ë‹µë³€ ë¡œê·¸ ì¶œë ¥ (í›„ì²˜ë¦¬ ì—†ì´ ì›ë³¸ ê·¸ëŒ€ë¡œ)
        logger.info(f"ğŸ” [DEBUG] LLM ì›ë³¸ ë‹µë³€ (ê¸¸ì´: {len(collected_response)}ì):")
        logger.info(f"ğŸ” [DEBUG] ì›ë³¸ ë‹µë³€ (í›„ì²˜ë¦¬ ì—†ìŒ):\n{collected_response}")

        # PPT ì˜ë„ ì‹œ ì¶œë ¥ ì •ë¦¬ (ì½”ë“œíœìŠ¤ ì œê±° ë“±)
        try:
            ppt_intent = detect_ppt_intent_in_query(message)
        except Exception:
            ppt_intent = False
        final_to_store = collected_response
        if ppt_intent:
            final_to_store = sanitize_ppt_markdown(final_to_store)
            final_to_store = fix_markdown_formatting(final_to_store)
        
        # AI ì‘ë‹µì„ Redisì— ì €ì¥ (ì›ë³¸ LLM ë‹µë³€ ê·¸ëŒ€ë¡œ)
        saved_message = None
        try:
            # ğŸ” ë””ë²„ê¹…: references êµ¬ì¡° í™•ì¸
            logger.info(f"ğŸ” [DEBUG] references íƒ€ì…: {type(references)}")
            logger.info(f"ğŸ” [DEBUG] references ê¸¸ì´: {len(references) if references else 0}")
            if references and len(references) > 0:
                logger.info(f"ğŸ” [DEBUG] ì²« ë²ˆì§¸ reference íƒ€ì…: {type(references[0])}")
                logger.info(f"ğŸ” [DEBUG] ì²« ë²ˆì§¸ reference ë‚´ìš©: {references[0]}")
                if hasattr(references[0], '__dict__'):
                    logger.info(f"ğŸ” [DEBUG] ì²« ë²ˆì§¸ reference ì†ì„±ë“¤: {references[0].__dict__}")
            
            # referencesì—ì„œ ë¬¸ì„œ ID ì¶”ì¶œ (ì •ê·œí™”: int ë³€í™˜ ë° ì¤‘ë³µ ì œê±°)
            referenced_doc_ids: List[int] = []
            if references:
                seen_ids = set()
                for ref in references:
                    doc_id = None
                    if isinstance(ref, dict):
                        # ì‹¤ì œ í•„ë“œëª…ì€ file_bss_info_snoì…ë‹ˆë‹¤
                        doc_id = ref.get('file_bss_info_sno') or ref.get('document_id')
                    else:
                        # ê°ì²´ì¸ ê²½ìš°
                        try:
                            doc_id = getattr(ref, 'file_bss_info_sno', None) or getattr(ref, 'document_id', None)
                        except Exception:
                            doc_id = None
                    # intë¡œ ì •ê·œí™” (ë¬¸ìì—´ ìˆ«ì í—ˆìš©)
                    if doc_id is not None:
                        try:
                            normalized = int(doc_id)
                        except Exception:
                            # 'doc_123' ê°™ì€ ì¼€ì´ìŠ¤ ëŒ€ì‘
                            try:
                                import re as _re
                                m = _re.search(r"(\d+)", str(doc_id))
                                normalized = int(m.group(1)) if m else None
                            except Exception:
                                normalized = None
                        if normalized is not None and normalized not in seen_ids:
                            seen_ids.add(normalized)
                            referenced_doc_ids.append(normalized)

            # ì„ íƒëœ ë¬¸ì„œ ID ì¶”ì¶œ (selected_documents í¬í•¨í•˜ë„ë¡ ê°œì„ )
            selected_doc_ids: List[int] = []
            try:
                if 'normalized_docs' in locals() and normalized_docs:
                    for sd in normalized_docs:
                        raw_id = getattr(sd, 'id', None)
                        if raw_id is None and isinstance(sd, dict):
                            raw_id = sd.get('id') or sd.get('fileId')
                        if raw_id is not None:
                            try:
                                normalized = int(raw_id)
                            except Exception:
                                import re as _re
                                m = _re.search(r"(\d+)", str(raw_id))
                                normalized = int(m.group(1)) if m else None
                            if normalized is not None and normalized not in selected_doc_ids:
                                selected_doc_ids.append(normalized)
            except Exception as sel_err:
                logger.warning(f"ì„ íƒëœ ë¬¸ì„œ ID ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {sel_err}")

            # ìµœì¢… ì €ì¥ìš© ë¬¸ì„œ ID: references âˆª selected_documents (ì¤‘ë³µ ì œê±°)
            union_ids_set = set(referenced_doc_ids) | set(selected_doc_ids)
            union_doc_ids: List[int] = sorted(list(union_ids_set))

            # ì •í•©ì„± ì²´í¬ ë¡œê·¸: references ê¸¸ì´ vs selected vs union vs used_chunks
            try:
                refs_len = len(references) if references else 0
                used_chunks_count = None
                if isinstance(context_info, dict):
                    used_chunks_count = context_info.get('used_chunks')
                logger.info(
                    f"ğŸ“Š ì°¸ê³ ìë£Œ ì •í•©ì„±: references={refs_len}, selected={len(selected_doc_ids)}, union={len(union_doc_ids)}, used_chunks={used_chunks_count}"
                )
            except Exception:
                pass

            logger.info(f"ğŸ“š ì°¸ê³ ìë£Œ ì €ì¥ (references âˆª selected): {len(union_doc_ids)}ê°œ ë¬¸ì„œ ID")
            
            # ğŸ†• ì²­í¬ ìƒì„¸ ì •ë³´ êµ¬ì¡°í™” (ë¬¸ì„œëª…, í˜ì´ì§€, ë‚´ìš© í¬í•¨)
            detailed_chunks = []
            if references:
                for idx, ref in enumerate(references):
                    chunk_info = {
                        'index': idx + 1,
                        'file_id': ref.get('file_bss_info_sno'),
                        'file_name': ref.get('file_name', ''),
                        'chunk_index': ref.get('chunk_index', 0),
                        'page_number': ref.get('page_number'),
                        'content_preview': ref.get('content', '')[:200] if ref.get('content') else '',  # 200ì ë¯¸ë¦¬ë³´ê¸°
                        'similarity_score': ref.get('similarity_score', 0.0),
                        'search_type': ref.get('search_type', 'unknown'),
                        'section_title': ref.get('section_title', ''),
                    }
                    detailed_chunks.append(chunk_info)
            
            # search_resultsì— ì²­í¬ ìƒì„¸ ì •ë³´ ì¶”ê°€
            enhanced_search_results = {
                **(context_info if context_info else {}),
                'detailed_chunks': detailed_chunks,  # ğŸ†• ì²­í¬ ìƒì„¸ ì •ë³´
                'chunks_count': len(detailed_chunks),
                'documents_count': len(union_doc_ids)
            }
            if attachment_metadata:
                enhanced_search_results['attachments'] = attachment_metadata
            if voice_asset_id:
                enhanced_search_results['voice_asset_id'] = voice_asset_id
            
            logger.info(f"ğŸ“ ì²­í¬ ìƒì„¸ ì •ë³´ ì €ì¥: {len(detailed_chunks)}ê°œ ì²­í¬, {len(union_doc_ids)}ê°œ ë¬¸ì„œ")
            
            saved_message = await chat_manager.add_message(
                session_id=session_id,
                content=final_to_store,  # ì •ë¦¬ëœ ë‹µë³€ ì €ì¥ (PPT ì˜ë„ ì‹œ sanitize ì ìš©)
                message_type=MessageType.ASSISTANT,
                user_emp_no=user_emp_no,
                user_name=str("AI Assistant"),
                model_used=provider or settings.get_current_llm_provider(),
                search_context=enhanced_search_results,  # ì²­í¬ ì •ë³´ í¬í•¨
                referenced_documents=union_doc_ids if union_doc_ids else None
            )
            
            # ğŸ†• PostgreSQL tb_chat_sessions í…Œì´ë¸”ì—ë„ ì„¸ì…˜ ì €ì¥/ì—…ë°ì´íŠ¸
            try:
                from sqlalchemy.ext.asyncio import AsyncSession
                from app.core.database import get_db
                
                # DB ì„¸ì…˜ ìƒì„±
                db_gen = get_db()
                db: AsyncSession = await db_gen.__anext__()
                
                try:
                    # ì°¸ê³ ìë£Œì™€ ê²€ìƒ‰ ê²°ê³¼ í¬í•¨í•˜ì—¬ ì €ì¥
                    await save_chat_session(
                        db=db,
                        session_id=session_id,
                        user_emp_no=user_emp_no,
                        message=message,
                        response=final_to_store,
                        referenced_documents=union_doc_ids if union_doc_ids else None,
                        search_results=enhanced_search_results,  # ì²­í¬ ìƒì„¸ ì •ë³´ í¬í•¨
                        conversation_context=selected_docs_context if selected_docs_context else None  # ì„ íƒ ë¬¸ì„œ ë³´ì¡´
                    )
                    logger.info(f"âœ… PostgreSQL ì„¸ì…˜ ë° ë©”ì‹œì§€ ì €ì¥ ì™„ë£Œ: {session_id} (ì²­í¬ {len(detailed_chunks)}ê°œ)")
                finally:
                    # DB ì„¸ì…˜ ì •ë¦¬
                    try:
                        await db_gen.aclose()
                    except:
                        pass
                        
            except Exception as db_save_error:
                logger.error(f"âŒ PostgreSQL ì„¸ì…˜ ì €ì¥ ì‹¤íŒ¨ (RedisëŠ” ì •ìƒ): {db_save_error}")
                import traceback
                logger.error(f"âŒ ì„¸ì…˜ ì €ì¥ ì‹¤íŒ¨ ìƒì„¸:\n{traceback.format_exc()}")
                
        except Exception as e:
            logger.warning(f"AI ì‘ë‹µ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # ì™„ë£Œ ì´ë²¤íŠ¸ (message_id í¬í•¨)
        complete_event = {
            'type': 'complete',
            'session_id': session_id,
            'message_id': saved_message.message_id if saved_message else None,
            'assistant_message_id': saved_message.message_id if saved_message else None,
            'references': clean_references_for_json(references),
             'attachments': attachment_metadata,
             'voice_asset_id': voice_asset_id,
            'context_info': clean_stats_for_json(context_info),
            'rag_stats': clean_stats_for_json({**rag_stats, "provider": settings.get_current_llm_provider()})
        }
        yield f"data: {json.dumps(complete_event, ensure_ascii=False)}\n\n"
        try:
            state_payload = build_conversation_state(final_to_store or collected_response, context_info, references)
            yield f"data: {json.dumps({'type': 'conversation_state', 'state': state_payload}, ensure_ascii=False)}\n\n"
        except Exception as state_err:
            logger.warning(f"ëŒ€í™” ìƒíƒœ ìƒì„± ì‹¤íŒ¨: {state_err}")

        # ì™„ë£Œ/ì¢…ë£Œ ì´ë²¤íŠ¸ (done + DONE ë§ˆì»¤)
        done_event = {"type": "done", "session_id": session_id, "length": len(collected_response)}
        yield f"data: {json.dumps(done_event, ensure_ascii=False)}\n\n"
        yield "data: [DONE]\n\n"
        logger.info("âœ… ì±„íŒ… ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"âŒ ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        error_event = {"type": "error", "message": str(e)}
        try:
            yield f"data: {json.dumps(error_event, ensure_ascii=False)}\n\n"
            yield "data: [DONE]\n\n"
        except Exception:
            pass

# ===== Multi-Agent helper endpoints =====

@router.get("/chat/multi-agent/capabilities")
async def get_multi_agent_capabilities(current_user: User = Depends(get_current_user)):
    """í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ì—­ëŸ‰ ëª©ë¡ ì œê³µ"""
    try:
        caps = integrated_multi_agent_service.enhanced_tool_registry.get_agent_capabilities()
        # í”„ë¡ íŠ¸ì—”ë“œëŠ” agent_capabilities í‚¤ë¥¼ ê¸°ëŒ€í•¨
        return {"success": True, "agent_capabilities": caps}
    except Exception as e:
        logger.error(f"ë©€í‹° ì—ì´ì „íŠ¸ capabilities ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"success": False, "agent_capabilities": {}, "error": str(e)}
