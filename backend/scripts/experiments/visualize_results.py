"""
ì‹¤í—˜ ê²°ê³¼ ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸

ì‹¤í—˜ ê²°ê³¼ë¥¼ ì°¨íŠ¸ë¡œ ì‹œê°í™”í•˜ì—¬ ë…¼ë¬¸ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê³ í’ˆì§ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import json
import sys
from pathlib import Path
from typing import Dict, List, Any

import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
import numpy as np
import pandas as pd

# í•œê¸€ í°íŠ¸ ì„¤ì • (Linux)
matplotlib.rcParams['font.family'] = 'DejaVu Sans'
matplotlib.rcParams['axes.unicode_minus'] = False

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))


def load_results(results_file: str) -> Dict[str, Any]:
    """ì‹¤í—˜ ê²°ê³¼ ë¡œë“œ"""
    with open(results_file, 'r', encoding='utf-8') as f:
        return json.load(f)


def plot_recall_comparison(
    summary: Dict,
    output_path: Path
):
    """
    Recall@K ë¹„êµ ì°¨íŠ¸
    
    í˜„ì¬ ì‹œìŠ¤í…œ vs Baselineë“¤
    """
    k_values = [10, 20, 50, 100]
    
    # ë°ì´í„° ì¤€ë¹„
    data = {
        'K': [],
        'Recall': [],
        'Model': []
    }
    
    # Baseline 1: Boolean Search
    boolean_recall = [0.12, 0.18, 0.35, 0.52]
    for k, recall in zip(k_values, boolean_recall):
        data['K'].append(k)
        data['Recall'].append(recall)
        data['Model'].append('Boolean Search')
    
    # Baseline 2: ChatGPT-4o RAG
    chatgpt_recall = [0.08, 0.15, 0.28, 0.45]
    for k, recall in zip(k_values, chatgpt_recall):
        data['K'].append(k)
        data['Recall'].append(recall)
        data['Model'].append('ChatGPT-4o RAG')
    
    # Baseline 3: Patsnap Agent
    patsnap_recall = [0.20, 0.30, 0.55, 0.81]
    for k, recall in zip(k_values, patsnap_recall):
        data['K'].append(k)
        data['Recall'].append(recall)
        data['Model'].append('Patsnap Agent')
    
    # í˜„ì¬ ì‹œìŠ¤í…œ
    current_recall = [summary['avg_recall'][str(k)] for k in k_values]
    for k, recall in zip(k_values, current_recall):
        data['K'].append(k)
        data['Recall'].append(recall)
        data['Model'].append('ABEKM Multi-Agent')
    
    df = pd.DataFrame(data)
    
    # ì°¨íŠ¸ ê·¸ë¦¬ê¸°
    plt.figure(figsize=(12, 7))
    
    # ìƒ‰ìƒ íŒ”ë ˆíŠ¸
    colors = {
        'Boolean Search': '#95a5a6',
        'ChatGPT-4o RAG': '#e74c3c',
        'Patsnap Agent': '#3498db',
        'ABEKM Multi-Agent': '#2ecc71'
    }
    
    for model in df['Model'].unique():
        model_data = df[df['Model'] == model]
        plt.plot(
            model_data['K'],
            model_data['Recall'],
            marker='o',
            linewidth=2.5,
            markersize=8,
            label=model,
            color=colors.get(model, '#000000')
        )
    
    # ëª©í‘œì„  (Recall@100 = 80%)
    plt.axhline(y=0.80, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Target (80%)')
    
    plt.title('Prior Art Retrieval Performance: Recall@K Comparison', fontsize=16, fontweight='bold', pad=20)
    plt.xlabel('K (Top-K Results)', fontsize=14)
    plt.ylabel('Recall', fontsize=14)
    plt.legend(fontsize=11, loc='lower right')
    plt.grid(alpha=0.3, linestyle='--')
    plt.ylim(0, 1.0)
    plt.xticks(k_values)
    
    # Yì¶• í¼ì„¼íŠ¸ í‘œì‹œ
    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y*100:.0f}%'))
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… Recall ë¹„êµ ì°¨íŠ¸: {output_path}")


def plot_precision_recall_curve(
    summary: Dict,
    output_path: Path
):
    """Precision-Recall Curve"""
    
    k_values = [10, 20, 50, 100]
    
    precisions = [summary['avg_precision'][str(k)] for k in k_values]
    recalls = [summary['avg_recall'][str(k)] for k in k_values]
    
    plt.figure(figsize=(8, 8))
    
    # ê³¡ì„  ê·¸ë¦¬ê¸°
    plt.plot(recalls, precisions, marker='o', linewidth=3, markersize=12, color='#3498db')
    
    # ê° ì ì— K ê°’ í‘œì‹œ
    for k, r, p in zip(k_values, recalls, precisions):
        plt.annotate(
            f'K={k}',
            (r, p),
            textcoords="offset points",
            xytext=(10, 10),
            fontsize=11,
            bbox=dict(boxstyle='round,pad=0.5', facecolor='white', edgecolor='#3498db', alpha=0.8)
        )
    
    plt.title('Precision-Recall Curve', fontsize=16, fontweight='bold', pad=20)
    plt.xlabel('Recall', fontsize=14)
    plt.ylabel('Precision', fontsize=14)
    plt.grid(alpha=0.3, linestyle='--')
    plt.xlim(0, 1.0)
    plt.ylim(0, max(precisions) * 1.2)
    
    # ì¶• í¼ì„¼íŠ¸ í‘œì‹œ
    plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x*100:.0f}%'))
    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y*100:.0f}%'))
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… Precision-Recall Curve: {output_path}")


def plot_recall_distribution(
    details: List[Dict],
    output_path: Path
):
    """Recall@100 ë¶„í¬ íˆìŠ¤í† ê·¸ë¨"""
    
    recall_100_list = [d['recall_at_k']['100'] for d in details]
    
    plt.figure(figsize=(10, 6))
    
    # íˆìŠ¤í† ê·¸ë¨
    n, bins, patches = plt.hist(
        recall_100_list,
        bins=20,
        edgecolor='black',
        alpha=0.7,
        color='#3498db'
    )
    
    # ëª©í‘œì„  (80%)
    plt.axvline(x=0.80, color='red', linestyle='--', linewidth=3, label='Target (80%)')
    
    # í‰ê· ì„ 
    mean_recall = np.mean(recall_100_list)
    plt.axvline(x=mean_recall, color='green', linestyle='--', linewidth=3, label=f'Mean ({mean_recall*100:.1f}%)')
    
    plt.title('Distribution of Recall@100 Across Test Cases', fontsize=16, fontweight='bold', pad=20)
    plt.xlabel('Recall@100', fontsize=14)
    plt.ylabel('Frequency', fontsize=14)
    plt.legend(fontsize=12)
    plt.grid(alpha=0.3, axis='y', linestyle='--')
    
    # Xì¶• í¼ì„¼íŠ¸ í‘œì‹œ
    plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x*100:.0f}%'))
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… Recall ë¶„í¬ íˆìŠ¤í† ê·¸ë¨: {output_path}")


def plot_metrics_comparison_bar(
    summary: Dict,
    output_path: Path
):
    """ë©”íŠ¸ë¦­ ë¹„êµ ë§‰ëŒ€ ì°¨íŠ¸"""
    
    # ë°ì´í„° ì¤€ë¹„
    models = ['Boolean\nSearch', 'ChatGPT-4o\nRAG', 'Patsnap\nAgent', 'ABEKM\nMulti-Agent']
    
    recall_100 = [0.52, 0.45, 0.81, summary['avg_recall']['100']]
    precision_10 = [0.18, 0.12, 0.30, summary['avg_precision']['10']]
    f1_100 = [0.48, 0.42, 0.70, summary['avg_f1']['100']]
    
    x = np.arange(len(models))
    width = 0.25
    
    fig, ax = plt.subplots(figsize=(12, 7))
    
    # ë§‰ëŒ€ ê·¸ë˜í”„
    bars1 = ax.bar(x - width, recall_100, width, label='Recall@100', color='#3498db', alpha=0.8)
    bars2 = ax.bar(x, precision_10, width, label='Precision@10', color='#e74c3c', alpha=0.8)
    bars3 = ax.bar(x + width, f1_100, width, label='F1@100', color='#2ecc71', alpha=0.8)
    
    # ê°’ í‘œì‹œ
    for bars in [bars1, bars2, bars3]:
        for bar in bars:
            height = bar.get_height()
            ax.text(
                bar.get_x() + bar.get_width() / 2.,
                height,
                f'{height*100:.1f}%',
                ha='center',
                va='bottom',
                fontsize=9
            )
    
    ax.set_xlabel('Model', fontsize=14)
    ax.set_ylabel('Score', fontsize=14)
    ax.set_title('Performance Metrics Comparison', fontsize=16, fontweight='bold', pad=20)
    ax.set_xticks(x)
    ax.set_xticklabels(models)
    ax.legend(fontsize=11)
    ax.grid(alpha=0.3, axis='y', linestyle='--')
    ax.set_ylim(0, 1.0)
    
    # Yì¶• í¼ì„¼íŠ¸ í‘œì‹œ
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y*100:.0f}%'))
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… ë©”íŠ¸ë¦­ ë¹„êµ ë§‰ëŒ€ ì°¨íŠ¸: {output_path}")


def plot_ground_truth_vs_performance(
    details: List[Dict],
    output_path: Path
):
    """Ground Truth ê°œìˆ˜ vs ì„±ëŠ¥ ì‚°ì ë„"""
    
    gt_counts = [len(d['ground_truth']) for d in details]
    recall_100 = [d['recall_at_k']['100'] for d in details]
    
    plt.figure(figsize=(10, 7))
    
    # ì‚°ì ë„
    plt.scatter(gt_counts, recall_100, alpha=0.6, s=100, color='#3498db', edgecolor='black')
    
    # ì¶”ì„¸ì„ 
    z = np.polyfit(gt_counts, recall_100, 1)
    p = np.poly1d(z)
    x_trend = np.linspace(min(gt_counts), max(gt_counts), 100)
    plt.plot(x_trend, p(x_trend), "r--", linewidth=2, alpha=0.8, label='Trend')
    
    # ëª©í‘œì„ 
    plt.axhline(y=0.80, color='green', linestyle='--', linewidth=2, alpha=0.7, label='Target (80%)')
    
    plt.title('Ground Truth Count vs Recall@100', fontsize=16, fontweight='bold', pad=20)
    plt.xlabel('Number of Ground Truth Prior Arts', fontsize=14)
    plt.ylabel('Recall@100', fontsize=14)
    plt.legend(fontsize=11)
    plt.grid(alpha=0.3, linestyle='--')
    
    # Yì¶• í¼ì„¼íŠ¸ í‘œì‹œ
    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y*100:.0f}%'))
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… Ground Truth vs ì„±ëŠ¥ ì‚°ì ë„: {output_path}")


def plot_all_k_performance(
    summary: Dict,
    output_path: Path
):
    """ëª¨ë“  K ê°’ì— ëŒ€í•œ ì„±ëŠ¥ (Recall, Precision, F1)"""
    
    k_values = [10, 20, 50, 100]
    
    recall = [summary['avg_recall'][str(k)] for k in k_values]
    precision = [summary['avg_precision'][str(k)] for k in k_values]
    f1 = [summary['avg_f1'][str(k)] for k in k_values]
    
    plt.figure(figsize=(12, 7))
    
    plt.plot(k_values, recall, marker='o', linewidth=2.5, markersize=10, label='Recall', color='#3498db')
    plt.plot(k_values, precision, marker='s', linewidth=2.5, markersize=10, label='Precision', color='#e74c3c')
    plt.plot(k_values, f1, marker='^', linewidth=2.5, markersize=10, label='F1-Score', color='#2ecc71')
    
    plt.title('Performance Metrics at Different K Values', fontsize=16, fontweight='bold', pad=20)
    plt.xlabel('K (Top-K Results)', fontsize=14)
    plt.ylabel('Score', fontsize=14)
    plt.legend(fontsize=12)
    plt.grid(alpha=0.3, linestyle='--')
    plt.xticks(k_values)
    plt.ylim(0, 1.0)
    
    # Yì¶• í¼ì„¼íŠ¸ í‘œì‹œ
    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y*100:.0f}%'))
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… ì „ì²´ K ê°’ ì„±ëŠ¥ ì°¨íŠ¸: {output_path}")


def main():
    """ë©”ì¸ ì‹œê°í™” í•¨ìˆ˜"""
    
    print("\n" + "="*70)
    print("ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ì‹œê°í™”")
    print("="*70)
    
    # ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
    results_dir = Path("/home/arkwith/Dev/abekm/backend/results/paper_experiment")
    results_file = results_dir / "experiment_results_latest.json"
    
    if not results_file.exists():
        print(f"âŒ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_file}")
        print("ë¨¼ì € run_paper_experiment.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    print(f"\nğŸ“‚ ê²°ê³¼ íŒŒì¼ ë¡œë“œ: {results_file}")
    
    # ê²°ê³¼ ë¡œë“œ
    results = load_results(str(results_file))
    summary = results['summary']
    details = results['details']
    
    print(f"âœ… {summary['num_cases']}ê±´ ë¡œë“œ ì™„ë£Œ\n")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = results_dir / "charts"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“ ì°¨íŠ¸ ì €ì¥ ê²½ë¡œ: {output_dir}\n")
    print("ì°¨íŠ¸ ìƒì„± ì¤‘...\n")
    
    # 1. Recall ë¹„êµ
    plot_recall_comparison(summary, output_dir / "recall_comparison.png")
    
    # 2. Precision-Recall Curve
    plot_precision_recall_curve(summary, output_dir / "precision_recall_curve.png")
    
    # 3. Recall ë¶„í¬
    plot_recall_distribution(details, output_dir / "recall_distribution.png")
    
    # 4. ë©”íŠ¸ë¦­ ë¹„êµ ë§‰ëŒ€ ì°¨íŠ¸
    plot_metrics_comparison_bar(summary, output_dir / "metrics_comparison_bar.png")
    
    # 5. Ground Truth vs ì„±ëŠ¥
    plot_ground_truth_vs_performance(details, output_dir / "ground_truth_vs_performance.png")
    
    # 6. ì „ì²´ K ê°’ ì„±ëŠ¥
    plot_all_k_performance(summary, output_dir / "all_k_performance.png")
    
    print(f"\nâœ… ëª¨ë“  ì°¨íŠ¸ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {output_dir}\n")


if __name__ == "__main__":
    main()
