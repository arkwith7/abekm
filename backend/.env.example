# =============================================================================
# 🌟 CORE SETTINGS (공통 기본 설정)
# =============================================================================

# 데이터베이스 설정
# ✅ 권장(Docker Compose 기반 개발/운영): 서비스 이름으로 접속
DATABASE_URL=postgresql+asyncpg://wkms:wkms123@postgres:5432/wkms
POSTGRES_DB=wkms
POSTGRES_USER=wkms
POSTGRES_PASSWORD=wkms123

# Redis 설정
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_URL=redis://redis:6379/0

# 보안 설정
SECRET_KEY=your-secret-key-change-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=480
REFRESH_TOKEN_EXPIRE_MINUTES=10080

# CORS 설정
CORS_ORIGINS=["http://localhost:3000","http://15.165.163.233:3000"]

# 파일 업로드 설정
UPLOAD_DIR=uploads
MAX_FILE_SIZE=104857600
ALLOWED_FILE_TYPES=[".pdf", ".docx", ".pptx", ".txt", ".md"]

# 로깅 설정
LOG_LEVEL=INFO
LOG_FORMAT=json

# =============================================================================
# ☁️ CLOUD PROVIDER SELECTION
# =============================================================================

# 스토리지 백엔드 선택: local | s3 | azure_blob
# ✅ 예제 기본값은 로컬(클라우드 자격증명 없이 실행 가능)
STORAGE_BACKEND=local
USE_STANDARD_RAW_PREFIX=true

# ---------------------
# (선택) 백엔드를 로컬(호스트)에서 직접 실행하는 경우
# ---------------------
# DATABASE_URL=postgresql+asyncpg://wkms:wkms123@localhost:5432/wkms
# REDIS_URL=redis://localhost:6379/0
# REDIS_HOST=localhost

# LLM/임베딩 제공자 선택
DEFAULT_LLM_PROVIDER=bedrock
DEFAULT_EMBEDDING_PROVIDER=bedrock
LLM_PROVIDERS=["bedrock", "azure_openai", "openai"]

# =============================================================================
# 📄 DOCUMENT PROCESSING (문서 처리)
# =============================================================================

# 문서 처리 제공자 선택: azure_di | upstage | aws_textract | etc_other
# ⚠️ 주의: Azure DI는 한국어 완벽 지원, Upstage는 한국어 우수, AWS Textract는 영문 중심
DOCUMENT_PROCESSING_PROVIDER=upstage
DOCUMENT_PROCESSING_FALLBACK=azure_di
USE_AZURE_DOCUMENT_INTELLIGENCE_PDF=false

# ---------------------
# Azure Document Intelligence (✅ 한국어 지원)
# ---------------------
AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-endpoint.cognitiveservices.azure.com/
AZURE_DOCUMENT_INTELLIGENCE_API_KEY=your-azure-document-intelligence-api-key
AZURE_DOCUMENT_INTELLIGENCE_API_VERSION=2024-11-30
AZURE_DOCUMENT_INTELLIGENCE_DEFAULT_MODEL=prebuilt-layout
AZURE_DOCUMENT_INTELLIGENCE_LAYOUT_MODEL=prebuilt-layout
AZURE_DOCUMENT_INTELLIGENCE_DOCUMENT_MODEL=prebuilt-layout
AZURE_DOCUMENT_INTELLIGENCE_MAX_PAGES=150
AZURE_DOCUMENT_INTELLIGENCE_TIMEOUT_SECONDS=300
AZURE_DOCUMENT_INTELLIGENCE_RETRY_MAX_ATTEMPTS=3
AZURE_DOCUMENT_INTELLIGENCE_CONFIDENCE_THRESHOLD=0.8
AZURE_DOCUMENT_INTELLIGENCE_USE_KOREAN_OPTIMIZATION=true

# DI 성능 최적화 설정
DI_PARALLEL_ENABLED=false
DI_PAGE_GROUP_SIZE=3
DI_MAX_CONCURRENCY=3
DI_CACHE_ENABLED=false
DI_TWO_COLUMN_REORDER_ENABLED=true

# ---------------------
# AWS Textract (⚠️ 영문 중심 - 한국어 미지원)
# ---------------------
# 기본 설정
TEXTRACT_MODE=layout
TEXTRACT_FEATURE_TYPES=TABLES,FORMS,LAYOUT
TEXTRACT_MAX_CONCURRENCY=3
TEXTRACT_ENABLE_ASYNC=true

# 공통 파라미터
TEXTRACT_MAX_PAGES=50
TEXTRACT_CONFIDENCE_THRESHOLD=80.0
TEXTRACT_USE_ASYNC_THRESHOLD_SIZE=5242880
TEXTRACT_USE_ASYNC_PAGE_COUNT=10
TEXTRACT_JOB_POLL_INTERVAL=4
TEXTRACT_JOB_TIMEOUT=600

# S3 결과 저장
TEXTRACT_S3_BUCKET=your-s3-bucket
TEXTRACT_RESULT_PREFIX=textract/results

# 안정성 설정
TEXTRACT_RATE_LIMIT_PER_MIN=60
TEXTRACT_MAX_RETRIES=3
TEXTRACT_FALLBACK_ON_FAILURE=true

# 보안/로깅
TEXTRACT_LOG_RAW_RESPONSE=false
TEXTRACT_ENABLE_PII_MASKING=true

# 고급 기능
TEXTRACT_ENABLE_QUERIES=false
TEXTRACT_QUERIES=총금액,서명자,문서제목

# ---------------------
# Upstage Document Parse (✅ 한국어 우수 - Azure DI 대안)
# ---------------------
UPSTAGE_API_KEY=your-upstage-api-key
UPSTAGE_API_ENDPOINT=https://api.upstage.ai/v1/document-digitization
UPSTAGE_MAX_PAGES=150
UPSTAGE_TIMEOUT_SECONDS=300
UPSTAGE_RETRY_MAX_ATTEMPTS=3
UPSTAGE_MODEL=document-parse
# force | auto 등 선택 가능 (공백 시 기본값 auto)
UPSTAGE_OCR_MODE=auto
# JSON 배열 문자열로 지정 (예: ["figure","table"])
UPSTAGE_BASE64_CATEGORIES=["figure"]
UPSTAGE_MERGE_MULTIPAGE_TABLES=true
UPSTAGE_USE_ASYNC_API=false
UPSTAGE_ASYNC_POLL_INTERVAL_SECONDS=5
UPSTAGE_ASYNC_TIMEOUT_SECONDS=900
# 필요 시 개별 엔드포인트를 재정의할 수 있음
# UPSTAGE_ASYNC_API_ENDPOINT=
# UPSTAGE_ASYNC_STATUS_ENDPOINT=

# =============================================================================
# 🔷 AZURE SERVICES
# =============================================================================

# ---------------------
# Azure Blob Storage
# ---------------------
AZURE_BLOB_ACCOUNT_NAME=your-storage-account
AZURE_BLOB_ACCOUNT_KEY=your-storage-account-key
AZURE_BLOB_CONTAINER_RAW=wkms-raw
AZURE_BLOB_CONTAINER_INTERMEDIATE=wkms-intermediate
AZURE_BLOB_CONTAINER_DERIVED=wkms-derived
AZURE_BLOB_SAS_EXPIRY_SECONDS=3600
AZURE_BLOB_ENABLE_AUTO_CONTAINER=true
AZURE_BLOB_DOWNLOAD_MODE=proxy

# ---------------------
# Azure OpenAI - Main LLM
# ---------------------
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
AZURE_OPENAI_API_KEY=your-azure-openai-api-key
AZURE_OPENAI_API_VERSION=2024-12-01-preview

# 배포 모델 이름 (⚠️ Azure Portal에서 실제 배포 이름 확인 필요)
AZURE_OPENAI_LLM_DEPLOYMENT=gpt-4o
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small
AZURE_OPENAI_MULTIMODAL_DEPLOYMENT=gpt-4o

# ---------------------
# Azure OpenAI - CLIP Embedding (별도 엔드포인트)
# ---------------------
AZURE_OPENAI_MULTIMODAL_EMBEDDING_ENDPOINT=https://your-ml-endpoint.inference.ml.azure.com/score
AZURE_OPENAI_MULTIMODAL_EMBEDDING_API_KEY=your-multimodal-embedding-api-key
AZURE_OPENAI_MULTIMODAL_EMBEDDING_DEPLOYMENT=openai-clip-image-text-embed

# ---------------------
# Azure OpenAI - Query Rewrite
# ---------------------
QUERY_REWRITE_PROVIDER=azure_openai
QUERY_REWRITE_AZURE_DEPLOYMENT=gpt-4o
QUERY_REWRITE_AZURE_ENDPOINT=https://your-endpoint.openai.azure.com/
QUERY_REWRITE_AZURE_API_KEY=your-azure-openai-api-key
QUERY_REWRITE_AZURE_API_VERSION=2024-12-01-preview
QUERY_REWRITE_MAX_TOKENS=500
QUERY_REWRITE_TEMPERATURE=0.3

# ---------------------
# Azure OpenAI - RAG Reranking
# ---------------------
RAG_RERANKING_PROVIDER=bedrock
RAG_RERANKING_ENDPOINT=https://your-endpoint.openai.azure.com/
RAG_RERANKING_API_KEY=your-azure-openai-api-key
RAG_RERANKING_DEPLOYMENT=gpt-4o
RAG_RERANKING_API_VERSION=2025-01-01-preview

# =============================================================================
# 🟧 AWS SERVICES
# =============================================================================

# ---------------------
# AWS Credentials
# ---------------------
AWS_REGION=ap-northeast-2
AWS_ACCESS_KEY_ID=your-aws-access-key-id
AWS_SECRET_ACCESS_KEY=your-aws-secret-access-key

# ---------------------
# AWS S3 Storage
# ---------------------
AWS_S3_BUCKET=your-s3-bucket
S3_PRESIGN_EXPIRY_SECONDS=3600

# ---------------------
# AWS Bedrock (LLM & Embedding)
# ---------------------
# Main LLM: Claude 3 Haiku (서울 리전 직접 지원)
# - Input: $0.25/MTok, Output: $1.25/MTok (비용 효율적)
# - 200K 컨텍스트, 빠른 응답 속도
# - 한국어 지원 우수, ap-northeast-2(서울) On-Demand 지원 ✅

# ✅ Latest Models in ap-northeast-2 (Confirmed 2025-12-05)
# 1. Claude Sonnet 4.5 (Direct Seoul)
# BEDROCK_LLM_MODEL_ID=anthropic.claude-sonnet-4-5-20250929-v1:0
# 2. Claude Opus 4.5 (Direct Seoul)
# BEDROCK_LLM_MODEL_ID=anthropic.claude-opus-4-5-20251101-v1:0
# 3. Claude 3.7 Sonnet (Direct Seoul)
# BEDROCK_LLM_MODEL_ID=anthropic.claude-3-7-sonnet-20250219-v1:0

# ✅ Cross-Region Inference Profiles
# 1. Global Claude Opus 4.5
# BEDROCK_LLM_MODEL_ID=global.anthropic.claude-opus-4-5-20251101-v1:0
# 2. APAC Claude Sonnet 4
# BEDROCK_LLM_MODEL_ID=apac.anthropic.claude-sonnet-4-20250514-v1:0

# ✅ Active Selection: Claude 3.5 Sonnet v2 (APAC Cross-region) - Verified Working 2025-12-05
BEDROCK_LLM_MODEL_ID=apac.anthropic.claude-3-5-sonnet-20241022-v2:0

# Previous Working: Claude 3 Haiku
# BEDROCK_LLM_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0

# Embedding: Amazon Titan Text Embeddings v2 (text-embedding-3-small 대응) ✅ 선택됨
# - $0.0001/1K tokens (Azure 대비 90% 저렴)
# - 1024차원 (256/512/1024 선택 가능), 25개 언어 지원 (한국어 포함)
# - 8192 토큰 입력 지원 (긴 문서 처리 유리)
# - 검색/분류/클러스터링 최적화, RAG 전용 설계
# - 대안: cohere.embed-v4:0 (512 토큰 제한, 100개 언어)
BEDROCK_EMBEDDING_MODEL_ID=amazon.titan-embed-text-v2:0
# BEDROCK_EMBEDDING_MODEL_ID=cohere.embed-v4:0
BEDROCK_EMBEDDING_DIMENSION=1024

# Multimodal Embedding: TwelveLabs Marengo Embed 3.0 (이미지+텍스트 임베딩, Azure CLIP 대응) ✅ 복원
# - 512차원 (고효율 임베딩), 비디오/이미지/텍스트 멀티모달 지원
# - Twelve Labs 비디오 AI 전문 기술 기반 임베딩
# - 시맨틱 검색, 객체 인식, 장면 이해 최적화
# - 한국어 텍스트 지원, 시각적 콘텐츠 분석 특화
# - ap-northeast-2(서울) 리전 지원 ✅ (2025년 10월 28일 출시)
# - 이미지 색인 및 검색에 최적화된 모델
BEDROCK_MULTIMODAL_EMBEDDING_MODEL_ID=twelvelabs.marengo-embed-3-0-v1:0
BEDROCK_MULTIMODAL_EMBEDDING_DIMENSION=512

# Multimodal LLM: Claude 3 Haiku (이미지 분석/캡션 생성) ✅ 변경됨
# - Input: $0.25/MTok, Output: $1.25/MTok (비용 효율적)
# - 200K 컨텍스트, Vision 기능 (PDF 이미지, 차트, 다이어그램)
# - 한국어 지원 우수, 빠른 응답 속도
# - ap-northeast-2(서울) 리전 On-Demand 지원 ✅
# - 이전: Claude 3 Sonnet (On-Demand 미지원으로 실패)
BEDROCK_MULTIMODAL_LLM_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0

# Query Rewrite: Claude 3 Haiku (쿼리 재작성) ✅ 변경됨
# - Input: $0.25/MTok, Output: $1.25/MTok (비용 효율적)
# - 200K 컨텍스트, 빠른 쿼리 처리
# - 한국어 자연어 이해 우수
# - ap-northeast-2(서울) 리전 On-Demand 지원 ✅
# - 이전: Claude 3.5 Sonnet (채널 프로그램 계정 미지원으로 실패)
QUERY_REWRITE_BEDROCK_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0
QUERY_REWRITE_BEDROCK_REGION=ap-northeast-2
QUERY_REWRITE_BEDROCK_MAX_TOKENS=500
QUERY_REWRITE_BEDROCK_TEMPERATURE=0.3

# RAG Reranking: Claude 3 Haiku (경량 리랭킹)
# - Input: $0.25/MTok, Output: $1.25/MTok (저렴하고 빠름)
# - 200K 컨텍스트, 문맥 기반 관련성 평가
# - 한국어 문서 검색 최적화
# - ap-northeast-2(서울) 리전 지원
# - 대안: cohere.rerank-v3-5:0 (리랭킹 전문, $2/1K searches)
RAG_RERANKING_BEDROCK_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0
RAG_RERANKING_BEDROCK_REGION=ap-northeast-2
RAG_RERANKING_BEDROCK_MAX_TOKENS=500
RAG_RERANKING_BEDROCK_TEMPERATURE=0.2

# 대안 모델 (성능 우선 시)
# BEDROCK_LLM_MODEL_ID=us.amazon.nova-pro-v1:0  # AWS Nova Pro (최신, GPT-4 Turbo급)
# BEDROCK_EMBEDDING_MODEL_ID=cohere.embed-multilingual-v3  # Cohere v3 (다국어 강점)

# ---------------------
# AWS OpenSearch
# ---------------------
OPENSEARCH_ENDPOINT=https://your-opensearch-domain.ap-northeast-2.es.amazonaws.com
OPENSEARCH_USERNAME=admin
OPENSEARCH_PASSWORD=your-opensearch-password
OPENSEARCH_INDEX=wkms-documents

# =============================================================================
# 🌐 OTHER PROVIDERS (대안/백업)
# =============================================================================

# ---------------------
# OpenAI
# ---------------------
OPENAI_API_KEY=your-openai-api-key
OPENAI_LLM_MODEL=gpt-4o
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002

# ---------------------
# Pinecone
# ---------------------
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_ENVIRONMENT=your-pinecone-environment
PINECONE_INDEX_NAME=wkms-index

# ---------------------
# 웹 검색 툴
# ---------------------
# Tavily (권장 - AI 에이전트 최적화, 무료 1,000건/월)
TAVILY_API_KEY=your-tavily-api-key

# Bing Search (Azure - 엔터프라이즈 안정성)
BING_SEARCH_API_KEY=your-bing-search-api-key

# 웹 검색 제공자 선택 (tavily | bing | duckduckgo)
WEB_SEARCH_PROVIDER=tavily

# ---------------------
# 특허 Agents 설정
# ---------------------
# Patent Search
PATENT_SEARCH_ENABLED=true
KIPRIS_API_KEY=your-kipris-api-key
# SerpAPI (웹 검색 + 특허 검색 공유)
SERPAPI_API_KEY=your-serpapi-api-key
SERPAPI_GOOGLE_PATENTS_ENABLED=true

# =============================================================================
# ⚙️ APPLICATION SETTINGS
# =============================================================================

# ---------------------
# LLM 공통 파라미터
# ---------------------
MAX_TOKENS=4096
TEMPERATURE=0.7
TOP_P=0.9

# ---------------------
# 벡터 검색 설정
# ---------------------
VECTOR_DIMENSION=1024
SIMILARITY_THRESHOLD=0.4

# ---------------------
# RAG 검색 설정
# ---------------------
RAG_SIMILARITY_THRESHOLD=0.3
RAG_MAX_CHUNKS=30
RAG_KEYWORD_BOOST=0.5
RAG_SEMANTIC_BOOST=0.5
RAG_USE_RERANKING=true

# ---------------------
# AI Agent 아키텍처
# ---------------------
USE_AGENT_ARCHITECTURE=true
AGENT_ENABLE_OBSERVABILITY=true
AGENT_ENABLE_EVALUATION=true

# ---------------------
# 한국어 NLP 설정
# ---------------------
KOREAN_NLP_PROVIDER=hybrid
KOREAN_TOKENIZER_MODEL=cl100k_base
KIWI_MODEL_TYPE=sbg
KIWI_TYPOS_CORRECTION=basic_with_continual_and_lengthening
USER_DICTIONARY_PATH=dictionaries/company_dict.txt
KOREAN_STOPWORDS_PATH=dictionaries/korean_stopwords.txt

# ---------------------
# 문서 처리 설정
# ---------------------
SUPPORTED_DOCUMENT_FORMATS=[".pdf", ".docx", ".pptx", ".xlsx", ".txt", ".md", ".hwp", ".doc", ".xls", ".ppt"]
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# ---------------------
# 하이브리드 검색 설정
# ---------------------
HYBRID_SEARCH_WEIGHTS={"semantic": 0.7, "keyword": 0.3}
KOREAN_EMBEDDING_MODEL=jhgan/ko-sroberta-multitask
