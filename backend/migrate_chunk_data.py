"""
ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜: tb_document_chunks â†’ vs_doc_contents_chunks
ì•ˆì „í•œ ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
"""
import asyncio
from sqlalchemy import text
        result = await session.execute(text("""
            SELECT COUNT(*) as new_count 
            FROM vs_doc_contents_chunks 
            WHERE del_yn = 'N'
        """))app.core.database import get_sync_engine, get_async_engine
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import sessionmaker

async def migrate_chunk_data():
    """tb_document_chunks ë°ì´í„°ë¥¼ vs_doc_contents_chunksë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
    
    # ë™ê¸° ì—”ì§„ìœ¼ë¡œ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ
    sync_engine = get_sync_engine()
    
    # ë¹„ë™ê¸° ì—”ì§„ìœ¼ë¡œ ìƒˆ í…Œì´ë¸”ì— ì‚½ì…
    async_engine = get_async_engine()
    AsyncSessionLocal = sessionmaker(async_engine, class_=AsyncSession, expire_on_commit=False)
    
    print("ğŸ”„ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
    
    # 1. ê¸°ì¡´ ë°ì´í„° í™•ì¸
    with sync_engine.connect() as conn:
        result = conn.execute(text("""
            SELECT COUNT(*) as total_count 
            FROM tb_document_chunks 
            WHERE "DEL_YN" = 'N'
        """))
        total_count = result.fetchone()[0]
        print(f"ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ìƒ: {total_count}ê°œ ë ˆì½”ë“œ")
        
        if total_count == 0:
            print("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
    
    # 2. ë°°ì¹˜ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ (1000ê°œì”©)
    batch_size = 1000
    migrated_count = 0
    
    with sync_engine.connect() as conn:
        # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ (ë°°ì¹˜ë³„)
        offset = 0
        while True:
            result = conn.execute(text(f"""
                SELECT 
                    "FILE_BSS_INFO_SNO",
                    "CHUNK_INDEX",
                    "CHUNK_TEXT",
                    "CHUNK_SIZE",
                    "CHUNK_EMBEDDING",
                    "PAGE_NUMBER",
                    "SECTION_TITLE",
                    "DEL_YN",
                    "CREATED_BY",
                    "CREATED_DATE",
                    "LAST_MODIFIED_BY",
                    "LAST_MODIFIED_DATE",
                    "KNOWLEDGE_CONTAINER_ID"
                FROM tb_document_chunks 
                WHERE "DEL_YN" = 'N'
                ORDER BY "CHUNK_SNO"
                LIMIT {batch_size} OFFSET {offset}
            """))
            
            batch_data = result.fetchall()
            if not batch_data:
                break
                
            # ë¹„ë™ê¸°ë¡œ ìƒˆ í…Œì´ë¸”ì— ì‚½ì…
            async with AsyncSessionLocal() as session:
                try:
                    for row in batch_data:
                        # ë©”íƒ€ë°ì´í„° JSON ìƒì„± (í˜¸í™˜ì„±)
                        metadata_json = {
                            "page_number": row[5] if row[5] else 1,
                            "section_title": row[6] if row[6] else "",
                            "keywords": [],  # ê¸°ì¡´ ë°ì´í„°ì—ëŠ” í‚¤ì›Œë“œ ì—†ìŒ
                            "named_entities": []  # ê¸°ì¡´ ë°ì´í„°ì—ëŠ” ê°œì²´ëª… ì—†ìŒ
                        }
                        
                        insert_sql = text("""
                            INSERT INTO vs_doc_contents_chunks (
                                file_bss_info_sno, chunk_index, chunk_text, chunk_size,
                                chunk_embedding, page_number, section_title, 
                                knowledge_container_id, metadata_json,
                                del_yn, created_by, created_date, last_modified_by, last_modified_date
                            ) VALUES (
                                :file_bss_info_sno, :chunk_index, :chunk_text, :chunk_size,
                                :chunk_embedding, :page_number, :section_title, 
                                :knowledge_container_id, :metadata_json,
                                :del_yn, :created_by, :created_date, :last_modified_by, :last_modified_date
                            )
                        """)
                        
                        await session.execute(insert_sql, {
                            "file_bss_info_sno": row[0],
                            "chunk_index": row[1],
                            "chunk_text": row[2],
                            "chunk_size": row[3],
                            "chunk_embedding": row[4],
                            "page_number": row[5],
                            "section_title": row[6],
                            "knowledge_container_id": row[12],  # ë§ˆì§€ë§‰ ì»¬ëŸ¼
                            "metadata_json": str(metadata_json) if metadata_json else None,
                            "del_yn": row[7],
                            "created_by": row[8],
                            "created_date": row[9],
                            "last_modified_by": row[10],
                            "last_modified_date": row[11]
                        })
                    
                    await session.commit()
                    migrated_count += len(batch_data)
                    print(f"ğŸ“¦ ë°°ì¹˜ ì™„ë£Œ: {migrated_count}/{total_count} ({migrated_count/total_count*100:.1f}%)")
                    
                except Exception as e:
                    await session.rollback()
                    print(f"âŒ ë°°ì¹˜ ì‹¤íŒ¨: {e}")
                    raise
            
            offset += batch_size
    
    print(f"âœ… ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {migrated_count}ê°œ ë ˆì½”ë“œ")
    
    # 3. ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦
    async with AsyncSessionLocal() as session:
        result = await session.execute(text("""
            SELECT COUNT(*) as new_count 
            FROM vs_doc_contents_chunks 
            WHERE "DEL_YN" = 'N'
        """))
        new_count = result.fetchone()[0]
        
        if new_count == total_count:
            print(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì„±ê³µ: {new_count} == {total_count}")
        else:
            print(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì‹¤íŒ¨: {new_count} != {total_count}")

async def verify_migration():
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ê²€ì¦"""
    async_engine = get_async_engine()
    AsyncSessionLocal = sessionmaker(async_engine, class_=AsyncSession, expire_on_commit=False)
    
    async with AsyncSessionLocal() as session:
        # ìƒ˜í”Œ ë°ì´í„° ë¹„êµ
        result = await session.execute(text("""
            SELECT 
                file_bss_info_sno, chunk_index, 
                LEFT(chunk_text, 50) as chunk_preview,
                page_number, keywords
            FROM vs_doc_contents_chunks 
            WHERE "DEL_YN" = 'N'
            ORDER BY chunk_sno 
            LIMIT 5
        """))
        
        print("ğŸ” ë§ˆì´ê·¸ë ˆì´ì…˜ëœ ìƒ˜í”Œ ë°ì´í„°:")
        for row in result:
            print(f"  íŒŒì¼: {row[0]}, ì²­í¬: {row[1]}, í˜ì´ì§€: {row[3]}")
            print(f"  ë‚´ìš©: {row[2]}...")
            print(f"  í‚¤ì›Œë“œ: {row[4]}")
            print()

if __name__ == "__main__":
    print("ğŸš€ TB_DOCUMENT_CHUNKS â†’ VS_DOC_CONTENTS_CHUNKS ë§ˆì´ê·¸ë ˆì´ì…˜")
    print("=" * 60)
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    asyncio.run(migrate_chunk_data())
    
    # ê²€ì¦
    asyncio.run(verify_migration())
    
    print("=" * 60)
    print("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
