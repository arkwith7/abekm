# ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ê´€ë¦¬

ì´ ë””ë ‰í† ë¦¬ëŠ” WKMS ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ì— í•„ìš”í•œ ëª¨ë“  ë°ì´í„°ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
data/
â”œâ”€â”€ ground_truth/                   # ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ë°ì´í„°
â”‚   â”œâ”€â”€ ground_truth_criteria.csv   # ë©”ì¸ ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ (130ê°œ ì¼€ì´ìŠ¤)
â”‚   â”œâ”€â”€ documents_analysis.csv      # ì—…ë¡œë“œ ë¬¸ì„œ ë¶„ì„ ê²°ê³¼
â”‚   â”œâ”€â”€ documents_analysis_detail.json # ìƒì„¸ ë¬¸ì„œ ì •ë³´ (í‚¤ì›Œë“œ, ìš”ì•½ ë“±)
â”‚   â””â”€â”€ ground_truth_v*.csv         # ë²„ì „ë³„ ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ë°±ì—…
â”œâ”€â”€ test_results/                   # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ rag_chat/                  # RAG ì±„íŒ… í…ŒìŠ¤íŠ¸ ê²°ê³¼
â”‚   â”‚   â”œâ”€â”€ 2025-09-16/            # ë‚ ì§œë³„ ê²°ê³¼ ì €ì¥
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_test_report.json
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_test_results.csv
â”‚   â”‚   â”‚   â””â”€â”€ rag_test_summary.md
â”‚   â”‚   â””â”€â”€ latest -> 2025-09-16/  # ìµœì‹  ê²°ê³¼ ì‹¬ë³¼ë¦­ ë§í¬
â”‚   â”œâ”€â”€ document_processing/        # ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼
â”‚   â”‚   â”œâ”€â”€ text_extraction/
â”‚   â”‚   â”œâ”€â”€ chunking_strategy/
â”‚   â”‚   â””â”€â”€ embedding_generation/
â”‚   â””â”€â”€ hybrid_search/             # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ê²°ê³¼
â”‚       â”œâ”€â”€ semantic_search/
â”‚       â”œâ”€â”€ keyword_search/
â”‚       â””â”€â”€ fusion_algorithms/
â”œâ”€â”€ sample_documents/              # í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë¬¸ì„œ
â”‚   â”œâ”€â”€ pdf_samples/
â”‚   â”œâ”€â”€ docx_samples/
â”‚   â”œâ”€â”€ pptx_samples/
â”‚   â””â”€â”€ txt_samples/
â”œâ”€â”€ benchmarks/                    # ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°
â”‚   â”œâ”€â”€ performance_baselines.json # ì„±ëŠ¥ ê¸°ì¤€ì„ 
â”‚   â”œâ”€â”€ quality_metrics.csv       # í’ˆì§ˆ ì§€í‘œ íˆìŠ¤í† ë¦¬
â”‚   â””â”€â”€ comparison_data/           # íƒ€ ì‹œìŠ¤í…œ ë¹„êµ ë°ì´í„°
â””â”€â”€ README.md                      # ì´ íŒŒì¼
```

## ğŸ¯ ë°ì´í„° ìœ í˜•ë³„ ì„¤ëª…

### 1. ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ë°ì´í„° (`ground_truth/`)

#### `ground_truth_criteria.csv`
ì‹¤ì œ ì—…ë¡œë“œëœ 19ê°œ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ìƒì„±ëœ 130ê°œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

**ì»¬ëŸ¼ êµ¬ì¡°**:
- `question`: í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
- `category`: ì¹´í…Œê³ ë¦¬ (document_existence, content_inquiry, ppt_generation, non_existent_content)
- `api_type`: API ìœ í˜• (general, ppt)
- `expected_has_reference`: ì°¸ê³ ìë£Œ ì¡´ì¬ ì—¬ë¶€ (True/False)
- `expected_reference_file`: ì˜ˆìƒ ì°¸ê³ ìë£Œ íŒŒì¼ëª…
- `expected_answer_type`: ì˜ˆìƒ ë‹µë³€ ìœ í˜• (í™•ì¸, ì„¤ëª…, PPT ìƒì„±, ìë£Œ ì—†ìŒ ì•ˆë‚´)
- `keywords`: ê´€ë ¨ í‚¤ì›Œë“œ (ì½¤ë§ˆ êµ¬ë¶„)
- `difficulty`: ë‚œì´ë„ (easy, medium, hard)
- `test_purpose`: í…ŒìŠ¤íŠ¸ ëª©ì 

#### `documents_analysis.csv`
ì—…ë¡œë“œëœ ë¬¸ì„œë“¤ì˜ ê¸°ë³¸ ì •ë³´ì™€ ë¶„ì„ ê²°ê³¼

#### `documents_analysis_detail.json`
ê° ë¬¸ì„œì˜ ìƒì„¸ ì •ë³´ (í‚¤ì›Œë“œ, ìš”ì•½, ë‚´ìš© ë“±) JSON í˜•íƒœ

### 2. í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë°ì´í„° (`test_results/`)

#### ê²°ê³¼ íŒŒì¼ í˜•ì‹
- **JSON ë¦¬í¬íŠ¸**: ìƒì„¸í•œ í…ŒìŠ¤íŠ¸ ê²°ê³¼, í†µê³„ ì •ë³´, ë©”íƒ€ë°ì´í„°
- **CSV ê²°ê³¼**: í‘œ í˜•íƒœì˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ (ë¶„ì„/ì‹œê°í™” ìš©ë„)
- **ë§ˆí¬ë‹¤ìš´ ìš”ì•½**: ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ìš”ì•½ ë¦¬í¬íŠ¸

#### ë‚ ì§œë³„ ë²„ì „ ê´€ë¦¬
- ê° í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê²°ê³¼ëŠ” ë‚ ì§œë³„ ë””ë ‰í† ë¦¬ì— ì €ì¥
- `latest` ì‹¬ë³¼ë¦­ ë§í¬ë¡œ ìµœì‹  ê²°ê³¼ ì‰½ê²Œ ì ‘ê·¼
- ì„±ëŠ¥ ë³€í™” ì¶”ì  ë° íšŒê·€ ë¶„ì„ ê°€ëŠ¥

### 3. ìƒ˜í”Œ ë¬¸ì„œ (`sample_documents/`)

í…ŒìŠ¤íŠ¸ìš© í‘œì¤€ ìƒ˜í”Œ ë¬¸ì„œë“¤:
- **PDF**: ë‹¤ì–‘í•œ ë ˆì´ì•„ì›ƒê³¼ í°íŠ¸ì˜ PDF ë¬¸ì„œ
- **DOCX**: í‘œ, ì´ë¯¸ì§€, ë³µì¡í•œ ì„œì‹ì˜ ì›Œë“œ ë¬¸ì„œ  
- **PPTX**: ìŠ¬ë¼ì´ë“œ, ì°¨íŠ¸, ì• ë‹ˆë©”ì´ì…˜ í¬í•¨ í”„ë ˆì  í…Œì´ì…˜
- **TXT**: ìˆœìˆ˜ í…ìŠ¤íŠ¸ íŒŒì¼

## ğŸš€ ë°ì´í„° ê´€ë¦¬ ë„êµ¬

### ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ìƒì„±/ì—…ë°ì´íŠ¸
```bash
cd /home/admin/wkms-aws/jupyter_notebook/utils
python analyze_uploads_documents.py
```

### í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì •ë¦¬
```bash
cd /home/admin/wkms-aws/jupyter_notebook/data/test_results
python ../utils/organize_test_results.py
```

### ë°ì´í„° ë°±ì—…
```bash
cd /home/admin/wkms-aws/jupyter_notebook/data
tar -czf backup_$(date +%Y%m%d).tar.gz ground_truth/ test_results/
```

## ğŸ“Š ë°ì´í„° ë¶„ì„ ë° í™œìš©

### ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
```python
import pandas as pd
import matplotlib.pyplot as plt

# ì‹œê°„ë³„ ì„±ëŠ¥ ë³€í™” ì¶”ì 
results_dir = "/home/admin/wkms-aws/jupyter_notebook/data/test_results/rag_chat/"
dates = ["2025-09-15", "2025-09-16"]

performance_data = []
for date in dates:
    df = pd.read_csv(f"{results_dir}/{date}/rag_test_results.csv")
    avg_score = df["overall_score"].mean()
    performance_data.append({"date": date, "average_score": avg_score})

trend_df = pd.DataFrame(performance_data)
trend_df.plot(x="date", y="average_score", kind="line")
```

### ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë¹„êµ
```python
# ìµœì‹  í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¡œë“œ
latest_results = pd.read_csv("test_results/rag_chat/latest/rag_test_results.csv")

# ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë¶„ì„
category_performance = latest_results.groupby("category")["overall_score"].agg([
    "mean", "std", "count"
]).round(3)

print(category_performance)
```

### ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ í’ˆì§ˆ ê²€ì¦
```python
# ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ë°ì´í„° ê²€ì¦
gt_df = pd.read_csv("ground_truth/ground_truth_criteria.csv")

# ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬ í™•ì¸
print("ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
print(gt_df["category"].value_counts())

# ë‚œì´ë„ë³„ ë¶„í¬ í™•ì¸  
print("\në‚œì´ë„ë³„ ë¶„í¬:")
print(gt_df["difficulty"].value_counts())

# ëˆ„ë½ëœ í‚¤ì›Œë“œ í™•ì¸
missing_keywords = gt_df[gt_df["keywords"].isna()]
if not missing_keywords.empty:
    print(f"\ní‚¤ì›Œë“œê°€ ëˆ„ë½ëœ ì¼€ì´ìŠ¤: {len(missing_keywords)}ê°œ")
```

## ğŸ”§ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬

### ë°ì´í„° ê²€ì¦ ê·œì¹™
1. **ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ì¼ê´€ì„±**: ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•œ ì¼ê´€ëœ ê¸°ëŒ€ê°’
2. **ì°¸ê³ ìë£Œ ì¡´ì¬ì„±**: expected_reference_fileì´ ì‹¤ì œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
3. **í‚¤ì›Œë“œ ì •í™•ì„±**: ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì‹¤ì œ ë¬¸ì„œ ë‚´ìš©ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦
4. **ì¹´í…Œê³ ë¦¬ ê· í˜•**: ê° ì¹´í…Œê³ ë¦¬ë³„ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì ì ˆí•œ ë¶„í¬

### ìë™ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
```bash
cd /home/admin/wkms-aws/jupyter_notebook/utils
python validate_ground_truth.py
```

### ë°ì´í„° ì •í•©ì„± ì²´í¬
```python
def validate_ground_truth(csv_path):
    df = pd.read_csv(csv_path)
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_columns = ["question", "category", "expected_has_reference"]
    missing_columns = set(required_columns) - set(df.columns)
    if missing_columns:
        print(f"âŒ ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_columns}")
    
    # ì¤‘ë³µ ì§ˆë¬¸ í™•ì¸
    duplicates = df[df.duplicated("question")]
    if not duplicates.empty:
        print(f"âŒ ì¤‘ë³µëœ ì§ˆë¬¸: {len(duplicates)}ê°œ")
    
    # ìœ íš¨í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ í™•ì¸
    valid_categories = ["document_existence", "content_inquiry", "ppt_generation", "non_existent_content"]
    invalid_categories = df[~df["category"].isin(valid_categories)]
    if not invalid_categories.empty:
        print(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬: {len(invalid_categories)}ê°œ")
    
    print("âœ… ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ê²€ì¦ ì™„ë£Œ")
```

## ğŸ“ˆ ì„±ëŠ¥ ê¸°ì¤€ì„  (Baseline)

### í˜„ì¬ ì„±ëŠ¥ ê¸°ì¤€
- **ì „ì²´ í‰ê·  ì ìˆ˜**: 0.75 ì´ìƒ
- **ì°¸ê³ ìë£Œ ì •í™•ë„**: 0.85 ì´ìƒ
- **ë‚´ìš© ê´€ë ¨ì„±**: 0.70 ì´ìƒ
- **í‰ê·  ì‘ë‹µ ì‹œê°„**: 2.0ì´ˆ ì´í•˜

### ì„±ëŠ¥ ì•ŒëŒ ì„ê³„ê°’
- **ì‹¬ê°**: ì „ì²´ í‰ê·  ì ìˆ˜ 0.60 ë¯¸ë§Œ
- **ê²½ê³ **: ì „ì²´ í‰ê·  ì ìˆ˜ 0.65 ë¯¸ë§Œ
- **ì£¼ì˜**: ì´ì „ ëŒ€ë¹„ 10% ì´ìƒ ì„±ëŠ¥ ì €í•˜

## ğŸ¤ ë°ì´í„° ê¸°ì—¬ ê°€ì´ë“œ

### ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€
1. `ground_truth/ground_truth_criteria.csv`ì— ìƒˆ í–‰ ì¶”ê°€
2. í•„ìˆ˜ ì»¬ëŸ¼ ëª¨ë‘ ì±„ìš°ê¸°
3. ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ë¡œ í’ˆì§ˆ í™•ì¸
4. ë²„ì „ ë°±ì—… ìƒì„±

### ìƒ˜í”Œ ë¬¸ì„œ ì¶”ê°€
1. ì ì ˆí•œ `sample_documents/` í•˜ìœ„ ë””ë ‰í† ë¦¬ì— íŒŒì¼ ì¶”ê°€
2. íŒŒì¼ëª… ê·œì¹™: `category_description_v1.ext`
3. ë©”íƒ€ë°ì´í„° íŒŒì¼ ìƒì„± (JSON í˜•íƒœ)

### í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ì—¬
1. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ ë‚ ì§œë³„ ë””ë ‰í† ë¦¬ì— ì €ì¥
2. ì„±ëŠ¥ ê°œì„ /ì €í•˜ ì›ì¸ ë¶„ì„ ë…¸íŠ¸ ì¶”ê°€
3. ë¹„ì •ìƒì ì¸ ê²°ê³¼ëŠ” ë³„ë„ ì´ìŠˆë¡œ ë¬¸ì„œí™”

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-09-16  
**ë°ì´í„° ë²„ì „**: v1.0  
**ê´€ë¦¬ì**: WKMS í…ŒìŠ¤íŠ¸íŒ€