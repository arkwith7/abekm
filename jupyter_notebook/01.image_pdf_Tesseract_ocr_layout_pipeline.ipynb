{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170e6135",
   "metadata": {},
   "source": [
    "# ğŸ“„ ì´ë¯¸ì§€ PDF OCR + ë ˆì´ì•„ì›ƒ ì¶”ì¶œ íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "ëª©ì : ì „ì²´ íŒŒì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì—ì„œ ì´ë¯¸ì§€ ê¸°ë°˜ PDFë¥¼ ìë™ íŒë³„í•˜ì—¬ OCR ëŒ€ìƒìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ , í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í…ìŠ¤íŠ¸/ì´ë¯¸ì§€/í‘œ ë°ì´í„°ë¥¼ ì¶”ì¶œÂ·ì €ì¥í•˜ë©° ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "í•µì‹¬ ê¸°ëŠ¥:\n",
    "- ì´ë¯¸ì§€ PDF ìë™ íŒë³„(í…ìŠ¤íŠ¸ ì ìŒ â†’ OCR ëŒ€ìƒ)\n",
    "- í˜ì´ì§€ ë‹¨ìœ„ OCR ì‹¤í–‰ ë° ì‹¤ì‹œê°„ ì§„í–‰ ë¡œê·¸\n",
    "- í˜ì´ì§€ ì´ë¯¸ì§€ ì €ì¥, í‘œ ì¶”ì¶œ(pdfplumber ê¸°ë°˜) ë° ì €ì¥\n",
    "- ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì¼ ë° ë©”íƒ€ë°ì´í„° JSON ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aecbc748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœ í™•ì¸:\n",
      "âœ” pdf2image ì‚¬ìš© ê°€ëŠ¥\n",
      "âœ” pdf2image ì‚¬ìš© ê°€ëŠ¥\n",
      "âœ” pytesseract ì‚¬ìš© ê°€ëŠ¥\n",
      "âœ– pdfplumber ë¶ˆê°€: No module named 'pdfminer.pdftypes'\n",
      "âœ” PIL ì‚¬ìš© ê°€ëŠ¥\n",
      "âš  ì„¤ì¹˜ í•„ìš”: pdfplumber\n",
      "âœ” pytesseract ì‚¬ìš© ê°€ëŠ¥\n",
      "âœ– pdfplumber ë¶ˆê°€: No module named 'pdfminer.pdftypes'\n",
      "âœ” PIL ì‚¬ìš© ê°€ëŠ¥\n",
      "âš  ì„¤ì¹˜ í•„ìš”: pdfplumber\n"
     ]
    }
   ],
   "source": [
    "# âœ… ì˜ì¡´ì„± ì ê²€ (ë¹ ë¥¸ í™•ì¸ ì „ìš©: ì„¤ì¹˜ëŠ” ë³„ë„)\n",
    "import importlib, sys\n",
    "\n",
    "\n",
    "def check_lib(name):\n",
    "    try:\n",
    "        importlib.import_module(name)\n",
    "        print(f'âœ” {name} ì‚¬ìš© ê°€ëŠ¥', flush=True)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f'âœ– {name} ë¶ˆê°€: {e}', flush=True)\n",
    "        return False\n",
    "\n",
    "\n",
    "needed = ['pdf2image', 'pytesseract', 'pdfplumber', 'PIL']\n",
    "print('ğŸ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒíƒœ í™•ì¸:', flush=True)\n",
    "status = {n: check_lib(n) for n in needed}\n",
    "missing = [n for n, ok in status.items() if not ok]\n",
    "if missing:\n",
    "    print(f'âš  ì„¤ì¹˜ í•„ìš”: {\", \".join(missing)}', flush=True)\n",
    "else:\n",
    "    print('âœ… ëª¨ë“  í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ë¨', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45e205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ì¶œë ¥ ê²½ë¡œ ì„¤ì • ì™„ë£Œ:\n",
      " - í˜ì´ì§€ í…ìŠ¤íŠ¸: /home/admin/wkms-aws/jupyter_notebook/data/opensource_output/extracted_texts\n",
      " - í˜ì´ì§€ ì´ë¯¸ì§€: /home/admin/wkms-aws/jupyter_notebook/data/opensource_output/extracted_texts/page_images\n",
      " - í‘œ ì¶œë ¥: /home/admin/wkms-aws/jupyter_notebook/data/opensource_output/extracted_texts/page_tables\n",
      " - í˜ì´ì§€ í…ìŠ¤íŠ¸: /home/admin/wkms-aws/jupyter_notebook/data/opensource_output/extracted_texts\n",
      " - í˜ì´ì§€ ì´ë¯¸ì§€: /home/admin/wkms-aws/jupyter_notebook/data/opensource_output/extracted_texts/page_images\n",
      " - í‘œ ì¶œë ¥: /home/admin/wkms-aws/jupyter_notebook/data/opensource_output/extracted_texts/page_tables\n"
     ]
    }
   ],
   "source": [
    "# âš™ï¸ ê²½ë¡œ/ì„¤ì •\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, Any\n",
    "import time, json\n",
    "\n",
    "BASE_DIR = Path('/home/admin/wkms-aws/jupyter_notebook')\n",
    "INPUT_PDF = BASE_DIR / 'data/input_docs/test.pdf'  # í•„ìš”ì‹œ ë³€ê²½\n",
    "OUTPUT_DIR = BASE_DIR / 'data/opensource_output/extracted_texts'\n",
    "\n",
    "@dataclass\n",
    "class OCRConfig:\n",
    "    ocr_enabled: bool = True\n",
    "    ocr_language: str = 'eng'  # ì˜ˆ: 'kor' ë˜ëŠ” 'kor+eng'\n",
    "    ocr_dpi: int = 220\n",
    "\n",
    "@dataclass\n",
    "class Paths:\n",
    "    output_root: Path = OUTPUT_DIR\n",
    "    page_texts: Path = field(default_factory=lambda: OUTPUT_DIR)\n",
    "    page_images: Path = field(default_factory=lambda: OUTPUT_DIR / 'page_images')\n",
    "    page_tables: Path = field(default_factory=lambda: OUTPUT_DIR / 'page_tables')\n",
    "\n",
    "paths = Paths()\n",
    "for d in [paths.output_root, paths.page_images, paths.page_tables]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ocr_cfg = OCRConfig()\n",
    "print('ğŸ“‚ ì¶œë ¥ ê²½ë¡œ ì„¤ì • ì™„ë£Œ:', flush=True)\n",
    "print(f' - í˜ì´ì§€ í…ìŠ¤íŠ¸: {paths.page_texts}', flush=True)\n",
    "print(f' - í˜ì´ì§€ ì´ë¯¸ì§€: {paths.page_images}', flush=True)\n",
    "print(f' - í‘œ ì¶œë ¥: {paths.page_tables}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d9e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ ìœ í‹¸ë¦¬í‹°\n",
    "def write_text(path: Path, content: str):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def write_json(path: Path, data: Dict[str, Any]):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def is_image_pdf(pdf_path: Path, sample_pages: int = 3) -> bool:\n",
    "    \"\"\"ê°„ë‹¨ ê¸°ì¤€: pdfplumberë¡œ ì•ë¶€ë¶„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œ ë§¤ìš° ì ìœ¼ë©´ ì´ë¯¸ì§€ ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨\"\"\"\n",
    "    try:\n",
    "        import pdfplumber  # type: ignore\n",
    "        total_txt = ''\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for i, page in enumerate(pdf.pages[:sample_pages], 1):\n",
    "                try:\n",
    "                    total_txt += (page.extract_text() or '')\n",
    "                except Exception:\n",
    "                    pass\n",
    "        return len((total_txt or '').strip()) < 100\n",
    "    except Exception:\n",
    "        # ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ê±°ë‚˜ ì‹¤íŒ¨ ì‹œ ë³´ìˆ˜ì ìœ¼ë¡œ OCR ëŒ€ìƒìœ¼ë¡œ ê°„ì£¼\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbfff2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¤ OCR + í˜ì´ì§€ë³„ ì €ì¥ (í…ìŠ¤íŠ¸/ì´ë¯¸ì§€)\n",
    "\n",
    "def ocr_pdf_to_text(pdf_path: Path, paths: Paths, cfg: OCRConfig) -> Dict[str, Any]:\n",
    "    import time\n",
    "    from pathlib import Path as _P\n",
    "    try:\n",
    "        from pdf2image import convert_from_path  # type: ignore\n",
    "        import pytesseract  # type: ignore\n",
    "        from PIL import Image  # type: ignore\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f'OCR ì‹¤í–‰ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {e}')\n",
    "\n",
    "    start = time.time()\n",
    "    print(f'ğŸ”„ PDFâ†’ì´ë¯¸ì§€ ë³€í™˜ ì¤‘ (DPI={cfg.ocr_dpi})...', flush=True)\n",
    "    images = convert_from_path(str(pdf_path), dpi=cfg.ocr_dpi)\n",
    "    print(f'   âœ… ë³€í™˜ ì™„ë£Œ: {len(images)}í˜ì´ì§€', flush=True)\n",
    "\n",
    "    full_text_parts = []\n",
    "    page_text_files = []\n",
    "    page_image_files = []\n",
    "    page_meta = []\n",
    "\n",
    "    for idx, img in enumerate(images, 1):\n",
    "        p_start = time.time()\n",
    "        print(f'   ğŸ” í˜ì´ì§€ {idx}/{len(images)} OCR...', flush=True)\n",
    "        txt = pytesseract.image_to_string(img, lang=cfg.ocr_language)\n",
    "        txt = txt.strip()\n",
    "        page_txt_path = paths.page_texts / f'{pdf_path.stem}_page_{idx:03d}.txt'\n",
    "        write_text(page_txt_path, txt)\n",
    "        page_text_files.append(str(page_txt_path))\n",
    "\n",
    "        page_img_path = paths.page_images / f'{pdf_path.stem}_page_{idx:03d}.png'\n",
    "        try:\n",
    "            img.save(page_img_path)\n",
    "            page_image_files.append(str(page_img_path))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        full_text_parts.append(f'\\n\\n=== í˜ì´ì§€ {idx} ===\\n' + txt)\n",
    "        page_meta.append({\n",
    "            'page': idx,\n",
    "            'text_length': len(txt),\n",
    "            'processing_time': round(time.time() - p_start, 3),\n",
    "            'text_file': str(page_txt_path),\n",
    "            'image_file': str(page_img_path) if page_image_files else None\n",
    "        })\n",
    "\n",
    "    full_text = '\\n'.join(full_text_parts).strip()\n",
    "    full_txt_path = paths.output_root / f'{pdf_path.stem}_ocr_full.txt'\n",
    "    write_text(full_txt_path, full_text)\n",
    "\n",
    "    meta = {\n",
    "        'method': 'ocr',\n",
    "        'pages': len(images),\n",
    "        'ocr_language': cfg.ocr_language,\n",
    "        'ocr_dpi': cfg.ocr_dpi,\n",
    "        'total_time': round(time.time() - start, 3),\n",
    "        'page_details': page_meta,\n",
    "        'output_file': str(full_txt_path),\n",
    "        'page_text_files': page_text_files,\n",
    "        'page_image_files': page_image_files\n",
    "    }\n",
    "    return {'text': full_text, 'metadata': meta}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202b0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š í‘œ ì¶”ì¶œ(pdfplumber) â€” ë²¡í„° ê¸°ë°˜ PDFì—ì„œ ìœ íš¨. ì´ë¯¸ì§€ PDFì—ì„  ë³´í†µ ì—†ìŒ\n",
    "\n",
    "def extract_tables_with_pdfplumber(pdf_path: Path, paths: Paths, max_pages: Optional[int] = None) -> Dict[str, Any]:\n",
    "    try:\n",
    "        import pdfplumber  # type: ignore\n",
    "    except Exception as e:\n",
    "        print(f'âš  pdfplumber ë¶ˆê°€: {e}', flush=True)\n",
    "        return {'tables': [], 'files': []}\n",
    "\n",
    "    saved = []\n",
    "    tables_summary = []\n",
    "    with pdfplumber.open(str(pdf_path)) as pdf:\n",
    "        pages = pdf.pages if max_pages is None else pdf.pages[:max_pages]\n",
    "        for idx, page in enumerate(pages, 1):\n",
    "            try:\n",
    "                tbls = page.extract_tables() or []\n",
    "            except Exception:\n",
    "                tbls = []\n",
    "            if not tbls:\n",
    "                continue\n",
    "            # ê° í…Œì´ë¸”ì„ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¡œ ì €ì¥\n",
    "            for t_i, table in enumerate(tbls, 1):\n",
    "                lines = [' | '.join([(c or '').strip() for c in row]) for row in table if row]\n",
    "                content = (f'=== í˜ì´ì§€ {idx} í…Œì´ë¸” {t_i} ===\\n' + '\\n'.join(lines)).strip()\n",
    "                out = paths.page_tables / f'{pdf_path.stem}_p{idx:03d}_t{t_i:02d}.txt'\n",
    "                write_text(out, content)\n",
    "                saved.append(str(out))\n",
    "                tables_summary.append({'page': idx, 'table_index': t_i, 'rows': len(table)})\n",
    "    return {'tables': tables_summary, 'files': saved}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc81b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§  ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°: ì´ë¯¸ì§€ PDF íŒë³„ â†’ OCR â†’ í‘œ ì¶”ì¶œ â†’ ê²°ê³¼ ì €ì¥\n",
    "\n",
    "def process_pdf(pdf_path: Path, paths: Paths, cfg: OCRConfig) -> Dict[str, Any]:\n",
    "    print(f'ğŸ“¥ ì…ë ¥ íŒŒì¼: {pdf_path}', flush=True)\n",
    "    if not pdf_path.exists():\n",
    "        raise FileNotFoundError(f'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pdf_path}')\n",
    "    img_pdf = is_image_pdf(pdf_path)\n",
    "    print(f'ğŸ§ª ì´ë¯¸ì§€ PDF íŒë³„: {\"ì˜ˆ\" if img_pdf else \"ì•„ë‹ˆì˜¤\"}', flush=True)\n",
    "\n",
    "    # 1) í…ìŠ¤íŠ¸/ì „ì²´ íŒŒì¼ ì¶”ì¶œ\n",
    "    if img_pdf or cfg.ocr_enabled:\n",
    "        print('ğŸ”¤ OCR ê²½ë¡œë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.', flush=True)\n",
    "        res = ocr_pdf_to_text(pdf_path, paths, cfg)\n",
    "    else:\n",
    "        # í…ìŠ¤íŠ¸ ê¸°ë°˜ PDF ê°„ë‹¨ ì¶”ì¶œ (ë³´ì¡°)\n",
    "        try:\n",
    "            import pdfplumber  # type: ignore\n",
    "            print('ğŸ“ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì¶œ(pdfplumber.extract_text) ì‹œë„', flush=True)\n",
    "            texts = []\n",
    "            with pdfplumber.open(str(pdf_path)) as pdf:\n",
    "                for idx, page in enumerate(pdf.pages, 1):\n",
    "                    t = page.extract_text() or ''\n",
    "                    write_text(paths.page_texts / f'{pdf_path.stem}_page_{idx:03d}.txt', (t or '').strip())\n",
    "                    texts.append(f'\\n\\n=== í˜ì´ì§€ {idx} ===\\n' + (t or '').strip())\n",
    "            full = '\\n'.join(texts).strip()\n",
    "            out = paths.output_root / f'{pdf_path.stem}_full.txt'\n",
    "            write_text(out, full)\n",
    "            res = {'text': full, 'metadata': {'method': 'text', 'output_file': str(out)}}\n",
    "        except Exception as e:\n",
    "            print(f'âš  í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨, OCRë¡œ ëŒ€ì²´: {e}', flush=True)\n",
    "            res = ocr_pdf_to_text(pdf_path, paths, cfg)\n",
    "\n",
    "    # 2) í‘œ ì¶”ì¶œ (ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "    print('ğŸ“Š í‘œ ì¶”ì¶œ ì‹œë„(pdfplumber)', flush=True)\n",
    "    table_info = extract_tables_with_pdfplumber(pdf_path, paths)\n",
    "\n",
    "    # 3) ë©”íƒ€ë°ì´í„° í•©ì„±\n",
    "    meta = res.get('metadata', {})\n",
    "    meta.update({\n",
    "        'tables': table_info.get('tables', []),\n",
    "        'table_files': table_info.get('files', [])\n",
    "    })\n",
    "    doc_meta_path = paths.output_root / f'{pdf_path.stem}_metadata.json'\n",
    "    write_json(doc_meta_path, meta)\n",
    "\n",
    "    print('âœ… ì²˜ë¦¬ ì™„ë£Œ', flush=True)\n",
    "    print(f' - ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì¼: {meta.get(\"output_file\")}', flush=True)\n",
    "    print(f' - í‘œ íŒŒì¼ ìˆ˜: {len(meta.get(\"table_files\", []))}', flush=True)\n",
    "    print(f' - í˜ì´ì§€ í…ìŠ¤íŠ¸ íŒŒì¼ ìˆ˜: {len(meta.get(\"page_text_files\", []))}', flush=True)\n",
    "    print(f' - í˜ì´ì§€ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜: {len(meta.get(\"page_image_files\", []))}', flush=True)\n",
    "    return {'text': res.get('text', ''), 'metadata': meta}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f4641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì´ë¯¸ì§€ PDF OCR + ë ˆì´ì•„ì›ƒ ì¶”ì¶œ ë°ëª¨ ì‹œì‘\n",
      "ì…ë ¥: /home/admin/wkms-aws/jupyter_notebook/data/input_docs/test.pdf\n",
      "ğŸ“¥ ì…ë ¥ íŒŒì¼: /home/admin/wkms-aws/jupyter_notebook/data/input_docs/test.pdf\n",
      "ğŸ§ª ì´ë¯¸ì§€ PDF íŒë³„: ì˜ˆ\n",
      "ğŸ”¤ OCR ê²½ë¡œë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
      "ğŸ”„ PDFâ†’ì´ë¯¸ì§€ ë³€í™˜ ì¤‘ (DPI=220)...\n",
      "ì…ë ¥: /home/admin/wkms-aws/jupyter_notebook/data/input_docs/test.pdf\n",
      "ğŸ“¥ ì…ë ¥ íŒŒì¼: /home/admin/wkms-aws/jupyter_notebook/data/input_docs/test.pdf\n",
      "ğŸ§ª ì´ë¯¸ì§€ PDF íŒë³„: ì˜ˆ\n",
      "ğŸ”¤ OCR ê²½ë¡œë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
      "ğŸ”„ PDFâ†’ì´ë¯¸ì§€ ë³€í™˜ ì¤‘ (DPI=220)...\n",
      "   âœ… ë³€í™˜ ì™„ë£Œ: 27í˜ì´ì§€\n",
      "   ğŸ” í˜ì´ì§€ 1/27 OCR...\n",
      "   âœ… ë³€í™˜ ì™„ë£Œ: 27í˜ì´ì§€\n",
      "   ğŸ” í˜ì´ì§€ 1/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 2/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 2/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 3/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 3/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 4/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 4/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 5/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 5/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 6/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 6/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 7/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 7/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 8/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 8/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 9/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 9/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 10/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 10/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 11/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 11/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 12/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 12/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 13/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 13/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 14/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 14/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 15/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 15/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 16/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 16/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 17/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 17/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 18/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 18/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 19/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 19/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 20/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 20/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 21/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 21/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 22/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 22/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 23/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 23/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 24/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 24/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 25/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 25/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 26/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 26/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 27/27 OCR...\n",
      "   ğŸ” í˜ì´ì§€ 27/27 OCR...\n",
      "ğŸ“Š í‘œ ì¶”ì¶œ ì‹œë„(pdfplumber)\n",
      "âš  pdfplumber ë¶ˆê°€: No module named 'pdfminer.pdftypes'\n",
      "âœ… ì²˜ë¦¬ ì™„ë£Œ\n",
      " - ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì¼: /home/admin/wkms-aws/jupyter_notebook/data/opensource_output/extracted_texts/test_ocr_full.txt\n",
      " - í‘œ íŒŒì¼ ìˆ˜: 0\n",
      " - í˜ì´ì§€ í…ìŠ¤íŠ¸ íŒŒì¼ ìˆ˜: 27\n",
      " - í˜ì´ì§€ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜: 27\n",
      "\n",
      "ğŸ” ì „ì²´ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°(ìƒìœ„ 500ì):\n",
      "=== í˜ì´ì§€ 1 ===\n",
      "if\n",
      "\n",
      "a\n",
      "\n",
      "ITM BLAS\n",
      "\n",
      "Bab\n",
      "\n",
      "R208 Boh Journal of Information Technology Services\n",
      "2023 6A, pp.1-27 https://doi.org/10.9716/KITS.2023.22.3.001\n",
      "\n",
      "2~ == vv >) Py\n",
      "\n",
      "Yego] elcst alae) eh APE:\n",
      "ay RES] Ale] S7\n",
      "\n",
      "Ey] alg] o} ni] 2** Â» 93] alg] KEK ea ae TE od * eH\n",
      "\n",
      "Ambidextrous Leadership and Innovative Work Behavior:\n",
      "Evidence from South Korea Semiconductor Industryâ€\n",
      "\n",
      "Henry Ameyaw Domfeh**-: Henry Ofori*** - Sora Yoon**** - Juyoung Kang*****\n",
      "\n",
      "m@ Abstract @\n",
      "\n",
      "The semiconductor industry is a competitive\n",
      "ğŸ“Š í‘œ ì¶”ì¶œ ì‹œë„(pdfplumber)\n",
      "âš  pdfplumber ë¶ˆê°€: No module named 'pdfminer.pdftypes'\n",
      "âœ… ì²˜ë¦¬ ì™„ë£Œ\n",
      " - ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì¼: /home/admin/wkms-aws/jupyter_notebook/data/opensource_output/extracted_texts/test_ocr_full.txt\n",
      " - í‘œ íŒŒì¼ ìˆ˜: 0\n",
      " - í˜ì´ì§€ í…ìŠ¤íŠ¸ íŒŒì¼ ìˆ˜: 27\n",
      " - í˜ì´ì§€ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜: 27\n",
      "\n",
      "ğŸ” ì „ì²´ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°(ìƒìœ„ 500ì):\n",
      "=== í˜ì´ì§€ 1 ===\n",
      "if\n",
      "\n",
      "a\n",
      "\n",
      "ITM BLAS\n",
      "\n",
      "Bab\n",
      "\n",
      "R208 Boh Journal of Information Technology Services\n",
      "2023 6A, pp.1-27 https://doi.org/10.9716/KITS.2023.22.3.001\n",
      "\n",
      "2~ == vv >) Py\n",
      "\n",
      "Yego] elcst alae) eh APE:\n",
      "ay RES] Ale] S7\n",
      "\n",
      "Ey] alg] o} ni] 2** Â» 93] alg] KEK ea ae TE od * eH\n",
      "\n",
      "Ambidextrous Leadership and Innovative Work Behavior:\n",
      "Evidence from South Korea Semiconductor Industryâ€\n",
      "\n",
      "Henry Ameyaw Domfeh**-: Henry Ofori*** - Sora Yoon**** - Juyoung Kang*****\n",
      "\n",
      "m@ Abstract @\n",
      "\n",
      "The semiconductor industry is a competitive\n"
     ]
    }
   ],
   "source": [
    "# â–¶ï¸ ì‹¤í–‰ ëŸ¬ë„ˆ: test.pdf ëŒ€ìƒìœ¼ë¡œ ë°ëª¨ ì‹¤í–‰\n",
    "pdf_path = INPUT_PDF\n",
    "print('ğŸš€ ì´ë¯¸ì§€ PDF OCR + ë ˆì´ì•„ì›ƒ ì¶”ì¶œ ë°ëª¨ ì‹œì‘', flush=True)\n",
    "print(f'ì…ë ¥: {pdf_path}', flush=True)\n",
    "result = process_pdf(pdf_path, paths, ocr_cfg)\n",
    "\n",
    "# ìƒìœ„ 500ì ë¯¸ë¦¬ë³´ê¸°\n",
    "preview = (result.get('text') or '')[:500]\n",
    "print('\\nğŸ” ì „ì²´ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°(ìƒìœ„ 500ì):', flush=True)\n",
    "print(preview if preview else '(ë¯¸ë¦¬ë³´ê¸° ì—†ìŒ)', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146cd9a",
   "metadata": {},
   "source": [
    "## ì°¸ê³ \n",
    "- Tesseract OCRì´ ì‹œìŠ¤í…œì— ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤ (ì˜ˆ: Ubuntu: `sudo apt-get install -y tesseract-ocr`).\n",
    "- í•œêµ­ì–´ OCRì€ `kor` ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤ (ì˜ˆ: `sudo apt-get install -y tesseract-ocr-kor` ë˜ëŠ” í•™ìŠµë°ì´í„° ì„¤ì¹˜).\n",
    "- í‘œ ì¶”ì¶œì€ ë²¡í„° ê¸°ë°˜ PDFì—ì„œë§Œ ë™ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ PDFì˜ í‘œëŠ” OCRë¬¸ìì—´ ê¸°ë°˜ìœ¼ë¡œ í›„ì²˜ë¦¬í•´ì•¼ í•˜ë©°, ë³¸ ë…¸íŠ¸ë¶ì€ ê¸°ë³¸ì ì¸ í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ìš°ì„  ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "- ì¶œë ¥ë¬¼:\n",
    "  - ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì¼: `<íŒŒì¼ëª…>_ocr_full.txt` ë˜ëŠ” `<íŒŒì¼ëª…>_full.txt`\n",
    "  - í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ íŒŒì¼: `<íŒŒì¼ëª…>_page_###.txt`\n",
    "  - í˜ì´ì§€ ì´ë¯¸ì§€: `page_images/` í´ë” ë‚´ PNG\n",
    "  - í‘œ í…ìŠ¤íŠ¸: `page_tables/` í´ë” ë‚´ í…ìŠ¤íŠ¸ íŒŒì¼\n",
    "  - ë¬¸ì„œ ë©”íƒ€ë°ì´í„° JSON: `<íŒŒì¼ëª…>_metadata.json`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
