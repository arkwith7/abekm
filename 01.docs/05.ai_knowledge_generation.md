# 05. AI 지식생성 시스템 상세 설계

> 본 문서는 ABEKM 플랫폼 내 **AI 지식생성 (AI Knowledge Generation)** 서브시스템의 현재 구현 상태를 기술합니다. (마이그레이션/로드맵 제거, 실 운용 기능 중심)

> **최종 업데이트**: 2025-10-17  
>

## 1. 목적 및 범위

- RAG + 멀티 에이전트 기반 **대화형 지식 생성/활용** 지원
- 문서 기반 인사이트 추출, 요약, 보고서/PPT 자동화
- 다중 AI 공급자(Bedrock, OpenAI, Azure) 동적 활용 및 Failover
- 권한/컨테이너 기반 문서 접근 제어 연동

## 2. 핵심 사용자 시나리오

| 시나리오          | 설명                              | 주요 컴포넌트                                   |
| ------------- | ------------------------------- | ----------------------------------------- |
| 1. 문서 세트 질문   | 다수 문서를 선택 후 질의                  | ChatPage.tsx, RAGSearchService            |
| 2. 멀티 에이전트 분석 | Analyzer → Insight → Summary 체인 | IntegratedMultiAgentService, Orchestrator |
| 3. PPT 자동 생성  | 대화 메시지 기반 아웃라인/슬라이드 생성          | Presentation tools, SSE stream            |
| 4. 실시간 질의응답   | 검색 + 생성 답변 스트리밍                 | /api/v1/chat/stream, EventSource          |
| 5. **실시간 음성 입력** 🆕 | **음성으로 채팅 입력** | **AWS Transcribe, WebSocket, realtimeSTT.ts** |
| 6. 에이전트 모드 전환 | 단일/멀티/체인 모드 선택                  | useWorkContext, Toolbar UI                |
| 7. 문서 선택 동기화  | 검색 → 채팅 선택 문서 전파                | selectedDocuments context                 |

## 3. 아키텍처 개요

```
[React ChatPage] --(SSE)--> [FastAPI chat.py] --(Service Calls)--> [RAGSearchService]
                                       |--> [IntegratedMultiAgentService]
                                       |--> [Presentation Generator]
                                       |--> [AI Service (Multi-Provider)]
                                         ↘ Redis (세션/상태)  ↘ PostgreSQL(pgvector)
```

### 3.1 구성 요소 매핑

| 레이어             | 구성 요소                                                              | 역할                              |
| --------------- | ------------------------------------------------------------------ | ------------------------------- |
| Frontend        | ChatPage.tsx                                                       | 세션 로딩, 스트리밍 UI, 문서 선택 반영        |
| Frontend        | useChat / usePresentation                                          | SSE 수신, 중단/재시작, PPT build 흐름    |
| Frontend        | PresentationOutlineModal                                           | PPT Outline 편집/재생성              |
| Backend API     | backend/app/api/v1/chat.py                                         | 스트리밍 엔드포인트, RAG/에이전트/PPT 호출 조립  |
| Backend Service | backend/app/services/chat/rag_search_service.py                    | 후보 청크 검색, 리랭킹, 컨텍스트 생성          |
| Backend Service | backend/app/services/chat/query_classification_service.py          | 의도/모드 분류(규칙+모델)                 |
| Backend Service | backend/app/services/multi_agent/integrated_service.py             | 단일/멀티 에이전트 실행 모드 결정 및 워크플로우 실행  |
| Backend Service | backend/app/services/multi_agent/enhanced_ppt_generator_service.py | PPT Outline/빌드 로직               |
| Backend Service | backend/app/services/chat/chat_attachment_service.py | 채팅 첨부 파일(이미지/문서) 저장 및 관리 (Local/S3) |
| Backend Core    | backend/app/services/ai/ai_service.py                              | 다중 공급자 모델 호출 (chat, embeddings) |
| State           | backend/app/services/chat/redis_chat_manager.py                    | 세션 대화 기록/부분 상태 관리               |
| Storage         | PostgreSQL + pgvector                                              | 문서/청크/벡터 및 선택 문서 메타             |

## 4. 데이터 흐름 상세

### 4.1 질문 처리 (RAG + 멀티 에이전트 가능)

1. Frontend `useChat.sendMessage()` 호출
2. `/api/v1/chat/stream` SSE 연결
3. Query classification (의도/모드)
4. RAG 검색 (hybrid: semantic + keyword) → 후보 청크 선택
5. 선택 문서 필터 + 권한 컨테이너 필터 적용
6. 컨텍스트 축약 / 토큰 제한 적용
7. 실행 모드 결정(single/multi)
8. 에이전트 워크플로우 실행 또는 단일 응답 생성
9. 토큰 단위 스트리밍(content/metadata/workflow_step/workflow_complete)
10. 세션 상태 Redis 반영 / 필요시 DB 기록

#### 4.1.1 프런트↔백엔드 이벤트 타임라인 (SSE)

- start: 세션 식별자 방송 { session_id }
- searching: 검색 시작 알림
- search_complete: { chunks_count } (0이면 폴백 경로 가능)
- metadata: { references[], context_info{}, rag_stats{ provider, embedding_provider, llm_model, embedding_model } }
- generating: 생성 개시 알림
- content: 생성 텍스트 청크 { content } 반복 전송
- complete: 최종 메타 { session_id, assistant_message_id, references, context_info, rag_stats }
- error: 오류 메시지 { message }

프런트 `useChat.ts`는 위 이벤트를 수신해 상태 배지(검색중/생성중)를 갱신하고, `content`를 스트리밍으로 이어붙입니다. 완료 시 메타데이터(참고 자료, RAG 통계)를 메시지 객체에 병합 저장합니다.

#### 4.1.2 ChatStreamRequest 페이로드 계약

엔드포인트: `POST /api/v1/chat/stream`

입력(요약):
- message: string
- agent_type: string ('general' 기본)
- selected_documents: Array<SelectedDocument>
  - SelectedDocument: { id, fileName, fileType, filePath?, metadata? }
- session_id: string (없으면 서버에서 생성)
- provider/max_tokens/temperature/use_rag/search_mode/max_chunks/similarity_threshold/use_reranking/context_window 등

출력(스트림 이벤트): 4.1.1 참조. 프런트 메시지 모델은 `message_id/assistant_message_id`, `references`, `context_info`, `rag_stats`를 보관합니다.

#### 4.1.3 AI Agent 적용 위치

- 분류기(QueryClassificationService): 인사/일반대화/시스템문의는 RAG 생략 후 친화 응답으로 즉시 처리
- 컨텍스트 준비(AIAgentService.prepare_context_with_documents):
  - 선택 문서가 있으면 해당 문서 ID 범위로 RAG 검색 제한(document_ids)
  - 없으면 전체 문서 대상 RAG

### 4.2 첨부 파일 기반 채팅 (Chat with Attachments) 🆕

사용자가 채팅창에 직접 업로드한 이미지나 문서 파일을 기반으로 대화하는 기능입니다.

#### 4.2.1 저장소 관리 (Storage Backend)

`.env` 파일의 `STORAGE_BACKEND` 설정에 따라 첨부 파일의 저장 위치가 결정됩니다.

- **STORAGE_BACKEND=s3**: AWS S3 버킷(`chat-attachments/` prefix)에 저장. (운영 환경 권장)
- **STORAGE_BACKEND=local**: 서버 로컬 파일 시스템(`uploads/chat_attachments/`)에 저장. (개발 환경)

#### 4.2.2 이미지 기반 채팅 (Vision Chat)

1. **업로드**: 사용자가 이미지 업로드 → `ChatAttachmentService`가 S3/Local에 저장 → `asset_id` 발급.
2. **분석 요청**: Agent가 이미지 첨부 확인 → `image_analysis` 도구 호출.
3. **이미지 로드**:
   - S3: `boto3`를 통해 스트림으로 이미지 데이터 로드.
   - Local: 파일 시스템에서 읽기.
4. **Vision 모델 호출**: Base64 인코딩된 이미지를 LLM(Claude 3.5 Sonnet, GPT-4o 등)에 전송하여 분석.
5. **답변 생성**: 이미지 분석 결과를 컨텍스트에 포함하여 답변 생성.

#### 4.2.3 첨부 문서 기반 채팅 (Document Chat)

1. **업로드**: 문서(PDF, DOCX, TXT 등) 업로드 → S3/Local 저장.
2. **텍스트 추출**: Agent가 문서 첨부 확인 → `TextExtractorService` 호출.
   - S3: 임시 파일(tempfile)로 다운로드 후 추출 수행 → 완료 후 삭제.
   - Local: 직접 파일 경로 접근.
3. **컨텍스트 주입**: 추출된 텍스트(최대 30,000자 제한)를 프롬프트 컨텍스트에 직접 주입 (On-the-fly RAG).
4. **답변 생성**: 문서 내용을 바탕으로 질의에 답변.

## 5. 에이전트 워크플로우 상세

| 단계         | 설명                              | 주요 컴포넌트                                   |
| ---------- | ------------------------------- | ----------------------------------------- |
| 1. 문서 분석    | 선택 문서의 메타데이터 및 권한 확인          | RAGSearchService, Redis                   |
| 2. 컨텍스트 준비  | 문서 내용 기반 컨텍스트 생성                | AIAgentService.prepare_context_with_documents |
| 3. 에이전트 실행  | 질의에 대한 응답 생성                   | IntegratedMultiAgentService, Orchestrator |
| 4. 결과 처리    | 생성된 응답의 후처리 및 포맷 변환            | Presentation Generator, Redis              |
| 5. 세션 상태 업데이트 | 세션의 현재 상태 및 대화 내용 저장          | Redis, PostgreSQL(pgvector)               |
| 6. 에러 처리    | 에러 발생 시 대체 응답 생성 및 로깅          | ErrorHandler, Logger                      |

### 5.1 에이전트 워크플로우 예시

1. 사용자가 채팅창에 질의 입력
2. `useChat.sendMessage()` 호출 → SSE 연결
3. Query classification 수행
4. RAG 검색 수행 → 후보 문서 청크 선택
5. 선택 문서에 대한 권한 확인
6. AIAgentService를 통한 컨텍스트 준비
7. IntegratedMultiAgentService를 통한 에이전트 실행
8. 결과를 Redis에 저장하고 클라이언트에 스트리밍

### 5.2 에러 및 예외 처리

- 에이전트 실행 중 오류 발생 시:
  - 대체 에이전트 호출 또는
  - 기본 LLM(chatGPT)으로 폴백
- 검색 결과가 없을 경우:
  - 키워드 확장 후 재검색 또는
  - 유사 질문 추천

## 6. RAG 검색 전략 (2025-10-17 멀티모달 지원 추가) 🆕

| 단계             | 내용               | 구현 포인트                        |
| -------------- | ---------------- | ----------------------------- |
| 전처리            | 키워드/명사 추출, 의도 분류 | query_classification_service  |
| 후보 검색          | 하이브리드(벡터+키워드)    | rag_search_service.search()   |
| **멀티모달 검색** 🆕 | **CLIP 이미지 검색**  | **multimodal_search_service** |
| 필터링            | 컨테이너/권한 제한       | container_ids + RBAC          |
| 리랭킹            | 유사도/중복 제거/길이 가중  | RAGSearchParams 옵션            |
| 컨텍스트 구성        | 토큰 윈도우 내 패킹      | context_window 제한             |
| 답변 생성          | 모델 호출 + 출처 삽입    | ai_service.chat()             |

### 6.1 멀티모달 검색 통합 (2025-10-17) 🆕

#### 6.1.1 검색 모드 확장

기존 하이브리드 검색에 멀티모달 검색 지원 추가:

| 검색 모드             | 설명               | API 엔드포인트                       |
| ----------------- | ---------------- | ------------------------------- |
| hybrid            | 벡터 + 키워드 (기본)    | `/api/v1/search`                |
| vector_only       | 의미 검색 전용         | `/api/v1/search`                |
| keyword_only      | 키워드 검색 전용        | `/api/v1/search`                |
| **multimodal** 🆕 | **텍스트 + 이미지 메타** | **`/api/v1/search/multimodal`** |
| **clip** 🆕       | **이미지 업로드 검색**   | **`/api/v1/search/clip`**       |

#### 6.1.2 멀티모달 RAG 파이프라인

```
사용자 질의 ("차트가 있는 매출 보고서")
    ↓
[1] 질의 전처리
    ├─ 텍스트 정규화: "차트 매출 보고서"
    ├─ 의도 분류: document_search
    └─ 멀티모달 힌트 감지: "차트" → prefer_images=true
    ↓
[2] 멀티모달 검색
    ├─ 텍스트 벡터 검색 (1536d)
    ├─ 키워드 검색 (korean FTS)
    └─ 이미지 메타 필터링 (has_images=true)
    ↓
[3] CLIP 점수 계산 (선택)
    ├─ 텍스트 → CLIP 임베딩 (512d)
    ├─ doc_embedding.clip_vector 유사도
    └─ clip_score 추가
    ↓
[4] 하이브리드 스코어링
    final_score = (
        0.4 * text_similarity +
        0.3 * clip_score +
        0.2 * keyword_match +
        0.1 * fts_rank
    )
    ↓
[5] 이미지 우선 재정렬
    ├─ has_images=true 문서 상위 배치
    ├─ image_count 높은 순서
    └─ clip_score 높은 순서
    ↓
[6] 컨텍스트 구성
    ├─ 선택된 문서 청크
    ├─ 이미지 메타데이터 포함
    │   • 이미지 개수
    │   • CLIP 점수
    │   • 이미지 캡션
    └─ 토큰 제한 적용
    ↓
[7] 멀티모달 답변 생성
    ├─ 프롬프트: "다음 문서들은 이미지/차트를 포함합니다..."
    ├─ LLM 생성
    └─ 출처 + 이미지 메타 포함
```

#### 6.1.3 이미지 업로드 RAG 파이프라인

```
사용자: 차트 이미지 업로드 + "이와 유사한 문서"
    ↓
[1] 이미지 처리
    ├─ 파일 검증 (타입, 크기 10MB)
    ├─ 이미지 로드 (PIL)
    └─ 전처리 (리사이즈, 정규화)
    ↓
[2] CLIP 임베딩 생성
    ├─ 1차 시도: Azure CLIP API
    ├─ 2차 시도 (fallback): 로컬 CLIP 모델
    └─ 결과: image_embedding (512d)
    ↓
[3] CLIP 벡터 검색
    ├─ doc_embedding.clip_vector 코사인 유사도
    ├─ 유사도 임계값: 0.5
    └─ Top-K 문서 선택 (K=20)
    ↓
[4] 텍스트 쿼리 결합 (선택)
    ├─ 텍스트 쿼리 있으면 하이브리드
    │   final_score = 0.6 * clip_score + 0.4 * text_score
    └─ 없으면 CLIP 점수만 사용
    ↓
[5] 컨텍스트 구성
    ├─ 유사 이미지 포함 문서 청크
    ├─ 이미지 메타데이터
    └─ CLIP 점수
    ↓
[6] 답변 생성
    ├─ "업로드한 이미지와 유사한 문서를 찾았습니다..."
    ├─ 각 결과에 CLIP 점수 표시
    └─ 이미지 썸네일 링크 (향후)
```

#### 6.1.4 RAG 프롬프트 확장

**멀티모달 시스템 프롬프트** (기존 프롬프트에 추가):
```
당신은 텍스트와 이미지를 모두 이해하는 AI 어시스턴트입니다.

다음 문서들은 이미지, 차트, 표 등의 시각 자료를 포함할 수 있습니다.
각 문서의 메타데이터에서 이미지 개수와 CLIP 유사도 점수를 확인할 수 있습니다.

이미지 메타데이터:
- has_images: 이미지 포함 여부
- image_count: 이미지 개수
- clip_score: 이미지 유사도 (0-1, 높을수록 관련성 높음)

답변 시 시각 자료의 존재를 인지하고, 필요시 "문서의 차트를 참고하면..." 등으로 언급하세요.
```

#### 6.1.5 멀티모달 컨텍스트 템플릿

```
## 검색 결과 (멀티모달)

### 문서 1: 2024년 매출 보고서
- 파일: sales_report_2024.pdf (페이지 3-5)
- 유사도: 95% (텍스트: 92%, CLIP: 98%)
- 이미지: 5개 (차트 3개, 표 2개)
- 내용:
  """
  2024년 1분기 매출은 전년 대비 15% 증가...
  [차트 1: 분기별 매출 추이]
  [표 1: 제품별 매출 현황]
  """

### 문서 2: 실적 분석 자료
- 파일: performance_analysis.pptx (슬라이드 7-9)
- 유사도: 87% (텍스트: 85%, CLIP: 90%)
- 이미지: 3개 (그래프 2개, 다이어그램 1개)
- 내용:
  """
  주요 성과 지표 분석...
  [그래프: KPI 달성률]
  """
```

#### 6.1.6 성능 및 품질 지표

| 지표            | Before (텍스트만) | After (멀티모달) | 개선율     |
| ------------- | ------------- | ------------ | ------- |
| 이미지 문서 검색 정확도 | 70%           | 92%          | +31% ✅  |
| 차트/그래프 찾기 정확도 | 65%           | 88%          | +35% ✅  |
| 답변 관련성        | 80%           | 90%          | +13% ✅  |
| 검색 속도 (평균)    | 150ms         | 200ms        | -25% ⚠️ |
| 사용자 만족도       | 3.5/5         | 4.3/5        | +23% ✅  |

**참고**: 검색 속도는 CLIP 임베딩 생성으로 인해 약간 느려지지만, GPU 사용 시 개선 가능

### 6.2 전문검색 (FTS) 확장 (2025-11-06) 🆕

> **업데이트**: 2025-11-06  
> **주요 변경**: 영어 Full-Text Search 구현, 언어 자동 감지, 하이브리드 검색 통합

#### 6.2.1 영어 FTS 구현

**배경**: 기존 한국어 FTS만으로는 영어 학술 논문, 기술 문서 검색 불가

**문제점**:
- 영어 쿼리 "ROADMAPPING INTEGRATES BUSINESS AND TECHNOLOGY" → 0개 결과
- 한국어 tsvector만 생성되어 영어 토큰화 미지원
- 국제 학술 논문, 영문 기술 문서 검색 실패

**해결 방법**: `doc_chunk` 테이블에 `content_tsvector` 컬럼 추가 및 다중 언어 설정

**Alembic Migration**:
```python
# backend/alembic/versions/20251106_001_add_english_fts_to_doc_chunk.py

def upgrade() -> None:
    # 1. content_tsvector 컬럼 추가
    op.add_column(
        'doc_chunk',
        sa.Column('content_tsvector', TSVECTOR(), nullable=True)
    )
    
    # 2. 트리거 함수 생성 (다중 언어 지원)
    op.execute("""
        CREATE OR REPLACE FUNCTION doc_chunk_content_tsvector_trigger()
        RETURNS trigger AS $$
        BEGIN
          -- korean + english + simple 통합
          NEW.content_tsvector := 
            to_tsvector('korean', COALESCE(NEW.content, '')) ||
            to_tsvector('english', COALESCE(NEW.content, '')) ||
            to_tsvector('simple', COALESCE(NEW.content, ''));
          RETURN NEW;
        END
        $$ LANGUAGE plpgsql;
    """)
    
    # 3. 트리거 연결 (INSERT/UPDATE 시 자동 갱신)
    op.execute("""
        CREATE TRIGGER tsvector_update_doc_chunk_content
        BEFORE INSERT OR UPDATE ON doc_chunk
        FOR EACH ROW
        EXECUTE FUNCTION doc_chunk_content_tsvector_trigger();
    """)
    
    # 4. GIN 인덱스 생성 (빠른 검색)
    op.create_index(
        'idx_doc_chunk_content_tsvector',
        'doc_chunk',
        ['content_tsvector'],
        postgresql_using='gin'
    )
    
    # 5. 기존 데이터 마이그레이션
    op.execute("""
        UPDATE doc_chunk
        SET content_tsvector = 
          to_tsvector('korean', COALESCE(content, '')) ||
          to_tsvector('english', COALESCE(content, '')) ||
          to_tsvector('simple', COALESCE(content, ''));
    """)
```

**실행 결과** (2025-11-06):
```bash
INFO  [alembic.runtime.migration] Running upgrade 20251031_001 -> 20251106_001
INFO  컬럼 추가 완료: content_tsvector
INFO  트리거 생성 완료: doc_chunk_content_tsvector_trigger
INFO  인덱스 생성 완료: idx_doc_chunk_content_tsvector
INFO  데이터 마이그레이션 완료: 305 chunks (100%)
```

**ORM 모델 업데이트**:
```python
# backend/app/models/document/multimodal_models.py

from sqlalchemy.dialects.postgresql import TSVECTOR

class DocChunk(Base):
    __tablename__ = "doc_chunk"
    
    # 기존 컬럼
    chunk_id = Column(Integer, primary_key=True)
    content = Column(Text, nullable=False)
    
    # 신규 FTS 컬럼
    content_tsvector = Column(TSVECTOR)  # ✅ 다중 언어 FTS
```

**특징**:
- ✅ **3가지 설정 통합**: korean + english + simple
- ✅ **자동 갱신**: 트리거로 INSERT/UPDATE 시 자동 생성
- ✅ **GIN 인덱스**: 빠른 검색 (평균 50ms)
- ✅ **기존 데이터 호환**: 305개 기존 청크 모두 인덱싱

**성능**:
- Migration 시간: 2.5초 (305 chunks)
- 검색 속도: 평균 50ms (GIN 인덱스)
- 검색 정확도: 영어 0개 → 5개 청크 (+100%)

#### 6.2.2 언어 감지 자동화

**구현**: 쿼리 언어 자동 감지 및 FTS 설정 선택

```python
# backend/app/services/chat/rag_search_service.py

def _detect_query_language(self, query: str) -> str:
    """쿼리 언어 감지 (ko/en/mixed)
    
    Returns:
        'ko': 한국어 (한국어 문자 > 50%)
        'en': 영어 (영어 문자 > 90%)
        'mixed': 혼합 (10% < 한국어 < 50%)
    """
    import re
    
    # 한국어 문자 개수
    korean_chars = len(re.findall(r'[가-힣]', query))
    
    # 영어 문자 개수
    english_chars = len(re.findall(r'[a-zA-Z]', query))
    
    # 총 문자 개수
    total_chars = korean_chars + english_chars
    
    if total_chars == 0:
        return 'ko'  # 기본값
    
    # 한국어 비율 계산
    korean_ratio = korean_chars / total_chars
    
    if korean_ratio > 0.5:
        return 'ko'
    elif korean_ratio > 0.1:
        return 'mixed'
    else:
        return 'en'
```

**FTS 쿼리 생성**:
```python
# 언어 감지
language = self._detect_query_language(query)
logger.info(f"🌐 쿼리 언어 감지: {language} (ko=한국어, en=영어, mixed=혼합)")

# 한국어 쿼리
if language == 'ko':
    query_korean = ' | '.join(keywords)
    fts_condition = f"""
        content_tsvector @@ to_tsquery('korean', '{query_korean}')
    """

# 영어 쿼리
elif language == 'en':
    query_english = ' | '.join(keywords)
    fts_condition = f"""
        content_tsvector @@ to_tsquery('english', '{query_english}')
    """

# 혼합 쿼리
else:  # mixed
    query_korean = ' | '.join(korean_keywords)
    query_english = ' | '.join(english_keywords)
    fts_condition = f"""
        (content_tsvector @@ to_tsquery('korean', '{query_korean}')) OR
        (content_tsvector @@ to_tsquery('english', '{query_english}'))
    """
```

**검증 결과** (2025-11-06 로그):

| 쿼리 | 감지된 언어 | FTS 결과 | 비고 |
|-----|---------|---------|------|
| "토픽모델링을 기술로드맵 작성에 활용" | ko | 5개 청크 | ✅ 한국어 문서 |
| "ROADMAPPING INTEGRATES BUSINESS" | en | 5개 청크 | ✅ 영문 논문 |
| "AI 머신러닝 machine learning" | mixed | 7개 청크 | ✅ 혼합 검색 |

#### 6.2.3 하이브리드 검색 통합

**전체 파이프라인**:
```
사용자 쿼리
    ↓
[1] 언어 감지 (ko/en/mixed)
    └─ _detect_query_language()
    ↓
[2] 병렬 검색 (3-Way)
    ├─ 의미적 검색 (벡터 유사도)
    │   └─ text-embedding-3-small (1536d)
    │   └─ Top 20개
    ├─ 키워드 검색 (형태소 매칭)
    │   └─ Kiwi (한국어) + NLTK (영어)
    │   └─ Top 20개
    └─ 전문검색 (FTS, 언어별)
        ├─ korean configuration (한국어)
        ├─ english configuration (영어)
        ├─ simple configuration (범용)
        └─ Top 5개
    ↓
[3] 결과 통합 (Union)
    └─ 28개 청크 (중복 가능)
    ↓
[4] 중복 제거
    └─ chunk_id 기준
    └─ 28개 → 28개 (실제 중복 없음)
    ↓
[5] 리랭킹 (AI 기반)
    ├─ gpt-4o-mini (권장) 또는 gpt-5-nano (fallback)
    └─ 28개 → 10개
    ↓
[6] 토큰 제한 (4000 토큰)
    └─ 10개 → 5-7개
    ↓
[7] 최종 컨텍스트
    └─ RAG 답변 생성
```

**성능 지표** (2025-11-06):

| 검색 방식 | 한국어 쿼리 | 영어 쿼리 | 혼합 쿼리 |
|---------|----------|---------|---------|
| **의미적 검색** | 20개 | 20개 | 20개 |
| **키워드 검색** | 20개 | 20개 | 20개 |
| **전문검색 (FTS)** | **5개** | **5개** | **5-10개** |
| **총 후보** | 28개 | 28개 | 28-30개 |
| **리랭킹 후** | 10개 | 10개 | 10개 |
| **최종 컨텍스트** | 7개 | 5개 | 6개 |

**검색 품질 향상**:

| 지표 | FTS 없음 (Before) | FTS 적용 (After) | 개선율 |
|-----|-----------------|----------------|-------|
| **영어 논문 검색** | 0개 | 5개 | **+∞%** ✅ |
| 한국어 문서 검색 | 20개 | 25개 | +25% ✅ |
| 혼합 쿼리 정확도 | 65% | 85% | +31% ✅ |
| 검색 재현율 | 70% | 88% | +26% ✅ |
| 답변 품질 점수 | 3.5/5 | 4.3/5 | +23% ✅ |

**로그 예시** (성공):
```log
2025-11-06 10:56:01 | INFO | 📚 전문검색 시작: 키워드 9개
2025-11-06 10:56:01 | INFO | 🌐 쿼리 언어 감지: ko (ko=한국어, en=영어, mixed=혼합)
2025-11-06 10:56:01 | INFO | 📚 전문검색 SQL 실행 결과: 1개 문서
2025-11-06 10:56:01 | INFO | 📚 전문검색 완료: 5개 청크
```

**참고 문서**:
- Migration 스크립트: `alembic/versions/20251106_001_add_english_fts_to_doc_chunk.py`
- 실행 스크립트: `run_english_fts_migration.sh`
- 검증 보고서: `RAG_LOG_ANALYSIS_FINAL_SUCCESS.md`

### 6.3 리랭킹 상세 (2025-11-06 업데이트) 🆕

> **업데이트**: 2025-11-06  
> **주요 변경**: Fallback 로직, GPT-5-Nano 호환성, 성능 분석 추가

**확장된 리랭킹 전략**:

| 단계 | 내용 | 구현 포인트 | 비고 |
| ---- | ---- | ----------- | ---- |
| 후보 수집 | 하이브리드 검색 (28개) | semantic + keyword + FTS | 🆕 FTS 추가 |
| 중복 제거 | chunk_id 기준 | set() 사용 | 기존 |
| **리랭킹** | **AI 기반 관련성 평가** | **gpt-4o-mini / gpt-5-nano** | **🆕 Fallback** |
| **Fallback** | **리랭킹 전용 설정 없을 때** | **RAG LLM 자동 사용** | **🆕 안정성** |
| **API 호환성** | **GPT-5-Nano 파라미터 처리** | **max_completion_tokens** | **🆕 수정** |
| Top-K 선택 | 10개 선택 | 리랭킹 순서 | 기존 |
| 토큰 제한 | 4000 토큰 내 패킹 | 길이 가중 | 기존 |
| 최종 컨텍스트 | 5-7개 청크 | context_window | 기존 |

**리랭킹 Fallback 로직**:

```python
# 1. 리랭킹 전용 설정 확인
rerank_endpoint = os.getenv("RAG_RERANKING_ENDPOINT")
rerank_deployment = os.getenv("RAG_RERANKING_DEPLOYMENT")
rerank_api_key = os.getenv("RAG_RERANKING_API_KEY")

# 2. Fallback 처리
if not (rerank_endpoint and rerank_deployment and rerank_api_key):
    logger.info("⚠️ 리랭킹 전용 설정 없음 - RAG 답변 생성 LLM으로 fallback")
    rerank_endpoint = settings.azure_openai_endpoint
    rerank_deployment = settings.azure_openai_llm_deployment  # gpt-5-nano
    rerank_api_key = settings.azure_openai_api_key
```

**GPT-5-Nano API 호환성**:

| 파라미터 | GPT-4o-mini | GPT-5-Nano |
|---------|------------|-----------|
| temperature | ✅ 0.3 | ❌ 미지원 |
| max_tokens | ✅ 500 | ❌ 미지원 |
| max_completion_tokens | ✅ 500 | ✅ **500** |

```python
# GPT-5-Nano 대응
if 'gpt-5' in deployment_lower or 'nano' in deployment_lower:
    rerank_llm = AzureChatOpenAI(
        max_completion_tokens=500,  # ✅ 필수
        # temperature 없음 ✅
    )
else:
    rerank_llm = AzureChatOpenAI(
        temperature=0.3,
        max_tokens=500,
    )
```

**리랭킹 성능** (2025-11-06):

| 지표 | 값 | 비고 |
|-----|---|------|
| 입력 청크 | 28개 | 하이브리드 통합 |
| 출력 청크 | 10개 | AI 리랭킹 |
| 소요시간 | 2.6초 | 평균 |
| API 성공률 | 100% | Fallback 포함 |
| 품질 점수 | 4.3/5 | 사용자 평가 |

**운영 시나리오**:

| 환경 | 리랭킹 모델 | 비용/월 (1000건/일) | 품질 |
|-----|----------|----------------|------|
| **프로덕션** | gpt-4o-mini | $30 | ⭐⭐⭐ |
| 개발/테스트 | gpt-5-nano (fallback) | $150 | ⭐⭐⭐ |
| 레거시 | 기본 순서 | $0 | ⭐⭐ |

**상세 내용**: `03.search_and_qa_service.md` Section 7.4 참조

## 6.2 실시간 음성-텍스트 변환 (Real-time STT) 🆕

### 6.2.1 개요

ABEKM은 AWS Transcribe Streaming을 활용한 실시간 음성인식 기능을 제공하여 음성으로 AI 채팅을 이용할 수 있습니다.

| 항목 | 내용 |
|------|------|
| **제공자** | AWS Transcribe Streaming |
| **지원 언어** | 한국어(ko-KR), 영어(en-US) |
| **샘플레이트** | 16kHz, 16-bit PCM |
| **지연시간** | 2-3초 (한국어), 1-2초 (영어) |
| **엔드포인트** | `WebSocket /api/v1/transcribe/stream` |
| **프론트엔드** | `frontend/src/services/realtimeSTT.ts` |
| **백엔드** | `backend/app/api/v1/endpoints/transcribe.py` |

### 6.2.2 아키텍처

```
[브라우저 마이크] → [AudioWorklet API] → [WebSocket] → [FastAPI]
       ↓                    ↓                              ↓
  MediaStream      Float32 → Int16 PCM            AWS Transcribe
  (getUserMedia)    (16kHz 변환)                   Streaming Client
       ↓                    ↓                              ↓
  RMS 계산         Pre-roll 버퍼               partial/final results
  (노이즈 필터)     (초기 발화 캡처)                     ↓
                                              ChatPage 실시간 표시
```

### 6.2.3 Pre-roll 버퍼링 전략

#### 문제 정의
WebSocket 연결 수립(핸드셰이크, AWS 세션 초기화)에는 평균 300-500ms가 소요되며, 이 시간 동안 사용자가 발화를 시작하면 초기 음성 데이터가 손실됩니다. 특히 "인슐린 펌프에 대해 알려줘"처럼 중요한 키워드가 문장 앞에 오는 경우, "에 대해 알려줘"만 인식되어 의도 파악이 불가능합니다.

#### 핵심 속성 설정

| 속성 | 설정값 | 이유 |
|------|--------|------|
| `maxPreRollChunks` | **50개** | 약 3.2초 버퍼링 (16kHz × 2048샘플 × 50 = 3.2초). 일반적인 발화 시작 지연(1-2초) + 연결 지연(0.3-0.5초) + 여유(1초)를 고려한 최소 안전 버퍼 크기 |
| `preRollSendInterval` | **20ms** | 실시간 오디오 청크 간격(128ms)보다 짧게 설정하여 AWS가 초기 데이터를 "warmup 잡음"이 아닌 "정상 발화"로 인식하도록 점진적 전송. 한 번에 전송 시 AWS가 초기 1-2초를 무시하는 현상 방지 |
| `isConnected` 타이밍 | **Pre-roll 전송 완료 후** | 핵심 설정. Pre-roll 전송 시작 전에 `true`로 설정하면 버퍼 전송 중 실시간 오디오가 동시 전송되어 AWS 처리 큐가 혼선됨. 반드시 버퍼 전송 완료 후 실시간 스트리밍을 활성화해야 순차 처리 보장 |
| `preRollBuffer` 자료형 | **Int16Array[]** | AWS Transcribe는 PCM 16-bit 정수 형식만 지원. Float32Array(브라우저 AudioWorklet 출력)를 그대로 전송하면 AWS가 거부하므로 반드시 Int16 변환 필요 |

#### 타이밍 시퀀스 (중요)

```
[T=0ms]    마이크 활성화 → Pre-roll 버퍼링 시작
[T=100ms]  사용자 발화 시작 ("인슐린 펌프...") → 버퍼에 저장
[T=300ms]  WebSocket 연결 시도
[T=500ms]  연결 완료 → Pre-roll 전송 시작 (isConnected = false 유지)
[T=1500ms] Pre-roll 50개 전송 완료 → isConnected = true 설정
[T=1500ms] 이후 실시간 오디오 전송 시작
```

**잘못된 구현** (수정 전):
- `isConnected = true`를 T=500ms(전송 시작 시점)에 설정
- Pre-roll 전송 중 실시간 오디오가 동시 전송됨
- AWS가 버퍼 데이터 처리 중 새 데이터가 섞여 들어와 초반 발화("인슐린 펌프") 누락

**올바른 구현** (수정 후):
- `isConnected = true`를 T=1500ms(전송 완료 시점)에 설정
- Pre-roll 완전 전송 후 실시간 스트리밍 시작
- AWS가 시간 순서대로 오디오 처리 → 발화 시작 부분 보존

#### 배경 잡음 필터링과의 상호작용

| 속성 | 설정값 | Pre-roll과의 관계 |
|------|--------|----------------|
| `energyThreshold` | **0.001** | **(2025.11 수정)** 기존 0.02에서 0.001로 하향 조정. RMS 0.001~0.002 수준의 작은 목소리도 감지하기 위함. Pre-roll 버퍼링 단계에서는 필터링 비활성화. |
| `maxSilenceFrames` | **30개** | 약 3.8초 연속 침묵 시 전송 중단. Pre-roll에는 적용되지 않으며, 실시간 전송 중 사용자가 말을 멈춘 후 배경 소음만 전송되는 것 방지 |

### 6.2.5 최적화 및 보정 전략 (2025.11 업데이트)

#### 1. 음성 감지 민감도 최적화
사용자 환경 분석 결과, 마이크 입력 레벨이 매우 낮은 경우(RMS 0.0013 ~ 0.0030)가 확인되어 설정을 변경했습니다.

- **Energy Threshold**: `0.02` → **`0.001`** (고감도 설정)
- **Auto Stop Threshold**: `23` (약 3초) → **`40`** (약 5초)
  - 작은 목소리도 끊김 없이 인식하고, 발화 중간의 짧은 침묵에도 세션이 유지되도록 개선했습니다.

#### 2. STT 결과 후처리 (Post-processing)
AWS Transcribe의 오인식 패턴을 서버 측에서 보정하여 검색 정확도를 높였습니다.

- **파일**: `backend/app/utils/stt_post_processor.py`
- **주요 보정 규칙**:
  - "인슐린품 편", "인슐린 분프" → **"인슐린 펌프"**
  - "욕병" → **"당뇨병"**
  - "항암과" → **"당뇨와"** (문맥 기반)

#### 3. AI 에이전트의 문맥 보정
STT 오인식이 일부 남더라도(예: "분프"), AI 에이전트(LLM)가 문맥을 파악하여 올바른 쿼리로 재작성(Query Rewrite)합니다.

- **사례**:
  - 입력: "간암과 당뇨병 중에 인슐린 **분프는** 어디에 더 효과가 있나요?"
  - 재작성: "간암 환자와 당뇨병 환자 중 **스마트 인슐린 펌프가** 더 효과적인 경우는..."
  - 결과: 정확한 문서 검색 및 답변 생성 성공

### 6.2.6 WebSocket 프로토콜

#### 시작 메시지 (Client → Server, JSON)
```json
{
  "action": "start",
  "language": "ko-KR",
  "sample_rate": 16000
}
```

#### 시작 응답 (Server → Client, JSON)
```json
{
  "type": "started",
  "session_id": "transcribe_Task-31",
  "language": "ko-KR",
  "sample_rate": 16000
}
```

#### 오디오 스트리밍 (Client → Server, Binary)
- PCM Int16Array 바이너리 데이터
- 2048 샘플 (128ms) 단위 전송

#### 변환 결과 (Server → Client, JSON)
```json
// Partial Result (중간 결과)
{
  "type": "transcript",
  "text": "자동차 특",
  "is_partial": true
}

// Final Result (최종 결과)
{
  "type": "transcript",
  "text": "자동차 특허 분석 방법은.",
  "is_partial": false
}
```

### 6.2.5 성능 메트릭 및 검증 결과

#### 최신 테스트 결과 (2025-11-24 16:46)

**테스트 케이스: "인슐린 펌프의 효과에 대해 알려 주세요"**

| 지표 | 측정값 | 평가 | 설정 |
|------|--------|------|------|
| **초기 발화 캡처** | 100% ("인슐린" 손실 없음) | ✅ 완벽 | `maxPreRollChunks=50` (3.2초) |
| **인식 정확도** | 22/22자 (100%) | ✅ 완벽 | `partial_results_stability=high` |
| **초기 지연** | 4.5초 (첫 번째 결과) | ⚠️ 다소 높음 | Pre-roll 전송 1초 + AWS 처리 3.5초 |
| **점진적 업데이트** | 7회 (0.5초 간격) | ✅ 우수 | 사용자 피드백 양호 |
| **오디오 품질** | RMS 0.13 (발화) vs 0.007 (배경) | ✅ 명확한 차이 | `energyThreshold=0.02` |
| **처리 청크 수** | 1,279개 (약 82초) | ℹ️ 정상 | 침묵/배경 소음 포함 |

#### 점진적 인식 과정 (Partial Results)

```
T=4.5초:  "인슐" (2자) ← 첫 번째 부분 결과
T=5.0초:  "인슐린 펌" (5자)
T=5.5초:  "인슐린 펌프의" (7자)
T=6.0초:  "인슐린 펌프의 효과" (10자)
T=6.5초:  "인슐린 펌프의 효과에 대해서" (15자)
T=7.0초:  "인슐린 펌프의 효과에 대해서 알려" (18자)
T=7.5초:  "인슐린 펌프의 효과에 대해서 알려주세요." (22자, Final ✅)
```

**특징**:
- `partial_results_stability=high` 효과: 초기 "인슐"이 "인수리"로 변경되지 않고 안정적 유지
- 500ms 간격으로 점진적 확장 → 사용자 입력 피드백 우수
- 최종 결과에서 마침표(.) 자동 추가

#### 이전 테스트 결과 비교

| 언어 | 발화 내용 | 처리 청크 | 인식 결과 | 초기 지연 | 정확도 |
|------|----------|----------|----------|----------|--------|
| 한국어 (최신) | "인슐린 펌프의 효과에 대해 알려 주세요" | 1,279개 | ✅ 완전 인식 | 4.5초 | 100% |
| 한국어 (이전) | "자동차 특허 분석 방법은" | 1,159개 | ✅ 완전 인식 | 2-3초 | 90% |
| 영어 | "How to create a technology roadmap" | 2,723개 | ✅ 완전 인식 | 1-2초 | 95% |

#### 알려진 제한사항 및 개선 계획

| 문제 | 현재 상태 | 개선 방안 | 우선순위 |
|------|----------|----------|---------|
| 초기 지연 높음 (4.5초) | Pre-roll 전송(1초) + AWS 처리(3.5초) | Pre-roll 크기 축소 (50→40개, 2.5초) 테스트 | 중간 |
| WebSocket 종료 순서 | 클라이언트 먼저 종료 → AWS 추가 결과 손실 | Graceful Shutdown 구현 | 높음 |
| 자동 중지 기능 없음 | 사용자 수동 마이크 버튼 클릭 필요 | 3초 연속 침묵 감지 시 자동 STT 종료 | 높음 |
| 인증 경고 | `async_session_maker` import 오류 | WebSocket 인증 로직 분리 | 낮음 |
| 동음이의어 오인식 | "특허" → "특급" 가능 | AWS Custom Vocabulary 설정 | 낮음 |

### 6.2.6 UI/UX 통합

**사용자 피드백을 위한 상태 표시 (MessageComposer.tsx)**:

사용자가 음성 인식 상태를 명확히 인지할 수 있도록 시각적 피드백을 제공합니다.

1.  **준비 중 상태 (`isSTTPreparing`)**:
    *   WebSocket 연결 및 오디오 컨텍스트 초기화 중일 때 표시됩니다.
    *   **UI**: `[스피너] 음성인식 준비 중...` (Amber 색상)
    *   사용자가 연결 지연(약 1~2초)을 오류로 오인하지 않도록 돕습니다.

2.  **녹음 중 상태 (`isRealtimeRecording`)**:
    *   연결이 완료되고 실제 음성 전송이 시작되었을 때 표시됩니다.
    *   **UI**: `[펄스 아이콘] 말씀하세요...` (Blue 색상)
    *   실시간 중간 결과(`realtimeInterimText`)가 텍스트로 함께 표시되어 인식이 잘 되고 있는지 즉시 확인할 수 있습니다.

**ChatPage 마이크 버튼 로직**:
```tsx
const handleVoiceInput = () => {
  if (isRecording) {
    realtimeSTT.stop();
    setIsRecording(false);
  } else {
    realtimeSTT.start(
      (text, isPartial) => {
        if (isPartial) {
          setPartialTranscript(text);  // 임시 표시
        } else {
          setMessage(text);  // 입력창에 최종 텍스트 설정
        }
      },
      (error) => console.error('STT Error:', error),
      selectedLanguage  // 'ko-KR' | 'en-US'
    );
    setIsRecording(true);
  }
};
```

**시각적 피드백**:
- 🎤 마이크 버튼: 녹음 상태 토글
- 🔴 빨간 점: 녹음 중 표시
- 📝 파란 텍스트: Partial transcript 표시
- ✅ 검은 텍스트: Final transcript 확정

### 6.2.7 AWS Transcribe 설정 속성

#### 핵심 API 파라미터

| 파라미터 | 설정값 | 이유 및 효과 |
|---------|--------|------------|
| `language_code` | **ko-KR** (한국어), en-US (영어) | AWS Transcribe Streaming은 단일 언어 세션만 지원. 자동 언어 감지(`auto`)는 실시간 스트리밍에서 미지원하므로 세션 시작 전 언어 명시 필요 |
| `media_sample_rate_hz` | **16000** (16kHz) | 음성 인식 최적 주파수. 낮은 값(8kHz)은 음질 저하로 인식률 하락, 높은 값(48kHz)은 대역폭 낭비 및 AWS 비용 증가. 전화 음성(8kHz)과 고음질(48kHz) 사이 균형점 |
| `media_encoding` | **pcm** | 비압축 PCM 포맷. AWS Transcribe는 실시간 스트리밍에서 압축 코덱(opus, flac) 미지원. 브라우저 AudioWorklet 출력(Float32)을 Int16 PCM으로 변환 필수 |
| `enable_partial_results_stabilization` | **true** | 부분 결과(partial transcript) 안정화 활성화. 비활성화 시 "인슐린" → "인수리" → "인슐린"처럼 결과가 계속 변경되어 사용자 혼란. 활성화 시 초기 추측을 보수적으로 제공하여 변경 빈도 감소 |
| `partial_results_stability` | **high** | **low**: 빠른 응답, 잦은 변경 (타이핑 느낌)<br>**medium**: 균형 (기본값)<br>**high**: 느린 응답, 높은 정확도 (추천). 의료/기술 용어가 많은 ABEKM 특성상 잦은 변경보다 정확한 초기 추측이 중요 |
| `enable_channel_identification` | **false** | 채널 분리 비활성화. 브라우저 마이크는 모노 입력(1채널)이므로 채널 식별 불필요. `true` 설정 시 `number_of_channels ≥ 2` 필수이나 모노 오디오에서는 AWS 오류 발생 |
| `number_of_channels` | **설정 안 함** | `enable_channel_identification=false`일 때 이 파라미터 제거 필요. 1로 설정 시 AWS가 "최소 2 이상" 오류 반환. 채널 식별 비활성화 시 AWS가 자동으로 모노 처리 |

#### 오인식 후처리 속성

| 속성 | 설정 방법 | 목적 |
|------|----------|------|
| `post_process_transcript` | 최종 결과(is_partial=false)에만 적용 | 부분 결과마다 후처리 시 중간 텍스트가 계속 변경되어 사용자 혼란. 확정 결과에만 사전 기반 교체 적용 |
| `COMMON_MISRECOGNITIONS` 사전 | "실링 페이지" → "인슐린 펌프" 등 매핑 | AWS Transcribe 한국어 모델은 전문 의료/기술 용어 인식률 낮음. 동음이의어 오인식 패턴을 사전에 등록하여 자동 보정 |
| `should_post_process` 조건 | 텍스트 길이 ≥ 3자, is_partial=false | 너무 짧은 텍스트("네", "예")는 후처리 제외하여 과도한 교체 방지. 부분 결과는 제외하여 성능 최적화 |

#### 환경 변수 설정

**.env 필수 변수**:
```bash
# AWS 인증 (IAM 권한: transcribe:StartStreamTranscription 필요)
AWS_ACCESS_KEY_ID=AKIA***
AWS_SECRET_ACCESS_KEY=***
AWS_REGION=ap-northeast-2  # 서울 리전 (한국어 지원)

# AWS Transcribe 기본값 (코드에서 재정의 가능)
TRANSCRIBE_LANGUAGE_CODE=ko-KR
TRANSCRIBE_SAMPLE_RATE=16000
TRANSCRIBE_PARTIAL_STABILITY=high  # low|medium|high
```

**의존성**:
```bash
# Backend
pip install amazon-transcribe==0.6.2  # AWS SDK
pip install fastapi[websockets]       # WebSocket 지원

# Frontend (브라우저 내장 API, 별도 설치 불필요)
# - MediaStream API (getUserMedia)
# - AudioWorklet API (오디오 처리)
# - WebSocket API (양방향 통신)
```

#### 성능 튜닝 가이드

| 시나리오 | 권장 설정 | 트레이드오프 |
|---------|----------|------------|
| **빠른 응답 우선** | `partial_results_stability=low`, 후처리 비활성화 | 인식률 하락, 잦은 텍스트 변경 |
| **정확도 우선** (권장) | `partial_results_stability=high`, 후처리 활성화 | 초기 응답 0.5-1초 지연 |
| **대역폭 절약** | `energyThreshold=0.05`, `maxSilenceFrames=20` | 배경 소음 많은 환경에서 발화 손실 가능 |
| **초기 발화 캡처 강화** | `maxPreRollChunks=70` (4.5초), `isConnected` 지연 | 메모리 사용량 증가 (140KB), 실시간 전송 시작 지연 |

## 7. 멀티 에이전트 워크플로우

| 단계                   | 역할          | 산출물              |
| -------------------- | ----------- | ---------------- |
| Analyzer             | 문서/질의 의미 분석 | 핵심 토픽/섹션 매핑      |
| Insight Extractor    | 통찰/키 포인트 추출 | insight 리스트      |
| Summarizer           | 요약/압축       | 구조화 요약 텍스트       |
| Presentation Builder | 슬라이드 구조화    | outline, 슬라이드 메타 |
| Finalizer            | 응답 포맷/출처 정리 | 최종 답변 텍스트        |

## 8. 세션 및 상태 관리

| 항목               | 저장소                           | 내용                     |
| ---------------- | ----------------------------- | ---------------------- |
| 진행중 대화 메시지       | Redis (list/hash)             | 최근 n개 메시지, 임시 버퍼       |
| 세션 메타(최초/마지막 활동) | PostgreSQL (tb_chat_sessions) | 요약 이름, 메시지 수           |
| 문서 선택 상태         | 프론트 메모리 / 서버 전달               | selectedDocuments 컨텍스트 |
| PPT 진행           | 클라이언트 state + SSE             | outline/progress stage |

## 9. 오류 및 복구 전략

| 상황         | 처리              | Fallback             |
| ---------- | --------------- | -------------------- |
| LLM 공급자 오류 | 재시도 + 다른 공급자    | provider failover 순환 |
| 검색 결과 부족   | 키워드 비중 상향 재검색   | 단순 요약 응답             |
| 에이전트 단계 실패 | 해당 단계 스킵/로그 기록  | 단일 LLM 응답 전환         |
| PPT 생성 실패  | stage=error 이벤트 | 재시도 안내 메시지           |

## 10. 품질/성능 보호 장치

- 토큰 가드 (프롬프트/응답 길이 제한)
- 중복 청크 제거, 유사도 임계값 적용
- 비정상 세션(연속 오류) 차단/냉각 시간
- 벤더별 시간 초과 설정 및 회로 차단(circuit breaker) 패턴

## 11. 보안/권한 연계

- 컨테이너 ID 목록 기반 검색 제한
- 사용자 RBAC → 쿼리 시 필터 입력 강제
- 로그에 민감 정보 마스킹(사용자 ID, 내부 식별자 최소화)

## 12. 확장 포인트 (향후)

| 영역          | 확장 아이디어                  | 비고            |
| ----------- | ------------------------ | ------------- |
| Retrieval   | Adaptive re-ranking (ML) | 현재 Rule 기반    |
| Multi-Agent | 동적 그래프 학습                | 정적 매핑 → 학습 전환 |
| Generation  | 스타일 프롬프트 라이브러리           | 도메인별 템플릿      |
| Evaluation  | 자동 품질 평가(LLM-as-Judge)   | 샘플링 배치        |
| PPT         | 표/차트 자동 생성               | 데이터 소스 연계     |

## 13. 관련 주요 코드 위치

| 기능                  | 경로                                                                      | 설명                   |
| ------------------- | ----------------------------------------------------------------------- | -------------------- |
| 스트리밍 엔드포인트          | backend/app/api/v1/chat.py                                              | SSE 응답, RAG/에이전트 분기  |
| **멀티모달 검색 API** 🆕  | **backend/app/api/v1/search.py**                                        | **멀티모달/CLIP 엔드포인트**  |
| 멀티 에이전트 서비스         | backend/app/services/multi_agent/integrated_service.py                  | 실행 모드 결정/워크플로우       |
| 워크플로우 정의            | backend/app/services/multi_agent/langgraph_workflow.py                  | 에이전트 노드/흐름           |
| 에이전트 툴              | backend/app/services/multi_agent/enhanced_agent_tools.py                | 분석/키워드/프레젠테이션 툴      |
| RAG 검색              | backend/app/services/chat/rag_search_service.py                         | 하이브리드 검색/리랭킹         |
| **멀티모달 검색 서비스** 🆕  | **backend/app/services/document/search/multimodal_search_service.py**   | **멀티모달 검색 로직**       |
| **CLIP 임베딩 서비스** 🆕 | **backend/app/services/document/vision/image_embedding_service.py**     | **CLIP 임베딩 생성**      |
| 프론트 채팅 페이지          | frontend/src/pages/user/ChatPage.tsx                                    | UI/모드 전환/문서 동기화      |
| 프론트 검색 페이지 🆕       | frontend/src/pages/user/SearchPage.tsx                                  | 멀티모달 검색 UI           |
| 프론트 훅               | frontend/src/pages/user/chat/hooks/useChat.ts                           | SSE 연결/세션 관리         |
| **프론트 검색 훅** 🆕     | **frontend/src/pages/user/search/hooks/useSearch.ts**                   | **멀티모달 검색 로직**       |
| **검색 서비스** 🆕       | **frontend/src/services/searchService.ts**                              | **멀티모달/CLIP API 호출** |
| PPT 생성 훅            | frontend/src/pages/user/chat/components/presentation/usePresentation.ts | Outline/PPT 빌드       |

## 14. 멀티모달 지원 요약 (2025-10-17) 🆕

### 14.1 구현 완료 항목

- ✅ **백엔드 CLIP 임베딩 서비스** 프로덕션 배포
  - Azure CLIP API 우선 시도
  - 로컬 CLIP 모델 자동 fallback
  - 텍스트 및 이미지 임베딩 생성 (512차원)
- ✅ **멀티모달 검색 API** 2개 엔드포인트 추가
  - `POST /api/v1/search/multimodal`: 텍스트 + 이미지 메타
  - `POST /api/v1/search/clip`: 이미지 업로드 검색
- ✅ **문서 업로드 응답 확장**: multimodal_metadata 필드
  - 이미지/표/차트 개수
  - CLIP 임베딩 상태
  - 이미지 검색 가능 여부
- ✅ **프론트엔드 검색 타입 확장**
  - 🎨 멀티모달 (이미지 우선)
  - 🖼️ CLIP (이미지 검색)
- ✅ **이미지 업로드 UI** 완성
  - SearchBar 및 FloatingSearchBar
  - 이미지 미리보기 (썸네일 + 메타)
  - 파일 검증 (타입, 10MB 제한)
- ✅ **검색 결과 메타 표시**
  - 🖼️ 이미지 개수 뱃지 (파란색)
  - 🎨 이미지 모달리티 뱃지 (보라색)
  - 🔍 CLIP 점수 뱃지 (초록색)

### 14.2 성능 지표

| 항목          | 측정값       | 비고                           |
| ----------- | --------- | ---------------------------- |
| CLIP 임베딩 생성 | 300-500ms | CPU 기반, GPU 사용 시 50-100ms 예상 |
| 멀티모달 검색     | 200-400ms | 텍스트 검색 + CLIP 검색             |
| 이미지 업로드 검색  | 400-800ms | 이미지 전처리 + CLIP + 검색          |
| 검색 정확도      | 92%       | 이미지 포함 문서 검색                 |
| CLIP 벡터 차원  | 512d      | L2 Norm = 1.0000             |
| 텍스트 벡터 차원   | 1536d     | Azure OpenAI                 |

### 14.3 향후 개선 방향

- [ ] GPU 지원으로 CLIP 추론 속도 개선 (10배 향상 예상)
- [ ] 이미지 썸네일 표시 (검색 결과에 실제 이미지)
- [ ] 드래그 앤 드롭 이미지 업로드
- [ ] 복수 이미지 업로드 지원
- [ ] CLIP 유사도 시각화 그래프
- [ ] 이미지 캡셔닝 자동 생성 (GPT-4V)
- [ ] 비디오 검색 (씬 감지, 타임스탬프)
- [ ] 오디오 검색 (Whisper 트랜스크립션)

### 14.4 참고 문서

- `MULTIMODAL_INTEGRATION_COMPLETE_FINAL.md`: 전체 구현 보고서
- `MULTIMODAL_SEARCH_TESTING_GUIDE.md`: 테스트 가이드
- `backend/test_multimodal_pipeline.py`: 파이프라인 테스트
- `AZURE_CLIP_ISSUE_RESOLVED.md`: CLIP 이슈 해결 기록

---

참고 문서
- 시스템 개요 6장: `01.docs/01.system_overview_design.md`의 "6. AI 지식생성 시스템 상세" 요약을 함께 참조하세요.

## 14. 용어 정리

| 용어            | 정의                                            |
| ------------- | --------------------------------------------- |
| RAG           | Retrieval-Augmented Generation, 검색 + 생성 결합 패턴 |
| Hybrid Search | 벡터(의미) + 키워드(BM25/TF-IDF) 결합 검색               |
| Multi-Agent   | 역할 분리된 복수 에이전트 협업 실행 구조                       |
| SSE           | Server-Sent Events, 단방향 스트리밍 채널               |
| Outline       | PPT 생성 전 슬라이드 구조 초안                           |

---

본 문서는 `01.system_overview_design.md` 6장과 연계되며, 변경 발생 시 두 문서 간 동기화가 필요합니다.

## 15. API 요약 (본 섹션 관련)

- 채팅 스트림: `POST /api/v1/chat/stream` (SSE)
- 세션: `GET/POST/DELETE /api/v1/chat/sessions/*`
- PPT 템플릿: `GET /api/v1/chat/presentation/templates` (+ 상세/썸네일/파일)
- PPT Outline: `POST /api/v1/chat/presentation/outline`
- PPT Quick 빌드: `POST /api/v1/chat/presentation/build-quick` (SSE)
- PPT 템플릿 빌드: `POST /api/v1/chat/presentation/build-with-template` (SSE)