# ğŸ“ˆ ì—…ë¡œë“œ ì„±ëŠ¥ ê°œì„  ê°€ì´ë“œ (ì‹¤ì „ ì ìš©)

**ì‘ì„±ì¼**: 2025-10-14  
**ëŒ€ìƒ íŒŒì¼**: 27í˜ì´ì§€ PDF (12MB, 80Kì)  
**í˜„ì¬ ì†Œìš” ì‹œê°„**: 98ì´ˆ â†’ **ëª©í‘œ: 3ì´ˆ ì´ë‚´**

---

## ğŸ”´ í˜„ì¬ ë¬¸ì œì 

### ì²˜ë¦¬ ì‹œê°„ ë¶„ì„

- **ì´ ì†Œìš”**: 98.21ì´ˆ
- **Azure DI ë¶„ì„**: 75ì´ˆ (76%) â† ê°€ì¥ í° ë³‘ëª©
- **ì„ë² ë”© ìƒì„±**: 21ì´ˆ (21%) â† ë‘ ë²ˆì§¸ ë³‘ëª©
- **ê¸°íƒ€**: 2ì´ˆ (2%)

### ì‚¬ìš©ì ê²½í—˜ ë¬¸ì œ

âŒ **98ì´ˆ ë™ì•ˆ ë¸Œë¼ìš°ì €ê°€ ë©ˆì¶°ìˆìŒ**  
âŒ ì—…ë¡œë“œ ì§„í–‰ ìƒí™©ì„ ì•Œ ìˆ˜ ì—†ìŒ  
âŒ ì‹¤íŒ¨ ì‹œ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œë„

---

## âœ… í•´ê²°ì±…: ë¹„ë™ê¸° ì²˜ë¦¬ (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥)

### ê°œì„  í›„ íë¦„

```
[í˜„ì¬] ë™ê¸°ì‹ ì²˜ë¦¬
í´ë¼ì´ì–¸íŠ¸ â†’ ì—…ë¡œë“œ â†’ DI(75ì´ˆ) â†’ ì„ë² ë”©(21ì´ˆ) â†’ ì‘ë‹µ
                      â†“
                98ì´ˆ ëŒ€ê¸°... ğŸ˜°

[ê°œì„ ] ë¹„ë™ê¸° ì²˜ë¦¬
í´ë¼ì´ì–¸íŠ¸ â†’ ì—…ë¡œë“œ â†’ ì¦‰ì‹œ ì‘ë‹µ (2ì´ˆ) âœ…
                    â†“
              ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ (ì‚¬ìš©ìëŠ” ë‹¤ë¥¸ ì‘ì—… ê°€ëŠ¥)
                - DI ë¶„ì„
                - ì„ë² ë”© ìƒì„±
                - ìƒíƒœ: processing â†’ completed
```

---

## ğŸš€ êµ¬í˜„ ë°©ë²• (3ë‹¨ê³„)

### Step 1: ë¬¸ì„œ ìƒíƒœ ê´€ë¦¬ ì¶”ê°€

#### 1-1. DB ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸

```sql
-- tb_file_bss_info í…Œì´ë¸”ì— ì»¬ëŸ¼ ì¶”ê°€
ALTER TABLE tb_file_bss_info 
ADD COLUMN processing_status VARCHAR(20) DEFAULT 'pending',
ADD COLUMN processing_error TEXT,
ADD COLUMN processing_started_at TIMESTAMP,
ADD COLUMN processing_completed_at TIMESTAMP;

-- ì¸ë±ìŠ¤ ì¶”ê°€ (ìƒíƒœë³„ ì¡°íšŒ ì„±ëŠ¥ í–¥ìƒ)
CREATE INDEX idx_file_processing_status ON tb_file_bss_info(processing_status);
```

**ìƒíƒœê°’:**
- `pending`: ì—…ë¡œë“œ ì™„ë£Œ, ì²˜ë¦¬ ëŒ€ê¸°
- `processing`: ì²˜ë¦¬ ì¤‘
- `completed`: ì²˜ë¦¬ ì™„ë£Œ
- `failed`: ì²˜ë¦¬ ì‹¤íŒ¨

#### 1-2. ëª¨ë¸ ì—…ë°ì´íŠ¸

```python
# backend/app/models/document/file_models.py

class TbFileBssInfo(Base):
    # ... ê¸°ì¡´ ì»¬ëŸ¼ ...
    
    # ë¹„ë™ê¸° ì²˜ë¦¬ ìƒíƒœ ê´€ë¦¬
    processing_status = Column(String(20), default='pending')
    processing_error = Column(Text, nullable=True)
    processing_started_at = Column(DateTime, nullable=True)
    processing_completed_at = Column(DateTime, nullable=True)
```

---

### Step 2: ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… í ì„¤ì •

#### 2-1. Celery ì„¤ì¹˜ ë° ì„¤ì •

```bash
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install celery redis
```

#### 2-2. Celery ì•± ì„¤ì •

```python
# backend/app/core/celery_app.py (ìƒˆ íŒŒì¼)

from celery import Celery
from app.core.config import settings

celery_app = Celery(
    "wkms",
    broker=f"redis://{settings.redis_host}:{settings.redis_port}/0",
    backend=f"redis://{settings.redis_host}:{settings.redis_port}/0"
)

celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='Asia/Seoul',
    enable_utc=True,
    task_track_started=True,
    task_time_limit=3600,  # 1ì‹œê°„ ì œí•œ
)
```

#### 2-3. í™˜ê²½ë³€ìˆ˜ ì¶”ê°€

```bash
# .env íŒŒì¼
REDIS_HOST=localhost
REDIS_PORT=6379
```

---

### Step 3: ë¹„ë™ê¸° ì²˜ë¦¬ íƒœìŠ¤í¬ êµ¬í˜„

#### 3-1. Celery íƒœìŠ¤í¬ ìƒì„±

```python
# backend/app/tasks/document_tasks.py (ìƒˆ íŒŒì¼)

from celery import Task
from app.core.celery_app import celery_app
from app.core.database import get_async_session_local
from app.models import TbFileBssInfo
from app.services.document.multimodal_document_service import multimodal_document_service
from sqlalchemy import select, update
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class CallbackTask(Task):
    """ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ì»¤ìŠ¤í…€ Task"""
    
    def on_failure(self, exc, task_id, args, kwargs, einfo):
        """ì‘ì—… ì‹¤íŒ¨ ì‹œ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        document_id = args[0] if args else kwargs.get('document_id')
        if document_id:
            self.update_status(document_id, 'failed', str(exc))
    
    def update_status(self, document_id, status, error=None):
        """ë¬¸ì„œ ì²˜ë¦¬ ìƒíƒœ ì—…ë°ì´íŠ¸ (ë™ê¸°)"""
        import asyncio
        asyncio.run(self._update_status_async(document_id, status, error))
    
    async def _update_status_async(self, document_id, status, error):
        async_session_factory = get_async_session_local()
        async with async_session_factory() as session:
            update_data = {'processing_status': status}
            if error:
                update_data['processing_error'] = error
            if status == 'processing':
                update_data['processing_started_at'] = datetime.now()
            elif status in ('completed', 'failed'):
                update_data['processing_completed_at'] = datetime.now()
            
            stmt = (
                update(TbFileBssInfo)
                .where(TbFileBssInfo.file_bss_info_sno == document_id)
                .values(**update_data)
            )
            await session.execute(stmt)
            await session.commit()


@celery_app.task(bind=True, base=CallbackTask, name='process_document_async')
def process_document_async(self, document_id: int, file_path: str, container_id: str, user_emp_no: str):
    """
    ë¬¸ì„œ ë¹„ë™ê¸° ì²˜ë¦¬ (DI ë¶„ì„ + ì„ë² ë”©)
    
    Args:
        document_id: ë¬¸ì„œ ID
        file_path: íŒŒì¼ ê²½ë¡œ
        container_id: ì»¨í…Œì´ë„ˆ ID
        user_emp_no: ì‚¬ìš©ì ì‚¬ë²ˆ
    """
    import asyncio
    
    logger.info(f"ğŸ”„ [ASYNC-TASK] ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: ID={document_id}")
    
    # ìƒíƒœë¥¼ processingìœ¼ë¡œ ë³€ê²½
    self.update_status(document_id, 'processing')
    
    try:
        # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
        result = asyncio.run(
            _process_document_multimodal(document_id, file_path, container_id, user_emp_no)
        )
        
        if result.get('success'):
            self.update_status(document_id, 'completed')
            logger.info(f"âœ… [ASYNC-TASK] ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ: ID={document_id}")
            return {
                'success': True,
                'document_id': document_id,
                'chunks_count': result.get('chunks_count', 0),
                'embeddings_count': result.get('embeddings_count', 0)
            }
        else:
            error_msg = result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
            self.update_status(document_id, 'failed', error_msg)
            logger.error(f"âŒ [ASYNC-TASK] ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: ID={document_id}, {error_msg}")
            return {'success': False, 'error': error_msg}
            
    except Exception as e:
        error_msg = str(e)
        self.update_status(document_id, 'failed', error_msg)
        logger.error(f"ğŸ’¥ [ASYNC-TASK] ë¬¸ì„œ ì²˜ë¦¬ ì˜ˆì™¸: ID={document_id}, {error_msg}")
        raise


async def _process_document_multimodal(document_id: int, file_path: str, container_id: str, user_emp_no: str):
    """ë©€í‹°ëª¨ë‹¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    async_session_factory = get_async_session_local()
    async with async_session_factory() as session:
        result = await multimodal_document_service.process_document_multimodal(
            file_path=file_path,
            file_bss_info_sno=document_id,
            container_id=container_id,
            user_emp_no=user_emp_no,
            session=session,
            provider="azure",
            model_profile="default"
        )
        return result
```

---

### Step 4: ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸ ìˆ˜ì •

```python
# backend/app/api/v1/documents.py

from app.tasks.document_tasks import process_document_async

@router.post("/upload", response_model=DocumentUploadResponse)
async def upload_document(
    file: UploadFile = File(...),
    container_id: Optional[str] = Form(...),
    use_multimodal: bool = Form(True),
    user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_db)
):
    """
    ë¬¸ì„œ ì—…ë¡œë“œ (ë¹„ë™ê¸° ì²˜ë¦¬)
    
    1. íŒŒì¼ ì—…ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´ ì €ì¥ (2ì´ˆ)
    2. ë°±ê·¸ë¼ìš´ë“œì—ì„œ DI ë¶„ì„ + ì„ë² ë”© ì²˜ë¦¬ (90ì´ˆ+)
    3. ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜
    """
    upload_start_time = datetime.now()
    
    try:
        # ... ê¶Œí•œ í™•ì¸, íŒŒì¼ ê²€ì¦ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€) ...
        
        # íŒŒì¼ ì €ì¥ (ë¡œì»¬ + Azure Blob)
        saved_file_path = await _save_upload_file(file)
        
        # Azure Blob ì—…ë¡œë“œ
        # ... (ê¸°ì¡´ ì½”ë“œ ìœ ì§€) ...
        
        # âœ… DBì— ê¸°ë³¸ ì •ë³´ë§Œ ì €ì¥ (RAG íŒŒì´í”„ë¼ì¸ ì œì™¸)
        file_bss_info = TbFileBssInfo(
            drcy_sno=1,
            file_dtl_info_sno=file_dtl_info.file_dtl_info_sno,
            file_lgc_nm=file_name,
            file_psl_nm=file_name,
            file_extsn=file_extension.lstrip('.'),
            path=db_file_path,
            knowledge_container_id=container_id,
            owner_emp_no=user_emp_no,
            created_by=user_emp_no,
            last_modified_by=user_emp_no,
            processing_status='pending',  # ğŸ†• ì²˜ë¦¬ ëŒ€ê¸° ìƒíƒœ
            korean_metadata={"file_hash": file_hash, "file_size": file_size}
        )
        
        session.add(file_bss_info)
        await session.flush()
        await session.commit()
        
        document_id = file_bss_info.file_bss_info_sno
        
        logger.info(f"âœ… [UPLOAD] ë¬¸ì„œ ê¸°ë³¸ ì •ë³´ ì €ì¥ ì™„ë£Œ: ID={document_id}")
        
        # ğŸš€ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ë“±ë¡
        if use_multimodal:
            task = process_document_async.delay(
                document_id=document_id,
                file_path=saved_file_path,
                container_id=container_id,
                user_emp_no=str(user.emp_no)
            )
            logger.info(f"ğŸ”„ [UPLOAD] ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ë“±ë¡: task_id={task.id}, doc_id={document_id}")
        
        processing_time = (datetime.now() - upload_start_time).total_seconds()
        
        # ğŸ“¤ ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜ (2-3ì´ˆ ì´ë‚´)
        response = DocumentUploadResponse(
            success=True,
            message="ë¬¸ì„œê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.",
            document_id=document_id,
            file_info={
                "original_name": safe_filename,
                "file_size": file_size,
                "file_type": file_extension,
                "upload_time": upload_start_time.isoformat(),
                "saved_path": db_file_path,
            },
            processing_stats={
                "upload_time": processing_time,
                "status": "processing",  # ğŸ†• ì²˜ë¦¬ ìƒíƒœ
                "message": "ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤."
            }
        )
        
        # ë¡œì»¬ ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if (s3_object_key or azure_blob_object_key) and os.path.exists(saved_file_path):
            os.remove(saved_file_path)
        
        logger.info(f"ğŸ“¤ [UPLOAD] ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜: doc_id={document_id}, ì†Œìš”={processing_time:.2f}ì´ˆ")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [UPLOAD] ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

---

### Step 5: ìƒíƒœ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€

```python
# backend/app/api/v1/documents.py

@router.get("/{document_id}/status", summary="ë¬¸ì„œ ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ")
async def get_document_status(
    document_id: int,
    user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_db)
):
    """
    ë¬¸ì„œ ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ
    
    Returns:
        - status: pending | processing | completed | failed
        - progress: ì§„í–‰ë¥  (0-100)
        - error: ì˜¤ë¥˜ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
    """
    stmt = select(TbFileBssInfo).where(TbFileBssInfo.file_bss_info_sno == document_id)
    result = await session.execute(stmt)
    doc = result.scalar_one_or_none()
    
    if not doc:
        raise HTTPException(status_code=404, detail="ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    status = getattr(doc, 'processing_status', 'unknown')
    
    # ì§„í–‰ë¥  ê³„ì‚°
    progress = 0
    if status == 'pending':
        progress = 0
    elif status == 'processing':
        # ì²˜ë¦¬ ì‹œì‘ í›„ ê²½ê³¼ ì‹œê°„ ê¸°ë°˜ ì¶”ì •
        started = getattr(doc, 'processing_started_at', None)
        if started:
            elapsed = (datetime.now() - started).total_seconds()
            progress = min(int((elapsed / 100) * 100), 95)  # ìµœëŒ€ 95%
        else:
            progress = 10
    elif status == 'completed':
        progress = 100
    elif status == 'failed':
        progress = 0
    
    return {
        "document_id": document_id,
        "status": status,
        "progress": progress,
        "error": getattr(doc, 'processing_error', None),
        "started_at": getattr(doc, 'processing_started_at', None),
        "completed_at": getattr(doc, 'processing_completed_at', None)
    }
```

---

## ğŸ–¥ï¸ í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™

### í´ë§ ë°©ì‹ (ê°„ë‹¨)

```javascript
// íŒŒì¼ ì—…ë¡œë“œ
async function uploadFile(file, containerId) {
  const formData = new FormData();
  formData.append('file', file);
  formData.append('container_id', containerId);
  
  // 1. ì—…ë¡œë“œ (2-3ì´ˆ)
  const response = await fetch('/api/v1/documents/upload', {
    method: 'POST',
    body: formData
  });
  
  const result = await response.json();
  const documentId = result.document_id;
  
  // 2. ìƒíƒœ í´ë§ (3ì´ˆë§ˆë‹¤)
  const checkStatus = setInterval(async () => {
    const statusRes = await fetch(`/api/v1/documents/${documentId}/status`);
    const status = await statusRes.json();
    
    console.log(`ì²˜ë¦¬ ì§„í–‰ë¥ : ${status.progress}%`);
    
    if (status.status === 'completed') {
      clearInterval(checkStatus);
      alert('ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ!');
      refreshDocumentList();
    } else if (status.status === 'failed') {
      clearInterval(checkStatus);
      alert(`ì²˜ë¦¬ ì‹¤íŒ¨: ${status.error}`);
    }
  }, 3000);
}
```

---

## ğŸƒ ì‹¤í–‰ ë°©ë²•

### 1. Redis ì„¤ì¹˜ ë° ì‹¤í–‰

```bash
# Ubuntu/Debian
sudo apt-get install redis-server
sudo systemctl start redis

# macOS
brew install redis
brew services start redis

# Docker
docker run -d -p 6379:6379 redis:latest
```

### 2. Celery Worker ì‹¤í–‰

```bash
# í„°ë¯¸ë„ 1: Celery Worker
cd backend
celery -A app.core.celery_app worker --loglevel=info

# í„°ë¯¸ë„ 2: FastAPI ì„œë²„
uvicorn app.main:app --reload
```

### 3. Celery Flower (ëª¨ë‹ˆí„°ë§ - ì„ íƒ)

```bash
pip install flower
celery -A app.core.celery_app flower --port=5555

# ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5555 ì ‘ì†
```

---

## ğŸ“Š ê°œì„  íš¨ê³¼

### Before (ë™ê¸° ì²˜ë¦¬)

- âŒ ì—…ë¡œë“œ ëŒ€ê¸°: **98ì´ˆ**
- âŒ ë¸Œë¼ìš°ì € ë©ˆì¶¤
- âŒ ì§„í–‰ ìƒí™© ë¶ˆëª…í™•

### After (ë¹„ë™ê¸° ì²˜ë¦¬)

- âœ… ì—…ë¡œë“œ ì‘ë‹µ: **2-3ì´ˆ**
- âœ… ì‚¬ìš©ìëŠ” ì¦‰ì‹œ ë‹¤ë¥¸ ì‘ì—… ê°€ëŠ¥
- âœ… ìƒíƒœ ì¡°íšŒë¡œ ì§„í–‰ ìƒí™© í™•ì¸
- âœ… ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ì‰¬ì›€

---

## ğŸ”§ ì¶”ê°€ ìµœì í™” (ì„ íƒì‚¬í•­)

### 1. ì„ë² ë”© ë°°ì¹˜ ì²˜ë¦¬

í˜„ì¬ 48ê°œ ì²­í¬ë¥¼ ìˆœì°¨ ì²˜ë¦¬í•˜ëŠ” ëŒ€ì‹  ë°°ì¹˜ë¡œ ì²˜ë¦¬:

```python
# ìˆœì°¨ (í˜„ì¬): 48 * 0.43ì´ˆ = 20.76ì´ˆ
# ë°°ì¹˜ (ê°œì„ ): 3 batch * 2ì´ˆ = 6ì´ˆ

# ë°°ì¹˜ í¬ê¸° 16ê°œë¡œ ì„¤ì •
for i in range(0, len(chunks), 16):
    batch = chunks[i:i+16]
    embeddings = await nlp_service.generate_embeddings_batch(batch)
```

### 2. WebSocket ì‹¤ì‹œê°„ ì§„í–‰ë¥ 

í´ë§ ëŒ€ì‹  WebSocketìœ¼ë¡œ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì „ì†¡:

```python
# backend/app/api/v1/websocket.py
@router.websocket("/ws/document/{document_id}")
async def document_progress_websocket(websocket: WebSocket, document_id: int):
    await websocket.accept()
    
    while True:
        status = await get_document_status(document_id)
        await websocket.send_json(status)
        
        if status['status'] in ('completed', 'failed'):
            break
        
        await asyncio.sleep(2)
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

ë°°í¬ ì „ í™•ì¸ì‚¬í•­:

- [ ] Redis ì„œë²„ ì‹¤í–‰ ì¤‘
- [ ] Celery Worker ì‹¤í–‰ ì¤‘
- [ ] DB ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] í™˜ê²½ë³€ìˆ˜ ì„¤ì • (REDIS_HOST, REDIS_PORT)
- [ ] í”„ë¡ íŠ¸ì—”ë“œ í´ë§ ë¡œì§ êµ¬í˜„
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹… í™•ì¸
- [ ] í…ŒìŠ¤íŠ¸ ì—…ë¡œë“œ ì™„ë£Œ

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

1. **ì¦‰ì‹œ**: ë¹„ë™ê¸° ì²˜ë¦¬ êµ¬í˜„ (ìœ„ ê°€ì´ë“œ ë”°ë¼í•˜ê¸°)
2. **1ì£¼ì¼ í›„**: ì„ë² ë”© ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
3. **2ì£¼ì¼ í›„**: WebSocket ì‹¤ì‹œê°„ ì§„í–‰ë¥  êµ¬í˜„
4. **1ê°œì›” í›„**: Azure DI ëŒ€ì‹  ê²½ëŸ‰ OCR ê³ ë ¤ (Tesseract + PyMuPDF)

---

**ì‘ì„±ì**: AI Assistant  
**ë²„ì „**: 1.0  
**ìµœì¢… ìˆ˜ì •**: 2025-10-14
