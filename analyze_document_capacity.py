#!/usr/bin/env python3
"""
ì¼ë°˜ì ì¸ ì—…ë¬´ìš© ë¬¸ì„œ í¬ê¸° ë¶„ì„ ë° ì‹œìŠ¤í…œ ì í•©ì„± ê²€ì¦
"""

def analyze_typical_business_documents():
    """ì¼ë°˜ì ì¸ ì—…ë¬´ ë¬¸ì„œ í¬ê¸° ë¶„ì„"""
    
    print("=== ì¼ë°˜ì ì¸ ì—…ë¬´ìš© ë¬¸ì„œ í¬ê¸° ë¶„ì„ ===")
    print()
    
    # ì²¨ë¶€ëœ ë¬¸ì„œ ê¸°ì¤€
    user_documents = [
        {"name": "AIê¸°ê¸° ê³¼ì œ ì •ì˜ì„œ(ì ê³ )", "size_mb": 2.9, "type": "PowerPoint", "pages": "ì¶”ì • 15-20í˜ì´ì§€"},
        {"name": "ì„œë²„_ë„¤íŠ¸ì›Œí¬ ì •ì˜_20250327_v1.0", "size_mb": 3.0, "type": "PowerPoint", "pages": "ì¶”ì • 20-25í˜ì´ì§€"},
        {"name": "ì£¼ê°„ ì£¼ê°„ë³´ê³ ì„œ_20240809", "size_mb": 0.003, "type": "í…ìŠ¤íŠ¸", "pages": "1-2í˜ì´ì§€"}
    ]
    
    print("ğŸ“‹ ì‚¬ìš©ì ì œê³µ ë¬¸ì„œ ë¶„ì„:")
    for doc in user_documents:
        print(f"  â€¢ {doc['name']}")
        print(f"    í¬ê¸°: {doc['size_mb']:.1f}MB, í˜•ì‹: {doc['type']}, {doc['pages']}")
    print()
    
    # ì¼ë°˜ì ì¸ ì—…ë¬´ ë¬¸ì„œ í¬ê¸° ë²”ìœ„
    typical_ranges = {
        "í…ìŠ¤íŠ¸/ë©”ëª¨": {"min_mb": 0.001, "max_mb": 0.1, "typical_mb": 0.01},
        "ì£¼ê°„/ì›”ê°„ ë³´ê³ ì„œ": {"min_mb": 0.1, "max_mb": 2, "typical_mb": 0.5},
        "í”„ë ˆì  í…Œì´ì…˜ (ê¸°ë³¸)": {"min_mb": 1, "max_mb": 10, "typical_mb": 3},
        "í”„ë ˆì  í…Œì´ì…˜ (ì´ë¯¸ì§€ ë§ìŒ)": {"min_mb": 5, "max_mb": 30, "typical_mb": 15},
        "ê¸°ìˆ ë¬¸ì„œ/ë§¤ë‰´ì–¼": {"min_mb": 2, "max_mb": 50, "typical_mb": 10},
        "PDF ë³´ê³ ì„œ": {"min_mb": 1, "max_mb": 20, "typical_mb": 5},
        "Excel ë°ì´í„°": {"min_mb": 0.1, "max_mb": 15, "typical_mb": 2},
        "Word ë¬¸ì„œ": {"min_mb": 0.1, "max_mb": 10, "typical_mb": 1},
        "ëŒ€ìš©ëŸ‰ ê¸°ìˆ ë¬¸ì„œ": {"min_mb": 20, "max_mb": 100, "typical_mb": 40}
    }
    
    print("ğŸ“Š ì¼ë°˜ì ì¸ ì—…ë¬´ ë¬¸ì„œ í¬ê¸° ë²”ìœ„:")
    for doc_type, sizes in typical_ranges.items():
        print(f"  â€¢ {doc_type}:")
        print(f"    ë²”ìœ„: {sizes['min_mb']:.1f}MB - {sizes['max_mb']:.1f}MB")
        print(f"    ì¼ë°˜ì : {sizes['typical_mb']:.1f}MB")
    print()
    
    return user_documents, typical_ranges

def check_system_capacity(user_docs, typical_ranges):
    """í˜„ì¬ ì‹œìŠ¤í…œì˜ ì²˜ë¦¬ ëŠ¥ë ¥ í™•ì¸"""
    
    print("ğŸ” í˜„ì¬ ì‹œìŠ¤í…œ ì²˜ë¦¬ ëŠ¥ë ¥ ë¶„ì„:")
    
    current_limits = {
        "max_file_size_mb": 100,
        "large_file_threshold_mb": 20,
        "concurrent_processing": 8,
        "chunk_strategies": {
            "small": {"size": 1000, "max_file_mb": 20},
            "medium": {"size": 2000, "max_file_mb": 50},
            "large": {"size": 3000, "max_file_mb": 100}
        }
    }
    
    print(f"  ìµœëŒ€ íŒŒì¼ í¬ê¸°: {current_limits['max_file_size_mb']}MB")
    print(f"  ëŒ€ìš©ëŸ‰ ì„ê³„ê°’: {current_limits['large_file_threshold_mb']}MB")
    print(f"  ë™ì‹œ ì²˜ë¦¬ ìˆ˜: {current_limits['concurrent_processing']}ê°œ")
    print()
    
    # ì‚¬ìš©ì ë¬¸ì„œ ì í•©ì„± ê²€ì¦
    print("âœ… ì‚¬ìš©ì ë¬¸ì„œ ì í•©ì„± ê²€ì¦:")
    for doc in user_docs:
        if doc["size_mb"] <= current_limits["max_file_size_mb"]:
            processing_type = "ì¦‰ì‹œ ì²˜ë¦¬" if doc["size_mb"] < 20 else "ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬"
            print(f"  âœ… {doc['name']}: {doc['size_mb']:.1f}MB - {processing_type}")
        else:
            print(f"  âŒ {doc['name']}: {doc['size_mb']:.1f}MB - í¬ê¸° ì´ˆê³¼")
    print()
    
    # ì¼ë°˜ì  ë¬¸ì„œ ìœ í˜•ë³„ ì í•©ì„±
    print("ğŸ“ˆ ì¼ë°˜ì  ë¬¸ì„œ ìœ í˜•ë³„ ì í•©ì„±:")
    for doc_type, sizes in typical_ranges.items():
        max_size = sizes["max_mb"]
        typical_size = sizes["typical_mb"]
        
        if max_size <= current_limits["max_file_size_mb"]:
            if typical_size < 20:
                status = "âœ… ì™„ì „ ì§€ì› (ì¦‰ì‹œ ì²˜ë¦¬)"
            else:
                status = "âœ… ì™„ì „ ì§€ì› (ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬)"
        else:
            status = f"âš ï¸ ë¶€ë¶„ ì§€ì› (ìµœëŒ€ {max_size}MB ì¤‘ {current_limits['max_file_size_mb']}MBê¹Œì§€)"
        
        print(f"  {doc_type}: {status}")
        print(f"    ì¼ë°˜ì  í¬ê¸°: {typical_size}MB, ìµœëŒ€: {max_size}MB")
    print()

def estimate_processing_performance(user_docs):
    """ì²˜ë¦¬ ì„±ëŠ¥ ì˜ˆìƒ"""
    
    print("âš¡ ì²˜ë¦¬ ì„±ëŠ¥ ì˜ˆìƒ:")
    
    # ê°„ë‹¨í•œ ì„±ëŠ¥ ëª¨ë¸ (ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì •)
    def estimate_time(size_mb, doc_type):
        base_time = 2  # ê¸°ë³¸ 2ì´ˆ
        
        if "PowerPoint" in doc_type or "í”„ë ˆì  í…Œì´ì…˜" in doc_type:
            size_factor = size_mb * 0.8  # PPTëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë¹ ë¦„
        elif "PDF" in doc_type:
            size_factor = size_mb * 1.2  # PDFëŠ” ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦¼
        else:
            size_factor = size_mb * 1.0
        
        nlp_factor = min(size_mb * 0.5, 10)  # NLP ì²˜ë¦¬ ì‹œê°„ (ìµœëŒ€ 10ì´ˆ)
        
        return base_time + size_factor + nlp_factor
    
    for doc in user_docs:
        estimated_time = estimate_time(doc["size_mb"], doc["type"])
        memory_usage = doc["size_mb"] * 3  # ëŒ€ëµì ì¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        
        print(f"  â€¢ {doc['name']}:")
        print(f"    ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_time:.1f}ì´ˆ")
        print(f"    ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©: {memory_usage:.1f}MB")
        print(f"    ì²˜ë¦¬ ë°©ì‹: {'ì¦‰ì‹œ ì²˜ë¦¬' if doc['size_mb'] < 20 else 'ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬'}")
    print()

def provide_recommendations():
    """ê°œì„  ê¶Œì¥ì‚¬í•­"""
    
    print("ğŸš€ ê¶Œì¥ì‚¬í•­:")
    print()
    
    print("í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ:")
    print("  âœ… ì¼ë°˜ì ì¸ ì—…ë¬´ ë¬¸ì„œ (< 20MB) ì™„ì „ ì§€ì›")
    print("  âœ… ëŒ€ìš©ëŸ‰ ë¬¸ì„œ (20-100MB) ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì§€ì›")
    print("  âœ… ë™ì‹œ ì²˜ë¦¬ (ìµœëŒ€ 8ê°œ íŒŒì¼)")
    print("  âœ… í•œêµ­ì–´ NLP ìµœì í™”")
    print()
    
    print("ì¦‰ì‹œ ì ìš© ê¶Œì¥ì‚¬í•­:")
    print("  1. í˜„ì¬ ì„¤ì • ìœ ì§€ (100MB ì œí•œ ì ì ˆ)")
    print("  2. 20MB ì´ìƒ íŒŒì¼ì€ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ í™œìš©")
    print("  3. ë°°ì¹˜ ì—…ë¡œë“œë¡œ ì—¬ëŸ¬ íŒŒì¼ ë™ì‹œ ì²˜ë¦¬")
    print()
    
    print("í–¥í›„ ê³ ë ¤ì‚¬í•­:")
    print("  â€¢ 100MB ì´ìƒ íŠ¹ìˆ˜ ë¬¸ì„œ ì²˜ë¦¬ ì‹œ Celery ë„ì…")
    print("  â€¢ ë™ì‹œ ì‚¬ìš©ì ì¦ê°€ ì‹œ ì²˜ë¦¬ ìš©ëŸ‰ í™•ì¥")
    print("  â€¢ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•")

def test_actual_processing():
    """ì‹¤ì œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    
    print("\nğŸ§ª ì‹¤ì œ ì²˜ë¦¬ ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸:")
    
    # ìœ ì‚¬í•œ í¬ê¸°ì˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ë¡œ ì‹¤ì œ ì„±ëŠ¥ í™•ì¸
    test_scenarios = [
        {"name": "ì†Œê·œëª¨_í”„ë ˆì  í…Œì´ì…˜.txt", "size_mb": 3, "content_type": "presentation"},
        {"name": "ì¤‘ê°„_ë³´ê³ ì„œ.txt", "size_mb": 8, "content_type": "report"},
        {"name": "ëŒ€ìš©ëŸ‰_ë§¤ë‰´ì–¼.txt", "size_mb": 25, "content_type": "manual"}
    ]
    
    for scenario in test_scenarios:
        print(f"\ní…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤: {scenario['name']} ({scenario['size_mb']}MB)")
        
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
        content = f"""
ì›…ì§„ WKMS í…ŒìŠ¤íŠ¸ ë¬¸ì„œ - {scenario['content_type']}

ì´ ë¬¸ì„œëŠ” {scenario['size_mb']}MB í¬ê¸°ì˜ {scenario['content_type']} ë¬¸ì„œë¥¼ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.

ì£¼ìš” ë‚´ìš©:
- ì›…ì§„ê·¸ë£¹ ì§€ì‹ê´€ë¦¬ì‹œìŠ¤í…œ ê°œìš”
- AWS ê¸°ë°˜ í´ë¼ìš°ë“œ ì•„í‚¤í…ì²˜
- í•œêµ­ì–´ NLP ì²˜ë¦¬ ì„±ëŠ¥
- ë¬¸ì„œ ë²¡í„°í™” ë° ê²€ìƒ‰ ê¸°ëŠ¥
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ìµœì í™”

ê¸°ìˆ ì  íŠ¹ì§•:
- FastAPI ê¸°ë°˜ ê³ ì„±ëŠ¥ API
- PostgreSQL + pgvector ë²¡í„° DB
- AWS Bedrock AI ì„œë¹„ìŠ¤ ì—°ë™
- ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ í†µí•œ ì„±ëŠ¥ ìµœì í™”

ì„±ëŠ¥ ë©”íŠ¸ë¦­:
- ì²˜ë¦¬ ì†ë„: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ìµœì í™”ëœ ì²­í‚¹
- ë™ì‹œ ì²˜ë¦¬: ë‹¤ì¤‘ íŒŒì¼ ë°°ì¹˜ ì—…ë¡œë“œ
- í•œêµ­ì–´ ë¶„ì„: í‚¤ì›Œë“œ ì¶”ì¶œ ë° ê°ì • ë¶„ì„

ì›…ì§„ê·¸ë£¹ì˜ ë””ì§€í„¸ í˜ì‹ ì„ ìœ„í•œ í•µì‹¬ ì¸í”„ë¼ë¡œì„œ
ì§€ì‹ê´€ë¦¬ì‹œìŠ¤í…œì´ ì¡°ì§ì˜ ê²½ìŸë ¥ í–¥ìƒì— ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.
""" * int(scenario['size_mb'] * 100)  # ëŒ€ëµì ì¸ í¬ê¸° ì¡°ì ˆ
        
        filename = f"test_{scenario['name']}"
        
        try:
            # íŒŒì¼ ìƒì„±
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(content)
            
            # ì‹¤ì œ íŒŒì¼ í¬ê¸° í™•ì¸
            import os
            actual_size = os.path.getsize(filename) / (1024 * 1024)
            
            print(f"  ìƒì„±ëœ íŒŒì¼ í¬ê¸°: {actual_size:.1f}MB")
            
            # API í…ŒìŠ¤íŠ¸ (íŒŒì¼ í¬ê¸° ì˜ˆìƒ)
            import requests
            
            try:
                with open(filename, 'rb') as f:
                    files = {'file': (filename, f, 'text/plain')}
                    response = requests.post(
                        "http://localhost:8000/api/documents/estimate-processing-time",
                        files=files,
                        timeout=30
                    )
                
                if response.status_code == 200:
                    result = response.json()
                    print(f"  âœ… API í…ŒìŠ¤íŠ¸ ì„±ê³µ:")
                    print(f"    ì²˜ë¦¬ ì „ëµ: {result['strategy']}")
                    print(f"    ì˜ˆìƒ ì‹œê°„: {result['estimated_time_seconds']:.1f}ì´ˆ")
                    print(f"    ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬: {'ì˜ˆ' if result['requires_background'] else 'ì•„ë‹ˆì˜¤'}")
                else:
                    print(f"  âŒ API í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {response.status_code}")
                    
            except Exception as e:
                print(f"  âš ï¸ API í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€: {e}")
            
        except Exception as e:
            print(f"  âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            
        finally:
            # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬
            try:
                os.remove(filename)
            except:
                pass

if __name__ == "__main__":
    print("ğŸ“Š ì—…ë¬´ìš© ë¬¸ì„œ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì í•©ì„± ë¶„ì„")
    print("=" * 60)
    
    user_docs, typical_ranges = analyze_typical_business_documents()
    check_system_capacity(user_docs, typical_ranges)
    estimate_processing_performance(user_docs)
    provide_recommendations()
    test_actual_processing()
    
    print("\n" + "=" * 60)
    print("âœ… ê²°ë¡ : í˜„ì¬ ì‹œìŠ¤í…œì€ ì¼ë°˜ì ì¸ ì—…ë¬´ìš© ë¬¸ì„œë¥¼ ì¶©ë¶„íˆ ìˆ˜ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    print("ğŸ“ ì²¨ë¶€í•´ì£¼ì‹  ë¬¸ì„œë“¤(2-3MB)ì€ ëª¨ë‘ ì¦‰ì‹œ ì²˜ë¦¬ ê°€ëŠ¥í•œ ë²”ìœ„ì…ë‹ˆë‹¤.")
